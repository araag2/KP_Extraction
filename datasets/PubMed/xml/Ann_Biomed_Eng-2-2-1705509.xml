<?xml version="1.0" ?>
<!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd">
<pmc-articleset><article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
  <?properties open_access?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Ann Biomed Eng</journal-id>
      <journal-title>Annals of Biomedical Engineering</journal-title>
      <issn pub-type="ppub">0090-6964</issn>
      <issn pub-type="epub">1521-6047</issn>
      <publisher>
        <publisher-name>Kluwer Academic Publishers-Plenum Publishers</publisher-name>
        <publisher-loc>New York</publisher-loc>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">17048103</article-id>
      <article-id pub-id-type="pmc">1705509</article-id>
      <article-id pub-id-type="publisher-id">9198</article-id>
      <article-id pub-id-type="doi">10.1007/s10439-006-9198-1</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Remote Non-invasive Stereoscopic Imaging of Blood Vessels: First In-vivo Results of a New Multispectral Contrast Enhancement Technology</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" corresp="yes">
          <name name-style="western">
            <surname>Wieringa</surname>
            <given-names>F. P.</given-names>
          </name>
          <address>
            <phone>+31-10-408-8031</phone>
            <fax>+31-10-408-9445</fax>
            <email>F.Wieringa@erasmusmc.nl</email>
          </address>
          <xref ref-type="aff" rid="Aff1">1</xref>
          <xref ref-type="aff" rid="Aff2">2</xref>
          <xref ref-type="aff" rid="Aff3">3</xref>
        </contrib>
        <contrib contrib-type="author">
          <name name-style="western">
            <surname>Mastik</surname>
            <given-names>F.</given-names>
          </name>
          <xref ref-type="aff" rid="Aff1">1</xref>
        </contrib>
        <contrib contrib-type="author">
          <name name-style="western">
            <surname>Cate</surname>
            <given-names>F. J. ten</given-names>
          </name>
          <xref ref-type="aff" rid="Aff4">4</xref>
        </contrib>
        <contrib contrib-type="author">
          <name name-style="western">
            <surname>Neumann</surname>
            <given-names>H. A. M.</given-names>
          </name>
          <xref ref-type="aff" rid="Aff5">5</xref>
        </contrib>
        <contrib contrib-type="author">
          <name name-style="western">
            <surname>van der  Steen</surname>
            <given-names>A. F. W.</given-names>
          </name>
          <xref ref-type="aff" rid="Aff1">1</xref>
          <xref ref-type="aff" rid="Aff6">6</xref>
        </contrib>
        <aff id="Aff1"><label>1</label>Erasmus MC, Department of Biomedical Engineering, Thorax Centre Rotterdam, Office Ee 2302, P.O. Box 1738, 3000 DR Rotterdam, The Netherlands </aff>
        <aff id="Aff2"><label>2</label>TNO Quality of Life, Leiden, The Netherlands </aff>
        <aff id="Aff3"><label>3</label>TNO O2 View BV, Leiden, The Netherlands </aff>
        <aff id="Aff4"><label>4</label>Erasmus MC, Department of Cardiology, Thorax Centre, Rotterdam, The Netherlands </aff>
        <aff id="Aff5"><label>5</label>Erasmus MC, Department of Dermatology and Venereology, Thorax Centre, Rotterdam, The Netherlands </aff>
        <aff id="Aff6"><label>6</label>Interuniversity Cardiology Institute of the Netherlands (ICIN), Utrecht, The Netherlands </aff>
      </contrib-group>
      <pub-date pub-type="epub">
        <day>12</day>
        <month>10</month>
        <year>2006</year>
      </pub-date>
      <pub-date pub-type="ppub">
        <month>12</month>
        <year>2006</year>
      </pub-date>
      <volume>34</volume>
      <issue>12</issue>
      <fpage>1870</fpage>
      <lpage>1878</lpage>
      <history>
        <date date-type="received">
          <day>15</day>
          <month>12</month>
          <year>2005</year>
        </date>
        <date date-type="accepted">
          <day>1</day>
          <month>9</month>
          <year>2006</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>&#xA9; Biomedical Engineering Society 2006</copyright-statement>
      </permissions>
      <abstract>
        <p>We describe a contactless optical technique selectively enhancing superficial blood vessels below variously pigmented intact human skin by combining images in different spectral bands. Two CMOS-cameras, with apochromatic lenses and dual-band LED-arrays, simultaneously streamed Left (L) and Right (R) image data to a dual-processor PC. Both cameras captured color images within the visible range (VIS, 400&#x2013;780&#xA0;nm) and grey-scale images within the near infrared range (NIR, 910&#x2013;920&#xA0;nm) by sequentially switching between LED-array emission bands. Image-size-settings of 1280&#xA0;&#xD7;&#xA0;1024 for VIS &amp; 640&#xA0;&#xD7;&#xA0;512 for NIR produced 12 cycles/s (1 cycle&#xA0;=&#xA0;1 VIS L&amp;R-pair&#xA0;+&#xA0;1 NIR L&amp;R-pair). Decreasing image-size-settings (640&#xA0;&#xD7;&#xA0;512 for VIS and 320&#xA0;&#xD7;&#xA0;256 for NIR) increased camera-speed to 25 cycles/s. Contrasts from below the tissue surface were algorithmically distinguished from surface shadows, reflections, etc. Thus blood vessels were selectively enhanced and back-projected into the stereoscopic VIS-color-image using either a 3D-display or conventional shutter glasses.</p>
        <p>As a first usability reconnaissance we applied this custom-built mobile stereoscopic camera for several clinical settings:</p>
        <p>&#x2022; blood withdrawal;</p>
        <p>&#x2022; vein inspection in dark skin;</p>
        <p>&#x2022; vein detection through iodide;</p>
        <p>&#x2022; varicose vein and nevi pigmentosum inspection.</p>
        <p>Our technique improves blood vessel visualization compared to the naked eye, and supports depth perception.</p>
      </abstract>
      <kwd-group>
        <title>Keywords</title>
        <kwd>Multispectral stereoscopy</kwd>
        <kwd>Contactless enhanced viewing of superficial vasculature</kwd>
        <kwd>Intuitive technology</kwd>
        <kwd>Reconnaissance of feasibility for various clinical applications</kwd>
        <kwd>3D-display</kwd>
      </kwd-group>
      <custom-meta-wrap>
        <custom-meta>
          <meta-name>issue-copyright-statement</meta-name>
          <meta-value>&#xA9; Biomedical Engineering Society 2006</meta-value>
        </custom-meta>
      </custom-meta-wrap>
    </article-meta>
  </front>
  <body>
    <sec id="Sec1" sec-type="introduction">
      <title>Introduction</title>
      <p>Visually guided procedures provide instant feedback and meantime afford insights that would otherwise be difficult or even impossible to obtain.<xref ref-type="bibr" rid="CR26">26</xref> This is a primary reason for mankind&#x2019;s continuous desire to extend vision beyond the boundaries of the human eye, which has resulted in many successful diagnostic imaging modalities like X-ray imaging, endoscopy, thermography, ultrasound scans and MRI that all found their way into the clinic.</p>
      <p>While investigating the principal feasability of a camera for imaging blood oxygenation levels, we noticed that our multispectral images also contained information about subcutaneous vasculature, with improved contrast in the near infrared.<xref ref-type="bibr" rid="CR24">24</xref> Near infrared imaging of superficial blood vessels in itself is not new; soon after infrared photography<xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR9">9</xref>,<xref ref-type="bibr" rid="CR25">25</xref> early electronic cameras were used for experiments.<xref ref-type="bibr" rid="CR13">13</xref>,<xref ref-type="bibr" rid="CR15">15</xref> Since then, numerous near infrared imaging methods have been developed using transillumination mode and/or reflection mode.<xref ref-type="bibr" rid="CR5">5</xref>,<xref ref-type="bibr" rid="CR6">6</xref>,<xref ref-type="bibr" rid="CR10">10</xref>,<xref ref-type="bibr" rid="CR14">14</xref>, <xref ref-type="bibr" rid="CR22">22</xref> Our multispectral camera, however, provides the opportunity to obtain normal color images within the visible range (VIS) which are pixel-to-pixel matched with images obtained in the invisible near infrared range (NIR). By combining the image information content of both spectral bands with a processing algorithm, we developed a new technique that allows selective enhancement of superficial blood vessels with selectable pigment suppression within a normal color image.<xref ref-type="bibr" rid="CR23">23</xref></p>
      <p>The underlying principle does not necessarily require stereoscopic image acquisition to derive increased vessel contrasts from the tissue. When, however, developing a new medical imaging technique, deriving image information from patient tissue is not the only issue. Especially for visually guided procedures it is also crucial to put effort in an ergonomic human interface and avoid conflicts between the proprioceptional and visual perceptions of the user. The added value of stereoscopic image recordings already was recognized and successfully used to document medical cases more than a century ago.<xref ref-type="bibr" rid="CR4">4</xref> We likewise reasoned that offering enhanced blood vessel contrast at the cost of depth perception would restrict the usefulness of our technique and therefore decided to realize a stereoscopic version of our vessel contrast enhancement device.</p>
      <p>Visually guided procedures typically require a combination of well trained eyes and specific fine-motoric skills, since the coordination between eyes and hands is task dependent.<xref ref-type="bibr" rid="CR16">16</xref> For eye-hand coordination, brain processes for perception and action interact so closely that they cannot be separated and the influence of visual illusions (like human depth perception) to motoric tasks becomes stronger when input takes place via lower levels in the brain.<xref ref-type="bibr" rid="CR3">3</xref> The match between a human interface device and the visual and motoric brain processes strongly defines whether a technology can be applied intuitively or not. A new technology can be classified as intuitive if it speeds up the learning process for novices in a certain skill, without impairing the performance of persons already skilled in the existing art.<xref ref-type="bibr" rid="CR20">20</xref> Thus a useful increase in vascular contrast should neither imply a task-impairing decrease in depth perception (like in monoscopic techniques) nor distort spatial clues for human vision (like shadows) nor introduce false depth information (like projection parallax).</p>
      <p>As a first reconnaissance of practical feasibility, we applied our new technique to several visual clinical procedures for which we expected that improved visualization of blood vessels would be of interest, being:<list list-type="bullet"><list-item><p>blood withdrawal;</p></list-item><list-item><p>vein inspection in dark skin;</p></list-item><list-item><p>detection of veins through iodide;</p></list-item><list-item><p>inspection of varicose veins and nevi pigmentosum.</p></list-item></list></p>
    </sec>
    <sec id="Sec2" sec-type="methods">
      <title>Methods</title>
      <sec id="Sec3">
        <title>Instrumental Setup</title>
        <p>The instrumental hardware setup is schematically drawn in Fig.&#xA0;<xref rid="Fig1" ref-type="fig">1</xref>. Two synchronized identical single-chip CMOS-cameras (Vector Technologies Belgium, custom built) were equipped with apochromatic lenses and two identical custom-built dual-band LED-arrays (O<sub>2</sub>-View, the Netherlands). These LED-arrays were current controlled and each had two individually programmable channels for the emission of in total &#xB1;1.2 Cd visible white light with adjustable color temperature (consisting of 40 broadband white LEDs with a yellow accent and 20 broadband white LEDs with a blue accent) as well as one programmable channel for the emission of near infrared radiation (20 LEDs, 920&#xA0;nm, max. 32&#xA0;mW per LED). The light sources were constructed so that the geometrical beam profiles of VIS and NIR matched very closely (and thus also any resulting shadows and/or reflections). Left (L) and Right (R) image data was simultaneously acquired and streamed to a dual processor PC equipped with a stereoscopic monitor (Sharp LL-151&#x2013;3D). It was also possible to connect a conventional cathode ray tube (CRT) monitor equipped with shutter glasses, for comparison of stereoscopic representation.
<fig id="Fig1"><label>Figure&#xA0;1.</label><caption><p>Experimental setup. Two CMOS-cameras, with apochromatic lenses and dual-band LED-arrays, simultaneously stream Left (L) and Right (R) image data to a dual processor PC. Both cameras captured color images within the visible range (VIS, 400&#x2013;780&#xA0;nm) and grey-scale images within the near infrared range (NIR, 910&#x2013;920&#xA0;nm) by sequentially switching between LED-array emission bands.</p></caption><graphic position="anchor" xlink:href="10439_2006_9198_Fig1_HTML" id="MO1"/></fig></p>
        <p>A schematical representation of image aquisition and data structure is drawn in Fig.&#xA0;<xref rid="Fig2" ref-type="fig">2</xref>. The CMOS-camera detector chips were equipped with a Bayer filter mosaic to obtain an RGB color image within the VIS. The camera pixels, however, were also sensitive to near infrared radiation because all three filter channels of the Bayer mosaic (red, green and blue) were designed as highly transparant within the NIR. Thus four NIR-pixels were acquired for each VIS RGB color pixel group. By sequentially switching between emission bands of the LED-arrays, images within the Visual range (VIS, 400&#x2013;780&#xA0;nm) and Near Infrared range (NIR, 910&#x2013;920&#xA0;nm) were acquired in an alternating fashion. VIS and NIR image-size-settings could be varied independantly. For 8-bit encoding depth, at image-size-settings of 1280&#xA0;&#xD7;&#xA0;1024 for VIS and 640&#xA0;&#xD7;&#xA0;512 for NIR, 12&#xA0;cycles/s were obtained (1&#xA0;cycle&#xA0;=&#xA0;1 VIS L&amp;R-pair&#xA0;+&#xA0;1 NIR L&amp;R-pair). At the cost of decreasing image-size-settings downto 640&#xA0;&#xD7;&#xA0;512 for VIS and 320&#xA0;&#xD7;&#xA0;256 for NIR, camera speed could be increased up to 25&#xA0;cycles/s. Encoding depths of 10-bit and 12-bit were also available, but only used for stills (due to the lower obtainable framerate).
<fig id="Fig2"><label>Figure&#xA0;2.</label><caption><p>Schematic diagram of image aquisition. The sequentially acquired alternating VIS and NIR raw image frames form 3D-matrices for the Left and Right channel. The NIR image size is smaller than the VIS image size to increase framerate while maintaining an overview of the imaged area. Enlarged details illustrate the NIR transparency of the Bayer pattern RGB-filters which are applied to obtain a VIS color image. The time domain axis is expressed in image cycles. Along this image cycle axis, the control signals for NIR and VIS LEDs (synchronized with respectively NIR and VIS camera exposures) are visualized.</p></caption><graphic position="anchor" xlink:href="10439_2006_9198_Fig2_HTML" id="MO2"/></fig></p>
      </sec>
      <sec id="Sec4">
        <title>Data Aquisition</title>
        <p>Multispectral stereoscopic movies were recorded in several typical clinical settings for which the technique was considered as possibly useful. LED currents and diaphragm settings were chosen so that for each movie saturated pixels were avoided. A preview mode allowed aiming, adjustment of converging angle &#x3B1; and focusing of the cameras. After software triggering the stereo-camera streamed a sequence of 8-bit digitally encoded image cycles to PC-memory (using auto-incremental numbering). All images were automatically saved on a fast SATA harddisk-array. Camera and light source settings were automatically stored in a text file and located in the same directory.</p>
        <p>All patients and volunteers gave their informed consent for filming as well as for publishing the resulting image material. No diagnosis or therapy was based upon any of our results.</p>
      </sec>
      <sec id="Sec5">
        <title>Data Processing</title>
        <sec id="Sec6">
          <title>General Aspects</title>
          <p>Processing was performed with custom developed software (programming language C<sup>++</sup>) using the stored text file with camera and light source settings as additional input values. Figure&#xA0;<xref rid="Fig3" ref-type="fig">3</xref> schematically represents this process.
<fig id="Fig3"><label>Figure&#xA0;3.</label><caption><p>Schematic diagram of image processing. The images captured within the visible range (VIS) and the images captured within the near infrared range (NIR) are combined, which reveals blood vessel patterns below the skin. The left and middle column focus on edge-enhancement and suppression of superficial artifacts, the right column serves to fill-in the blood vessel lumen. For raw VIS &amp; NIR images as well as processed results see figures 6, 7, 8 and 9.</p></caption><graphic position="anchor" xlink:href="10439_2006_9198_Fig3_HTML" id="MO3"/></fig></p>
          <p>The processing method allowed discrimination between image information obtained from the tissue surface versus image information obtained from within the tissue. In order to achieve this, a distinction was made between shadows, reflections and absorption contrasts for both VIS and NIR.</p>
        </sec>
        <sec id="Sec7">
          <title>Suppressing Shadows on the Surface</title>
          <p>Since NIR and VIS beams were matched closely, shadows produced by irregular shapes at the tissue surface (e.g. skin structure, skin folds, nevi, hair, etc.) or by objects between the light sources and the tissue (fingers, needles, surgical tools, etc.) also matched well in both wavelength ranges. Our algorithm excluded such matching shadows from enhancement and left all useful aspects of shadows unaffected (e.g. depth clues).</p>
        </sec>
        <sec id="Sec8">
          <title>Useful Effects of Shadows and Lighting Geometry</title>
          <p>Due to the fact that the VIS and IR shadows matched very closely, the algorithm was able to selectively enhance contrast from below the surface while leaving shadows on the surface unaffected (thus not distorting these important depth clues).</p>
          <p>Due to the shallow angle of the lightbeams, the skin texture was pronounced. Due to the lighting from two sides, objects that were brought towards the tissue surface (e.g. needles, scalpels, probes, etc.) when lighted from both sides, could produce two separate (not too heavy) shadows. These shadows met and typically formed a &#x201C;V&#x201D; pattern when an object touched the surface in the middle of the field of view, thus providing extra information for depth perception.</p>
        </sec>
        <sec id="Sec9">
          <title>Enhancing Absorption Contrast of Blood Vessel Walls</title>
          <p>Edge detection by a Prewitt image filter was performed on each VIS and NIR image. Pixel positions containing edge information above a certain adjustable threshold in both spectral regions were classified as surface artefacts and excluded from enhancement. The boundary regions of absorption contrasts caused by structures below the tissue surface, produced edges that were mainly present in the NIR image. Enhancement was selectively performed only for pixel positions where the NIR image contained more edge information than the corresponding VIS image. These &#x201C;valid&#x201D; pixels identified the vessel boundaries. The positions of these valid pixels were stored in a 1st NIR mask.</p>
        </sec>
        <sec id="Sec10">
          <title>Discarding Reflections on the Surface</title>
          <p>Shiny areas that produced reflections and/or saturated pixels also matched in both wavelength ranges. This characteristic allowed to calculate a 2<sup>nd</sup> NIR mask in which superficial reflections were also excluded from enhancement. Neighboring pixels of identified saturated pixels were excluded from enhancement. The radius of this exclusion region was programmable, but due to the favorable anti-blooming behavior of the CMOS-camera chips, suppressing direct neighbor pixels appeared sufficient.</p>
        </sec>
        <sec id="Sec11">
          <title>Enhancing Absorption Contrast of Blood Vessel Lumen</title>
          <p>The &#x201C;content&#x201D; of blood vessels was separately enhanced by raising pixel values of the normalized NIR image to the power of N (with N user adjustable between 0.5 and 2.5) while discriminating NIR pixels below a freely adjustable noise threshold and excluding information from identified shadows. Multiplication with the 2nd NIR mask then produced a final enhancement mask for subsequential backprojection into the VIS image by pixel-to-pixel multiplication.</p>
        </sec>
        <sec id="Sec12">
          <title>Suppressing Contrasts Originating from Melanin Pigment</title>
          <p>Superficial contrasts within the VIS, originating from melanin pigment concentrations, could either be filtered out or left unchanged. Figure&#xA0;<xref rid="Fig4" ref-type="fig">4</xref> illustrates the normalized distribution of the intensities for the aquired <italic>separate</italic> spectral bands (R, G, B and NIR) in relation to the intensity (I<sub>VIS</sub>) of the <italic>composed</italic> visible RGB-image. Intensities were calculated using the Intel ippiRGBtoGray function.<xref ref-type="bibr" rid="CR11">11</xref> Four clouds of data points can be discerned, being I<sub>R</sub>/I<sub>VIS </sub>(red channel), I<sub>G</sub>/I<sub>VIS </sub>(green channel), I<sub>B</sub>/I<sub>VIS </sub>(blue channel) and I<sub>NIR</sub>/I<sub>VIS </sub>(NIR channel). By calculating the ratio of (I<sub>R</sub>/I<sub>VIS </sub>)/(I<sub>NIR</sub>/I<sub>VIS </sub>) and comparing the result for each pixel with an adjustable threshold, it can be decided whether or not to apply backprojection to a pixel. This concerns the pixels located within the overlapping region of I<sub>R</sub>/I<sub>VIS </sub>and I<sub>NIR</sub>/I<sub>VIS </sub>within Fig.&#xA0;<xref rid="Fig4" ref-type="fig">4</xref>. The resulting difference is clear when comparing between Fig.&#xA0;<xref rid="Fig9" ref-type="fig">9</xref>c and d with regard to the visualization of nevi pigmentosum and hair.
<fig id="Fig4"><label>Figure&#xA0;4.</label><caption><p>Relative intensity distribution of the different spectral bands. Dimensionless normalized distribution of the intensities for the 4 aquired red (<italic>I</italic><sub>R</sub>), Green (<italic>I</italic><sub>G</sub>), Blue (<italic>I</italic><sub>B</sub>) and near infrared (<italic>I</italic><sub>NIR</sub>) individual spectral bands expressed in ratio to the normalized intensity (<italic>I</italic><sub>VIS</sub>) of the composed RGB-image. The four data clouds (R, G and B labeled by their natural colors and NIR labeled as pink) show a generally marked separation, but especially for a number of pixels within the red and infrared the data clouds partly overlap. This indicates regions where the VIS contrast potentially is superior to the NIR contrast. By comparing an adjustable threshold with the calculated ratio of (<italic>I</italic><sub>R</sub>/<italic>I</italic><sub>VIS</sub>)/(<italic>I</italic><sub>NIR</sub>/<italic>I</italic><sub>VIS</sub>) it can be decided which spectral band provides superior contrast for the pertaining pixel and thus whether or not it is used for enhanced backprojection.</p></caption><graphic position="anchor" xlink:href="10439_2006_9198_Fig4_HTML" id="MO4"/></fig></p>
        </sec>
      </sec>
      <sec id="Sec13">
        <title>Data Presentation</title>
        <p>The images could either be displayed on an auto-stereoscopic liquid crystal display (LCD) monitor or on a conventional CRT monitor equipped with shutter glasses.</p>
        <p>The auto-stereoscopic LCD-monitor (Sharp LL-151&#x2013;3D) was equipped with software controllable switching between stereoscopic (or 3D) and normal (monoscopic or 2D) mode. Monitor resolution was 1280&#xA0;&#xD7;&#xA0;768 in monoscopic mode (XGA). In stereoscopic mode the available pixels were split-up in two separate images (L&amp;R) by activation of a vertical LCD parallax barrier. The principle behind this technology is illustrated in Fig.&#xA0;<xref rid="Fig5" ref-type="fig">5</xref>.
<fig id="Fig5"><label>Figure&#xA0;5.</label><caption><p>Principle of applied autostereoscopic LCD-monitor (reprinted with permission from Sharp). In 2D mode, only one camera-channel is displayed (either from the L or R camera) and the parallax barrier is not actuated. Both eyes of an observer therefore receive the same image and a conventional flat image with full resolution is seen. In 3D mode, both camera channels are displayed (L&amp;R) and the parallax barrier is actuated. The left eye and right eye of an observer now receive different images, and a stereoscopic (in-depth image) with halve resolution is seen.</p></caption><graphic position="anchor" xlink:href="10439_2006_9198_Fig5_HTML" id="MO5"/></fig></p>
        <p>The CRT-monitor (iiyama vision master 21) was used at a resolution setting of 1280&#xA0;&#xD7;&#xA0;1024 in combination with wireless shutter glasses (e-Dimensional) and thus provided stereoscopic information without sacrificing resolution.</p>
        <p>The enhancement algorithm occurs on a pixel-to-pixel basis and does not affect resolution.</p>
        <p>Our device offered several imaging modes for data presentation:<list list-type="bullet"><list-item><p>Monocopic raw VIS preview (normal full color vision)</p></list-item><list-item><p>Monoscopic raw NIR preview (greyscale)</p></list-item><list-item><p>Off-line stereoscopic looped VIS view with and without enhanced blood vessel back-projection (with freely adjustable enhancement settings).</p></list-item><list-item><p>Off-line stereoscopic looped raw NIR view or enhanced NIR view (with freely adjustable enhancement settings)</p></list-item><list-item><p>Stereoscopic stills in all modes</p></list-item><list-item><p>Monoscopic stills in all modes (freely switchable between Left and Right)</p></list-item></list></p>
        <p>All modes offered the possibility for pause and scrolling forward or reverse frame-by-frame. By means of virtual slider controls and virtual pushbuttons the user interface allowed freely adjustable settings for shadow suppression, pigment suppression, noise threshold and vessel lumen fill-in contrast.</p>
      </sec>
    </sec>
    <sec id="Sec14" sec-type="results">
      <title>Results</title>
      <sec id="Sec15">
        <title>Results for Blood Withdrawal</title>
        <p>During routine blood withdrawal the inserted needle tip remained only slightly visible on the VIS image due to skin surface deformation (see Fig.&#xA0;<xref rid="Fig6" ref-type="fig">6</xref>a). On the raw NIR image, however, the inserted needle remained visible within the tissue for a few mm with some metallic reflection. Subcutaneous bleeding during needle removal could be detected in the raw NIR image while the needle tip was still in the tissue (see Fig.&#xA0;<xref rid="Fig6" ref-type="fig">6</xref>b). This was clearly highlighted by backprojection in the VIS image (see Fig.&#xA0;<xref rid="Fig6" ref-type="fig">6</xref>c). The processing settings used to obtain this backprojection mainly laid the accent upon enhancing the absorption contrast of blood vessel lumen, whereas edge enhancement was set to minimum. Reflections on the thumb nail did not lead to image distortion and the blood volume in the nail bed showed more contrast.
<fig id="Fig6"><label>Figure&#xA0;6.</label><caption><p>Routine blood withdrawal. Image pairs showing unprocessed images for VIS (a) and NIR (b) as well as the result after application of the new image processing method (c). Note the forked shadow (which is not effected by the enhancement algorithm), the clearly visualized subcutaneous bleeding and the improved visibility of the needle tip.</p></caption><graphic position="anchor" xlink:href="10439_2006_9198_Fig6_HTML" id="MO6"/></fig></p>
      </sec>
      <sec id="Sec16">
        <title>Results for Dark Skin</title>
        <p>Hardly any vascular contrast is present within the VIS image (see Fig.&#xA0;<xref rid="Fig7" ref-type="fig">7</xref>a). The NIR image, however, is not affected by skin pigmentation and reveals a subcutaneous vascular pattern (see Fig.&#xA0;<xref rid="Fig7" ref-type="fig">7</xref>b). The combined information results in an enhanced image (see Fig.&#xA0;<xref rid="Fig7" ref-type="fig">7</xref>c).
<fig id="Fig7"><label>Figure&#xA0;7.</label><caption><p>Influence of skin pigmentation. A dark skin color (a) has no significance for the applied NIR wavelength of 920&#xA0;nm. Blood vessels provide good contrasts (b) and the resulting enhanced image (c) offers an improved visualization of the vasculature.</p></caption><graphic position="anchor" xlink:href="10439_2006_9198_Fig7_HTML" id="MO7"/></fig></p>
      </sec>
      <sec id="Sec17">
        <title>Results for Vein Detection Through Iodide</title>
        <p>Iodizing skin portions before surgery is a common clinical procedure which darkens the skin and lowers the visibility of blood vessels. Our method offers imaging right through iodide. To demonstrate this, we filmed a glass Petri dish, placed horizontally upon a volunteers arm while filling it up to a 3&#xA0;mm thick layer of iodide solution. From the VIS image no vessels could be detected through the iodide solution (see Fig.&#xA0;<xref rid="Fig8" ref-type="fig">8</xref>b) and hardly any through the empty Petri dish (see Fig.&#xA0;<xref rid="Fig8" ref-type="fig">8</xref>a). The raw NIR image, however, clearly showed superficial blood vessels even through the Petri dish (see Fig.&#xA0;<xref rid="Fig8" ref-type="fig">8</xref>c).
<fig id="Fig8"><label>Figure&#xA0;8.</label><caption><p>Vein detection through iodide. Within the visible range, the superficial vasculature is only vaguely discernable (a). After filling the Petri-dish with a 3&#xA0;mm thick layer of iodide solution, this fully blocks out the tissue view within the visual range (b), whereas a clear view of the vasculature remains possible at the applied NIR wavelength of 920&#xA0;nm (fig 8c).</p></caption><graphic position="anchor" xlink:href="10439_2006_9198_Fig8_HTML" id="MO8"/></fig></p>
      </sec>
      <sec id="Sec18">
        <title>Results for Varicose Vein and Nevi Pigmentosum Inspection</title>
        <p>The device was used to film varicosis patients during dermatological outpatient clinic. The visualization of varicose veins could be drastically improved. Even in cases where the blood vessels were covered by subcutaneous fat, they could be detected quite well (see Fig.&#xA0;<xref rid="Fig9" ref-type="fig">9</xref>). By either de-activating or activating the first NIR mask in the processing algorithm (see Fig.&#xA0;<xref rid="Fig3" ref-type="fig">3</xref>) it was also possible to choose whether pigment contrasts in the visual range were left intact or filtered out. The difference is clear when comparing between Fig.&#xA0;<xref rid="Fig9" ref-type="fig">9</xref>c and d with regard to the visualization of nevi pigmentosum and hair. By clicking a software screen button, this suppression of pigment contrast could be freely switched on and off during viewing.
<fig id="Fig9"><label>Figure&#xA0;9.</label><caption><p>The VIS image does not contain much information about the underlying vascular pattern (a). The NIR image, however, clearly shows what&#x2019;s hiding beneath the surface (b). Note that, when building the enhanced image, the nevus which is present in the VIS image can freely either be suppressed as a surface contrast (c) or be kept visible (d).</p></caption><graphic position="anchor" xlink:href="10439_2006_9198_Fig9_HTML" id="MO9"/></fig></p>
      </sec>
    </sec>
    <sec id="Sec19" sec-type="discussion">
      <title>Discussion</title>
      <p>From the figures presented in this article, it is clear that all experiments resulted in improved visualization of superficial blood vessels. Based upon the absorption coefficients of Hb versus HbO<sub>2</sub>, arteries provide superior contrasts at 920&#xA0;nm. The presented images, however, show enhanced venous contrasts, because the larger arteries are buried deeper underneath the skin. Stereoscopic movies provide a more lifely impression of the underlying, but presentation of stereoscopic movies is not possible in a printed journal. We therefore offer the possibility to download viewer software and movies via the internet http://www.erasmusmc.nl/ThoraxcenterBME/html/research/additional/bloodvesselcamera.htm</p>
      <p>For both the autostereoscopic LCD and the CRT display plus shutter glasses, we found that the perception of depth was less for <italic>stills</italic> than for <italic>movies</italic>. This qualitative observation matches research findings on stereoscopic display techniques in X-ray technology<xref ref-type="bibr" rid="CR8">8</xref> and is also consistent with the differences between static and dynamic stereoacuity described by Mathias and Rudolf Sachsenweger.<xref ref-type="bibr" rid="CR17">17</xref> Stereoscopic movies also showed an increase in apparent image sharpness compared to stereoscopic stills, which may be explained by Shipley&#x2019;s description of stereoscopic contour integration over blur.<xref ref-type="bibr" rid="CR18">18</xref> Compared to the autostereoscopic LCD-display, the increase in perceived sharpness was much stronger when using a CRT with shutter glasses. For monoscopic stills, however, the LCD-display (switched to monoscopic mode) was superior to the CRT. These observations are in agreement with the technology overview by Szold<xref ref-type="bibr" rid="CR19">19</xref> and can be explained by the sacrifice of resolution when using the LCD display in autostereoscopic mode, which price has not to be paid when using the CRT with shutter glasses.</p>
      <p>The beneficial effect of separately adjustable enhancement paths for blood vessel contours and blood vessel lumen, which we experienced during the development of our processing algorithm, is consistent with the findings of Yin <italic>et&#xA0;al.</italic> that surface-features and edge processes make different contributions in determining an object&#x2019;s unity and shape.<xref ref-type="bibr" rid="CR27">27</xref> The perceived usefulness of stereoscopic information, however, also supports the concept formulated by Tse that &#x2018;&#x2018;mergeable&#x2019;&#x2019; <italic>volumes</italic>, rather than relatable contours, are the critical elements in completion.<xref ref-type="bibr" rid="CR21">21</xref></p>
      <p>With our technique we have aimed to avoid parallax errors and loss of vessel contrast by shadows which are inherent to other blood vessel contrast enhancement techniques projecting the vascular pattern via a projector onto the skin.<xref ref-type="bibr" rid="CR28">28</xref> We exclude parallax errors because the user truly looks <italic>beneath</italic> the tissue surface trough <italic>two</italic> camera&#x2019;s. Absence of vessel contrast in shadows is avoided by lighting from two sides and by discrimination of superficial artifacts versus contrasts originating from below the surface.</p>
      <p>This ability to selectively enhance contrasts from beneath the surface, while preserving the natural depth clues of shadows on the surface, supports both static and dynamic transmittance anchoring of the visual system which is crucial for depth perception.<xref ref-type="bibr" rid="CR1">1</xref> Preservation of natural shadows is furthermore important for the correct interpretation of depth clues by occlusion (e.g. from a hand or an instrument positioned between observer and tissue) thus precluding errors in depth perception.<xref ref-type="bibr" rid="CR12">12</xref></p>
      <p>Since only carefully balanced white light is projected on the skin, there is no impairment of color perception. It is up to the user to freely switch between normal full color vision, color vision plus superimposed blood vessel backprojection and stereoscopic near infrared greyscale vision (with or without enhancement features).</p>
      <p>The embodiment described in this article still has some drawbacks:<list list-type="bullet"><list-item><p>Due to the fact that the pertaining configuration aquires VIS and NIR images sequentially, motion artifacts can lead to a backprojection shift.</p></list-item><list-item><p>The deeper the vessels lie under the surface, the less we can visualize them. In the pertaining configuration, the depth range is limited to about 1&#xA0;mm. Based upon the absorption coefficients of Hb and HbO<sub>2</sub>, arteries provide superior contrasts at 920&#xA0;nm. The presented images, however, show enhanced venous contrasts, because the larger arteries are buried deeper underneath the skin.</p></list-item></list></p>
      <p>The above mentioned drawbacks require further development. Fortunately, many technological improvents still can be added. Allthough the device worked quite well under normal ambient lighting conditions (100&#x2013;200 Lux), the use of a switchable filter might further improve spectral separation. Furthermore, known techniques like application of crossed polarizers, in combination with more powerful light sources, can offer a considerably larger penetration depth.<xref ref-type="bibr" rid="CR7">7</xref></p>
    </sec>
    <sec id="Sec20" sec-type="conclusion">
      <title>Conclusions</title>
      <p>Compared to inspection with the naked eye under normal lighting conditions, the tested stereoscopic blood vessel contrast enhancer offered improved visualization in all investigated settings, providing the best stereoscopic image quality when using the CRT monitor with shutter glasses and the best monoscopic image quality when using the LCD set to monoscopic mode.</p>
      <p>Our technique supports perception of depth, 3-dimensional motion and discrimination between tissue surface and underlying structures. It also has potential as an educational tool by offering the possibility to look and record trough the eyes of an experienced specialist. Further improvements on penetration depth, frame-rate and focus depth-of-field form targets for momentary ongoing further research.</p>
    </sec>
  </body>
  <back>
    <ack>
      <p>This study was sponsored by TNO Quality of Life and by TNO O<sub>2 </sub>View BV (both based in Leiden, the Netherlands). Custom mechanical constructions were made by Mr. L. Bekkering and support on electronics was given by Mr. J. Honkoop (both from Biomedical Engineering, Thorax Centre). We greatly appreciate the possibilities to record data in clinical settings and the assistance of the blood withdrawal team of the cardiology outpatient clinic as well as the staff of the dermatology outpatient clinic (all within Erasmus MC Rotterdam, the Netherlands).</p>
    </ack>
    <ref-list id="Bib1">
      <title>Reference</title>
      <ref id="CR1">
        <label>1.</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Anderson</surname>
              <given-names>B. L.</given-names>
            </name>
            <name>
              <surname>Singh</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Meng</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>The perceived transmittance of inhomogenous surfaces and media</article-title>
          <source>Vision Res.</source>
          <year>2006</year>
          <volume>46</volume>
          <fpage>1982</fpage>
          <lpage>1995</lpage>
          <pub-id pub-id-type="doi">10.1016/j.visres.2005.11.024</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Anderson B. L., Singh M., Meng J. 2006. The perceived transmittance of inhomogenous surfaces and media. Vision Res. 46:1982&#x2013;1995 <pub-id pub-id-type="pmid">16410017</pub-id></citation>
      </ref>
      <ref id="CR2">
        <label>2.</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dallow</surname>
              <given-names>R. L.</given-names>
            </name>
            <name>
              <surname>McMeel</surname>
              <given-names>J. W.</given-names>
            </name>
          </person-group>
          <article-title>Penetration of retinal and vitreous opacities in diabetic retinopathy. Use of infrared fundus photography</article-title>
          <source>Arc. Ophthalmol.</source>
          <year>1974</year>
          <volume>92</volume>
          <fpage>531</fpage>
          <lpage>534</lpage>
        </citation>
        <citation citation-type="display-unstructured">Dallow R. L., McMeel J. W. 1974. Penetration of retinal and vitreous opacities in diabetic retinopathy. Use of infrared fundus photography. Arc. Ophthalmol. 92:531&#x2013;534 </citation>
      </ref>
      <ref id="CR3">
        <label>3.</label>
        <citation citation-type="other">de Grave, D. D. The use of illusory visual information in perception and action. Erasmus, Rotterdam, 2005, pp. 112.</citation>
      </ref>
      <ref id="CR4">
        <label>4.</label>
        <citation citation-type="other">Elschnig, Elschnig demonstrirt ferner stereoskopische Photographieen. Presented at Achtundzwansigte Versammlung der Opthalmologischen Gesellschaft, Heidelberg, 1900.</citation>
      </ref>
      <ref id="CR5">
        <label>5.</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Elsner</surname>
              <given-names>A. E.</given-names>
            </name>
            <name>
              <surname>Burns</surname>
              <given-names>S. A.</given-names>
            </name>
            <name>
              <surname>Weiter</surname>
              <given-names>J. J.</given-names>
            </name>
            <name>
              <surname>Delori</surname>
              <given-names>F. C.</given-names>
            </name>
          </person-group>
          <article-title>Infrared imaging of sub-retinal structures in the human ocular fundus</article-title>
          <source>Vision Res.</source>
          <year>1996</year>
          <volume>36</volume>
          <fpage>191</fpage>
          <lpage>205</lpage>
          <pub-id pub-id-type="doi">10.1016/0042-6989(95)00100-E</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Elsner A. E., Burns S. A., Weiter J. J., Delori F. C. 1996. Infrared imaging of sub-retinal structures in the human ocular fundus. Vision Res. 36:191&#x2013;205 <pub-id pub-id-type="pmid">8746253</pub-id></citation>
      </ref>
      <ref id="CR6">
        <label>6.</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gostout</surname>
              <given-names>C. J.</given-names>
            </name>
            <name>
              <surname>Jacques</surname>
              <given-names>S. L.</given-names>
            </name>
          </person-group>
          <article-title>Infrared video imaging of subsurface vessels: a feasibility study for the endoscopic management of gastrointestinal bleeding</article-title>
          <source>Gastrointest. Endosc.</source>
          <year>1995</year>
          <volume>41</volume>
          <fpage>218</fpage>
          <lpage>224</lpage>
          <pub-id pub-id-type="doi">10.1016/S0016-5107(95)70341-1</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Gostout C. J., Jacques S. L. 1995. Infrared video imaging of subsurface vessels: a feasibility study for the endoscopic management of gastrointestinal bleeding. Gastrointest. Endosc. 41:218&#x2013;224 <pub-id pub-id-type="pmid">7789680</pub-id></citation>
      </ref>
      <ref id="CR7">
        <label>7.</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Groner</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Winkelman</surname>
              <given-names>J. W.</given-names>
            </name>
            <name>
              <surname>Harris</surname>
              <given-names>A. G.</given-names>
            </name>
            <name>
              <surname>Ince</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Bouma</surname>
              <given-names>G. J.</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Orthogonal polarization spectral imaging: a new method for study of the microcirculation</article-title>
          <source>Nat. Med.</source>
          <year>1999</year>
          <volume>5</volume>
          <fpage>1209</fpage>
          <lpage>1212</lpage>
          <pub-id pub-id-type="doi">10.1038/13529</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Groner W., Winkelman J. W., Harris A. G., Ince C., Bouma G. J., et al. 1999. Orthogonal polarization spectral imaging: a new method for study of the microcirculation. Nat. Med. 5:1209&#x2013;1212 <pub-id pub-id-type="pmid">10502828</pub-id></citation>
      </ref>
      <ref id="CR8">
        <label>8.</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hardy</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Dodds</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Roberts</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>An objective evaluation of the effectiveness of different methods of displaying three-dimensional information with medical X-Ray images</article-title>
          <source>Invest. Radiol.</source>
          <year>1996</year>
          <volume>31</volume>
          <fpage>433</fpage>
          <lpage>445</lpage>
          <pub-id pub-id-type="doi">10.1097/00004424-199607000-00006</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Hardy J., Dodds S., Roberts A. 1996. An objective evaluation of the effectiveness of different methods of displaying three-dimensional information with medical X-Ray images. Invest. Radiol. 31:433&#x2013;445 <pub-id pub-id-type="pmid">8818783</pub-id></citation>
      </ref>
      <ref id="CR9">
        <label>9.</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Haustein</surname>
              <given-names>U. F.</given-names>
            </name>
          </person-group>
          <article-title>Infrared photodocumentation of the superficial venous system of the leg</article-title>
          <source>&#xC4;sthetische Medizin</source>
          <year>1967</year>
          <volume>16</volume>
          <fpage>155</fpage>
          <lpage>160</lpage>
        </citation>
        <citation citation-type="display-unstructured">Haustein U. F. 1967. Infrared photodocumentation of the superficial venous system of the leg. &#xC4;sthetische Medizin 16:155&#x2013;160 <pub-id pub-id-type="pmid">5304663</pub-id></citation>
      </ref>
      <ref id="CR10">
        <label>10.</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hayashi</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Kawano</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Tsuji</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Tsujii</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Takai</surname>
              <given-names>Y.</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Identification and diameter assessment of gastric submucosal vessels using infrared electronic endoscopy</article-title>
          <source>Endoscopy</source>
          <year>1994</year>
          <volume>26</volume>
          <issue>8</issue>
          <fpage>686</fpage>
          <lpage>689</lpage>
        </citation>
        <citation citation-type="display-unstructured">Hayashi N., Kawano S., Tsuji S., Tsujii M., Takai Y., et al. 1994. Identification and diameter assessment of gastric submucosal vessels using infrared electronic endoscopy. Endoscopy 26(8):686&#x2013;689 <pub-id pub-id-type="pmid">7859679</pub-id></citation>
      </ref>
      <ref id="CR11">
        <label>11.</label>
        <citation citation-type="other">Intel. Intel integrated performance primitives for Intel architecture&#x2014;Reference manual A70805&#x2013;017US, 2006</citation>
      </ref>
      <ref id="CR12">
        <label>12.</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Johnson</surname>
              <given-names>L. G.</given-names>
            </name>
            <name>
              <surname>Edwards</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Hawkes</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Surface transparency makes stereo overlays unpredictable: The implications for augmented reality</article-title>
          <source>Stud. Health Technol. Inform.</source>
          <year>2002</year>
          <volume>94</volume>
          <fpage>131</fpage>
          <lpage>136</lpage>
        </citation>
        <citation citation-type="display-unstructured">Johnson L. G., Edwards P., Hawkes D. 2002. Surface transparency makes stereo overlays unpredictable: The implications for augmented reality. Stud. Health Technol. Inform. 94:131&#x2013;136 <pub-id pub-id-type="pmid">15455878</pub-id></citation>
      </ref>
      <ref id="CR13">
        <label>13.</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Jones</surname>
              <given-names>C. H.</given-names>
            </name>
            <name>
              <surname>Newbery</surname>
              <given-names>S. P.</given-names>
            </name>
          </person-group>
          <article-title>Visualization of superficial vasculature using a Vidicon camera tube with silicon target</article-title>
          <source>British J. Radiol.</source>
          <year>1977</year>
          <volume>50</volume>
          <fpage>209</fpage>
          <lpage>210</lpage>
        </citation>
        <citation citation-type="display-unstructured">Jones C. H., Newbery S. P. 1977. Visualization of superficial vasculature using a Vidicon camera tube with silicon target. British J. Radiol. 50:209&#x2013;210 </citation>
      </ref>
      <ref id="CR14">
        <label>14.</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kono</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Ueki</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Umemura</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Near-infrared finger vein patterns for personal identification</article-title>
          <source>Appl. Optics</source>
          <year>2002</year>
          <volume>41</volume>
          <fpage>7429</fpage>
          <lpage>7436</lpage>
        </citation>
        <citation citation-type="display-unstructured">Kono M., Ueki H., Umemura S. 2002. Near-infrared finger vein patterns for personal identification. Appl. Optics 41:7429&#x2013;7436 </citation>
      </ref>
      <ref id="CR15">
        <label>15.</label>
        <citation citation-type="other">Ontikova N. M., Iaroslavtsev D. A., Lirman A. V. Increase in the information content of the image of the surface veins by using a television infrascope. <italic>Meditsinskaia tekhnika</italic>: 20&#x2013;22, 1976</citation>
      </ref>
      <ref id="CR16">
        <label>16.</label>
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Rotman</surname>
              <given-names>G.</given-names>
            </name>
          </person-group>
          <source>Localization during pursuit eye movement</source>
          <year>2005</year>
          <publisher-loc>Rotterdam</publisher-loc>
          <publisher-name>Erasmus</publisher-name>
          <fpage>102</fpage>
        </citation>
        <citation citation-type="display-unstructured">Rotman G. 2005. Localization during pursuit eye movement. Erasmus, Rotterdam, pp 102 </citation>
      </ref>
      <ref id="CR17">
        <label>17.</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sachsenweger</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Sachsenweger</surname>
              <given-names>U.</given-names>
            </name>
          </person-group>
          <article-title>Stereoscopic acuity in ocular pursuit of moving objects. Dynamic stereoscopy and movement parallax: relevance to road safety and occupational medicine</article-title>
          <source>Documenta Opthalmologica</source>
          <year>1991</year>
          <volume>78</volume>
          <fpage>1</fpage>
          <lpage>133</lpage>
        </citation>
        <citation citation-type="display-unstructured">Sachsenweger M, Sachsenweger U. 1991. Stereoscopic acuity in ocular pursuit of moving objects. Dynamic stereoscopy and movement parallax: relevance to road safety and occupational medicine. Documenta Opthalmologica 78:1&#x2013;133 </citation>
      </ref>
      <ref id="CR18">
        <label>18.</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Shipley</surname>
              <given-names>T. F.</given-names>
            </name>
          </person-group>
          <article-title>Field processes in stereovision. A description of stereopsis appropriate to opthalmology and visual perception</article-title>
          <source>Documenta Opthalmologica</source>
          <year>1987</year>
          <volume>66</volume>
          <fpage>95</fpage>
          <lpage>170</lpage>
          <pub-id pub-id-type="doi">10.1007/BF00140453</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Shipley T. F. 1987. Field processes in stereovision. A description of stereopsis appropriate to opthalmology and visual perception. Documenta Opthalmologica 66:95&#x2013;170 </citation>
      </ref>
      <ref id="CR19">
        <label>19.</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Szold</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Seeing is believing - Visualization systems in endoscopic surgery (video, HDTV, stereoscopy, and beyond)</article-title>
          <source>Surg. Endosc.</source>
          <year>2005</year>
          <volume>19</volume>
          <fpage>730</fpage>
          <lpage>733</lpage>
          <pub-id pub-id-type="doi">10.1007/s00464-004-8272-8</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Szold A. 2005. Seeing is believing - Visualization systems in endoscopic surgery (video, HDTV, stereoscopy, and beyond). Surg. Endosc. 19:730&#x2013;733 <pub-id pub-id-type="pmid">15759191</pub-id></citation>
      </ref>
      <ref id="CR20">
        <label>20.</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Taffinder</surname>
              <given-names>N.</given-names>
            </name>
            <name>
              <surname>Smith</surname>
              <given-names>S. G. T.</given-names>
            </name>
            <name>
              <surname>Huber</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Russel</surname>
              <given-names>R. C. G.</given-names>
            </name>
            <name>
              <surname>Darzi</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>The effect of a second-generation 3D endoscope on the laparoscopic precision of novices and experienced surgeons</article-title>
          <source>Surg. Endosc</source>
          <year>1999</year>
          <volume>13</volume>
          <fpage>1087</fpage>
          <lpage>1092</lpage>
          <pub-id pub-id-type="doi">10.1007/s004649901179</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Taffinder N., Smith S. G. T., Huber J., Russel R. C. G., Darzi A. 1999. The effect of a second-generation 3D endoscope on the laparoscopic precision of novices and experienced surgeons. Surg. Endosc 13:1087&#x2013;1092 <pub-id pub-id-type="pmid">10556444</pub-id></citation>
      </ref>
      <ref id="CR21">
        <label>21.</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Tse</surname>
              <given-names>P. U.</given-names>
            </name>
          </person-group>
          <article-title>Volume Completion</article-title>
          <source>Cognit. Psychol.</source>
          <year>1999</year>
          <volume>39</volume>
          <fpage>37</fpage>
          <lpage>68</lpage>
          <pub-id pub-id-type="doi">10.1006/cogp.1999.0715</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Tse P. U. 1999. Volume Completion. Cognit. Psychol. 39:37&#x2013;68 <pub-id pub-id-type="pmid">10433787</pub-id></citation>
      </ref>
      <ref id="CR22">
        <label>22.</label>
        <citation citation-type="other">Webb S. Imaging by diaphanography. In <italic>The physics of medical imaging</italic>, ed. S Webb. Bristol: Institute of physics publishing</citation>
      </ref>
      <ref id="CR23">
        <label>23.</label>
        <citation citation-type="other">Wieringa F. P., D. Bakker, A. F. W. van der Steen, F. Mastik, and R. G. M. van Melick. <italic>Patent No. EP1566142A1</italic>,  2005.</citation>
      </ref>
      <ref id="CR24">
        <label>24.</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wieringa</surname>
              <given-names>F. P.</given-names>
            </name>
            <name>
              <surname>Mastik</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Steen</surname>
              <given-names>A. F. W.</given-names>
            </name>
          </person-group>
          <article-title>Contactless multiple wavelength photoplethysmographic imaging: A first step towards &#x201C;SpO2 camera&#x201D; technology</article-title>
          <source>Ann. Biomed. Eng.</source>
          <year>2005</year>
          <volume>33</volume>
          <fpage>1034</fpage>
          <lpage>1041</lpage>
          <pub-id pub-id-type="doi">10.1007/s10439-005-5763-2</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Wieringa F. P., Mastik F., Van der Steen A. F. W. 2005. Contactless multiple wavelength photoplethysmographic imaging: A first step towards &#x201C;SpO2 camera&#x201D; technology. Ann. Biomed. Eng. 33:1034&#x2013;1041 <pub-id pub-id-type="pmid">16133912</pub-id></citation>
      </ref>
      <ref id="CR25">
        <label>25.</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Wissmanns</surname>
              <given-names>H. F.</given-names>
            </name>
          </person-group>
          <article-title>Prophylaxis and treatment of venous diseases in general practice. Objective evaluation by means of infrared photography</article-title>
          <source>die Medizinische Welt</source>
          <year>1968</year>
          <volume>20</volume>
          <fpage>191</fpage>
          <lpage>196</lpage>
        </citation>
        <citation citation-type="display-unstructured">Wissmanns H. F. 1968. Prophylaxis and treatment of venous diseases in general practice. Objective evaluation by means of infrared photography. die Medizinische Welt 20:191&#x2013;196 <pub-id pub-id-type="pmid">5732259</pub-id></citation>
      </ref>
      <ref id="CR26">
        <label>26.</label>
        <citation citation-type="other">Woods D. D., E. S. Patterson, and E. M. Roth.  Can we ever escape from data overload? A cognitive systems diagnosis. <italic>Cognition Technol.Work</italic>: 22&#x2013;36, 2002.</citation>
      </ref>
      <ref id="CR27">
        <label>27.</label>
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Yin</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Kellman</surname>
              <given-names>P. J.</given-names>
            </name>
            <name>
              <surname>Shipley</surname>
              <given-names>T. F.</given-names>
            </name>
          </person-group>
          <article-title>Surface integration influences depth discrimination</article-title>
          <source>Vision Res.</source>
          <year>2000</year>
          <volume>40</volume>
          <fpage>1969</fpage>
          <lpage>1978</lpage>
          <pub-id pub-id-type="doi">10.1016/S0042-6989(00)00047-X</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Yin C., Kellman P. J., Shipley T. F. 2000. Surface integration influences depth discrimination. Vision Res. 40:1969&#x2013;1978 <pub-id pub-id-type="pmid">10828465</pub-id></citation>
      </ref>
      <ref id="CR28">
        <label>28.</label>
        <citation citation-type="other">Zeman H. D., G. Lovhoiden, C. Vrancken. <italic>Prototype vein contrast enhancer</italic>. Presented at Photonics West 2004: Biomedical Optics (BiOS),  2004.</citation>
      </ref>
    </ref-list>
  </back>
</article>
</pmc-articleset>