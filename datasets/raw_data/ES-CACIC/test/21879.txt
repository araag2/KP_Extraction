Modelo para el entrenamiento de usuarios con déficit auditivo a través integración de sonidos con el contexto
﻿
 
Jorge Ierache 1,3,  Luís Campos,2,3, Marcela Bruno1,3 ,Hugo Padovani 3  
1Instituto  de Sistemas Inteligentes y Enseñanza Experimental de la Robótica. 
          2Instituto de Tecnología de la Información y Comunicación para el Desarrollo Social 
    3Facultad de Informática, Ciencias de la Comunicación y Técnicas Especiales.  
Universidad de Morón {jierache,mabruno,lcampos,hpadovani}@unimoron.edu.ar  
Tel: +5411 56272000 (189/746) 
 
Abstract 
A preliminary model for the training of users with severe auditory deficit appears in this work. The 
model contemplates to the edition of "Contexts of action" for example situations as the visit to a 
thematic park, zoological, etc; those that are made up of different images and sounds. The images 
consider associates with dynamic scenes that will contain sounds that represent them. Of this form it 
is tried that the disabled one can perceive from the simulator the vibrations corresponding to these 
sounds through a device of stimulation by vibrations the one that presents alternative means of 
communication for the people with severe auditory deficit, this device and its interaction was 
developed by J Escudero, L Campos 2004. In relation to mobility the proposed model contemplates 
the interoperability of the disabled one with contexts of real sounds through the connection of the 
device of stimulation by movable device vibrations that the user can take with himself, like for 
example cellular or PDA. The real context becomes rich when incorporating a reader of RFID to the 
movable devices that allow the user to unload information and sounds of the context to their cellular 
or PDA, from a physical URL.  
 
Key words: Engineering Centered in Contexts, Auditory Disabled, Tactile-vibration Stimulation, 
Model of trainer  
Resumen 
Se presenta en este trabajo un modelo preliminar para el entrenamiento de usuarios con déficit 
auditivo severo. El modelo  contempla la edición de “Contextos de acción” por ejemplo situaciones 
como la visita a un parque temático, zoológico, etc; los que se encuentran compuestos por 
diferentes imágenes y sonidos. Las imágenes se consideran asociadas con escenas dinámicas que 
contendrán sonidos que las representen. De esta forma se pretende que el discapacitado pueda 
percibir desde el simulador  las vibraciones correspondientes a estos sonidos a través de un 
dispositivo de estimulación por vibraciones el que presenta un  medio alternativo de comunicación 
para las personas con déficit auditivo severo, este dispositivo  y su interacción fue desarrollado por  
J Escudero, L Campos 2004. En relación a la movilidad el modelo propuesto contempla la 
interoperabilidad del discapacitado con contextos de sonidos reales a través de la conexión del 
dispositivo de estimulación por vibraciones a dispositivos móviles que el usuario puede llevar 
consigo, como por ejemplo un celular o una PDA. El contexto real se enriquece al incorporar un 
lector de RFID a los dispositivos móviles, que permitan al usuario descargar información y sonidos 
del contexto  a su celular o PDA, desde una URL física. 
 
Palabras Claves: Ingeniería centrada en contextos, Discapacidad auditiva, Estimulación vibrotactil,  
Modelo de entrenador 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
427
 1. INTRODUCCIÓN 
Se realizan diversos esfuerzos en la actualidad para ayudar a las personas con discapacidades ,el  
trabajo realizado por J Boyd Graber et al para personas  que sufren de Aphasia  [5], (desorden que 
implica dificultades para hablar leer escribir y entender el lenguaje) presenta el diseño y una 
evaluación preliminar de una aplicación de desktop-handheld para ayudar a  individuos con 
Aphasia, desarrollando una comunicación a través de imágenes y sonidos sobre una computadora 
desktop y  dispositivos móviles para soportar la comunicación fuera de casa. En esta línea se 
destaca el trabajo desarrollado por J Escudero, L Campos 2004 para discapacitados con déficit 
auditivo severo, donde  los resultados que se han obtenido con el uso del dispositivo de 
estimulación vibrotáctil [1], facilitaron a los  usuarios aprenden con rapidez a identificar y 
reconocer palabras, frases y también diversos sonidos del ambiente que los rodea, así como también 
la lectura de los labios. 
El presente trabajo contribuye con el trabajo de J Escudero y L Campos, aportando una  propuesta 
de modelo para  incorporar sonidos del contexto, a fin de facilitar el entrenamiento de 
discapacitados, el modelo pretende generar un contexto para los diversos sonidos que se pueden 
producir en un determinado ambiente. Por ejemplo, en la calle, se escucharán sonidos de motores de 
autos, de motos, bocinas, personas caminando, etc. En un zoológico en cambio, escucharemos 
sonidos de diversos animales, etc.   
La aplicación propuesta es centrada en Contexto, de acuerdo a lo planteado por Dey en el trabajo de 
A Fortier, G Grossi, S Gordillo [3] contexto es alguna información que puede ser usada para 
caracterizar una situación de una entidad, una entidad es una persona, un objeto, un lugar que es 
considerado relevante para la interacción entre el usuario y una  aplicación, incluyendo al usuario y 
sus aplicaciones. 
La visión de contexto fenomenológica  que presenta Dourish de acuerdo a lo planteado por Dey en 
el trabajo de A Fortier, G Grossi, S Gordillo [3] el foco es el ser humano, que percibe el contexto en 
nuestro caso con discapacidad  auditiva, se encuentra en un constante proceso de redescubrimiento, 
en nuestro caso el aprendizaje de nuevos sonidos del contexto, el contexto finalmente para esta 
visión es subjetivo y se acerca a definiciones abstractas; para esta visión el contexto no es 
información, habla de una relación contextualizada entre objetos o actividades, el contexto varia no 
puede modelarse de antemano, el contexto es una propiedad ocasionada, depende de las situaciones, 
el contexto surge de la actividad, no hay distinción entre actividad (comportamiento) y contexto 
(datos), para esta visión resulta necesario determinar un modelo que describa el contexto y que 
maneje los cambios de este, en nuestro caso los contexto que representan el ambiente y sus sonidos. 
2. JUSTIFICACIÓN: 
El uso del dispositivo de estimulación por vibraciones, abre un nuevo mundo de posibilidades de 
comunicación y de percepciones a los usuarios hipoacúsicos. Sin embargo existe la dificultad, que 
para entrenarse en la percepción de sonidos de diferentes contextos, el usuario debe trasladarse al 
lugar físico donde se producen esos sonidos para poder percibirlos. Esto sin duda es una desventaja, 
ya que según el contexto de que se trate, puede ser poco accesible para el usuario e  implica un 
esfuerzo el tener que movilizarse hasta el lugar. Por otra parte esto implica disponer de un tiempo 
limitado para entrenarse con los sonidos de ese contexto, y de no tener el usuario la posibilidad de 
“repetir” aquellos sonidos que tuvo más dificultad en reconocer. 
Surge así  la necesidad de disponer de una interfaz, que facilite el aprendizaje de sonidos de 
contexto, sin la necesidad de tener que ir hasta un determinado lugar. El usuario podrá recorrer 
escenarios creados virtualmente, que contendrán imágenes correspondientes al mismo. Estas 
imágenes, a su vez, están asociadas a un escenario dinámico, representado por imágenes y sonidos. 
Por otra parte cuando el usuario se encuentre en  un escenario real en donde existen objetos físicos, 
este tendrá la posibilidad de descargar información a través etiquetas RFID [4] que se encuentren en 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
428
 los objetos del ambiente, las que facilitaran la información  a través de URLs físicas. De esta forma, 
cuando el usuario recorra un determinado lugar, en donde existen objetos con etiquetas RFID, 
tendrá la posibilidad de descargar la información  y sonidos a su celular o PDA. Esta información 
podrá aportar una explicación sobre el objeto en cuestión, (por ejemplo si está en un zoológico y 
está frente a el hábitat de una animal, podría descargar toda la información referente a este animal, 
pero fundamentalmente los sonidos característicos (Por ejemplo en el caso de un paseo por el 
zoológico, el RFID de la jaula de los leones, podría contener el sonido del rugido del león). Todos 
estos sonidos, podría percibirlos a través del dispositivo de estimulación por vibraciones. 
La interfaz de usuario facilitara  el  armado de contextos de acción, con imágenes que 
pueden provenir de Internet, que el usuario mismo puede haber capturado con un celular, etc. 
Además permitirá recorrido de contextos de acción, en forma general, con la posibilidad de 
reproducir el nombre de las imágenes que contiene y acceder a los escenarios dinámicos 
correspondientes. En otro orden serán necesarias  funciones de apoyo para almacenar información 
relevante, relacionada con el nivel entrenamiento y tipo de discapacidad del usuario, como así 
también posibilidades de bajar nuevos escenarios desde Internet para el entrenamiento. 
3. CARACTERÍSTICAS DEL DISPOSITIVO DE ESTIMULACIÓN POR 
VIBRACIONES: 
En esta sección se hará una breve descripción de los aspectos más relevantes en cuanto a principios 
de funcionamiento y características del dispositivo de estimulación por vibraciones [1,2]. Los 
sonidos del mundo exterior, se captan por medio de un micrófono, y se transforman en estímulos 
vibratorios, que el usuario percibe  a través del dispositivo, el proceso de traducción de los sonidos 
a vibraciones  en forma general se distinguen tres etapas: 
– Generación de la Información: El evento disparador es la recepción de un sonido 
exterior. (Señal analógica). 
– Procesamiento: La señal, sonora recibida, se pasa a valores digitales mediante un 
conversor A/D, para poder procesarla. La salida resultante se vuelve a pasar a una señal 
analógica mediante un conversor D/A. 
– Recepción: La señal analógica resultante es recibida por el discapacitado auditivo 
mediante la utilización de una interfaz háptica. 
El dispositivo de comunicación por vibraciones consiste en un dispositivo de comunicación por 
vibraciones para personas con discapacidad auditiva, comprende un vibrador y un receptor, ambos 
conectados entre sí por medio de un circuito que puede comprender un medio informático, una PC, 
un amplificador de señal o cualquier otro medio que procese señales captadas por el receptor. El 
vibrador es un elemento transductor electroacústico, como por ejemplo un microparlante, y está en 
contacto con el cuerpo a través de la yema del dedo. Este vibrador puede estar conectado con el 
receptor en forma alámbrica o inalámbrica y el receptor comprende un sensor de ondas magnéticas, 
un micrófono o similar, del micrófono sale una señal de audio modulada en amplitud, la cual es 
amplificada para excitar el dispositivo vibrador. El vibrador es de tipo portable; está sujeto a un 
soporte, constituido por una faja anular elástica con un cierre de velcro, con el que puede fijarse al 
extremo del dedo índice para mantener la superficie vibradora en contacto permanente y seguro con 
la yema del dedo. El receptor de señal es portable, y es un micrófono que está conectado a una 
computadora que almacena sonidos en una biblioteca de sonidos. La persona podrá asociar cada 
vibración que le es transmitida a través del vibrador, a una letra, palabra o sonido y combinación de 
los mismos, llegando a interpretar claramente lo que le dicen o los sonidos de un entorno habitual, 
se requiere de un breve período de aprendizaje, como lo demuestran los ensayos. [2] Este 
dispositivo puede ser aplicado a personas sordas que también son ciegas. La persona sordo ciega 
escribe en el teclado Braille y la computadora le devuelve a través del vibrador, las vibraciones 
correspondientes a lo escrito. [2] El dispositivo es aplicable a un teléfono celular o de línea, en 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
429
 donde el vibrador estaría fijado a una parte del teléfono que sea accesible al usuario. Como se puede 
advertir, este mecanismo no sólo comprende un dispositivo de intercomunicación, sino que 
involucra una nueva tecnología y técnicas de comunicación para personas con discapacidad 
auditiva, así como nuevos sistemas de enseñanza. 
3.1. Interfaz Háptica:  
La Interfaz seleccionada para el dispositivo debía ser capaz de poner en contacto al discapacitado 
auditivo con la información procesada mediante la utilización de alguno de sus sentidos. 
Tradicionalmente, se ha atribuido al sentido de la vista la mayor importancia en la recepción de 
estímulos e interacción durante el proceso de comunicación, el oído se define en segundo lugar y 
por último el tacto. Este esquema de funcionamiento responde a la realidad de nuestra vida 
cotidiana, en una persona normalmente constituida y sin lesiones de ningún tipo, pero dado que el 
dispositivo de comunicación estaba orientado a personas con una lesión severa en su sentido 
auditivo, se propuso [1]. un nuevo esquema de funcionamiento priorizando la percepción de la 
información procesada mediante el sentido del tacto en ausencia del sentido del oído. Considerando 
el enorme caudal de información que puede ser recibida a través del tacto. Se denomina háptica a 
toda aquella percepción táctil realizada en forma activa y voluntaria; es decir, se requiere un uso 
activo de los dedos y manos en el descubrimiento de objetos de nuestro entorno debido a que el 
canal de comunicación está centrado en las manos, más específicamente las palmas y dedos. Las 
interfaces hápticas buscan combinar el sentido del tacto con su entorno, su investigación se puede 
subdividir en dos campos: 
– Retroalimentación de la fuerza: Trata con dispositivos que interactúan con músculos y 
tendones y dan al humano la sensación de que se aplica una fuerza. 
– Retroalimentación táctil: Es la que se usó en el desarrollo del dispositivo de estimulación 
por vibraciones. Trata con dispositivos que interactúan con los nervios terminales en la 
piel, los cuales indican la presencia del calor, presión y textura.  
3.2. Dispositivo de estimulación vibrotáctil: 
Se construyó Centro Argentino de Medios Alternativos de Comunicación (CAMAC) [2], este 
dispositivo se utiliza en el dedo índice adaptado a la forma y tamaño del dedo índice del 
discapacitado auditivo, la base del dispositivo tiene una cavidad libre, el objetivo de este diseño es 
contener el dedo y permitir el contacto de la yema con la vibración proveniente de la señal 
analógica sonora (Figura 1). 
 
 
Figura 1: Dispositivo de estimulación por vibraciones 
Bobina de 
parlante de 
auricular
Cavidad 
libre 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
430
  
3.3. Interfaz de entrenamiento lingüístico: 
El trabajo de Escudero J y Campos L presentó una interfaz de entrenamiento lingüístico (Figura 2), 
para reconocer los estímulos vibratorios correspondientes a palabras y frases, que permite al 
instructor administrar la información de los discapacitados auditivos con los que trabaja, estos datos 
son característicos de la voz digital con la que se estuvo trabajando y el historial de secuencias. 
Además se permite al instructor personalizar las características de la voz digital a trabajar con el 
discapacitado auditivo considerando el valor asociado a velocidad, pitch y tiempo. En otro orden se 
permite al instructor ingresar en un campo de edición las palabras u oraciones. Al mismo tiempo del 
ingreso, cada palabra se va visualizando en campos de lectura independientes. La interfaz cuenta 
con diez campos de lectura e incorpora la simulación de los labios correspondiente a las sílabas o 
palabras. 
 
 
Figura 2: Pantalla principal del software de entrenamiento 
 
4. MODELO PROPUESTO PARA EL ENTRENAMIENTO DE SONIDOS 
CONTEXTUALES: 
4.1. Interfaz de entrenamiento context-awareness  
La interfaz propuesta, será una interfaz context-awareness. Para entender la definición de “orientado 
al contexto” se debe empezar a definir y comprender el concepto de “computación contextawareness”. Cuando realizamos una acción, generalmente, es producto de la intención, que 
tenemos, de alcanzar un objetivo. Estos objetivos pueden ser muy simples para nosotros pero 
sumamente complejos para una aplicación de software, debido a que esta última, no conoce cuál es 
nuestro  deseo en ese momento, y además, no posee la capacidad de procesar cognitivamente gran 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
431
 cantidad de aspectos, contextuales (sonidos, luminosidad, espacio, tiempo, etc.) y personales 
(intensiones, intereses, gustos, preferencias, necesidades, etc.). Estos aspectos los percibimos en 
forma automática y no nos resultan un obstáculo, pero son un gran desafío para una aplicación. Los 
investigadores en el área de la ingeniería de software están incorporando estos aspectos en las 
nuevas aplicaciones logrando que estas, sean sensibles al contexto [10]. Este nuevo paradigma fue 
denominado computación sensible al contexto o context-awareness. 
4.1.1 Consideraciones acerca de context-awareness. 
A lo largo del tiempo se han formulado diferentes definiciones. La primera definición surge en 
1993, (Schilit [11]) define al contexto como “la localización, identidad de las personas y objetos 
cercanos y los cambios que se produzcan en estos objetos”, en forma similar, Brown [12] define al 
contexto como “localización, identidad de las personas que rodean al usuario, hora del día, 
estación del año, temperatura, etc.”. Ryan [13] lo presenta como “la localización del usuario, el 
entorno físico, la identidad y la hora”. Siguiendo esta línea, en cuanto a la percepción de los 
elementos que deben ser considerados parte del contexto, Dey [14], en 1998, brinda una definición 
más completa, donde ve al contexto como “el estado emocional del usuario, el foco de atención, la 
localización y orientación, fecha y hora, y las personas que componen el entorno del usuario”.  
Todas estas  definiciones enumeran los “elementos”, que para el autor, tendrían que formar parte 
del contexto, ahora, ¿qué ocurre si se agrega un nuevo elemento?, ¿como saber si forma o no parte 
del contexto? Un ejemplo de esto podría ser, “servicios disponibles”. Al Agregar un nuevo 
elemento, estas definiciones se vuelven insuficientes y dejan “una zona gris”, por tal motivo es 
necesario encontrar una definición más abstracta y amplia. Brown [15], expreso al contexto como 
“los elementos del entorno del usuario de los que la computadora del usuario es consciente”. Ward 
[16], lo define sencillamente como “el estado del entorno de la aplicación”. Pascoe [17] lo expresa 
como “el conjunto de estados físicos y conceptuales de interés para una entidad particular”. La 
definición de Franklin [18] es sumamente abstracta, caracterizo al contexto como “la situación del 
usuario”.  
Dey en el artículo “Towards a Better Understanding of Context and Context-Awareness” [9], aporta 
una definición desde el punto de vista del desarrollo de software, caracterizando al contexto como: 
“cualquier información que puede ser usada para caracterizar la situación de una entidad. Una 
entidad puede ser una persona, un lugar o un objeto que es considerado relevante para la 
interacción entre el usuario y la aplicación; incluyendo al usuario y la aplicación mismos”. 
4.1.2 Entorno de aplicaciónes context-awareness 
Todos los seres vivos interaccionan constantemente con su entorno. Con múltiples grados de 
complejidad, los organismos son capaces de percibir los cambios que se producen en el entorno que 
los rodea y de reacomodar su comportamiento o su metabolismo para adaptarse a dichos cambios. 
Un cambio que permita a un ser vivo funcionar eficientemente se llama adaptación. El cambio 
adaptativo significa una ventaja para vivir en un entorno concreto. B. Schilit y M. Theimer [19] y 
más tarde (1996), M. Brown [20], todos utilizaron el concepto de “adaptación” y coincidiendo en 
una primera definición que expresaba lo siguiente: “una aplicación de software es sensible al 
contexto si puede adaptarse, percibir o responder ante los cambios en el entorno”. Con el tiempo a 
las aplicaciones context-awareness se les atribuyeron términos como: “reactivas” [20], “obedientes” 
[21], “situadas” [22], “sensible al contexto” [23] y “dirigidas por el ambiente” [24]. Kortuem [25], 
tomo algunos de estos conceptos y definió este tipo de aplicaciones como “aquellas que pueden 
variar o adaptar dinámicamente su comportamiento en base al ambiente”. Una aplicación que varia 
dinámicamente su comportamiento evidentemente está dirigida o/y es sensible al contexto para 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
432
 poder adaptarse a él. Más adelante, entre 1997-1998, Hull [23] y Pascoe [26, 27, 13] definieron a las 
aplicaciones context-awareness por “la habilidad que poseen los dispositivos computacionales de 
detectar, censar, interpretar y responder a los aspectos del ambiente del usuario”. Dey [14], en 
1998, continua este camino y define la noción de las aplicaciones context-awareness como “el uso 
del contexto para automatizar un sistema de software, modificar su interface y proveer la máxima 
flexibilidad en términos de servicios”. Salber [28] añade “to be the ability to provide maximum 
flexibility of a computational service based on real-time sensing of context”, estas definiciones se 
centran en el conocimiento de determinados aspectos del contexto para brindar flexibilidad de 
servicios al usuario.  
Por otro lado, Ryan [29], define a las aplicaciones context-awareness como “aplicaciones que 
supervisan las entradas provenientes de los dispositivos de censado ambientales y permiten a los 
usuarios seleccionar un determinado contexto físico o lógico de acuerdo a sus intereses o sus 
actividades”. Esta definición es más restrictiva que las anteriores por que identifica el método por el 
cual las aplicaciones actúan sobre el contexto y sobre los intereses del usuario. Siguiendo esta línea, 
Brown [30] expresa, “aplicaciones que automáticamente proporcionan información y/o reaccionan 
de acuerdo contexto actual del usuario que es detectado por los sensores”. Esta definición se centra 
en el contexto del usuario, es decir, toda la información relevante que influya sobre las intensiones 
del usuario; esta información provocan una reacción por parte de la aplicación que se ajusta a ese 
contexto. Este tipo de aplicaciones buscan ser proactivas, anticipándose a las acciones que puede 
llegar a realizar el usuario, un por ejemplo de esto podría ser, modificar la configuración de un 
“layout” grafico, para esto la aplicación deberá, por ejemplo, tener en cuenta aspectos contextuales 
como, la luminosidad del ambiente, el horario, la cantidad de batería restante (si es un dispositivo 
móvil), la actividad que está realizando el usuario en ese momento, etc. 
Finalmente, Dey [31] expresa una aplicación context-awareness como: “aquella que utiliza al 
contexto para proveer información relevante y servicios al usuario, donde la relevancia depende de 
la tarea que está llevando a cabo el usuario”. 
4.2. Funcionalidades de la interfaz context-awareness 
 
Para el entrenamiento de discapacitados audibles se considera las siguientes funcionalidades: 
– Edición y recorrido de contextos para  facilitara  la composición de “Contextos”, (Ej: Un 
contexto podría ser un paseo por el zoológico). El usuario podrá ver el contexto 
completo, con todos los objetos relacionados con el mismo. En este caso los objetos 
serán las distintas imágenes pertenecientes a dicho contexto (Ej: en el caso del 
zoológico, la jaula de los leones, los elefantes, etc). Cada una de estas imágenes será en 
realidad una “imagen de escena”, ya que tendrán asociada una escena dinámica. 
Inicialmente el usuario podrá ver estas imágenes de escena en forma estática, mientras 
recorre el contexto. Cuando pase el mouse sobre alguna de estas imágenes de escenas, se 
reproducirá su nombre, el que podrá percibir con el dispositivo de estimulación, y podrá 
ver la simulación de los labios correspondiente. 
– Cada contexto estará compuesto por al menos una imagen de escena.  
– Cada imagen de escena tendrá asociada una escena dinámica que la representa 
– El usuario podrá hacer clic con el mouse sobre cualquier imagen de escena que desee 
para acceder estas escenas dinámicas.  
– Una escena dinámica, mostrará al elemento seleccionado en movimiento, y reproducirá 
los sonidos correspondientes al mismo. (Ej: la escena dinámica de los leones, podrá 
mostrar un león rugiendo, al mismo tiempo que se reproduce el sonido del rugido. Estos 
sonidos serán percibidos por el usuario a través del dispositivo de estimulación por 
vibraciones). 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
433
 – Las imágenes de escena y las escenas correspondientes, podrían utilizarse como objetos 
visuales y audibles reutilizables en distintos contextos. 
– Selección de contextos preprogramados, con diferentes niveles de dificultad: 
 El usuario tendrá la posibilidad de iniciarse en el uso del programa, con 
contextos previamente cargados. 
 Estos contextos estarán categorizados en distintos niveles de dificultad, que el 
usuario podrá seleccionar según sus preferencias y nivel de experticia alcanzado. 
– Comunicación con una URL física ,como ya se dijo anteriormente, el usuario tendrá la 
posibilidad de descargar información de un objeto real desde una etiqueta RFID, a su 
celular o PDA, y percibir los sonidos de esta información con el dispositivo de 
estimulación por vibraciones 
– Posibilidad de acceder a nuevos contextos existentes en la web a través de disponibilidad 
en el futuro de sitios con contextos para discapacitados auditivos, disponibles en internet  
– Manejo personalizado de la información de los usuarios considerando que cada usuario 
se podrá registrar en el sistema, indicando su nivel de discapacidad, así como su nivel de 
experticia alcanzada en el uso del dispositivo, 
– Historial asociado a cada usuario que contenga información relacionada con los 
entrenamientos realizados, incluyendo parámetros de seleccionados, y desempeño 
obtenido, como así también la información de los instructores que guían a cada usuario. 
4.3. Diagrama de clases UML 
 
 A continuación se incluye un diagrama UML detallado en la figura 3, que representa  en forma 
preliminar el modelo propuesto. El contexto del diagrama, representa al contexto que el usuario 
podrá visualizar y recorrer en forma global, hasta seleccionar una escena determinada. Las escenas 
estarán compuestas por al menos uno, o varios objetos (virtuales) de actuación, por ejemplo en el 
caso de una escena de autos, los objetos de actuación serán autos pero seguramente también habrá 
transeúntes, motos, etc. Dependiendo del contexto en que se desarrolle una determinada escena, 
serán los sonidos correspondientes a cada objeto de actuación, por ejemplo, en un contexto en el 
cual un automóvil está en un embotellamiento, el sonido asociado será el de la bocina 
En cambio por ejemplo en otro  contexto, en el que un animal se cruza repentinamente delante del 
camino de un auto, el sonido asociado será el de una frenada. Por otra parte, se hace una distinción 
en los distintos sonidos que pueden existir. Por un lado tendremos sonidos ambientales, que serán 
por ejemplo el maullido de un gato, el sonido del motor de un auto, el beep de un horno 
microondas, etc. Y por otro lado, tendremos los sonidos lingüísticos correspondientes a vocales y 
consonantes. 
Además, existirán algunos objetos virtuales de actuación, para los que haya una correspondencia 
con un objeto real de actuación. El usuario podría estar en su casa recorriendo un contexto virtual, y 
viendo distintos objetos de actuación. Pero también podría ser que por ejemplo estuviera 
recorriendo un zoológico en donde los objetos serían reales, y sobre los cuales, si tienen etiquetas 
RFID, podría descargar información  y sonidos a su celular o PDA, al mismo tiempo que podría  
percibir los sonidos  con su dispositivo de estímulos por vibraciones 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
434
  
Figura 3: Diagrama de clases UML 
 
.  
4.4. Modelo  Genérico del Entrenador 
 
Considerando el modelo presentado por J Ierache, M Bruno [6] constituido por un mundo real, un 
mundo virtual y un mundo constructivo basado en [7] y los principios relacionados con la 
conformación del comportamiento descrito, se elabora el modelo de entrenador propuesto en la 
figura 4  “Modelo genérico del entrenador”, el que se detalla a continuación: 
 
– Dentro del mundo real se encontrarán los objetos reales de actuación. Suponiendo que el 
usuario está recorriendo un zoológico, y está viendo la jaula de las aves, los objetos reales de 
actuación en este caso serán las aves de la jaula (por ejemplo loros cacatúas, papagayos, 
etc).  
– Dentro del mundo virtual, estarán los objetos virtuales de actuación, representados por 
información, imágenes digitales (por ejemplo, siguiendo el caso del paseo por el zoológico, 
fotos de loros, cacatúas, papagayos, etc). 
– En el mundo constructivo, se encontrarán todas las escenas, tanto virtuales como reales. Este 
mundo constructivo, es el que permite integrar a los objetos dentro de escenas que el usuario 
puede luego recorrer. 
 
Por otra parte, existen escenas reales que son implícitas, se producen cuando el usuario está en una 
determinada situación, en donde puede percibir sonidos generados por una escena real. (Por 
ejemplo, el usuario está frente a la jaula de las aves, y percibe los sonidos que estas producen, o está 
bajando la información y sonido de una URL física de una etiqueta RFID, a un dispositivo móvil, 
para enviarla al dispositivo de estimulación por vibraciones). Estas escenas reales, se ubican entre el 
mundo constructivo y el mundo real, ya que posee elementos de ambos. Las escenas virtuales, son 
explícitas. Están ubicadas entre el mundo virtual y el mundo constructivo. Son las escenas creadas a 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
435
 propósito, para que el usuario pueda acceder a las mismas en la PC o en un dispositivo móvil, y 
percibir sus sonidos por medio del dispositivo de estimulación por vibraciones. Entre el mundo real 
y el mundo virtual se encuentran los sonidos, que podrán ser ambientales o lingüísticos, como ya se 
dijo anteriormente. Por último, el contexto se encuentra en la intersección de los tres mundos. El 
contexto contendrá distintas escenas, que podrán ser reales o virtuales, dependiendo de si el usuario 
está recorriendo un lugar físico y percibiendo sus sonidos, o si está accediendo a través de una PC o 
de un dispositivo móvil a alguno de los escenarios virtuales creados. 
 
 
Figura 4: Modelo genérico del  entrenador  
 
5. CONCLUSIONES 
 
La Concepción y Desarrollo de Software Sensible al Contexto [8], facilitó la elaboración de un 
modelo preliminar para el entrenamiento de discapacitados con déficit auditivo severo en diferentes 
contextos y escenas, como así también el empleo de interfaces hápticas y el potencial uso de URL 
físicas que permiten enriquecer las capacidades de explotación  de los  sonidos contextuales a través 
de interfaces hápticas. 
 
La propuesta que conforma el contexto a partir de la interacción de situaciones del mundo real, 
constructivo y el  virtual presentan un potencial para el crecimiento de capacidades para el 
entrenamiento del discapacitado. 
 
Futuras actividades deberán centrarse en el desarrollo de un framework de simulación, la 
integración con los dispositivos hápticos, la integración de estos con dispositivos móviles.  
 
6.
