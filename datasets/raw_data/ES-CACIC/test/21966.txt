SSSTree v2 0 búsqueda por similitud en espacios métricos con solapamientos de planos
﻿. Sparse Spatial Sele
tion is a new pivot-based stru
ture for similarity sear
h in metri
 spa
es. It
is a array-type stru
ture whi
h has shown a good sear
h performan
e when 
ompared with other sele
tion
methods.
This work 
onsiders SSS as a general method for pivot or 
enter sele
tion and des
ribes the building of a new

lustering-based metri
 stru
ture organized as a tree built using SSS. Experimental results show that it presents
a better performan
e, in terms of the number of evaluations of the distan
e fun
tion, than other well-known
stru
tures.
Keywords: Databases, data stru
tures, algorithms, metri
 spa
es, similarity queries.
Resumen Sparse Spatial Sele
tion es una nueva estru
tura basada en pivotes para búsqueda por similitud
en espa
ios métri
os. Esta estru
tura es del tipo arreglo y ha demostrado un buen rendimiento durante la
búsqueda 
omparado 
on otros métodos de sele

ión.
El presente trabajo 
onsidera al SSS 
omo un método general para la sele

ión de 
entros o pivotes y des
ribe la

onstru

ión de una nueva estru
tura métri
a, basada en 
lustering y del tipo árbol la que es 
onstruida usando
SSS. Los resultados experimentales demuestran que tiene mejor desempeño, en términos de evalua
iones de
distan
ia, que mu
has otras estru
turas 
ono
idas.
Palabras 
laves: bases de datos, estru
turas de datos, algoritmos, espa
ios métri
os, 
onsultas por similitud.
1. Introdu

ión
1.1. Ante
edentes
Uno de los problemas de gran interés en 
ien
ias de la 
omputa
ión es el de búsqueda por
similitud, es de
ir, en
ontrar los elementos de un 
onjunto más similares a una muestra. Esta
búsqueda es ne
esaria en múltiples apli
a
iones, 
omo ser en re
ono
imiento de voz e imagen,

ompresión de video, genéti
a, minería de datos, re
upera
ión de informa
ión, et
. En 
asi todas
las apli
a
iones la evalua
ión de la similitud entre dos elementos es 
ara, por lo que usualmente se
trata 
omo medida del 
osto de la búsqueda la 
antidad de similitudes que se evalúan.
Interesa el 
aso donde la similitud des
ribe un espa
io métri
o, es de
ir, está modelada por una
fun
ión de distan
ia que respeta la desigualdad triangular. En este 
aso, el problema más 
omún y
difí
il es en aquellos espa
ios de alta dimensión donde el histograma de distan
ias es 
on
entrado,
es de
ir, todos los objetos están más o menos a la misma distan
ia unos de otros.
*
Par
ialmente nan
iado por programa de investiga
ión PR-F1-02IC-08, Universidad de Magallanes, Chile y proye
to de
investiga
ión 29/C035/1, Unidad A
adémi
a de Río Turbio, Universidad Na
ional de la Patagonia Austral, Argentina.
El aumento de tamaño de las bases de datos y la apari
ión de nuevos tipos de datos sobre los

uales no interesa realizar búsquedas exa
tas, 
rean la ne
esidad de plantear nuevas estru
turas
para búsqueda por similitud o búsqueda aproximada, esto en bus
a de superar los problemas de las
estruturas existentes hasta ahora. Asimismo, se ne
esita que di
has estru
turas sean dinámi
as,
es de
ir, que permitan agregar o eliminar elementos sin ne
esidad de 
rearlas nuevamente. Así
también, las apli
a
iones reales requieren que di
has estru
turas permitan ser alma
enadas en
memoria se
undaria e
ientemente, 
omo también que posean métodos optimizados para redu
ir
los 
ostos de a

esos a dis
o. Adi
ionalmente, el método elegido en las estru
turas para la ele

ión
de 
entros y pivotes resulta relevante al momento de des
artar elementos durante la búsqueda.
1.2. Mar
o Teóri
o
La similitud, en mu
hos 
asos, es modelada a través de un espa
io métri
o y la búsqueda de
objetos más similares bajo una fun
ión 
onveniente de similitud, a través de una búsqueda por
rango o ve
inos más 
er
anos.
Deni
ión 1 (Espa
ios Métri
os): Un espa
io métri
o es un 
onjunto X 
on una fun
ión de
distan
ia d : X2 → R, tal que ∀x, y, z ∈ X,
1. d(x, y) ≥ 0 and d(x, y) = 0 ssi x = y. (positividad)
2. d(x, y) = d(y, x). (Simetría)
3. d(x, y) + d(y, z) ≥ (d(x, z). (Desigualdad Triangular)
Deni
ión 2 (Consulta por Rango): Sea un espa
io métri
o (X,d), un 
onjunto de datos nito
Y ⊆ X, una 
onsulta x ∈ X, y un rango r ∈ R. La 
onsulta de rango alrededor de x 
on rango
r es el 
onjunto de puntos y ∈ Y, tal que d(x, y) ≤ r.
Deni
ión 3 (Los k Ve
inos más Cer
anos): Sea un espa
io métri
o (X,d)un 
onjunto de
datos nito Y ⊆ X, una 
onsulta x ∈ X y un entero k. Los k ve
inos más 
er
anos a x son un
sub
onjunto A de objetos de Y, donde la |A| = k y no existe un objeto y ∈ A tal que d(y,x)
sea menor a la distan
ia de algún objeto de A a x.
La implementa
ión trivial de la búsqueda por similitud 
onsiste en 
omparar la 
onsulta 
on
todos los objetos de la 
ole

ión. El problema es que, en general, la evalua
ión de la fun
ión
de distan
ia tiene un 
oste 
omputa
ional elevado que ha
e que la búsqueda se
uen
ial sea muy
ine
iente. Esto ha dado lugar a una gran 
antidad de trabajos en indexa
ión y búsqueda en
espa
ios métri
os, que tratan de ha
erla más e
iente y poder así apli
arla en grandes 
ole

iones
de datos. El objetivo de los algoritmos de indexa
ión es redu
ir el número de evalua
iones de la
fun
ión de distan
ia durante los pro
esos de búsqueda, aunque pagando algún 
osto adi
ional en el
pro
eso de 
onstru

ión. Esto se logra manteniendo en el índi
e informa
ión que, dada la 
onsulta,
permita des
artar una gran 
antidad de objetos sin 
ompararlos dire
tamente 
on la 
onsulta. Para
ello se utilizan las propiedades de espa
ios métri
os 
omo la desigualdad triangular.
Existen dos grandes enfoques que determinan los algoritmos de búsqueda en espa
ios métri
os
generales:
Algoritmos Basados en Pivotes : En los algoritmos basados en pivotes se sele

iona un

onjunto de k pivotes {p1, p2, . . . , pk} ∈ Y. En tiempo de indexamiento, para 
ada objeto x
de la base de datos Y se 
al
ula y alma
ena su distan
ia a los k pivotes (d(x, p1), . . . , d(x, pk)).
Si para algún pivote pi no se 
umple (1), enton
es por desigualdad triangular se 
ono
e que
d(q, x) > r y por lo tanto, no es ne
esario evaluar expli
itamente d(x, q). Todos los objetos que
no se puedan des
artar por esta regla deben ser 
omparados dire
tamente 
on la 
onsulta.
|d(q, pi) − d(x, pi)| ≤ r, ∀i = i...k (1)
Algoritmos Basados en Clustering : Los algoritmos basados en 
lustering dividen el espa
io
en áreas, donde 
ada área tiene un 
entro o split. Se alma
ena alguna informa
ión sobre el área
que permita des
artarla 
ompletamente mediante sólo 
omparar la 
onsulta 
on su 
entro.
Existen varios 
riterios para determinar las áreas en las estru
turas basadas en 
lustering:
Criterio de parti
ión de Voronoi: Se sele

iona un 
onjunto de puntos y se 
olo
a 
ada punto
restante dentro de la región 
on el 
entro más 
er
ano. Las áreas se delimitan 
on hiperplanos
y las zonas son análogas a las regiones de Voronoi en espa
ios ve
toriales.
Deni
ión (Diagrama de Voronoi): 
onsiderese un 
onjunto de puntos {c1, c2, ..., cm}
(
entros). Se dene el diagrama de Voronoi 
omo la subdivisión del plano en m áreas, por

ada ci. La q pertene
e al área si y sólo si la distan
ia eu
lidiana d(q, ci) ≤ d(q, cj) para 
ada
cj, 
on j 6= i.
Durante la búsqueda se evalúa d(q, c1), ..., d(q, cm), se elige 
omo 
entro ci más 
er
ano y se
des
artan todas las zonas cj que 
umplan 
on d(q, cj) > d(q, ci) + 2r, dado que su área de
Voronoi no puede interse
tar la bola de 
onsulta 
on 
entro q y radio r. Se entiende por bola
de 
onsulta al 
onjunto de objetos que está a distan
ia máxima r de q.
Criterio de radio 
obertor: El radio 
obertor rc(ci) es la distan
ia entre el 
entro ci y el objeto
más alejado dentro de su zona. Enton
es se puede des
artar la zona ci si d(q, ci) − r > rc(ci).
Algunas estru
turas 
ombinan estas té
ni
as, 
omo el 
aso del GNAT [1℄. Otras sólo utilizan radio

obertor, 
omo los M-trees [3℄, Lista de Clusters [2℄. Algunas que utilizan hiperplanos son GHT y
sus variantes [8,6℄ y los Vorinoi trees [4,5℄.
Por lo general, las estru
turas diseñadas para realizar búsquedas por similitud en espa
ios
métri
os no denen un 
riterio para sele

ionar 
entros o pivotes. Sin embargo, una buena ele

ión
de un 
onjunto 
entros o pivotes puede aumentar el rendimiento en los pro
esos de búsqueda.
En el siguiente trabajo se presenta un estru
tura métri
a diseñada en términos de los 
entros
sele

ionados, para ello se utiliza 
omo base un método de sele

ión de 
entros o pivotes denominado
SSS .
2. Sparse Spatial Sele
tion Tree (SSSTree)
2.1. Sparse Spatial Sele
tion (SSS)
Sparse Spatial Sele
tion [7℄ es un nuevo método de búsqueda basado en pivotes. El prin
ipal
aporte de este método es la estrategia de sele

ión de pivotes. A diferen
ia de otros, en los que
los pivotes de referen
ia se eligen de forma aleatoria, éste método sele

iona un 
onjunto dinámi
o
de pivotes bien distribuidos en el espa
io, lo que permite des
artar más objetos al momento de
realizar el pro
eso de búsqueda. Además el 
onjunto de pivotes es dinámi
o, en el sentido de que
es 
apaz de adaptarse al 
re
imiento de la base de datos sin que su e
ien
ia quede redu
ida.
Estrategia de sele

ión de pivotes Sea (X, d) un espa
io métri
o, Y ⊂ X y M la distan
ia
máxima entre dos objetos 
ualesquiera, M = max{d(x, y)/x, y ∈ Y}. Ini
ialmente el 
onjunto de
pivotes está formado por el primer elemento de la 
ole

ión. Después, 
ada elemento xi ∈ Y se
sele

iona 
omo pivote si y sólo sí está a una distan
ia mayor o igual a M ∗ α de todos los pivotes
ya sele

ionados, siendo α una 
onstante 
uyos valores óptimos están en torno a 0.4 [7℄. Es de
ir,
un objeto de la base de datos se toma 
omo pivote si está situado a más de una fra

ión de la
distan
ia máxima de todos los pivotes (ver algoritmo 1 y gura 1).
Algoritmo 1 Sele

ión de Pivotes
PIV OTES ⇐ {x1}
for all xi ∈ Y do
if ∀ p ∈ PIV OTES, d(xi, p) ≥ M ∗ α then
PIV OTES ⇐ PIV OTES ∪ {xi}
end if
end for
MM
d
C
C
C
C
C
d
C
Figura 1. Representa
ión de un espa
io métri
o. M : distan
ia entre los dos objetos más alejados
de la base de datos, la distan
ia entre los pivotes (d) es siempre mayor a M * α.
2.2. Sparse Spatial Sele
tion Tree Versión 1.0
SSSTree v1.0 es un árbol basado en 
lustering, que divide el espa
io a través de Parti
iones de
Voronoi y utiliza SSS para sele

ionar los 
entros para 
ada nodo. Además utiliza bolsas o bu
kets
auxiliares para poder 
al
ular el valor del parámetro M . El valor de M es ne
esario para poder
dividir el espa
io sin que éste quede sobredimensionado y así obtener un mayor rendimiento en los
pro
esos de búsqueda. Las bolsas o bu
ket también son utilizadas para alma
enar los objetos que
no son 
entros y luego reinsertarlos sobre la Parti
ión de Voronoi a la que pertene
en.
La prin
ipal desventaja de éste método es que al momento de 
al
ular el valor del parámetro M
y al reinsertar los objetos restantes sobre la Parti
ion de Voronoi a la que pertene
en se realizan
una gran 
antidad de evalua
iones de distan
ia ha
iendo sumamente ine
iente la 
onstru

ión
y/o reinser
ión de objetos sobre la estru
tura.
3. Sparse Spatial Sele
tion Tree 
on Solapamiento de Planos
El presente trabajo 
onsidera al SSS 
omo método general de sele

ión de 
entros tanto 
omo
de pivotes. El artí
ulo presenta al SSSTree v2.0, que es una estru
tura métri
a del tipo árbol basada
en 
lustering o parti
iones 
ompa
tas en la 
ual la ele

ión de 
entros para 
ada nodo es efe
tuada
por medio de la té
ni
a SSS y además utiliza en 
riterio de radio 
obertor para delimitar 
ada
subespa
io. Lo interesante de ésta estru
tura es que no es ne
esario la utiliza
ión de estru
turas
auxiliares durante el pro
eso de 
onstru

ión(a diferen
ia de la versión 1.0).
3.1. Constru

ión
Ini
ialmente, se extráe un objeto de la base de datos, posteriormente se 
rea un nodo va
ío,
di
ho objeto es 
onsiderado 
omo primer 
entro del nodo y se alma
ena el valor M ∗α 
omo radio

obertor del subespa
io al 
ual representa di
ho objeto. Luego, para 
ada objeto de la base de
datos se 
al
ula su distan
ia a 
ada uno de los 
entros, si la distan
ia a 
ada uno de los 
entros es
mayor a M ∗ α el objeto es 
onsiderado 
omo un nuevo 
entro para el nodo anteriomente 
reado,
de lo 
ontrario, se inserta en el primer 
luster 
uya distan
ia al 
entro sea menor o igual a M ∗ α,
respetando el orden de inser
ión de 
entros en di
ho nodo.
Finalmente, este pro
eso se realiza re
ursivamente para 
ada subespa
io hasta que todos objetos
de la base de datos se han insertado en algún nodo.
Esto puede 
ausar prin
ipalmente que un subespa
io tenga 
on
entrado una gran 
antidad de
objetos en 
ompara
ión a los subespa
ios 
ontiguos, 
omo se puede apre
iar en la Figura 2.
r = M * alfa
r = M * alfa
r = M * alfa
r = M * alfa
r = M * alfa
r = M * alfa
r = M * alfa
Figura 2. Solapamiento de Subespa
ios.
3.2. Estima
ión del Cál
ulo de M para los Subespa
ios
Como M es la distan
ia entre los dos objetos más alejados del espa
io, se 
umple que M ≤ 2∗RC
, donde el radio 
obertor RC es la distan
ia entre el 
entro y el objeto más alejado a éste en el
mismo subespa
io. Esta desigualdad es útil porque permite eliminar el 
ál
ulo de M (Pruebas de
esto se realizaron sobre el egnat 
on ex
elente resultados, no publi
ado).
MRC
RC
Figura 3. Optimiza
ión para el 
ál
ulo de M .
Como se puede apre
iar en la gura anterior, si se utiliza 2 ∗RC 
omo diámetro de la región,
también se logra abar
ar los mismos objetos 
omo al utilizar M 
omo diámetro. Como el valor de
2∗RC supera o iguala al valor M , 
ubre una región más amplia, esto puede afe
tar la distribu
ión de
los 
entros lo 
ual puede perjudi
ar la búsqueda, sin embargo, disminuye los 
ostos de 
onstru

ión.
3.3. Búsqueda
Para des
artar áreas durante la búsqueda, el SSSTree utiliza el 
riterio de radio 
obertor:
El radio 
obertor rc(ci) es la distan
ia entre el 
entro ci y el objeto más alejado dentro de su
zona. Enton
es, se puede des
artar 
ompletamente la zona ci si d(q, ci) − r > rc(ci).
La gura 6 muestra los resultados experimentales para la búsqueda en ambos espa
ios. En el
espa
io de Gauss, los valores gra
ados 
orresponden a los rangos que permiten re
uperar el 0,01,
el 0,1 y el 1%.
De los grá
os de búsqueda se puede ver 
laramente que el nuevo método aventaja a las
estru
turas MTree, GNAT y EGNAT. En el espa
io de Gauss el SSSTree tiene un desempeño
similar o mejor al EGNAT para menores radios de búsqueda, pero de
re
e 
on el aumento de los
radios de búsqueda, es de
ir, en el espa
io de palabras, 
uya dimensión intrínse
a es elevada,
la nueva estru
tura se 
omporta mejor que para dimensiones más bajas, logrando diferen
ias
extremadamente notorias. La gura 7 muestra los resultados 
omparativos 
on el EGNAT para
dos espa
ios de imágenes.
3.4. Datos Experimentales
Para validar el 
omportamiento y e
ien
ia de la estru
tura formulada en este trabajo, se han
realizado diversas pruebas, 
on distintas 
ole

iones de objetos. A 
ontinua
ión se des
ribirán las

ole

iones de datos utilizadas en las distintas pruebas.
Cole

ión de palabras: En este 
aso se trata de un espa
io métri
o real, una 
ole

ión de 86.061
palabras extraídas del di

ionario español.
Espa
ios ve
toriales sintéti
os: Cole

ión de 100.000 ve
tores de dimensión 10, 
reados
sintéti
amente, 
on distribu
ión gaussiana.
Cole

iones de imágenes: La primera es una 
ole

ión de 40.700 imagenes extraídas de los
ar
hivos de imágenes y videos de la NASA. La segunda 
ole

ión 
orresponde a 1.000 imágenes
representadas 
omo ve
tores de dimensión 3.084.
Los experimentos fueron realizados para 
ada versión de la estru
tura 
on 
ada espa
io des
rito
anteriormente. Además, los pro
esos de 
ostru

ión son realizados utilizando el 90% del total de los
objetos de 
ada base de datos y los pro
esos de búsqueda son realizados utilizando 
omo 
onsultas
el 10% restante.
3.5. Resultados Experimentales Preliminares
Resultados de Constru

ión En esta se

ión se presentan resultados de pruebas preliminares
que 
omparan el rendimiento de la 
onstru

ión del SSSTree v2.0 en 
ompara
ión a su versión
anterior.
 0
 5e+07
 1e+08
 1.5e+08
 2e+08
 2.5e+08
 3e+08
 3.5e+08
 4e+08
 0  10  20  30  40  50  60  70  80  90
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Porcentaje de construcción
Costo de Construcción Total (86061, dic. español)
ssstree v1.0
ssstree v2.0
(a) Di

ionario en Español.
 0
 1e+08
 2e+08
 3e+08
 4e+08
 5e+08
 6e+08
 7e+08
 8e+08
 0  10  20  30  40  50  60  70  80  90
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Porcentaje de Construcción
Costo de Construcción (n=100000, gauss dim 10)
ssstree v1.0
ssstree v2.0
(b) Gauss Dimensión 10.
 0
 5e+06
 1e+07
 1.5e+07
 2e+07
 2.5e+07
 3e+07
 3.5e+07
 4e+07
 0  10  20  30  40  50  60  70  80  90
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Porcentaje de Construcción
Costo de Construcción (n=40700, Vectores Dim 20)
ssstree v1.0
ssstree v2.0
(
) Ve
tores Dimensión 20.
 0
 100000
 200000
 300000
 400000
 500000
 600000
 700000
 0  10  20  30  40  50  60  70  80  90
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Porcentaje de Construcción
Costo de Construcción (n=1000, Vectores Dim 3084)
ssstree v1.0
ssstree v2.0
(d) Gauss Dimensión 3084.
Figura 4. SSSTree: Grá
os 
omparativos para la 
onstru

ión (SSSTree v2.0 y SSSTree v1.0).
Como se puede apre
iar en la gura 4, la nueva versión logra redu
ir 
onsiderablemente los

ál
ulos de distan
ia durante los pro
esos de 
onstru

ión en 
ompara
ión a la versión anterior.
Resultados de Búsqueda En esta se

ión se presentan resultados de pruebas preliminares que

omparan el rendimiento de la búsqueda del SSSTree v2.0 en 
ompara
ión a su su versión anterior.
 5000
 10000
 15000
 20000
 25000
 30000
 35000
 40000
1 2 3 4
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Rango de Búsqueda
Costo Promedio de Búsqueda (n=86061, dic. español)
ssstree v1.0
ssstree v2.0
(a) Di

ionario en Español.
 20000
 30000
 40000
 50000
 60000
 70000
 80000
0.01 0.10 1.00
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Rango de Búsqueda
Costo Promedio de Búsqueda (n=100000, gauss dim 10)
ssstree v1.0
ssstree v2.0
(b) Gauss Dimensión 10.
 18000
 20000
 22000
 24000
 26000
 28000
0.01 0.1 1
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Rango de Búsqueda
Costo Promedio de Búsqueda (n=40700, Vectores Dim 20)
ssstree v1.0
ssstree v2.0
(
) Ve
tores Dimensión 20.
 63000
 63500
 64000
 64500
 65000
 65500
 66000
 66500
 67000
0.10 1.00
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Rango de Búsqueda
Costo Promedio de Búsqueda (n=1000, Vectores Dim 3084)
ssstree v1.0
ssstree v2.0
(d) Gauss Dimensión 3084.
Figura 5. SSSTree: Grá
os 
omparativos para la búsqueda (SSSTree v2.0 y SSSTree v1.0).
Como se puede apre
iar en los grá
os 5(a), 5(b) y 5(
), la 
antidad de evalua
iones de distan
ia
es similar a su versión anterior, en 
ambio en el grá
o 5(d) 
orrespondiente a las imágenes
de dimensión 3084 la diferen
ia es mayor, esto debido probablemente a que los objetos de este
espa
io están más 
on
entrados y al estimar el valor de M 
ada subespa
io queda ampliamente
sobredimensionado.
A 
ontinua
ión se presentan resultados de pruebas preliminares que 
omparan el rendimiento
del SSSTree 
on solapamiento en el pro
eso de búsqueda 
on otras estru
turas basadas en 
lustering

ono
idas.
 10000
 20000
 30000
 40000
 50000
 60000
 70000
4321
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Rango de Búsqueda
Costo Promedio de Búsqueda (n=86061, dic. español)
ssstree v2.0
egnat
gnat
mtree
(a) Di

ionario en Español.
 20000
 30000
 40000
 50000
 60000
 70000
 80000
0.01 0.10 1.00
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Rango de Búsqueda
Costo Promedio de Búsqueda (n=100000, gauss dim 10)
ssstree v2.0
egnat
gnat
mtree
(b) Gauss Dimensión 10.
Figura 6. SSSTree: Grá
os 
omparativos para la búsqueda (MTree v/s GNAT v/s EGNAT v/s
SSSTree).
 18000
 20000
 22000
 24000
 26000
 28000
10.10.01
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Rango de Búsqueda
Costo Promedio de Búsqueda (n=40700, Vectores Dim 20)
ssstree v2.0
egnat
(a) Ve
tores Dimensión 20.
 66000
 68000
 70000
 72000
 74000
 76000
 78000
 80000
 82000
0.10 1.00
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Rango de Búsqueda
Costo Promedio de Búsqueda (n=1000, Vectores Dim 3084)
ssstree v2.0
egnat
(b) Gauss Dimensión 3084.
Figura 7. SSSTree: Grá
os 
omparativos para la búsqueda (EGNAT v/s SSSTree).
Como se puede apre
iar en los grá
os 6 y 7, esta nueva implementa
ión del SSSTree mantiene
los buenos resultados obtenidos en 
ompara
ión a otras estru
turas ya 
ono
idas 
omo son el
GNAT, EGNAT y MTree.
3.6. Otras Té
ni
as Apli
adas
Una té
ni
a utilizada en [9℄ 
on buenos resultados, fue 
ombinar el uso de la Distan
ia al
Padre al estilo de estru
turas basadas en pivotes. En este 
aso, 
ada nodo alma
ena la distan
ia al

entro del plano al que pertene
en, 
on el objetivo de dis
riminar adi
ionalmente objetos durante
la búsqueda utilizando la desigualdad (1).
Una segunda té
ni
a que es posible utilizar en SSSTree 
on Solapamiento de Planos, es
el uso de Propiedades de la Lista de Clusters [2℄. Mediante la utiliza
ión de esta té
ni
a es
posible dis
riminar todos los 
lusters 
ontiguos, siempre y 
uando la 
onsulta esté 
ompletamente

ontenida en un úni
o 
luster (ver gura 8).
rq
rq
rqq1
q2
q3
rc
center
Figura 8. Propiedades de la Lista de Clusters.
Como experimentalmente, tanto 
omo la utiliza
ión de la Distan
ia al Padre, 
omo las
Propiedades de Lista de Cluster, permitieron disminuir la 
antidad de evalua
iones de distan
ia en
los pro
esos de búsqueda en 
ompara
ión a su implementa
ión original, se de
idió utilizar estas
dos propiedades 
ombinadas para obtener mejores resultados(ver gura 9).
 5000
 10000
 15000
 20000
 25000
 30000
 35000
1 2 3 4
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Rango de Búsqueda
Costo Promedio de Búsqueda (n=86061, Diccionario Español)
SSSTree v2.0 alfa 0.3
SSSTree v2.0LCDP alfa 0.3
(a) Di

ionario en Español.
 25000
 30000
 35000
 40000
 45000
 50000
0.01 0.1 1
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Rango de Búsqueda
Costo Promedio de Búsqueda (n=100000 Gauss Dim 10)
SSSTree v2.0 alfa 0.35
SSSTree v2.0LCDP alfa 0.35
(b) Gauss Dimensión 10.
 19000
 20000
 21000
 22000
 23000
 24000
 25000
 26000
0.01 0.1 1
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Rango de Búsqueda
Costo Promedio de Búsqueda (n=40000 Vectores Dim 20)
SSSTree v2.0 alfa 0.3
SSSTree v2.0LCDP alfa 0.3
(
) Ve
tores Dimensión 20.
 35000
 40000
 45000
 50000
0.1 1
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Rango de Búsqueda
Costo Promedio de Búsqueda (n=1000 Vectores Dim 3084)
SSSTree v2.0 alfa 0.45
SSSTree v2.0LCDP alfa 0.45
(d) Gauss Dimensión 3084.
Figura 9. SSSTree: Grá
os 
omparativos para la búsqueda (SSSTree 2.0 v/s SSSTree 
on
Distan
ia al Padre y Propiedad de la Lista de Clusters).
Como se puede apre
iar en la gura 9 los resultados obtenidos en el 
aso de Gauss Dimensión 10
y Ve
tores de Dimensión 20 no varían gran 
antidad en 
ompara
ión a su implementa
ión original.
Pero en el 
aso del Di

ionario Español y sobre todo en el espa
io de Ve
tores de Dimensión
3084 se puede apre
iar una diferen
ia relevante en 
ompara
ión a su versión anterior. Esto es
probablemente debido a que la dimensión intrínse
a de éstos dos últimos espa
ios es más elevada.
4. Con
lusiones
4.1. Aspe
tos Relevantes y Aportes
Una buena ele

ión de pivotes y 
entros durante la 
onstru

ión de estru
turas métri
as
siempre será relevante para los pro
esos de búsqueda. Considerando que los mejores 
entros serán
dependientes del espa
io, es ideal 
ontar 
on me
anismos que permitan re
ole
tar, independiente
de la forma del espa
io, la mejores alternativas de 
entros.
En este sentido, los autores 
onsideran que el método SSS permite, efe
tivamente, obtener un

onjunto ade
uado de 
entros, lo que queda demostrado 
laramente en el presente artí
ulo.
Se 
onsidera que el prin
ipal aporte del presente trabajo es desarrollar una alternativa de

onstru

ión para el SSSTree, la 
ual permite disminuir los 
ostos durante el prepro
eso de datos
sin un aumento 
onsiderable en los 
ostos de búsqueda. La nueva versión de la estru
tura utiliza
de forma natural el método SSS durante el pro
eso de 
ontru

ión. Adi
ionalmente, sobre la nueva
versión fueron apli
adas té
ni
as 
ono
idas en otras estru
turas. La primera fue la de mantener
la distan
ia al padre típi
amente utilizada en estru
turas basadas en pivotes. También fue posible
utilizar una de las propiedades de la estru
tura Lista de Clusters. Todo lo anterior provo
a que
la nueva versión de la estru
tura iguala o mejora el desempeño de los pro
esos de búsqueda en

ompara
ión a la versión original 
omo se muestran en los grá
os de la se

ión 3.6.
Los primeros resultados demuestran lo anterior y propor
ionan una visión de las enormes
ventajas frente a otras estru
turas que son prometedoras.
4.2. Trabajos Futuros
El diseño de esta nueva estru
tura trae 
onsigo desaos que requieren analisis y pruebas 
on
diferentes espa
ios métri
os de baja 
omo alta dimensión, de análisis de las 
apa
idades dinámi
as,
del desempeño en memoria se
undaria, de las mejores alternativas de distribu
ión de la estru
tura,

onsiderando su eje
u
ión en paralelo, entre otros trabajos.
4.3. Agrade
imientos
Al laboratorio de Base de Datos de la Fa
ultad de Informáti
a de la Universidad de la Coruña,
España, en 
onjunto 
on quienes fue ini
ialmente propuesta la estru
tura.
Referen
ias
1. Sergei Brin. Near neighbor sear
h in large metri
 spa
es. In the 21st VLDB Conferen
e, pages 574584. Morgan Kaufmann
Publishers, 1995.
2. E. Chavéz and G. Navarro. An ee
tive 
lustering algorithm to index high dimensional metri
 spa
es. In The 7th
International Symposium on String Pro
essing and Information Retrieval (SPIRE'2000), pages 7586. IEEE CS Press,
2000.
3. P. Cia

ia, M. Patella, and P. Zezula. M-tree : An e
ient a

ess method for similarity sear
h in metri
 spa
es. In the
23st International Conferen
e on VLDB, pages 426435, 1997.
4. F. Dehne and H. Noltemeier. Voronoi trees and 
lustering problems. Informations Systems, 12(2):171175, 1987.
5. H. Noltemeier. Voronoi trees and appli
ations. In International WorkShop on Dis
rete Algorithms and Complexity, pages
6974, Fukuoka, Japan, 1989.
6. H. Noltemeier, K. Verbarg, and C. Zirkelba
h. Monotonous bise
tor* trees - a tool for e
ient partitioning of 
omplex
s
hemes of geometri
 obje
t. In Data Stru
tures and E
ient Algorithms, LNCS 594, pages 186203, Springer-Verlag
1992.
7. Os
ar Pedreira and Nieves R. Brisaboa. Spatial sele
tion of sparse pivots for similarity sear
h in metri
 spa
es. In
SOFSEM 2007: 33rd Conferen
e on Current Trends in Theory and Pra
ti
e of Computer S
ien
e, volume 4362 of Le
ture
Notes in Computer S
ien
e, pages 434445, Harra
hov, Cze
h Republi
, January, 20-26 2007. Springer.
8. J. Uhlmann. Satisfying general proximity/similarity queries with metri
 trees. In Information Pro
essing Letters, pages
40:175179, 1991.
9. Roberto Uribe-Paredes. Manipula
ión de estru
turas métri
as en memoria se
undaria. Master's thesis, Fa
ultad de
Cien
ias Físi
as y Matemáti
as, Universidad de Chile, Santiago, Chile, Abril 2005.
