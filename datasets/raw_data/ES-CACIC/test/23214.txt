Seguridad en sistemas de migración de procesos
﻿
Un sistema distribuido está compuesto de nodos, posiblemente heterogéneos, conectados
mediante una red. Un sistema de esta clase puede utilizarse efectivamente sólo si el software
es capaz de presentar al usuario el concepto de single system image (SSI) sobre el sistema
físicamente distribuido. De esta forma todos los recursos de un nodo deberían poder
accederse transparentemente desde cualquier otro nodo.
En este trabajo se desarrolla la problemática de un protocolo de migración de procesos
como componente fundamental de un sistema distribuido y su extensión al nuevo paradigma de computación: grid computing. Se consideran especialmente los aspectos relacionados
con la seguridad.
Palabras Clave: seguridad, grid computing, clustering, carga compartida, migración de
procesos, sistemas distribuidos.
1 Introducción
El desarrollo de microprocesadores de elevado poder de cómputo y bajo costo y las redes de alta
velocidad propiciaron en las dos últimas décadas un cambio en el paradigma de la computación.
Los grandes mainframes de ayer fueron reemplazados por clusters de pequeñas pero potentes
computadoras conectadas mediante redes de alta velocidad. El usuario, en lugar de trabajar
sobre una terminal boba conectada por un cable serie al mainframe, ahora tiene sobre su
escritorio una poderosa computadora unida a sus pares mediante una red. Potencialmente
todos los recursos que físicamente se encuentran en cualquier computadora están disponibles a
cualquier usuario del sistema. Sin embargo, este potencial no puede aprovecharse completamente
a menos que los usuarios puedan acceder transparentemente a estos recursos. La transparencia,
en este contexto, significa que los usuarios deben ser capaces de acceder a cualquier recurso sin
preocuparse (y de hecho, sin siquiera saber) su ubicación física. Este es el objetivo de un sistema
operativo distribuido, crear la ilusión en la mente de los usuarios de un sistema de tiempo
compartido único en lugar de una colección de máquinas independientes pero conectadas. Esta
ilusión se conoce como Single System Image, SSI [EA03].
*Becario del Consejo Nacional de Investigaciones Científicas y Técnicas, República Argentina.
Algunos de los sistemas más destacados son Amoeba [MvRT+90], Sprite [DO91], MOSIX
[BL98], Condor [DTL04], etc. La mayoría de estos sistemas trabajan corriendo una copia del
mismo sistema operativo en cada computadora participante, y estas copias a su vez, cooperan
para proveer SSI a sus usuarios.
Sin embargo, si bien conceptualmente estos sistemas resultan atractivos, no presentaron
un crecimiento real en su popularidad. Esto se debe principalmente al hecho de que ya existe
una gran cantidad de usuarios y software de base para UNIX; por lo tanto muchos sistemas
distribuidos tratan de emular UNIX para que las aplicaciones existentes sigan funcionando con
pocos o sin modificaciones, manteniendo un entorno de trabajo familiar a los usuarios.
Por otra parte el software de los sistemas distribuidos actuales debe resolver otro problema.
El problema surge debido a que los sistemas distribuidos actuales están compuestos de una
gran variedad de hardware (provisto por diferentes fabricantes) y de software de base (sistema
operativo). Lograr SSI sobre esta heterogeneidad constituye un gran reto. Los sistemas como
Amoeba, etc. no tratan de resolver el problema de la heterogeneidad de sistemas operativos,
simplemente asumen que todas las máquinas participantes del cluster corren el mismo S.O. Hoy
en día existen soluciones parciales a este problema, e.g. SunNFS [SM89] a nivel del sistema de
archivos distribuido con vista unificada. Otro recurso comúnmente compartido en los UNIX
actuales son las impresoras.
Sin embargo el CPU no suele ser compartido transparentemente en los sistemas UNIX. Existen varios estudios que muestran que existe una gran disparidad en la carga de los nodos de un
sistema distribuido en cualquier instante de tiempo. Mientras algunas máquinas están sobrecargadas otras se encuentran completamente ociosas. Es entonces deseable que estas máquinas
puedan compartir la carga y así los usuarios podrían observar una mejora en la performance del
sistema. Si bien existen comandos UNIX a nivel de usuario (e.g. rsh) que les permiten ejecutar
sus procesos remotamente en una máquina a su elección, claramente estos mecanismos no son
transparentes. En un ambiente ideal un usuario debería simplemente ejecutar una tarea y el
sistema automáticamente seleccionar su mejor ubicación (i.e., la máquina menos cargada) para
ejecutarla. Una forma más estricta de carga compartida es el llamado balance de carga, donde
el sistema trata de equiparar la carga de todas las máquinas en todo momento. Mientras que
con carga compartida el sistema simplemente debe seleccionar la mejor máquina para ejecutar
una tarea recientemente disparada y transparentemente transferirla a esa máquina, con balance
de carga típicamente se debería migrar una tarea a otra máquina, posiblemente durante su ejecución. Estas dos formas de migración de procesos se conocen como migración no apropiativa
(o ejecución remota) y apropiativa respectivamente.
Obviamente la migración no apropiativa es más sencilla de implementar que la apropiativa.
Esto se debe a que para implementar migración apropiativa, el sistema debe efectuar un checkpoint en el estado del proceso mientras se encuentra en ejecución y transferir dicho estado
a la máquina destino. Claramente este problema no tiene una fácil resolución si las máquinas
poseen arquitecturas y/o sistemas operativos diferentes, pues el checkpoint debería efectuarse
a nivel del código fuente del programa y no a nivel del código ejecutable. Tui [SH96] es el ejemplo paradigmático de un sistema que permite que procesos en ejecución migren a sistemas con
arquitecturas diferentes. Sin embargo, en este caso el proceso de migración no es transparente
al programa de aplicación, i.e., la aplicación debe colaborar con el software de migración para
que funcione correctamente. Por otra parte la tarea de migración es más costosa en términos de
tiempo, pues la totalidad del estado (que puede ser de tamaño considerable) debe transferirse
a la máquina destino. Hay estudios que muestran que este overhead adicional restringe severamente los beneficios en la performance que pueden obtenerse mediante la migración apropiativa
frente a la no apropiativa [ELZ88]. La ejecución remota no incurre en este costo adicional debido
a que únicamente las tareas recientemente disparadas son transferidas a otras máquinas, y por
lo tanto no hay espacio de direcciones a transferir. Adicionalmente, en este caso, el problema
de la heterogeneidad es más simple de resolver.
La carga compartida trae aparejados dos temas relacionados. El primero se relaciona con
las políticas de migración. Por ejemplo, cuándo debe un nodo tratar de transferir un proceso a
otro nodo, qué proceso debe migrarse y a cuál máquina. El segundo tema está constituido por
los mecanismos de transferencia de procesos, los cuales aseguran que la tarea migrada obtenga
un entorno aproximadamente igual al de la máquina que lo originó.
2 Políticas y mecanismos de migración
La planificación (scheduling) de tareas en un sistema distribuido de carga compartida involucra
decidir no solamente cuándo ejecutar un proceso, sino también dónde ejecutarlo. Para ello la
planificación se lleva a cabo mediante dos componentes: el distribuidor (políticas de distribución) y el planificador (políticas de planificación). El distribuidor decide dónde se ejecutará una
tarea y el planificador dictamina cuándo una tarea recibe su porción de CPU. Típicamente cada nodo de un sistema distribuido tiene su propio planificador responsable de organizar los
procesos en el(los) procesador(es) local(es), mientras que las decisiones de alto nivel de asignar
un proceso a un nodo son tomadas por el distribuidor. Aunque existen pequeñas variaciones
[Ous82], este esquema es el que surge naturalmente en un sistema distribuido. Esto se debe
a dos motivos, el primero es que cada nodo tiene su sistema operativo propio encargado de
planificar procesos, el segundo es la modularidad: los diseñadores pueden concentrarse mejor
en los temas relativamente complejos de la distribución de la carga sin necesidad de involucrarse con los detalles de planificación. Las políticas de distribución tratan de repartir la carga
total del sistema a sus nodos individuales transfiriendo procesos entre los nodos. Las políticas
de planificación simplemente eligen un proceso del conjunto de procesos listos a ejecutarse en
un nodo de forma tal de maximizar el throughput. La política de planificación de procesos de
cualquier sistema operativo tradicional puede funcionar como una política de planificación del
sistema distribuido. En realidad la planificación es efectuada por el S.O. por si mismo y por lo
tanto debemos concentraremos principalmente en la política de distribución.
La semántica de procesos UNIX no es simple de extender a un entorno distribuido debido a
dos razones: el diseño contempla únicamente el caso de un nodo único e independiente, y más
importante aún existe una fuerte relación entre el subsistema de procesos y otros subsistemas
UNIX [Shi97].
3 Seguridad en sistemas de migración de procesos
En esta sección se describe el mecanismo de autenticación de CLEX [Ech05], similar al empleado
por la mayoría de los sistemas con soporte de migración de procesos. Luego se describen mejoras
a este esquema básico de seguridad, soluciones generales que posiblemente pueden aplicarse a
otros sistemas de migración.
3.1 Seguridad en CLEX
3.1.1 Autenticación
La autenticación de un pedido de un cliente se implementa simplemente empleando un mecanismo de ports privilegiados. El cliente de ejecución remota envía un pedido mediante un
socket UDP ligado a un port privilegiado. En todos los sistemas UNIX actuales los números de
port entre 1 y 1023 inclusive constituyen los llamados ports privilegiados y por lo tanto, sólo el
Super Usuario (root) puede emplear estos ports, mediante la llamada a bind() de la librería de
sockets BSD. El servidor controla el número de port de los mensajes y los descarta si no es el
port privilegiado correcto. Esto hace que sea muy difícil que un usuario común accidentalmente
o en forma maliciosa envíe un mensaje falso hacia el servidor sin tener privilegios de administrador (root). Dado que solamente root puede emplear ports privilegiados se producirá un error
cuando legalmente un proceso de usuario trate de hacer un pedido remoto. Para solucionar
este problema1 se le dan capacidades temporales al proceso, mediante la llamada a sistema
setuid(0), mientras ejecuta el bind al port privilegiado. Los servidores de ejecución remota
aceptan los pedidos en el port 3002. La autenticación de un nodo cliente también es realizada
por el servidor. El header de un paquete de pedido contiene el NID (node id) del nodo cliente.
El servidor busca este NID en su base de datos para verificar que esté configurado y habilitado
como nodo del cluster (Subsección 3.1.3). Si no es el caso entonces descarta el pedido. Además
verifica que el NID coincida con el identificador de red (IP) para ese nodo.
3.1.2 Sistema de archivos
El sistema actual no incluye mecanismos criptográficos para el almacenamiento local de la
información, nuevamente asumiendo un entorno de ejecución controlado.
Por otra parte, el protocolo asume la presencia de NFS [SM89], el cual permite preservar la
vista uniforme del sistema de archivos a nivel del cluster. Lo más destacado de esta convención
es que NFS se encuentra presente en todo sistema UNIX actual, característica fundamental
para lograr portar (con relativa facilidad) nuestro protocolo a distintas arquitecturas y sistemas
operativos. Por otra parte, el empleo de un sistema de archivos distribuido existente en lugar
del diseño de uno nuevo acorta los tiempos de implementación.
3.1.3 Base de datos de nodos
El protocolo asume que el cluster de nodos participantes en la distribución de la carga está formado estáticamente y que cada máquina “conoce” todos los miembros del sistema. En cada
nodo se encuentra una lista que contiene todos los nodos (direcciones IP) del cluster. Esta lista
se denomina lista de acceso.
Actualmente el protocolo no soporta configuración dinámica del cluster. Esta limitación
facilita la implementación mientras que al mismo tiempo agrega seguridad, al dificultar el
agregado de nodos “hostiles” al cluster. Sin embargo dada la falta de mecanismos seguros de
autenticación, todavía es posible que un nodo “hostil” forme parte del cluster, sólo necesita
reemplazar (suplantar) a un nodo perteneciente a la lista de acceso, para ello debe simplemente
provocarle un DoS (Denial of Service) y luego tomar su dirección IP.
1Este tipo de problemas fue habitual incluso en los primeros sistemas UNIX, y por ello desde fines de la
década de 1970 se incluyó la llamada a sistema setuid(0) en System V (versión 7) para solucionarlo.
2La elección del port 300 se debe simplemente a que dicho port no se encuentra asociado a ningún otro
servicio.
3.1.4 Mensajes
El protocolo CLEX define un conjunto de mensajes a partir del cual los nodos del cluster
se comunican para implementar el sistema propuesto. Cada mensaje tiene un contenido y un
propósito específico y pertenece a una de las siguientes tres clases: pedido, respuesta, asincrónico. Un nodo A envía un mensaje de pedido a un nodo B cuando necesita que B haga alguna
operación para él. Al recibir el pedido, B lleva a cabo la tarea especificada por el protocolo y envía un mensaje de respuesta conteniendo el resultado de la operación. Los mensajes
asincrónicos se envían a un nodo B para notificar acerca de un evento de interés para B. Estos
mensajes no tienen respuesta. La operación llevada a cabo por un nodo luego de recibir un
pedido o una notificación puede en ciertos casos ser idempotente, es decir el efecto de efectuar
esta operación una vez es equivalente a hacerlo más de una vez. Por el contrario el efecto de
una operación no idempotente puede variar si se ejecuta más de una vez. Por ejemplo el envío
de una señal a un proceso constituye una operación no idempotente, pues el efecto de la señal
puede no ser el mismo si el proceso la recibe más de una vez. La idempotencia cumple un rol
muy importante en el ámbito de la tolerancia a fallas. La descripción general de un mensaje
incluye a los potenciales emisor y receptor del mensaje, la ocurrencia del envío de un mensaje,
la acción del receptor luego de recibir el mensaje, y el comportamiento tanto del receptor como
del emisor en caso de producirse una falla.
Formato de los paquetes de pedido y de respuesta
El formato de los paquetes de pedido y de respuesta se muestra en la Figura 1. Los primeros
cinco campos de los paquetes constituyen el encabezado (header) de los mismos.
Long. Total Id Nodo No. Era No. Sec. Id Msj. ... Resto del Msj.
Encabezado de los mensajes de pedido
Long. Total Id Nodo No. Era No. Sec. Id Msj. Código Error ... Resto del Msj.
Encabezado de los mensajes de respuesta
Figura 1: Encabezado de los mensajes de pedido y de respuesta
El Id Nodo es el identificador del nodo que hace el envío. El servidor, del lado del nodo
receptor, valida el Id Nodo buscándolo en la base de datos de nodos del cluster (una entrada
por cada nodo del sistema). El Número de Era tiene como objetivo preservar la unicidad de
los PIDs ante la presencia de fallas. El Número de Secuencia es empleado también para el
control de errores, por ejemplo para detectar mensajes duplicados. El Id Msj es el identificador
del mensaje transmitido en el pedido. Para ensamblar la respuesta el servidor copia el header
del paquete de pedido en el paquete de respuesta. El cliente, luego de recibir la respuesta,
la valida comparando el Id Nodo, Número de Era y Número de Secuencia que contiene con
aquellos enviados en el paquete de pedido. El resultado de la operación solicitada es enviado
por el servidor en el campo Código Error del mensaje de respuesta. Los datos específicos de
los mensajes de pedido y respuesta se describen a continuación.
Si el paquete de respuesta tiene como código de error -PROCESO MIGRADO, entonces los próximos bytes contienen el identificador del nodo del nuevo nodo del proceso remoto involucrado
en la operación. Por otro lado, si mientras se estaba atendiendo algún pedido relacionado con
un proceso remoto, el servidor no encuentra el proceso en su nodo, entonces verifica si está en
el nodo origen del proceso. Si este es el caso, entonces busca la entrada del proceso en la tabla
de referencias a procesos, y a partir de ella recupera el Id Nodo del nodo actual del proceso
y devuelve -PROCESO MIGRADO junto con este Id Nodo al cliente. Luego, el cliente al recibir
este error, redirige la llamada remota al nuevo Id Nodo del proceso. Este campo Id Nodo no
se muestra en el formato de respuestas descripto en la Figura 1, sin embargo está presente
implícitamente si el código de error es -PROCESO MIGRADO.
3.2 Mejoras en la seguridad de CLEX
Al tratar de solucionar los problemas de seguridad en torno a un sistema con soporte de SSI el
primer tópico que debe comprenderse es el de las relaciones de confianza. Un sistema con SSI
desdibuja los límites tradicionales entre el “dentro” y “fuera”. Dentro es la relación entre todos
los nodos que se encuentran presentes en la lista del kernel CLEX y el fuera es todo lo demás.
Si se consideran posibles extensiones del sistema, con posibilidades de agregar nodos dispersos
geográficamente entonces el dentro se vuelve un complejo conjunto de relaciones de confianza
que deben establecerse.
3.2.1 Autenticación
El esquema de autenticación arriba presentado no es seguro, pues cualquier persona que tenga
credenciales de root puede romper el sistema. Puede considerarse suficiente solamente si se
requiere implementar un nivel de seguridad mínimo bajo un ambiente controlado.
Las tecnologías convencionales3 tienen como objetivo garantizar la seguridad tanto en el
cliente como en el servidor. Sin embargo en un cluster típico, este mecanismo se vuelve necesariamente más complejo, pues un nodo suele ser al mismo tiempo cliente y servidor de procesos
de otros nodos. En este caso es entonces adecuado pensar que cada nodo del cluster actúa como
un par (peer). El proceso de autenticación de nuestro protocolo de migración de procesos podría
extenderse empleando un esquema de autenticación más potente, como por ejemplo Kerberos
[NSS88, KN93] o Public Key Infrastructure (certificados PKI/X509.3). Indudablemente ambas
alternativas mejorarían la seguridad del sistema, a cambio de la introducción de un único punto de falla potencial4, lo que esto significa es que el funcionamiento del sistema depende del
funcionamiento de este nuevo componente, el servidor de autenticación.
3.2.2 Sistema de archivos
NFS es muy simple en cuanto a estructura, sin embargo asume un modelo de confianza muy
fuerte: el cliente confía en el servidor de archivos remoto. Esta asunción es peligrosa en el mundo
real, pues el servidor (o cualquier persona con acceso root) puede obtener los datos del sistema
de archivos localmente, o en una LAN (empleando un programa analizador de protocolos de red
(sniffer), como el Ethereal5). Otro problema con NFS es la adulteración de la identidad de los
usuarios, pues la mayoría de los controles de permisos de NFS se efectúan en el kernel del cliente.
Es entonces evidente la necesidad del empleo de un sistema de archivos distribuido seguro que
reemplace a NFS. Por ejemplo se puede utilizar SFS (The Self-Certifying File System) [Kaa00]
o CryptosFS [O’s00] que introducen técnicas criptográficas en el sistema de archivos distribuido.
Otras alternativas razonables son AFS (u OpenAFS) y Coda, probablemente los dos sistemas
3Por ejemplo las empleadas en e-commerce, como la compra de artículos en E-Bay y Amazon.
4El término usual en inglés es single point of failures.
5Software con licencia open source, disponible para plataformas tipo UNIX y Microsoft Windows, en
http://www.ethereal.com/
de archivos distribuidos más conocidos (y por lo tanto portados a una gran variedad de sistemas
operativos) luego de NFS. De esta forma, gracias a los mecanismos de autenticación, encripción
y control de acceso presentes en el sistema de archivos distribuido la información que viaja
entre pares de nodos se encuentra protegida frente a ataques de intercepción, modificación, e
inyección de mensajes.
3.2.3 Base de datos de nodos
Sin dudas la única forma de obtener un sistema escalable y dinámico es mediante un servicio
que permita el agregado de nuevos nodos al cluster en tiempo real. Para ello es necesario
implementar una base de datos (lista de acceso) dinámica. Esta decisión conlleva a mejorar la
seguridad, pues debemos evitar que un nodo “hostil” pase ahora a integrar la lista de nodos
pertenecientes al cluster.
Este nuevo esquema, presente en cada nodo, puede implementarse dividiendo la base de
datos de nodos en dos partes, una estática y otra dinámica. Por un lado se sigue manteniendo una lista de direcciones IP de nodos, en este caso serán los nodos considerados como de
confianza implícita. Por otro lado y para permitir el agregado de nodos en forma dinámica,
puede implementarse un daemon que, mediante el uso de algoritmos conocidos y probados de
firma digital y certificados de clave pública, como por ejemplo el protocolo de intercambio de
claves de Diffie-Hellman o MQV (Menezes-Qu-Vanstone) [Jr.96, Lom97], permita la autenticación de pares de nodos de forma segura, evitando ataques MiM (man in the middle) al proveer
autenticación.
Dependiendo del grado de seguridad del entorno en el cual opera el cluster los nodos integrarán la parte estática o la parte dinámica de la lista. En los casos extremos de un ambiente
seguro y controlado todos los nodos integrarán la base de datos estática (como lo hace el protocolo original), mientras que en un ambiente no confiable todos los nodos se integrarán al
sistema mediante el intercambio de claves durante el mensaje INIC6, por supuesto tendremos
casos híbridos en casos no extremos.
3.2.4 Confidencialidad e integridad en las comunicaciones
El sistema original envía los mensajes sin ningún tipo de protección frente a rupturas de confidencialidad e integridad. Es posible entonces interceptar, corromper, inyectar y modificar
mensajes.
Posiblemente la forma más sencilla de solucionar estos problemas sea agregando seguridad
a nivel IP. IPSEC soporta una gran variedad de mecanismos de autenticación y encripción, y
en modo encapsulado permite encriptar la totalidad del tráfico de capa 3 (IP) entre dos nodos.
En este caso se implementa una VPN para incluir a los nodos del cluster, asegurando los límites
entre los nodos que se encuentran “dentro” y “fuera” del sistema.
4 Extendiendo el Cluster
Un cluster que cumpla con las características antes mencionadas no sólo proveerá una mayor
capacidad de cómputo (al aprovechar CPUs ociosos) sino que además será capaz de lograr un
mejor balance en la utilización de recursos, suavizando los picos de actividad.
6La primer acción que efectúa cada nodo luego de iniciarse es enviar un mensaje INIC a cada uno de los otros
nodos de la lista. Esta operación es parte del mecanismo de tolerancia a fallas.
Otras posibilidades interesantes de la migración de procesos en un cluster se relacionan
con un mejor aprovechamiento del espacio de almacenamiento, tolerancia a fallas, localidad de
acceso a los datos, mejor administración del sistema, y computación móvil [MDP+00].
El sistema descripto en [EA04], provee migración no apropiativa para clusters heterogéneos
tipo UNIX. Esta heterogeneidad se refiere no sólo a distintas configuraciones, sino también a
diferentes arquitecturas y sistemas operativos. Estas capacidades presentes en nuestro sistema,
pueden extenderse a un ambiente de grid computing.
Distintos autores [FG01, DK02, LBB02] han tratado de precisar la definición de grid. De
hecho, el concepto de grid computing se encuentra todavía en evolución y la mayoría de los intentos por precisarlo terminan excluyendo implementaciones que muchos considerarían grids. Es
por ello que en este trabajo no se persigue precisar este concepto. En este sentido emplearemos
este término para referirnos a un sistema distribuido geográficamente donde cada componente,
en lugar de ser un nodo es un cluster (ver Figura 2).
En la Figura 2 se muestra además un posible ejemplo de uso de este sistema. Supongamos
que el Cluster A presenta un índice de estado en sobrecarga, a diferencia de los restantes clusters
que se encuentran ociosos. En este caso A migrará tareas para balancear los recursos globales,
absorbiendo picos de carga en una parte del sistema. Si bien se trata de un ejemplo sencillo
es claro que la complejidad aumenta considerablemente al escalar nuestro cluster inicial a un
ambiente grid.
Cluster A Cluster B
Cluster C Cluster D
Figura 2: Migran tareas hacia clusters menos cargados para balancear recursos
A primera vista esta nueva tecnología puede verse como una herramienta capaz de tomar
cualquier aplicación y ejecutarla 1000 veces más rápido. Este no es el caso, pues no cualquier
aplicación puede paralelizarse. Más aún, adaptar ciertas aplicaciones para obtener un mayor
throughput en este nuevo ambiente llevaría mayor esfuerzo que el potencial beneficio. Por otro
lado la configuración del sistema podría afectar en gran medida la performance, confiabilidad
y seguridad de la infraestructura de cómputo de la organización.
4.1 Requerimientos
Al considerar la extensión de un cluster según lo arriba mencionado, agregando distribución
geográfica son necesarias ciertas características de diseño:
Jerarquia administrativa. Es necesaria una jerarquia administrativa capaz de gestionar este
nuevo y complejo ambiente, e.g. determinando como fluye la información administrativa
entre todos los nodos pertenecientes al sistema.
Comunicaciones. En el protocolo CLEX original, por cuestiones de performance se decidió emplear comunicaciones UDP. Este modelo ya no es válido, pues ahora será necesario emplear
también conexiones punto a punto confiables y QoS para fijar parámetros de latencia, ancho de banda, confiabilidad y tolerancia a fallas.
Sistemas de información. Los recursos de esta grid serán cambiantes debido a que el entorno
es ahora netamente dinámico. Sin embargo debe mantenerse el concepto de accesibilidad,
debe ser posible acceder a todos los recursos desde cualquier proceso del sistema, sin
necesidad de conocer su ubicación. Para cumplir con este requerimiento son necesarios
mecanismos de registro y de directorio que provean información acerca del sistema de
forma confiable y fácil de acceder por parte de los nodos que solicitan servicios.
Servicio de nombres. En un ambiente grid, al igual que en cualquier otro sistema distribuido,
se emplean nombres para hacer referencia a los recursos. Este servicio de nombres es el
responsable de proveer un espacio de nombres uniforme a nivel del grid.
Sistemas de archivo distribuido. Las aplicaciones distribuidas muchas veces requieren el
acceso a archivos remotos. Es por lo tanto este item un punto clave en un sistema distribuido. Las características de diseño del mismo incluyen: un espacio de nombres global,
soporte para una variedad de operaciones de E/S sobre archivos, tolerancia a fallas y
buena performance (por ejemplo empleando caches).
Seguridad. Cualquier sistema distribuido involucra los tres principales aspectos de seguridad
definidos por la ISO: confidencialidad, integridad, y autenticación. Se debe proveer seguridad evitando problemas tanto en nodos individuales como en el entorno como un todo,
al mismo tiempo que se evita impactar la usabilidad de los recursos. Este punto es el
tema central de este trabajo.
Tolerancia a fallas. Para proveer un ambiente confiable y robusto es importante el monitoreo
de recursos y aplicaciones.
Gestión de recursos. Es claro que el manejo de tiempos de procesador, memoria, red, almacenamiento y otros componentes es muy importante en este nuevo ambiente. El objetivo
general es lograr un scheduling efectivo de aplicaciones que necesitan utilizar los recursos
disponibles del sistema, para ello es necesario así mismo interactuar con el scheduler local
(nodo). Desde el punto de vista del usuario la gestión de recursos debe ser transparente
y la interacción con esta porción del sistema debe limitarse al envío de aplicaciones.
GUI administrativa y de usuario. Las interfases a los servicios y recursos disponibles debe
ser intuitiva y sencilla de utilizar7. Generalmente a nivel de grid son más usuales las
interfases basadas en la web, dada la inherente heterogeneidad del sistema.
7En este sentido nuestro grupo de investigación se encuentra desarrollando herramientas gráficas de monitoreo
conjuntamente con el Laboratorio de Visualización y Computación Gráfica
5 Trabajos Futuros
Habitualmente se considera que el cluster se encuentra contenido en un entorno seguro en el
sentido de seguridad lógica y física. Si este no es el caso debería implementarse un sistema
que fuese seguro a pesar del ambiente. Para ello deberían introducirse protocolos subyacentes
seguros, como los presentados en la Subsección 3.2. Deberían estudiarse entonces diferentes
alternativas que identifiquen el impacto en la performance y heterogeneidad del sistema, pues
la criptografía implica procesamiento adicional y puede suceder que no todos los protocolos se
encuentren disponibles en todas las plataformas empleadas.
Una vez verificado y optimizado el protocolo de carga compartida a partir de la implementación8 se procederá al análisis de las modificaciones y extensiones necesarias para el ambiente
grid. Deberán ser consideradas, entre otras, cuestiones relacionadas con la planificación y distribución de la carga, latencias de red, seguridad, y un nuevo modelo de tolerancia a fallas.
Sin duda alguna si bien las tecnologías de grid computing se encuentran atravesando sus
primeras etapas, muestran una tendencia que, potenciada por el crecimiento de la web, va en
claro ascenso.
Finalmente, sin dudas una de las líneas de trabajo más promisorias de la migración de
procesos es el uso de los agentes móviles en la Web. En este sentido, en lugar de los modelos de
workstations y pools de procesadores, en el entorno Web las computadoras se conectan como
interfases al modelo “la red es la computadora”, perdiendo entonces relevancia la transparencia.
Con respecto a la performance, ésta pasa a depender de la latencia de la red y por lo tanto
la transferencia de estado no es tan importante como en el caso de las redes locales. Así es
como siempre y cuando el entorno de ejecución sea seguro, los usuarios se verán estimulados
a permitir la ejecución de procesos remotos en sus computadoras. Otro tópico importante a
tener en cuenta es la heterogeneidad, automáticamente soportada a nivel del lenguaje. En este
sentido los agentes móviles en la Web solucionan impedimentos análogos a los de la migración
de procesos, posibilitando el uso masivo de ambas tecnologías, dado que comparten mecanismos
similares.
