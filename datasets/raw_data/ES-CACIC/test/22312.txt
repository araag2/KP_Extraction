Desarrollo de un escáner 3D mediante cámaras estereoscópicas e iluminación láser
﻿
Los dispositivos de escaneo tridimensional permiten obtener modelos de objetos utilizando distintas 
técnicas de captura.  Esta tarea puede ser llevada a cabo por ejemplo mediante estereovisión, el cual 
es un método de reconstrucción 3D a partir de fotografías.  Las técnicas de reconstrucción 3D 
mediante luz se basan en la proyección de un patrón de luz conocido sobre una escena y a partir del 
análisis de la proyección puede deducirse la forma de los objetos.  De esta manera, basándose en la 
información bidimensional de las fotografías en conjunto con la luz estructurada puede obtenerse la 
ubicación tridimensional y construirse un modelo virtual 3D de la escena u objeto fotografiado.  El 
presente trabajo tiene por objeto plantear una solución integral hardware/software al problema de 
reconstrucción de modelos tridimensionales que presente un buen balance costo/beneficio. 
Palabras claves: estereovisión, escáner tridimensional, reconstrucción 3D, proyección de luz 
Abstract
Three-dimensional scanning devices allow obtaining object models using several capturing 
techniques.  This task can be carried out through stereovision, which is a 3D reconstructing method 
based on photographies.  3D reconstruction techniques using light projection uses a known light 
pattern over the scene, the shape of the objects can then be deduced by the analysis of the 
projection.  In this way, based on the two-dimensional information from the photographies together 
with the structured light, the three-dimensional position can be obtained and build a 3D virtual 
model of the photographed object or scene.  The present paper poses an integral hardware/software 
solution to the three-dimensional model reconstruction problem which presents a good cost/benefit 
balance.
Keywords: stereovision, three-dimensional scanner, 3D reconstruction, light projection 
1 Esta investigación es financiada por la Agencia Española de Cooperacion Internacional AECI programa de 
cooperación interuniversitaria e investigación científica. Proyecto A/7155/06 – Diseño de un sistema de reconstrucción 
3D mediante cámaras estereoscópicas y luz estructurada. 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
V Workshop de Computación Gráfica, Imágenes y Visualización
_________________________________________________________________________
 
 
689
1  INTRODUCCIÓN 
En la actualidad existen distintos sistemas de digitalización 3D [1,2,3,4,5,6].  Según sus 
características, éstos pueden ser divididos en dos grandes grupos: sistemas con o sin contacto con el 
objeto a digitalizar. 
1.2 Escaneado por contacto
Los sistemas de digitalización por contacto son los más antiguos.  Principalmente se emplean en la 
verificación dimensional de piezas industriales para el control de calidad.  Con estos sistemas se 
obtienen las coordenadas de los puntos gracias al desplazamiento de una punta sobre la superficie a 
digitalizar.  Éstos poseen una elevada precisión; pero por el contrario tienen una velocidad de 
adquisición de datos muy baja, ya que se necesita llevar manualmente la punta a cada posición que 
se quiera digitalizar, con lo cual el tiempo de escaneado de un objeto de tamaño medio resulta 
relativamente elevado.  Para emplear estos sistemas por contacto, se necesita además que las piezas 
tengan la rigidez suficiente para que no se deformen por el contacto de la punta y debido a la 
geometría de las éstas, es imposible digitalizar ciertas ranuras y ángulos interiores. 
1.2 Escaneado sin contacto 
Los sistemas de digitalización sin contacto presentan la ventaja de lograr una velocidad de 
adquisición de datos muy superior a las de los digitalizadores por contacto.  Se pueden dividir las 
técnicas de digitalización sin contacto en dos grandes grupos: de visión pasiva y de visión activa. 
1.2.1 Técnicas de visión pasiva 
El sistema visual humano permite obtener información de profundidad mediante la fusión de dos 
escenas monoculares, que son las escenas que captan cada uno de nuestros ojos.  La visión pasiva se 
basa entonces en utilizar dos puntos de vista de un mismo objeto para encontrar las coordenadas 
tridimensionales. 
La principal complejidad de este método es la correspondencia de puntos en cada una de las 
imágenes monoculares.  Las técnicas encargadas de realizar esta tarea presentan generalmente un 
elevado costo computacional [7,8]. 
1.2.2 Técnicas de visión activa 
Estás técnicas son las que hacen intervenir una fuente de luz específica para determinar las 
coordenadas tridimensionales de los puntos de medida.  Constan como mínimo de un emisor de luz 
y uno o más receptores.  Conociendo la dirección del rayo emitido y la del recibido se obtienen las 
dimensiones del triángulo formado y por lo tanto se logra determinar la profundidad del punto 
inspeccionado.
Existen tres tipos de sistemas de visión activa: 
x Telemetría: La telemetría consiste en medir el tiempo de recorrido de un rayo luminoso 
(láser) hasta la superficie de medida.  La medición se obtiene determinando el tiempo entre 
la emisión del impulso luminoso y la observación del retorno.  
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
V Workshop de Computación Gráfica, Imágenes y Visualización
_________________________________________________________________________
 
 
690
x Proyección de luz estructurada: En este sistema el emisor es un proyector de luz blanca y el 
receptor una cámara CCD.  Cuando se inicia una digitalización el proyector lanza sobre el 
objeto una serie de franjas de luz verticales de claros y sombras alternadas, que son 
registradas por la cámara.  El cálculo de la profundidad consiste en resolver las 
intersecciones plano-recta de la proyección. 
x Digitalización por láser: Este sistema, utilizado en el presente trabajo, utiliza un láser de 
diodos como fuente lumínica.  Dicho láser proyecta una línea de luz sobre la superficie que 
va a ser digitalizada. La luz reflejada será detectada por uno o dos células fotosensibles que 
se encuentran situadas a ambos lados del láser.  Estos detectores leen el haz de luz reflejado 
y procesan la información obtenida a partir del perfil proyectado.  El resultado de la 
digitalización nos da la posibilidad de obtener la geometría completa de la pieza a escanear.
Aunque cada uno de estos sistemas posee características similares, éstas presentan ventajas y 
desventajas de acuerdo a los requerimientos específicos de la aplicación, las cuales serán 
comentadas a continuación. 
2  ANALISIS PRELIMINAR DE SISTEMAS 
La medición 3D de geometrías libres ha sido abordada mediante el desarrollo de instrumentos de 
medición como Máquina de Medir por Coordenadas (MMC), Sistemas Láser de Medición (SLM) y 
Sistemas de Medición por Visión (SMV).   
Los SLM son utilizados en la medición de longitud y ángulo con alta exactitud.  Su desventaja 
radica en el empleo de arreglos ópticos que generalmente son diseñados para evaluar el desempeño 
de máquinas y herramientas de ejes coordenados.   
Por otra parte, existen SLM diseñados para la medición de profundidad en escenas con una alta tasa 
de muestreo.  Su desventaja radica en la relativa baja exactitud.  En forma adicional, los 
instrumentos comerciales ya sea MMC o SLM tienen un alto costo de compra y mantenimiento, lo 
que hace difícil su disponibilidad en el ámbito nacional.   
Por el contrario, los SMV constituyen una oferta atractiva en cuanto a costos, a expensas de la 
disminución en exactitud. En forma adicional, los SMV pueden tener las más altas tasas de 
muestreo y los niveles más elevados de automatización en su operación. No obstante las desventajas 
de los SMV, existen aplicaciones industriales, artísticas y de entretenimiento que los convierten en 
una opción ideal. 
3  DESCRIPCION DE LA TECNICA IMPLEMENTADA 
Básicamente, la técnica emplea un sistema de medición sustentado en la generación de un patrón 
con luz proyectada y la captura de imágenes estéreo.  La proyección resalta las características de 
interés en el objeto a medir y facilita el procesamiento de la imagen para la reconstrucción 
tridimensional como también simplifica y optimiza el proceso de correspondencia de puntos 
utilizado en el procesamiento de las imágenes.   
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
V Workshop de Computación Gráfica, Imágenes y Visualización
_________________________________________________________________________
 
 
691
3.1 Metodología de adquisición 
3.1.1 Tipos de proyecciones 
El haz láser puede ser conformado de diferentes formas (figura 1): punto,  una o más líneas, cruz, 
círculo, grillas de diferentes pasos y tamaños [9,10,11]. 
Figura 1. Varios tipos de proyecciones mediante láser 
Las formas más utilizadas son el punto, la línea y la cruz.  Las diferentes formas del haz láser se 
utilizan en alineación, centrado, marcado de línea de corte, inspección, seguridad, visión industrial.  
Se determinó la línea como el patrón correcto para el sistema.  
3.1.2 Técnica implementada 
El sistema fue pensado a fin de incorporar dos métodos de adquisición de datos diferentes, los 
cuales comparten características similares. 
 Adquisición de datos mediante barrido láser: en este caso, el objeto a reconstruir permanece 
inmóvil, mientras que se releva la superficie del mismo barriendo el área de escaneado con 
un láser.  Pensado para objetos sin volumen de revolución o cuyo contenido se presenta en 
una sola cara.
 Adquisición de datos mediante objeto giratorio: en este caso, el láser permanece inmóvil, y 
es el objeto quien realizar un giro sobre su eje a fin de relevar la superficie del mismo.  Ideal 
para objetos con volumen de tipo cilíndrico, como vasijas, tazas, etc. 
Las simulaciones ilustradas en las figuras 2 y 3 muestran una secuencia de imágenes que 
ejemplifican la captura de ambos mecanismos.  La primera presenta la adquisición mediante barrido 
láser, mientras que la segunda presenta la secuencia mediante objetivo giratorio.  
Frame 5 Frame 15 Frame 25 Frame 35 
Figura 2. Barrido láser (total 50 frames) 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
V Workshop de Computación Gráfica, Imágenes y Visualización
_________________________________________________________________________
 
 
692
Frame 0 Frame 27 Frame 71 Frame 108 
Figura 3. Objetivo giratorio (total 180 frames) 
3.1.3 Detalle del proceso de reconstrucción 
Primeramente, y por única vez, es necesario realizar la calibración de cámaras, tanto intrínseca 
como extrínsecamente [12,13,14,15,16,17].  El sistema presenta un módulo de calibración 
específico para esta finalidad. 
Posteriormente, una vez obtenidas las capturas estéreo, se procede a realizar la reconstrucción del 
objeto mediante la obtención de la nube de puntos.  Básicamente se genera una matriz de 
profundidades, en la que cada celda (X, Y) refiere a un Z del objeto en particular.  La columna iesima de la matriz se obtiene con el par de imágenes estéreo i-ésimo de la secuencia de video, 
mediante la triangulación de los puntos iluminados con la proyección del láser. 
Por cada par de imágenes estéreo, se debe realizar la correspondencia de puntos en la zona donde se 
presenta la proyección del láser.  Gracias a ésta, dicha tarea es relativamente sencilla y presenta un 
reducido coste computacional.   
El pseudocódigo para la obtención de la matriz de profundidades es el siguiente: 
float depths[][]; 
int column = -1; 
for (int frame = 0; frame < leftVideo.frames; frame++) 
{
 leftImage  = leftVideo.getFrame(frame); 
 rightImage = rightVideo.getFrame(frame); 
 column++; 
 for (int leftRow = 0; leftRow < leftImage.rows; leftRow++) 
 { 
  rightRow = obtainRowCorrespondence(leftRow); 
  leftColumn  = obtainLaserPosition(leftImage,  leftRow); 
  rightColumn = obtainLaserPosition(rightImage, rightRow); 
  zValue = triangulate(leftColumn, leftRow, rightColumn, rightRow); 
  depths[column][leftRow] = zValue; 
 } 
}
La matriz obtenida es posteriormente utilizada para la renderización en el entorno de visualización 
3D.  En el caso del objeto giratorio, la reconstrucción del objeto se realiza de manera tal que se 
contemple el ángulo de giro en cada columna a reconstruir. 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
V Workshop de Computación Gráfica, Imágenes y Visualización
_________________________________________________________________________
 
 
693
4  PRUEBAS REALIZADAS Y RESULTADOS OBTENIDOS 
A fin de determinar la metodología de adquisición óptima que debe cumplimentar el sistema, se 
realizaron varias pruebas simuladas; observando en cada caso la calidad de los resultados obtenidos.
El criterio de evaluación se basó principalmente en dos factores: tiempo de procesamiento en la 
adquisición y generación de nube de puntos; y precisión en la triangulación de puntos.  Dado que el 
hardware a utilizar se encuentra en función del método de adquisición, este punto fue una 
derivación directa de la determinación del primero.   
Tal como se comentó previamente, las pruebas realizadas fueron basadas en simulaciones por 
computadora mediante la aplicación 3D Studio Max.  Las mismas fueron de vital utilidad al 
momento de verificar configuraciones de hardware/software, ubicación de las cámaras y correctitud 
de los algoritmos. 
La figura 4a presenta la renderización 3D de la nube de puntos obtenida mediante la primer técnica, 
correspondiente a la primer secuencia anteriormente mencionada. 
La figura 4b presenta la renderización 3D de la nube de puntos obtenida mediante la segunda 
técnica, correspondiente a la segunda secuencia anteriormente mencionada.  Cabe destacar que en 
esta interpretación debe contemplarse que la tetera se encuentra “abierta” y estirada (dada la forma 
en que Matlab realiza la renderización).
Como se muestra posteriormente, en la visualización en el entorno de renderización 3D será 
contemplado el ángulo de rotación de la captura para la reconstrucción del objeto de la figura 3.
Figura 4a. Visualización de la matriz de 
profundidades en Matlab. 
Figura 4b. Visualización de la matriz de 
profundidades en Matlab (rotación de objeto) 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
V Workshop de Computación Gráfica, Imágenes y Visualización
_________________________________________________________________________
 
 
694
5  ENTORNO DE RENDERIZACIÓN 3D 
El entorno de renderización 3D se encarga de procesar la nube de puntos almacenada en la matriz 
de profundidades y generar el objeto escaneado.  Una vez obtenido éste, se realiza la visualización 
del mismo.   
El entorno se encuentra en etapa de desarrollo.  Sin embargo, la figura 5 presenta dos 
visualizaciones iniciales de las reconstrucciones realizadas.  La figura 5a corresponde a la secuencia 
mostrada en la figura 2, mientras que la figura 5b corresponde a la secuencia de la figura 3. 
Figura 5a. Renderizaciones a partir de la matriz 
de profundidades 
Figura 5b. Renderizaciones a partir de la matriz 
de profundidades (rotación del objeto) 
El entorno permite observar la pieza desde cualquier posición que sea necesario, pudiendo rotar 
tanto la cámara como el objeto.   
Aunque el sistema de adquisición se encuentra desarrollado utilizando la librería OpenCV [18], el 
desarrollo del entorno de visualización se está efectuando apoyándose en la API de Java 3D de Sun 
Microsystems [19].  Esto indica una independencia funcional de cada una de las partes que 
componen la implementación, permitiendo el desarrollo por separado de cada una de éstas. 
6  IMPLEMENTACION DEL HARDWARE 
Actualmente se encuentra en desarrollo el armazón para el sistema de captura, el cual contará con 2 
cámaras, un láser, 2 motores y la estructura que lo soporta.  La misma fue pensada para permitir un 
fácil armado y desarmado a fin de facilitar su portabilidad. 
La estructura posee ciertas características que aumentan la versatilidad del sistema de captura, tales 
como regules de horizontalidad, posicionamiento de cámaras, láser y objeto en múltiples 
posiciones, etc. 
La figura 6 muestra dos vistas del prototipo en el cual actualmente se está trabajando. 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
V Workshop de Computación Gráfica, Imágenes y Visualización
_________________________________________________________________________
 
 
695
Figura 6. Hardware en desarrollo 
7  CONCLUSIONES 
Aunque todavía el proyecto no se encuentra finalizado, el estado actual del mismo permite prever 
resultados más que aceptables con la tecnología de hardware que se espera utilizar en conjunto con 
el software desarrollado. 
Aunque las pruebas realizadas hasta el momento fueron efectuadas en un ambiente controlado, las 
mismas arrojan un balance positivo en cuanto a la relaciones de costo/beneficio y de 
precisión/performance. 
Una vez finalizado el desarrollo del hardware se espera utilizar inicialmente el escáner para la 
digitalización 3D de vasijas y estatuillas pertenecientes a la colección del Museo de Ciencias 
Naturales de La Plata. 
8 
