Aplicaciones veterinarias del procesamiento de imágenes
﻿
Se presenta el desarrollo de un algoritmo de procesamiento de imágenes para el soporte de 
detección de celo vacuno. El método de detección se basa en el análisis del deterioro de pintadas 
lumbares, mediante la segmentación de fotografías color tomadas a la salida de un tambo. 
Inicialmente, las regiones de interés son aisladas del resto de la imagen en función de valores de 
umbral definidos en los espacios de color YUV e YIQ, generando un conjunto de componentes 
conectadas. Luego, se calcula un conjunto de características para posibilitar una evaluación 
cuantitativa de los objetos segmentados. Finalmente, la imagen es clasificada mediante una regla de 
decisión basada en el análisis de las diferencias entre las medidas obtenidas a partir de la imagen y 
las provenientes de un conjunto de imágenes manualmente segmentadas, de acuerdo a la evaluación 
de expertos. Este enfoque constituye una valiosa alternativa para la mejora del control de celo, ya 
que la ardua tarea de observación visual de los animales en el tambo puede ser reemplazada por el 
análisis automático de imágenes capturadas en ambientes controlados. Los resultados 
experimentales a partir de las segmentaciones obtenidas con este método resultan altamente 
satisfactorios, permitiendo una clasificación precisa de las imágenes con un bajo costo 
computacional.  
Palabras clave: Procesamiento de señales, segmentación de imágenes, clasificación. 
 
Abstract 
This paper presents the development of an algorithm of image processing which was applied to a 
decision support tool for estrus detection in cattle. The detection method is based on the analysis of 
rubbed off lumbar paintings, by means of the segmentation of color pictures taken to cows in a 
cattle ranch. Firstly, the regions of interest are isolated from the rest of the image based on threshold 
functions defined in the YUV and YIQ color spaces, producing a set of connected components. 
Then, a set of features is computed to enable a quantitative evaluation of the segmented objects. 
Finally, the image is classified by means of a decision rule based on the analysis of the differences 
between the computed measures and a set of ideally segmented images, according to experts’ 
assessment. This approach constitutes a valuable alternative to improve this process, as it may 
replace the visual observation by the automatic analysis of pictures taken to cows in controlled 
environments. Experimental results show that the segmentations obtained with this method are 
highly satisfactory and they allow a precise classification of the images with low computational 
complexity. 
Keywords: Signal processing, image segmentation, classification. 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
V Workshop de Computación Gráfica, Imágenes y Visualización
_________________________________________________________________________
 
 
668
1. INTRODUCCIÓN 
La segmentación es la operación de identificación y separación de objetos significativos 
contenidos en una imagen. Esta es una etapa sumamente importante en la automatización de 
procesos de reconocimiento y determina el eventual éxito o fracaso de tareas de más alto nivel 
como clasificación, análisis y visualización [2]. 
Se han propuesto diferentes técnicas de segmentación [6, 9]. El umbralado es uno de los métodos 
más simples y más comúnmente utilizados [10]. Se basa en una clasificación estadística de los 
niveles de gris de la imagen, suponiendo que todos los puntos con valores de intensidad dentro de 
un cierto rango corresponden al mismo objeto. Por otro lado, los enfoques basados en bordes 
buscan la detección de discontinuidades de los niveles de gris que idealmente se asocian a los 
límites entre diferentes componentes [2]. Otro tipo de enfoques se basa en la determinación de 
regiones homogéneas dentro de la imagen, por medio de la incorporación de aquellos píxeles que 
satisfacen cierto criterio de conectividad y similitud [1]. Finalmente, existen varios métodos que 
combinan dos o más de los enfoques anteriores y que resultan más complejos, como por ejemplo los 
basados en snakes [7] o redes neuronales [9]. Por lo general, la mayoría de estos algoritmos resultan 
computacionalmente intensivos y por lo tanto poco convenientes para aplicaciones en tiempo real. 
Recientemente se ha manifestado un interés creciente por su aplicación a imágenes color, debido 
a que éstas generalmente aportan mayor contenido de información, facilitando la identificación de 
objetos [11]. Entre los algoritmos desarrollados, se encuentran algunas técnicas ad hoc que utilizan 
conocimiento específico sobre la naturaleza de la información de color. Por otro lado, también 
pueden explorarse extensiones convenientes de las técnicas usadas para imágenes en tonos de gris, 
aplicando por ejemplo el algoritmo a cada componente del espacio de color (RGB, YIQ, etc.) para 
luego combinar los resultados individuales.  
El campo de aplicación de la segmentación de imágenes color es sumamente amplio y se han 
propuesto interesantes usos en diversas áreas. En particular, la detección de celo en bovinos en base 
a pintadas lumbares constituye un ejemplo práctico de estas aplicaciones. La técnica consiste en 
pintar una banda de 20 cm de largo por 5 cm de ancho a lo largo de la base de la cola del animal. 
Durante la monta, la pintura se desgasta y se pierde gradualmente. De esta manera, la ausencia o 
deterioro de la pintura en la zona lumbar puede ser usada para determinar un estado de celo [8]. La 
detección se realiza generalmente mediante la observación visual de operadores entrenados ya que 
no existen dispositivos automáticos para este propósito. Al disponer de una herramienta de 
segmentación de imágenes color provenientes de las pinturas lumbares en tiempo real, se podrían 
implementar sistemas automáticos de detección de celo que permitan reducir costos. 
En este trabajo se presenta un algoritmo computacionalmente eficiente para segmentación y 
clasificación de imágenes color. El método ha sido aplicado a la segmentación de pinturas sobre el 
área lumbar de vacunos, seguida por la extracción y comparación de algunas características de las 
imágenes a fin de extraer resultados significativos. Esta herramienta provee un sistema automático 
novedoso para el soporte de decisiones capaz de determinar en tiempo real el estado de celo de los 
animales, lo que permite mejorar el diagnóstico y obtener mayores ganancias a los productores. 
El artículo se organiza de la siguiente manera. En la Sección 2, se discute el algoritmo de 
segmentación basado en umbralado a partir de transformaciones no lineales de los espacios de 
color. Las etapas de extracción y clasificación se describen en la Sección 3. En la Sección 4, se 
analiza detenidamente la performance del método usando diferentes grupos de imágenes. 
Finalmente, en la Sección 5 se presentan las conclusiones generales del trabajo. 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
V Workshop de Computación Gráfica, Imágenes y Visualización
_________________________________________________________________________
 
 
669
2. SEGMENTACIÓN DE IMÁGENES COLOR 
A pesar de la disponibilidad de otras opciones de segmentación, el umbralado se encuentra entre las 
técnicas más populares para segmentar imágenes debido a su baja complejidad computacional y 
buena performance. El umbralado frecuentemente provee un enfoque simple y apropiado para la 
detección de objetos del fondo usando el histograma de la imagen. Si el rango de intensidades se 
encuentra bien diferenciado, esta tarea puede realizarse efectivamente eligiendo un valor de umbral 
adecuado en el valle entre las dos modas dominantes. El problema es más complicado cuando las 
distribuciones se superponen y por lo tanto no es simple determinar el valle [5]. 
En su forma más simple, cada píxel de una imagen f(i,j) es comparado con un umbral T, y luego 
es clasificado para obtener una imagen binaria I(i,j) definida como: 
( )
⎩⎨
⎧
≤
>=
T f(i,j)
Tf(i,j)
jiI
if     
 if     
0
1
,  (1)
esto es, los píxeles rotulados con 1 corresponden a objetos, mientras que los rotulados con 0 
corresponden al fondo.  
Si bien el umbralado es una técnica fácil de aplicar a imágenes en tonos de gris, pueden aparecer 
algunas complicaciones en el caso de imágenes color. El color se representa comúnmente por una 
tripla de componentes escales rojo, verde y azul (R, G, B) en un espacio ortogonal, o alguna 
transformación de ellos. Detectar clusters de puntos en este espacio involucra el análisis de picos y 
valles de tres histogramas diferentes o determinar un umbral apropiado en un histograma 
tridimensional, el cual puede requerir un alto costo computacional [3]. Por otra parte, el espacio 
RGB es apropiado para visualizar color, pero no es conveniente para muchas tareas de 
procesamiento de imágenes a causa de la alta correlación entre sus componentes. Contrariamente, el 
espacio YIQ tiene en cuenta la mayor sensibilidad humana a los cambios en luminosidad (Y) que en 
la información sobre el color (I y Q). Estas componentes se encuentran desacopladas, de manera 
que pueden ser procesadas independientemente. El espacio YUV es una versión levemente diferente 
del YIQ pero con las mismas ventajas [4]. 
Aunque el algoritmo desarrollado puede ser aplicado a diferentes áreas con pocas modificaciones, 
el presente estudio se enfoca en imágenes con zonas artificialmente pintadas de color rojo, amarillo, 
verde o azul (de acuerdo a los colores utilizados por los veterinarios en los diferentes ciclos de celo) 
sobre fondos en tonos marrón, negro y blanco (correspondientes a los posibles cueros vacunos). El 
principal objetivo es separar automáticamente las regiones pintadas del fondo para permitir su 
evaluación posterior (Figura 1). Inicialmente, las variables de crominancia (u,v en el espacio YUV e 
i,q en el espacio YIQ) fueron analizadas para todos los colores posibles de pintura y cuero, tratando 
de encontrar valores de umbral apropiado. Sin embargo, ni YUV ni YIQ poseen un rango de valores 
que puedan ser usados para discriminar efectivamente entre objetos y fondo. Por esta razón, se 
estudiaron varias funciones de color de las variables de crominancia a fin de identificar un campo 
escalar adecuado que permita asegurar una correcta segmentación de la imagen.  
 
 
             (a)                           (b) 
Figura 1. Segmentación de una imagen típica: banda de pintura sobre la base 
 de la cola de un animal (a), objeto de interés segmentado del fondo (b) 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
V Workshop de Computación Gráfica, Imágenes y Visualización
_________________________________________________________________________
 
 
670
A fin de evaluar los resultados de la segmentación de diferentes funciones de color, se generó un 
conjunto de 1000 imágenes sintéticas semejando escenas libres de error.  Este análisis permitió 
analizar el comportamiento de las funciones que lograron distinguir correctamente los diferentes 
colores utilizados para las pinturas y los asociados con los distintos cueros de los animales. Como 
ejemplo, la Figura 2 muestra cuatro histogramas correspondientes a la función 22 vu + , mostrando 
una clara distinción entre los dos grupos. 
Luego de haber procesado las imágenes con las distintas funciones propuestas, se eligió un 
subconjunto de ellas según su performance. Las funciones seleccionadas fueron: ( )vuk ,max  y 
22 vu + , en el espacio YUV, y ),(min),(max 21 qikqik +  y 22 qi +  en el espacio YIQ, ya que con 
ellas se logró segmentar aproximadamente el 97% de las imágenes de prueba, para los cuatro 
colores de pintura y con un rango de valores bastante amplio. Los valores de k, k1 y k2 fueron 
obtenidos mediante ensayos numéricos, verificando que con k= 11 para el primer caso, y k1= 10, k2= 
2 para el segundo se logran segmentaciones exitosas con una alta tasa de eficiencia. Este conjunto 
de funciones fue utilizado en pruebas con imágenes experimentales, como será explicado en la 
Sección 4.  
3. PROCESAMIENTO POST-SEGMENTACIÓN  
La imagen binaria obtenida en la etapa de segmentación se procesa mediante una operación de 
erosión para eliminar los posibles puntos espurios que pueden surgir durante el umbralado [2]. Esta 
operación morfológica puede reducir levemente el tamaño de los objetos, pero a la vez contribuye a 
revelar su forma básica, lo cual se requiere en la etapa de clasificación. Luego de este proceso, las 
componentes conectadas que permanecen son rotuladas a fin de poder determinar las regiones de 
interés [5]. Entonces, estas regiones son evaluadas mediante sus características geométricas y se las 
compara contra medidas ideales (Figura 3), como se describe en las siguientes subsecciones. 
 
Figura 2. Distribuciones de los valores de 
22 vu +  para los colores del fondo (negro, blanco y marrón) 
y los diferentes colores de pinturas: amarillo (a), verde (b), azul (c) y rojo (d) 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
V Workshop de Computación Gráfica, Imágenes y Visualización
_________________________________________________________________________
 
 
671
 
Figura 3. Etapas involucradas en la evaluación de las funciones 
3.1 Extracción de características  
Las regiones detectadas por el proceso de segmentación son evaluadas según sus características y 
descriptores de forma. Adquirir mediciones precisas de los objetos es un problema fundamental en 
análisis de imágenes, ya que tales medidas generalmente brindan información útil a tener en cuenta 
en la posterior etapa de clasificación [2]. En este caso, los objetos segmentados fueron 
caracterizados a través de las siguientes métricas: 
Área. El área es el momento de orden cero y se calcula como el número de pixels dentro del 
objeto incluyendo su borde, esto es: 
∑∑=
x y
yxIA ),(  (2)
Dispersión. Esta métrica indica cuán diseminados se encuentran los pixels del objeto con respecto 
al centroide. Entonces, para aquellos pixels con I(x,y) =1: 
( ) ( )∑∑ −+−=
x y
yyxxD 22  (3)
donde el centroide está dado por los momentos de primer orden x  y y : 
∑∑
∑∑
=
x y
x y
yxI
yxIx
x
),(
),(
       
∑∑
∑∑
=
x y
x y
yxI
yxIy
y
),(
),(
 (4)
Longitud del eje mayor. El eje mayor de un objeto se define como la línea más larga que puede 
dibujarse dentro del objeto. Para calcular esta medida, se calculan las distancias entre cada 
combinación de pixels (xi, yi) y (xj, yj) sobre el borde del objeto y se determina el par (xM1, yM1) y 
(xM2, yM2) con la mayor longitud. De esta manera, la longitud del eje mayor es la distancia en pixels 
entre estos puntos y representa la longitud del objeto. Se calcula como: 
( ) ( )212212 MMMMM yyxxL −+−=  (5)
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
V Workshop de Computación Gráfica, Imágenes y Visualización
_________________________________________________________________________
 
 
672
Longitud del eje menor. El eje menor se define como la línea más larga que atraviesa al objeto y 
que puede dibujarse en forma perpendicular al eje mayor. Los puntos extremos del eje menor (xm1, 
ym1) y (xm2, ym2) se determinan calculando la distancia en píxels entre cada par de puntos del borde 
(xi, yi) y (xj, yj) que definen segmentos perpendiculares al eje mayor y determinando el par con la 
mayor longitud. Así, la longitud del eje menor se obtiene como: 
( ) ( )212212 mmmmm yyxxL −+−=  (6)
 
3.2 Clasificación por comparación de medidas  
En este punto del proceso de evaluación, se ha logrado segmentar uno o más objetos dentro de la 
imagen de entrada y se han obtenido varias medidas a partir de ellos, de acuerdo a las Ec. (2) a (6). 
Estas métricas son utilizadas durante la tercera etapa correspondiente a la clasificación como 
entrada para una regla de decisión que permite determinar si un animal se encuentra en celo. 
Con en fin de asistir al proceso de decisión, se pueden usar distintos algoritmos de inteligencia 
artificial. Sin embargo, en este enfoque se ha implementado una regla sencilla basada en lógica 
difusa que analiza las diferencias entre las medidas calculadas a partir del conjunto de imágenes de 
prueba, clasificadas de acuerdo a la evaluación de expertos veterinarios y aquellas obtenidas por el 
algoritmo para imagen particular (Figura 4). Las medidas obtenidas a partir del primer conjunto 
fueron usadas como valores de referencia para definir intervalos de confianza para las propiedades 
geométricas derivadas de la región segmentada (A, D, LM y Lm). Para determinar un celo positivo se 
requiere que todas las métricas calculadas a partir de la imagen correspondiente caigan dentro de los 
respectivos intervalos de confianza. Basado en pruebas experimentales, se ha determinado que 
pérdidas por debajo del 30% representan casos de no-celo o dudosos, mientras que pérdidas 
superiores a este porcentaje dan indicio de que el animal está en celo. Por lo tanto, el valor usado 
para discriminar entre casos de celo positivo y negativo fue definido como 0.3x, donde x representa 
cada uno de los descriptores anteriores. El criterio puede ser modificado en el futuro, luego de una 
retro-información de aplicaciones reales. 
 
Figura 4. Criterio de éxito 
4. VALIDACIÓN EXPERIMENTAL DE FUNCIONES DE UMBRAL 
A partir de dos conjuntos de fotografías correspondientes a pinturas sobre cueros vacunos, se llevó a 
cabo una evaluación integral del método. La primera muestra fue tomada en un ambiente con luz 
controlada, usando cueros naturales con bandas de pintura de aproximadamente 100 cm2.  
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
V Workshop de Computación Gráfica, Imágenes y Visualización
_________________________________________________________________________
 
 
673
El segundo conjunto de imágenes fue obtenido a partir de fotografías de animales reales en un 
tambo (El Choique, zona de Napaleofú), a fin de reproducir lo más posible las condiciones de 
iluminación que se pueden encontrar en aplicaciones reales (Figura 5). La Tabla 1 muestra los 
resultados obtenidos, indicando el porcentaje de casos que el algoritmo descripto determinó 
positivos y que fueron confirmados mediante diagnóstico clínico. La segunda columna muestra el 
porcentaje de éxito de las funciones de umbral seleccionadas para la primera muestra y la tercera 
columna corresponde al conjunto obtenido a partir de animales reales. 
 
      
(a) 
 
(b) 
Figura 5. Pintadas de color sobre cueros: en muestra artificial (a),  
ejemplo de muestras con casos reales (b) 
 
 
Tabla 1. Resultados de las funciones de umbral de color  
función de color % de éxito con fotografías en ambiente controlado 
% de éxito con 
fotografías in situ 
22 vu +  96.28 94.59 ( )vu ,max11  96.85 97.29 
22 qi +  97.71 97.29 
),min(),max( qi2qi10 +  97.14 94.59 
 
La Figura 6(a) muestra la performance de las funciones ( )v,umax11  y 22 qi + , que lograron 
los mayores porcentajes de éxito en la clasificación al ser aplicadas a las imágenes del primer 
conjunto. Como se puede ver, hay un amplio rango de valores de umbral para cada función que 
permiten obtener buenos resultados de clasificación. Para valores de umbral más pequeños, el 
algoritmo no alcanza a identificar partes de las pintadas, mientras que en el caso de valores mayores 
el fondo no se distingue plenamente de las bandas de pintura. La altura de la curva, que corresponde 
al mayor porcentaje de éxito, indica el poder de segmentación de la función de umbral utilizada, y 
su ancho determina su robustez (es decir, cuanto más amplio es el rango, menos sensible serán los 
resultados a las fluctuaciones de color). La Figura 6(b) presenta el comportamiento de las mismas 
funciones para la segunda muestra de imágenes. En este caso, los resultados parecen menos 
robustos que en el caso anterior. Sin embargo, hay que notar que esto se debe a que el conjunto 
obtenido a partir de animales reales es menor que en la muestra controlada.  
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
V Workshop de Computación Gráfica, Imágenes y Visualización
_________________________________________________________________________
 
 
674
Aunque la observación visual es el método comúnmente usado para determinar el estado de celo, 
su eficiencia se estima en sólo 50% en la mayoría de los tambos y se estima que entre el 5 y el 30% 
de las inseminaciones se realizan en vacas que no se encuentran en celo. El uso de asistentes en el 
proceso de detección puede mejorar esta situación. Por ejemplo, los sistemas comerciales basados 
en dispositivos sensibles a la presión reportan una precisión de aproximadamente el 95%. El 
sistema automático basado en el análisis de pinturas presentado en este trabajo puede brindar una 
alternativa eficiente para la detección de celo, con una precisión cercana al 97%, siendo mucho más 
económico y accesible a la mayoría de los productores.  
 
(a)                                                                                              (b) 
 
(c) (d) 
Figura 6. Porcentaje de éxito alcanzado por las funciones ),max(11 vu∗  y 22 qi +  para el primer 
conjunto de imágenes – laboratorio controlado- (a) y para el conjunto de imágenes tomadas in-situ – tambo- 
5. CONCLUSIÓN 
Se presentó un método de umbralado para la segmentación automática de imágenes color, basado 
en transformaciones no-lineales de las componentes de los espacios de color YUV y YIQ. El método 
es simple, robusto y ha mostrado una excelente performance con baja complejidad computacional. 
Además, los valores de umbral y los valores de referencia para la clasificación se deben calcular 
sólo al comienzo de la operación del sistema. La técnica de segmentación no requiere parámetros de 
entrada para cada imagen, prescindiendo de la interacción con el usuario.  
El algoritmo fue utilizado en una herramienta de soporte de decisiones para detección de celo. 
Esta herramienta constituye una contribución de alto valor tecnológico para mejorar la eficiencia de 
este procedimiento, ya que aún no se han desarrollado dispositivos automáticos en este dominio de 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
V Workshop de Computación Gráfica, Imágenes y Visualización
_________________________________________________________________________
 
 
675
aplicación. Los resultados de la segmentación fueron caracterizados mediante medidas geométricas, 
las cuales brindan un conjunto de parámetros válidos para determinar el estado de celo. La técnica 
fue probada exitosamente contra conjuntos de fotografías tomadas en ambientes de luz controlada y 
también en tambos ubicados en el campo. Se ha advertido que ciertos efectos como sombras, 
cambios de iluminación y ruido pueden afectar la efectividad del proceso de segmentación, y serán 
investigados en el futuro.   
