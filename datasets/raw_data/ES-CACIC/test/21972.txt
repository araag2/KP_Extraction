Implementación de un digesto digital paralelo para búsquedas por similitud sobre documentos
﻿. Similarity sear
h 
onsists in retrieving those obje
ts within a database that are alike
or relevant in a given query. This 
on
ept has a broad range of appli
ations in diverse areas su
h
as multimedia database, pattern re
ognition, data mining, information retrieval, et
. The ne
essity
to pro
ess large amounts of data to nd fast answers to queries makes the stru
tures that support
this system parallel.
Besides, the quantity of information generated by publi
 and private institutions and the need to
re
uperate do
uments in a mu
h more 
omplex way allows for the union of parallel and similarity
sear
h areas to makes a real appli
ation.
This arti
le presents an e
ient solution with a low 
ost parallel sear
h engine as an alternative to
queries in an Institutional Digital Digest, do
ument sear
h by similitude.
keywords: database, data stru
tures, algorithms, metri
 spa
es, similarity sear
h, parallel
pro
essing, modelo BSP.
Resumen La búsqueda por similitud 
onsiste en re
uperar todos aquellos objetos dentro de una
base de datos que sean pare
idos o relevantes a una determinada 
onsulta. Este 
on
epto tiene una
amplia gama de apli
a
iones en áreas 
omo bases de datos multimedia, re
ono
imiento de patrones,
minería de datos, re
upera
ión de informa
ión, et
. La ne
esidad de pro
esar grandes volúmenes
de datos y de poner a disposi
ión de los usuarios respuestas rápidas a sus 
onsultas ha
e que las
estru
turas que soportan este tipo de búsquedas deban ser paralelizadas.
Por otro lado, la 
antidad de informa
ión generada por institu
iones públi
as y privadas y la
ne
esidad de re
uperar do
umentos de formas más 
omplejas, permite la unión de las áreas de
paralelismo y búsqueda por similitud en una apli
a
ión real.
El presente artí
ulo presenta un solu
ión e
iente y de bajo 
osto de un motor de búsqueda paralelo,
presentando una alternativa para 
onsultas en un Digesto Digital Institu
ional, la búsqueda de
do
umentos por similitud.
Palabras 
laves: bases de datos, estru
turas de datos, algoritmos, espa
ios métri
os, 
onsultas
por similaridad, paralelismo, modelo BSP.
1. Mar
o Teóri
o
1.1. Ante
edentes
Uno de los problemas de gran interés en 
ien
ias de la 
omputa
ión es el de búsqueda
por similitud, es de
ir, en
ontrar los elementos de un 
onjunto más similares a una
*
Par
ialmente nan
iado por Universidad de Magallanes (programa de investiga
ión PR-F1-02IC-08), Chile y
Universidad Na
ional de la Patagonia Austral (proye
tos de investiga
ión 29/C035/1, Unidad A
adémi
a de
Río Turbio y 29/A216-1, Unidad A
adémi
a de Río Gallegos), Argentina.
muestra. Esta búsqueda es ne
esaria en múltiples apli
a
iones, 
omo ser en re
ono
imiento
de voz e imagen, 
ompresión de video, genéti
a, minería de datos, re
upera
ión de
informa
ión, et
. En 
asi todas las apli
a
iones la evalua
ión de la similaridad entre dos
elementos es 
ara, por lo que usualmente se trata 
omo medida del 
osto de la búsqueda
la 
antidad de similitudes que se evalúan.
Interesa el 
aso donde la similaridad des
ribe un espa
io métri
o, es de
ir, está
modelada por una fun
ión de distan
ia que respeta la desigualdad triangular. En este

aso, el problema más 
omún y difí
il es en aquellos espa
ios de alta dimensión donde
el histograma de distan
ias es 
on
entrado, es de
ir, todos los objetos están más o menos
a la misma distan
ia unos de otros.
El aumento de tamaño de las bases de datos y la apari
ión de nuevos tipos de datos
sobre los 
uales no interesa realizar búsquedas exa
tas, 
rean la ne
esidad de plantear
nuevas estru
turas para búsqueda por similaridad o búsqueda aproximada. Asimismo, se
ne
esita que di
has estru
turas sean dinámi
as, es de
ir, que permitan agregar o eliminar
elementos sin ne
esidad de 
rearlas nuevamente, así 
omo también que sean óptimas en
la administra
ión de memoria se
undaria. La ne
esidad de pro
esar grandes volúmenes
de datos obligan a aumentar la 
apa
idad de pro
esamiento y 
on ello la paraleliza
ión
de los algoritmos y la distribu
ión de las bases de datos.
En este 
ontexto, la informa
ión generada en do
umentos de institu
iones públi
as
y privadas presenta un problema de interés en términos de búsqueda de do
umentos.
Mu
has ve
es no se requiere una búsqueda tradi
ional, si no más espe
í
a en fun
ión de
obtener do
umentos similares a uno dado 
omo 
onsulta.
1.2. Búsqueda por Similitud
La similaridad se modeliza en mu
hos 
asos interesantes a través de un espa
io métri
o,
y la búsqueda de objetos más similares a través de una búsqueda por rango o de ve
inos
más 
er
anos.
Deni
ión 1 (Espa
ios Métri
os): Un espa
io métri
o es un 
onjunto X 
on una
fun
ión de distan
ia d : X2 → R, tal que ∀x, y, z ∈ X,
1. d(x, y) ≥ 0 and d(x, y) = 0 ssi x = y. (positividad)
2. d(x, y) = d(y, x). (Simetría)
3. d(x, y) + d(y, z) ≥ (d(x, z). (Desigualdad Triangular)
Deni
ión 2 (Consulta por Rango): Sea un espa
io métri
o (X,d), un 
onjunto de
datos nito Y ⊆ X, una 
onsulta x ∈ X, y un rango r ∈ R. La 
onsulta de rango
alrededor de x 
on rango r es el 
onjunto de puntos y ∈ Y , tal que d(x, y) ≤ r.
Deni
ión 3 (Los k Ve
inos más Cer
anos): Sea un espa
io métri
o (X,d), un

onjunto de datos nito Y ⊆ X, una 
onsulta x ∈ X y un entero k. Los k ve
inos más

er
anos a x son un sub
onjunto A de objetos de Y, donde la |A| = k y no existe un
objeto y ∈ A tal que d(y,x) sea menor a la distan
ia de algún objeto de A a x.
El objetivo de los algoritmos de búsqueda es minimizar la 
antidad de evalua
iones
de distan
ia realizadas para resolver la 
onsulta. Los métodos para bus
ar en espa
ios
métri
os se basan prin
ipalmente en dividir el espa
io empleando la distan
ia a uno o más
objetos sele

ionados. El no trabajar 
on las 
ara
terísti
as parti
ulares de 
ada apli
a
ión
tiene la ventaja de ser más general, pues los algoritmos fun
ionan 
on 
ualquier tipo de
objeto [8℄.
Existen distintas estru
turas para bus
ar en espa
ios métri
os, las 
uales pueden
o
upar fun
iones dis
retas o 
ontinuas de distan
ia. Algunos son BKTree [6℄, Metri
Tree
[15℄, GNAT [4℄, VpTree [19℄, FQTree [1℄, MTree [9℄, SAT [11℄, Slim-Tree [14℄, EGNAT
[17℄.
Algunas de las estru
turas anteriores basan la búsqueda en pivotes y otras en

lustering. En el primer 
aso se sele

ionan pivotes del 
onjunto de datos y se pre
al
ulan
las distan
ias entre los elementos y los pivotes. Cuando se realiza una 
onsulta, se 
al
ula
la distan
ia de la 
onsulta a los pivotes y se usa la desigualdad triangular para des
artar

andidatos.
Los algoritmos basados en 
lustering dividen el espa
io en áreas, donde 
ada área tiene
un 
entro. Se alma
ena alguna informa
ión sobre el área que permita des
artar toda el
área mediante sólo 
omparar la 
onsulta 
on su 
entro. Los algoritmos de 
lustering son
los mejores para espa
ios de alta dimensión, que es el problema más difí
il en la prá
ti
a.
Existen dos 
riterios para delimitar las áreas en las estru
turas basadas en 
lustering,
hiperplanos y radio 
obertor (
overing radius). El primero divide el espa
io en parti
iones
de Voronoi y determina el hiperplano al 
ual pertene
e la 
onsulta según a qué 
entro

orresponde. El 
riterio de radio 
obertor divide el espa
io en esferas que pueden
interse
tarse y una 
onsulta puede pertene
er a más de una esfera.
Deni
ión 4 (Diagrama de Voronoi): Considérese un 
onjunto de puntos
{c1, c2, . . . , cn}(
entros). Se dene el diagrama de Voronoi 
omo la subdivisión
del plano en n áreas, una por 
ada ci, tal que q ∈ al área ci sí y sólo sí la distan
ia
eu
lidiana d(q, ci) < d(q, cj) para 
ada cj, 
on j 6= i.
En el presente trabajo se mostrará los resultados ini
iales obtenidos 
on dos estruturas,
el GNAT [4℄ y EGNAT [17℄. El EGNAT está basado en el GNAT que es una
generaliza
ión del Generalized Hyperplane Tree (GHT ) [15℄. Ambas estru
turas son
basadas en 
lustering y usan diagramas de Voronoi para dividir el espa
io. Para la
búsqueda usan el 
riterio de Hiperplano, aunque igualmente usan radio 
obertor.
1.3. Modelo de 
omputa
ión paralela BSP
El modelo BSP de 
omputa
ión paralela fue propuesto en 1990 
on el objetivo de
permitir que el desarrollo de software sea portable y tenga desempeño e
iente y es
alable
[18,12℄. BSP propone al
anzar este objetivo mediante la estru
tura
ión de la 
omputa
ión
en una se
uen
ia de pasos llamados supersteps y el empleo de té
ni
as aleatorias para
el ruteo de mensajes entre pro
esadores. El 
omputador paralelo, independiente de
su arquite
tura, es visto 
omo un 
onjunto de pares pro
esadores-memoria, los 
uales
son 
one
tados mediante una red de 
omuni
a
ión 
uya topología es transparente al
programador. Los supersteps son delimitados mediante la sin
roniza
ión de pro
esadores.
Los pro
esadores pro
eden al siguiente superstep una vez que todos ellos han al
anzado
el nal del superstep, los 
uales son agrupados en bloques para optimizar la e
ien
ia
de la 
omuni
a
ión. Durante un superstep, los pro
esadores trabajan asin
róni
amente

on datos alma
enados en sus memorias lo
ales. Cualquier mensaje enviado por un
pro
esador está disponible para pro
esamiento en el pro
esador destino sólo al 
omienzo
del siguiente superstep. Dada la estru
tura parti
ular del modelo de 
omputa
ión, el 
osto
de los programas BSP puede ser obtenido utilizando té
ni
as similares a las empleadas
en el análisis de algoritmos se
uen
iales. En BSP, el 
osto de 
ada superstep esta dado
por la suma del 
osto en 
omputa
ión (el máximo entre los pro
esadores), el 
osto de
sin
roniza
ión entre pro
esadores, y el 
osto de 
omuni
a
ión entre pro
esadores (el
máximo enviado/re
ibido entre pro
esadores).
BSPonMPI es una bibliote
a de software independiente de la plataforma de hardware
para desarrollar programas paralelos, realizada muy re
ientemente. Implementa el
estándar BSPlib (
on una pequeña ex
ep
ión) y 
orre sobre todas las máquinas que
eje
utan MPI. Esta última 
ara
terísti
a es el rasgo prin
ipal de esta bibliote
a y de
esta manera se distingue de otras bibliote
as 
omo Oxford BSP Toolset y la BSP PUB.
MPI (Message Passing Interfa
e o Interfa
e de paso de mensajes) debería ha
er más
fá
il la es
ritura de un programa paralelo. Sin embargo en la prá
ti
a todavía es muy

ompli
ado, porque esta API se 
ompone de 
ientos de fun
iones. También es ne
esario

uidar en la programa
ión que no se produz
an errores típi
os de los entornos paralelos,

omo los deadlo
ks y los 
omportamientos no determinísti
os. Por otro lado BSP 
onsiste
de sólo 20 primitivas, que propor
ionan la misma fun
ionalidad y velo
idad. BSPlib,

omo se 
ono
e a esta API, permite es
ribir programas paralelos según el paradigma
BSP [3℄. Este paradigma permite desarrollar un algoritmo paralelo de una manera
estru
turada, generando 
ódigo legible y e
iente. BSPlib ya es puesto en prá
ti
a para
varios superordenadores y 
lusters, pero 
omo es menos popular que MPI, no es puesto en
prá
ti
a para todas las plataformas de hardware. A
tualmente hay dos implementa
iones
prin
ipales de BSPlib: Oxford BSP Toolset y PUB. Ambos son implementa
iones para
plataformas de hardware espe
í
as (Cray T3E o el Origen SGI, et
), y poseen una versión
independiente de la plataforma sobre MPI. Sin embargo la arquite
tura de su bibliote
a
de software es optimizada para el empleo de 
ara
terísti
as de hardware espe
í
as,
ya que no fue el objetivo primario el desarrollo sobre MPI. Evalua
iones preliminares
han demostrado que la implementa
ión de BSPonMPI es mu
ho más e
iente que las
implementa
iones existentes [13℄.
2. Digesto Digital Institu
ional
El presente trabajo presenta un prototipo para un bus
ador por similitud sobre
un espa
io de do
umentos. La apli
a
ión, en etapa de prueba, se ha denominado
Digesto Digital Institu
ional. Originalmente el término Digesto se apli
ó a la 
odi
a
ión
del Dere
ho Romano, pero a
tualmente y por extensión se 
ono
e 
omo digesto a la

ompila
ión ordenada de toda norma jurídi
a. El Digesto Institu
ional permite a

eder a
todo lo a
tuado, san
ionado y legislado en el tiempo, por una Institu
ión dada. Constituye
el 
uerpo de leyes o reglamenta
iones por el 
ual se rige la a
tua
ión y las de
isiones de
una administra
ión, 
ompendiando además, todo lo resuelto o a
tuado en fun
ión y 
on
aten
ión a ese 
onjunto de reglamenta
iones bási
as.
Se optó por implementar el Digesto Digital 
on la informa
ión de una de las
Universidades a la que pertene
en los autores, ya que, ini
ialmente, el volumen de datos
involu
rados resultaba atra
tivo para realizar las pruebas de laboratorio de este trabajo.
Se ha estimado, a futuro, un volumen de datos de al menos 500.000 páginas de do
umentos

orrespondientes a los órganos de gobierno de la Universidad de los últimos 10 año.
Junto 
on la estru
tura métri
a que soportará toda la informa
ión, adi
ionalmente se
alma
enaran los do
umentos originales en formato texto en una base de datos distribuida
y en formato de ar
hivos PDF alma
enados en el servidor web (para poder obtener un

opia 
on autenti
a
ión por parte de la Universidad).
2.1. Modelo Ve
torial para Do
umentos
En re
upera
ión de informa
ión [2℄ se dene un do
umento 
omo una unidad de
re
upera
ión, la 
ual puede ser un párrafo, una se

ión, un 
apítulo, una página web,
un artí
ulo o un libro 
ompleto. Los modelos 
lási
os en re
upera
ión de la informa
ión

onsideran que 
ada do
umento está des
rito por un 
onjunto representativo de palabras

laves llamadas términos, que son palabras 
uya semánti
a ayuda a denir los temas
prin
ipales del do
umento.
Uno de estos modelos, el modelo ve
torial, 
onsidera un do
umento 
omo un ve
tor
t-dimensional, donde t representa el número total de términos de la 
ole

ión. Cada

oordenada i del ve
tor está aso
iada a un término del do
umento, 
uyo valor 
orresponde
a un peso positivo wij si es que di
ho término pertene
e al do
umento j o 0 en 
aso

ontrario. Si D es el 
onjunto de do
umentos y dj es el j-ésimo do
umento pertene
iente
a D, enton
es dj = (w1j, w2j, ..., wij).
En el modelo ve
torial se 
al
ula el grado de similitud entre un do
umento d y una

onsulta q, la 
ual puede ser vista 
omo un 
onjunto de términos o 
omo un do
umento

ompleto, 
omo el grado de similitud entre ve
tores
−→dj y −→q . Esta 
orrela
ión puede ser

uanti
ada, por ejemplo, 
omo el 
oseno del ángulo formado entre ambos ve
tores:
sim(dj , q) =
−→dj · −→q
∣
∣
∣
−→dj
∣
∣
∣
× |−→q |
=
t
∑
i=1
wij × wiq
√
√
√
√
t
∑
i=1
w2ij ×
t
∑
i=1
w2iq
donde wiq es el peso del i-ésimo término en la 
onsulta q.
Los pesos de los términos pueden 
al
ularse en varias formas. Una de las más
importantes es utilizando esquemas tf-idf, en donde los pesos están dados por:
wij = fi,j × log
(
N
ni
)
donde N es el número total de do
umentos, ni es el número de do
umentos en donde
el i-ésimo término apare
e, y fi,j es la fre
uen
ia normalizada del i-ésimo término, dada
por:
fi,j =
freqi,j
máx
l=1..t
(freql,j)
donde freqi,j es la fre
uen
ia del i-ésimo término en el do
umento dj, y máx
l=1..t
(freql,j))
es el máximo valor de la fre
uen
ia sobre todos los términos 
ontenidos en dj.
Si se 
onsidera que los do
umentos son puntos en un espa
io métri
o, el problema
de búsqueda de do
umentos similares a una 
onsulta dada se redu
e a una búsqueda
por similaridad en el espa
io métri
o. Dado que sim(dj , q) es una medida de similaridad
y no de distan
ia, se utiliza el ángulo formado entre los ve
tores
−→dj y −→q , d(dj, q) =
arc cos (sim(dj , q)), 
omo fun
ión de distan
ia, la 
ual se denomina distan
ia 
oseno [2℄.
Así denido, se puede de
ir que el par (D, d) es un espa
io métri
o.
2.2. Prepro
esamiento de Do
umentos
Durante la etapa de prepro
esamiento de do
umentos, una vez realizados los pro
esos
de elimina
ión de palabras va
ías y stemming, se obtuvieron ve
tores representativos de
dimensión 9,341, la dimensión original era sobre 18.000.
Existen 
ompli
a
iones propias del manejo de do
umentos reales que entorpe
ieron el
pro
esamiento de los do
umentos y disminuyeron el rendimiento de las estru
turas. Entre
estos, el uso de nombres propios, las faltas ortográ
as, la referen
ia
ión de do
umentos
previos y el 
ontexto de los do
umentos. En los dos primeros 
asos, se provo
aba un
aumento de dimensión, ya que por 
ada palabra nueva la dimensión 
re
ía en uno.
Respe
to del 
ontexto, se puede indi
ar que los nombres propios de 
iudades se repetían

ontinuamente, por ejemplo, en resolu
iones propias de una unidad a
adémi
a, esto
impli
aba que di
ha palabra fuera similar a una palabra va
ía.
Lo anterior podría subsanarse utilizando texto semiestru
turado y 
ompartir las
ventajas de la búsqueda por similitud y tradi
ional. Esto queda propuesto para una
etapa futura de este trabajo.
Igualmente se puede men
ionar, que la dimensión intrinse
a de este espa
io es elevada,
del orden de 158, por lo que la búsqueda resulta di
ultosa. Además, la 
antidad de
palabras de los primeros do
umentos de prueba eran del orden de 500 (sin palabras
va
ías y apli
ando stemming). Esto di
ultaba aún más la búsqueda, prin
ipalmente
debido a que el ve
tor representativo 
ontenia mu
has posi
iones en 0, lo que ha
e que
mu
hos do
umentos fueran relativamente similares o en términos de distan
ia, que mu
hos
estuvieran relativamente a distan
ias similares.
Los in
onvenientes anteriores, provo
an que este espa
io sea un medio di
il para
realizar búsquedas, lo que 
ontráriamente propor
iona, una ex
elente oportunidad para
experimentar sobre él.
3. Estru
turas Métri
as
Las estru
turas métri
as utilizadas en el presente trabajo 
orresponden a GNAT [4℄ y
EGNAT [17℄. Las estru
turas son basadas en 
lustering y son del tipo árbol. La ele

ión de
estas estru
turas es debido a su buen desempeño en espa
ios métri
os de alta dimensión.
Di
has estru
turas son pare
idas en la forma y presentan 
ara
terísti
as similares en sus
pro
esos de búsqueda.
Otras 
ara
terísti
as que determinaron el uso de estas estru
turas, es que se tienen
versiones estables de las mismas, y que fueron implementadas para memoria se
undaria,
siendo el egnat diseñada espe
i
amente para esto, además de dinámi
a. Esto permite
que los experimentos puedan tener una plataforma que soporte una apli
a
ión real.
3.1. GNAT
Durante la 
onstru

ión, el gnat (Geometri
 Near-neighbor A

ess Tree) sele

iona k
puntos 
lave para parti
ionar el espa
io, {c1, c2, . . . , ck} denominados 
entros. Cada punto
restante es asignado al 
entro más 
er
ano, deniéndose así el subárbol de inuen
ia. Cada
subárbol es parti
ionado re
ursivamente. Durante este pro
eso se van 
onstruyendo tablas
de rangos entre 
ada par de 
entros (ci, cj), alma
enando las distan
ias mínima y máxima
entre ci y el 
onjunto de objetos aso
iados acj, denominado Dcj .
En la gura 1 se muestra un ejemplo de 
onstru

ión del primer nivel de un gnat 
on
k=4, también se muestra la tabla de rangos que debe ser alma
enada para 
ada 
entro
ci. En este ejemplo se insertaron los puntos en orden al valor numéri
o que tienen.
p14
p13
p8
p15
p3 p12
p10
p6
p7 p11
p9
p1
p2
p5
p4 p4p3p2p1
p10 p12 p5 p7 p11 p15 p9 p6 p8 p13 p14
Figura 1. Parti
ión del espa
io, representa
ión de subplanos.
Durante la búsqueda se des
artan subplanos 
ompletos 
omparando la 
onsulta q

ontra alguno de los 
entros, por ejemplo c0 y si range(c0, q)∩range(c0, Dcx) = ∅, enton
es
se puede des
artar 
ompletamente el subárbol aso
iado a x (
onjunto Dcx).
3.2. Evolutionary GNAT (EGNAT)
El gnat evolutivo es una versión dinámi
a y optimizada para memoria se
undaria del
gnat. Permite realizar elimina
iones en línea, disminuye el tamaño de la estru
tura en
dis
o y redu
e los a

esos a dis
o, entre otros.
El egnat es bási
amente un árbol donde 
ada nodo na
e 
omo un bu
ket, sin
informa
ión alguna respe
to de los datos. Al llenar una página de dis
o, el nodo bu
ket
evolu
iona a un nodo gnat, 
on todas las propiedades de éste, y del 
ual 
uelgan hijos
del tipo bu
ket. Adi
ionalmente, los objetos ubi
ados en los bu
ket guardan la distan
ia
al padre o 
entro del 
luster. El pro
eso se repite re
ursivamente sobre los hijos bu
ket.
Durante la búsqueda se utilizan la propiedades del gnat y también la informa
ión
guardada para los objetos en los bu
ket, distan
ia al padre, una propiedad de las
estru
turas basadas en pivotes.
4. Paraleliza
ión de Estru
turas Métri
as
El motor de búsqueda se implementó sobre un 
luster de PCs, donde se realizaron
pruebas utilizando 2, 4 y 8 máquinas en el 
luster para tener una visión de la disminu
ión
de los 
ostos de pro
esamiento. Cada máquina del Cluster está 
ompuesta por un
pro
esador Intel Core 2 Duo de 2,2 GHz, memoria RAM de 1Gbytes, dis
os duros de
7200rpm SATA II.
El 
ontexto 
omún de los experimentos es que existe una máquina broker o maestro,
ésta se en
arga, ini
ialmente, en el pro
eso de 
onstru

ión de distribuir los datos y
posteriormente, durante la búsqueda de repli
ar en 
ada pro
esador las 
onsultas y
re
ole
tar los resultados.
Se 
onsidera que el sistema trabaja bajo régimen esta
ionario, por lo que la fase de

onstru

ión no ha sido presenta en este trabajo.
4.1. Estrategia de Índi
e Lo
al
Esta estrategia 
onsiste en que 
ada máquina tiene un árbol independiente y distinto
a los demás y 
ada uno ha
e el pro
eso de búsqueda solamente en su estru
tura lo
al.
Para esto el broker distribuye los datos en 
ada pro
esador. Posteriormente, 
ada
pro
esador 
onstruye lo
almente su estru
tura datos.
Durante los pro
esos de búsqueda, el broker ha
e difusión de las 
onsultas, tomando

ada una y enviandola a 
ada pro
esador. Lo presentado en este artí
ulo 
orresponde a
un superstep por 
onsulta, por lo que despues de pro
esada una 
onsulta, los resultados
son re
ole
tador por el broker.
Implementa
iones distintas al de índi
e lo
al han tenido 
omportamientos menos
e
ientes, éste es el 
aso de estru
turas 
on índi
es globales donde se distribuyen los
subárboles en el 
luster e índi
e globales que realizan multiplexión de los nodos, es de
ir,
para un árbol se distribuyen sus nodos dentro del 
luster. Esto o
urre prin
ipalmente
debido a que 
on BSP se paga un 
osto de 
omuni
a
ión durante la sin
roniza
ión de
pro
esos, por lo que para índi
es lo
ales, la sin
roniza
ión es mu
ho menor [16℄.
4.2. Resultados Preliminares
Los experimentos se realizaron sobre un espa
io métri
o de do
umentos, 
uya 
antidad
de objetos fue 
er
ana a los 10,000. Cada do
umento fue prepro
esado para obtener
un ve
tor representativo de 9,341 
omponentes (un punto en un espa
io de 9,341
dimensiones). El pro
esamiento de los do
umentos fue he
ha según lo expli
ado en la
se

ión 2.2.
Para la 
onstru

ión de la estrutura, se utiliza un 90% de la base de datos, el restante
10% es utilizado 
omo 
onsulta.
Los resultados obtenidos en esta implementa
ión paralela son evaluados en términos
de speed-up. Speed-up se dene 
omo la propor
ión de tiempo que toma solu
ionar un
problema sobre un pro
esador y el tiempo requerido para solu
ionar el mismo problema
sobre un 
omputador paralelo 
on p pro
esadores.
Los grá
os de la gura 2 muestran el speed-up para las estru
turas gnat e egnat.
Los rangos de búsqueda que apare
en en ambos grá
os 
orresponden a los rangos que,
dada un 
onsulta, permiten re
uperar el 0.1%, 1% y el 10% de la base de datos. Los
rangos fueron 
al
ulados experimentalmente y su objetivo es poder realizar análisis del

omportamiento de las estru
turas.
 2
 4
 6
 8
 10
 12
 14
2 4 8
Ti
em
po
 S
ec
ue
nc
ia
l/T
ie
m
po
 P
ar
al
el
o
Número de Procesadores
SpeedUP Promedio de Búsqueda (Gnat, Documentos Dim 9341)
Recuperación del 0.1%
Recuperación del 1%
Recuperación del 10%
(a) gnat
 2
 2.5
 3
 3.5
 4
 4.5
 5
 5.5
 6
 6.5
2 4 8
Ti
em
po
 S
ec
ue
nc
ia
l/T
ie
m
po
 P
ar
al
el
o
Número de Procesadores
SpeedUP Promedio de Búsqueda (EGnat, Documentos Dim 9341)
Recuperación del 0.1%
Recuperación del 1%
Recuperación del 10%
(b) egnat
Figura 2. Grá
os informativos para la búsqueda sobre el espa
io de do
umentos.
Llama la aten
ión que, si bien era de esperar, hubo una 
onsiderable disminu
ión de
los 
ostos en tiempo. Para el grá
o 2(a), el desempeño en términos de speed-up es mu
ho
mejor que para la estru
tura egnat. El 
omportamiento de esta 
urva es superlineal, es
de
ir, para 4 y 8 pro
esadores, la estru
tura se 
omporta mu
ho mejor que 4 y 8 ve
es
respe
tivamente, lo que no o
urre en el grá
o del egnat (2(b)).
Si se observa la gura 3, ésta muestra la 
antidad de evalua
iones de distan
ia para

ada estru
tura para el pro
eso de re
uperar un 10% de la base de datos. En este
grá
o se muestra que ambas estru
turas tienen un 
omportamiento muy pare
ido, lo que
igualmente su
ede al re
uperar el 0.1% y 1%. Lo anterior indi
a que si bien en términos
de evalua
iones de distan
ia son similares, en términos de tiempo no. El 
omportamiento
de la estru
tura gnat mejora en fun
ión del aumento de pro
esadores, mu
ho más que
el egnat. Sin embargo, esto se debe prin
ipalmente que si bien la primera estru
tura
fue implementada en una versión para memoria se
undaria, esta no ha sido diseñada ni
optimizada para tal efe
to. Al haber menos pro
esadores, requiere de mayor 
antidad de
a

esos a dis
o, lo 
ual no ha
e en forma e
iente, por lo que su desempeño aumenta

onsiderablemente al disponer de mayor 
antidad de RAM.
5. Con
lusiones
El trabajo presentado en el presente artí
ulo, 
orresponde a la fase ini
ial de un
proye
to de implementa
ión de un Digesto Digital Institu
ional para búsqueda de
do
umentos por Similitud. La informa
ión presentada demuestra que el proye
to es viable
de realizar y que los resultados son prometedores.
Se 
onsidera que el aporte más relevante del presente artí
ulo es presentar un trabajo
de investiga
ión orientado al desarrollo de una apli
a
ión real, que reune dos áreas de
investiga
ión. También se 
onsidera un aporte, brindar la posibilidad de aumentar la

omplejidad de las búsquedas en do
umentos de texto y entregar versiones paralelas de
dos estruturas métri
as.
 1e+06
 1.5e+06
 2e+06
 2.5e+06
 3e+06
 3.5e+06
2 4 8
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Número de Procesadores
Promedio de Búsqueda (Recuperación del 10% en Documentos Dim 9341)
EGnat
Gnat
Figura 3. Cál
ulos de evalua
iones de distan
ia para las estru
turas gnat y egnat para el espa
io de do
umentos
reales..
La versión original del Digesto implementado por los autores [10℄, bási
amente
alma
enaba el texto de los do
umentos en tablas alma
enadas en un servidor de bases
de datos y distribuidas en un Cluster de PCs. El pro
eso de búsqueda 
onsistía en
bus
ar palabras utilizando un lenguaje de 
onsulta. Con la nueva propuesta, se agrega
la posibilidad de realizar búsquedas por similaridad o aproximada de do
umentos. Lo
anterior 
onlleva a proveer de una herramienta util para los pro
esos de re
upera
ión de
informa
ión y nalmente a la toma de de
isiones en la institu
ión.
El trabajo que se está realizando en la a
tualidad, es la utiliza
ión de otras estru
turas
que permitan aumentar el rendimiento de las búsquedas. Los primeros experimentos nos
han indi
ados que algunas estru
turas denitivamente no responden ade
uadamente a
este tipo de espa
io, es el 
aso de una version del SSSTree [5℄ y otra del Spaghettis [7℄.
Entre los trabajos futuros que realizar, se en
uentran, bus
ar otras fun
iones de
distan
ia mas ade
uada para este tipo de ve
tores, realizar ajustes sobre la fun
ión de
distan
ia, evaluar la 
alidad de las búsquedas y resultados obtenidos, experimentar 
on
otras alternativas de paraleliza
ión de estruturas métri
as, entre otras.
Referen
ias
1. R. Baeza-Yates, W. Cunto, U. Manber, and S. Wu. Proximity mat
hing using xedqueries trees. In 5th
Combinatorial Pattern Mat
hing (CPM'94), LNCS 807, pages 198212, 1994.
2. R. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval. Addison-Wesley, 1999.
3. Rob H. Bisseling. Parallel S
ienti
 Computation: A Stru
tured Approa
h using BSP and MPI. Oxford
University Press, 2004.
4. Sergei Brin. Near neighbor sear
h in large metri
 spa
es. In the 21st VLDB Conferen
e, pages 574584.
Morgan Kaufmann Publishers, 1995.
5. Nieves R. Brisaboa, Os
ar Pedreira, Diego Se
o, Roberto Solar, and Roberto Uribe. Clustering-based
similarity sear
h in metri
 spa
es with sparse spatial 
enters. In SOFSEM 2008: 34rd Conferen
e on Current
Trends in Theory and Pra
ti
e of Computer S
ien
e, volume 4910 of Le
ture Notes in Computer S
ien
e,
pages 186197, Novy Smokove
, High Tatras, Slovakia, January, 19-25 2008. Springer.
6. W. Burkhard and R. Keller. Some approa
hes to best-mat
h le sear
hing. Communi
ation of ACM,
16(4):230236, 1973.
7. E. Chavéz, J. Marroquín, and R. Baeza-Yates. Spaghettis: An array based algorithm for similarity queries in
metri
 spa
es. In 6th International Symposium on String Pro
essing and Information Retrieval (SPIRE'99),
pages 3846. IEEE CS Press, 1999.
8. Edgar Chávez, Gonzalo Navarro, Ri
ardo Baeza-Yates, and José L. Marroquín. Sear
hing in metri
 spa
es.
In ACM Computing Surveys, pages 33(3):273321, September 2001.
9. P. Cia

ia, M. Patella, and P. Zezula. M-tree : An e
ient a

ess method for similarity sear
h in metri
spa
es. In the 23st International Conferen
e on VLDB, pages 426435, 1997.
10. Esteban Gesto, Daniel Laguia, Natalia Trejo, Osiris Soa, and Jose Canumán. Implementa
ión de un motor
de búsquedas paralelo 
on bsp. In 32a Conferen
ia Latinoameri
ana de informáti
a, Santiago de Chile Chile, Agosto 2006. CLEI 2006.
11. Gonzalo Navarro. Sear
hing in metri
 spa
es by spatial approximation. The Very Large Databases Journal
(VLDBJ), 11(1):2846, 2002.
12. D.B. Skilli
orn, J.M.D. Hill, and W.F. M
Coll. Questions and answers about BSP. Te
hni
al Report PRGTR-15-96, Computing Laboratory, Oxford University, 1996. Also in Journal of S
ienti
 Programming, V.6
N.3, 1997.
13. Wijnand Suijlen. Implementing BSPonMPI 0.1. Lessons Learned & Results, 2006.
14. Caetano Traina, Agma Traina, Bernhard Seeger, and Christos Faloutsos. Slim-trees: High performan
e metri
trees minimizing overlap between nodes. In VII International Conferen
e on Extending Database Te
hnology,
pages 5161, 2000.
15. J. Uhlmann. Satisfying general proximity/similarity queries with metri
 trees. In Information Pro
essing
Letters, pages 40:175179, 1991.
16. Roberto Uribe and Ri
ardo Barrientos. Estrategias de paraleliza
ión el egnat. In XXXII Conferen
ia
Latinoameri
ana de Estudios en Informáti
a (CLEI2006), Santiago, Chile, 2006.
17. Roberto Uribe-Paredes. Manipula
ión de estru
turas métri
as en memoria se
undaria. Master's thesis,
Fa
ultad de Cien
ias Físi
as y Matemáti
as, Universidad de Chile, Santiago, Chile, Abril 2005.
18. L.G. Valiant. A bridging model for parallel 
omputation. Comm. ACM, 33:103111, Aug. 1990.
19. P. Yianilos. Data stru
tures and algoritms for nearest neighbor sear
h in general metri
 spa
es. In 4th
ACM-SIAM Symposium on Dis
rete Algorithms (SODA'93), pages 311321, 1993.
