Superlinealidad sobre Clusters
﻿
 
This paper analyzes the scalability of superlinear parallel algorithms run over cluster architectures. 
The case study is the resolution of the N2 -1 Puzzle problem and, in it, the implementation of a 
parallel solution over clusters -based on the A* algorithm- is analyzed. 
In particular, the results relating the speedup in function of the number of processors in the clusters 
are presented together with a discussion on the superlinearity and efficiency (or pseudo-efficiency) 
attainable when scaling the architecture and / or the dimension of the problem. 
Finally, some future research lines, oriented to predicting the attainable superlinearity in function of 
the initial disorder degree, are presented. 
 
Keywords: Parallel Algorithms, Superlinearity, Scalability, Efficiency. Cluster Architectures. 
 
 
 
Resumen 
 
En este trabajo se analiza la escalabilidad de algoritmos paralelos superlineales ejecutándose sobre 
arquitecturas de cluster. 
El caso de estudio es la resolución del problema del Puzzle N2 -1 y en él se analiza la 
implementación de una solución paralela sobre clusters, basada en el algoritmo A*. 
En particular se presentan resultados que relacionan el speedup en función del número de 
procesadores en el cluster y se discute la superlinealidad y eficiencia (o seudoeficiencia) alcanzable 
al escalar la arquitectura y/o la dimensión del problema. 
Por último se presentan líneas de investigación futuras orientadas a predecir la superlinealidad 
alcanzable en función del grado de desorden inicial. 
 
Palabras Clave: Algoritmos paralelos. Superlinealidad. Escalabilidad. Eficiencia. Arquitecturas 
de Cluster. 
 
 
VI Workshop de Procesamiento Distribuido y Paralelo. 
 
                                                          
1 Becaria Alumna. Auxiliar Docente de la  Facultad de Informática UNLP.  vsanz@ciudad.com.ar. 
2 Becario de Doctorado del CONICET. Profesor Adjunto de la Facultad de Informática UNLP. francoch@lidi.info.unlp.edu.ar. 
3 Profesor Titular D.E. Facultad de Informática UNLP. mnaiouf@lidi.info.unlp.edu.ar. 
4 Profesor Adjunto de la Facultad de Informática UNLP.  ldgiusti@lidi.info.unlp.edu.ar 
5 Investigador Principal CONICET. Profesor Titular. Facultad de Informática UNLP. degiusti@lidi.info.unlp.edu.ar.  
 
* Esta investigación es parcialmente  financiada por la CIC y, la Fundación YPF. 
 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
VIII Workshop de Procesamiento Distribuido y Paralelo
_________________________________________________________________________
 
 
1300
1. INTRODUCCIÓN 
 
El primer punto de interés en la resolución de un algoritmo sobre una arquitectura multiprocesador 
es el factor de Speedup Sp  que es una medida de perfomance relativa, definida como la relación 
entre el tiempo de ejecución del mejor algoritmo secuencial sobre una máquina monoprocesador y 
el tiempo de ejecución del algoritmo paralelo correspondiente sobre una máquina multiprocesador 
[1] [2]. Si llamamos Ts al tiempo de ejecución secuencial y Tp al paralelo, tenemos la relación Sp = 
Ts/Tp  que normalmente se trata de maximizar en el desarrollo de aplicaciones paralelas. 
 
Normalmente el Speedup está limitado por el máximo grado de concurrencia que puede obtenerse 
de la aplicación, por el inevitable componente secuencial del algoritmo y por el número de 
procesadores N disponibles para la ejecución. Dos conceptos surgen para la mayoría de los 
algorimos paralelos:  
 El incremento del número de procesadores utilizados puede hacer crecer el Speedup, pero este 
crecimiento está acotado por el máximo grado de concurrencia alcanzable. A partir de este 
punto agregar procesadores no incrementará el Speedup, e incluso puede disminuirlo [3]. 
 El máximo teórico del Speedup está dado por el número de procesadores, es decir Sp <= N [4]. 
 
Un segundo parámetro de importancia al analizar aplicaciones paralelas es la Eficiencia E 
alcanzada. Se define como Eficiencia la relación entre el Speedup y el número de procesadores 
utilizados para obtenerlo: E = Sp / N.   Esta definición pone la Eficiencia entre 0 y 1. Alcanzar 
valores cercanos a 1 está significando que se logra Speedup cercano al óptimo N. 
 
La Eficiencia resulta una métrica de calidad y de costo del algoritmo paralelo que es 
particularmente importante y no siempre se puede mantener al escalar los problemas, al incrementar  
el número de procesadores o al portar el algoritmo sobre otra arquitectura multiprocesador [3] [5]. 
Mantener la eficiencia constante al escalar un algoritmo paralelo se denomina isoeficiencia y en 
muchas aplicaciones es un objetivo lograr algoritmos que tengan esta propiedad [1]. 
 
La Escalabilidad es un factor muy importante en las aplicaciones paralelas: normalmente los 
problemas “escalan” es decir aumenta el volumen de trabajo a realizar y también las arquitecturas 
multiprocesador que utilizamos pueden “escalar” incrementando los procesadores utilizados. Es de 
interés investigar el efecto de escalar trabajo y/o procesadores sobre el rendimiento de los 
algoritmos paralelos, considerando Speedup y Eficiencia [2] [3]. 
 
El máximo Speedup teórico puede en algunos casos ser mejorado y esto da lugar al concepto de 
Superlinealidad  Su. Es interesante analizar por qué el Speedup puede superar N: 
 
 En la mayoría de los casos se han utilizado algoritmos secuenciales sub-óptimos (al crecer Ts 
crece Sp) y la relación de cálculo de Sp no respeta la definición que indica emplear el mejor 
algoritmo secuencial. Estos casos podemos considerarlos como una “falla”. 
 En otras oportunidades, la memoria disponible en la arquitectura monoprocesador es mucho 
menor que la memoria total utilizable en la arquitectura paralela, con lo que un esquema de 
paralelización por división del espacio de datos puede conducir a un Speedup superlineal al no 
requerir accesos a memoria secundaria [6].  
 La clase de aplicaciones que nos interesan y pueden dar superlinealidad al paralelizarlos son los 
problemas de optimización discreta, donde la exploración del espacio total de soluciones 
posibles puede reducirse al distribuir el trabajo entre N procesadores y poder “cortar” o 
“finalizar” la búsqueda global al llegar al resultado esperado en cualquiera de ellos [7] [8]. 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
VIII Workshop de Procesamiento Distribuido y Paralelo
_________________________________________________________________________
 
 
1301
Los problemas de optimización discreta abarcan un gran número de áreas [9] y a menudo son 
resueltos con métodos de exploración del espacio de estados, buscando un estado “solución” [10]. 
Estas técnicas de búsqueda normalmente tienen un alto costo computacional y permiten una 
paralelización natural, con lo que los algoritmos de resolución paralela en optimización discreta han 
sido motivo de numerosos desarrollos y publicaciones dentro del procesamiento paralelo [11] [12]. 
 
En particular las técnicas de BFS (Best First Search) parten de nodo o estado inicial del grafo que 
represente el problema que es seleccionado por alguna métrica de estimación del trabajo para llegar 
a la solución y tratan de evolucionar a partir de este punto. La paralelización natural de la técnica 
consiste en iniciar la evolución desde diferentes nodos “posibles” sobre los distintos procesadores 
de la arquitectura multiprocesador. A medida que el algoritmo evoluciona es necesario comunicar 
los procesadores para informar resultados alcanzados o bien soluciones descartadas de acuerdo a la 
métrica elegida [13] [14]. 
  
Es interesante reflexionar sobre algunos aspectos que se dan al utilizar arquitecturas paralelas tipo 
cluster en la resolución de problemas de optimización discreta [15]: 
 La granularidad de la paralelización es crítica, porque de ella dependerá la mejora en el tiempo 
de solución y también el overhead de comunicaciones. 
 En general el balance de carga tiene que ser dinámico (lo que exige comunicación) ya que el 
trabajo exploratorio es variable y es muy difícil predecirlo a priori [16]. 
 Conceptualmente podría esperarse que para una dimensión fija del problema a resolver (espacio 
total de nodos a explorar), el incremento del número de procesadores permita escalar el Speedup 
hasta un punto, donde las comunicaciones limiten el crecimiento.  
 En teoría la arquitectura de cluster podrá permitirnos alcanzar superlinealidad, dependiendo del 
balance de carga, la heterogeneidad de los procesadores y la relación tiempo de 
procesamiento/tiempo de comunicaciones del algoritmo empleado [17]. 
 
Caso de Estudio y Contribución 
 
En este trabajo se estudia el caso del Puzzle N2 -1 [18][19], desarrollando una solución paralela con 
una técnica de BFS sobre un cluster. 
En particular se analiza la superlinealidad alcanzable para distintas dimensiones del problema y 
diferente número de procesadores.  
Asimismo se analiza la máxima eficiencia alcanzable y el número de procesadores en el cluster para 
alcanzar un nivel de eficiencia dado. 
 
 
 
2. ANALISIS DEL PROBLEMA DEL PUZZLE N2 -1 
 
El problema del Puzzle N2-1 es una generalización del Puzzle-15 ideado por Sam Lloyd [20][21]. 
Consiste en N2-1 piezas numeradas de 1 a N2-1 colocadas en un tablero de tamaño N2.  
 
N2-1 casilleros del tablero contienen exactamente una pieza, quedando sólo una casilla vacía la cual 
se denomina “hueco”. 
 
El objetivo del puzzle es repetidamente llenar el hueco con una pieza adyacente a él en sentido 
horizontal o vertical, hasta alcanzar un tablero donde en la casilla (i,j) se encuentra la pieza 
numerada como (i-1)*N + j y en la casilla (N,N) se encuentra el hueco. 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
VIII Workshop de Procesamiento Distribuido y Paralelo
_________________________________________________________________________
 
 
1302
 
La solución al problema planteado tendrá que ser aquella que minimice la cantidad de movimientos 
que deben realizarse para alcanzar la configuración final desde la configuración inicial dada. 
 
La Figura 1.a muestra un Puzzle N2-1 donde N es 4. La Figura 1.b representa un esquema de 
solución al problema. 
 
 
 
  
 
 
 
 
Construcción del espacio de estados del problema 
 
Para construir el grafo sobre el cual se realizará la búsqueda se requiere: 
 Esquema de ramificación: utilizado para generar subproblemas a partir de un problema dado. 
 Estrategia de búsqueda: indica cómo seleccionar un nodo entre los nodos pendientes de acuerdo 
a prioridades definidas. Generalmente la estrategia se basa en seleccionar nodos que estén 
próximos a la solución. 
 Función de costo: estima el costo de alcanzar la solución a partir de un nodo intermedio. Sea 
h(x) esta función (también llamada heurística); si h(x) es una cota inferior del costo real 
requerido para alcanzar el nodo solución a partir de x, entonces h(x) es admisible6. Sea g(x) la 
función que denota el costo de alcanzar el estado x a partir de la configuración inicial, luego la 
cota inferior para el camino que puede ser obtenido expandiendo el camino actual entre la 
configuración inicial y el estado x es L(x) = g(x) + h(x). 
 
 
Distancia de Manhattan 
 
Supongamos que cada posición del tablero se representa como un par ordenado. La distancia entre 
las posiciones (i,j) y (k,l) está definida como | i - k | + | j - l |. Dicha distancia recibe el nombre de 
Distancia de Manhattan. La suma de las distancias de Manhattan entre las posiciones del tablero x 
y el tablero final será un estimador mínimo del número de movimientos requeridos para transformar 
el tablero x en el tablero solución. Esta función se utilizará como función heurística admisible h(x). 
 
 
Algoritmo A*  
 
A* es una de las variantes más conocidas de la búsqueda Best First Search. Cada nodo n es valuado 
de acuerdo con el costo de alcanzar el mismo a partir de la raíz del árbol de búsqueda (g(n)) y una 
heurística que estima el costo para ir de n hasta un nodo solución (h(n)). Luego, la función de costo 
será L(x) = g(x) + h(x). 
Está garantizado que el algoritmo A* siempre encontrará la mejor solución. 
 
                                                          
6  Función admisible h(x): el costo real para alcanzar el nodo objetivo a partir del nodo x siempre es mayor o igual al 
valor de h(x). 
 
2 5 1 12 
15 3 8 14 
4 13 10  
11 6 9 7 
1 2 3 4 
5 6 7 8 
9 10 11 12 
13 14 15  
Figura 1.a. Tablero inicial Figura 1.b. Tablero final. 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
VIII Workshop de Procesamiento Distribuido y Paralelo
_________________________________________________________________________
 
 
1303
A*  secuencial 
 
Este algoritmo mantiene una lista de nodos no explorados (lista abierta) ordenada de acuerdo al 
valor de la función L, y otra lista de nodos ya explorados (lista cerrada). Inicialmente la lista abierta 
contiene un solo elemento, el nodo inicial, y la lista cerrada esta vacía.  
 
En cada paso, el nodo con menor valor L (el mejor nodo) es removido de la lista abierta y es 
examinado. Si es el nodo solución, el algoritmo termina. Caso contrario, el nodo es expandido y es 
insertado en la lista cerrada. Cada nodo sucesor es insertado en la lista abierta sólo si no estaba en la 
lista cerrada, o estaba pero su valor L es menor al anterior. 
La lista cerrada es utilizada para evitar trabajo repetido, de modo que no se expandirán nuevamente 
nodos ya explorados. 
 
Dado que siempre se remueve el nodo con menor valor L, la lista abierta comúnmente se 
implementa con una cola de prioridades. La lista cerrada se puede implementar con una tabla de 
hash , donde cada entrada contiene como clave un valor de la heurística h(x), y como valor una lista 
con todos los tableros cuyo h(x) es igual a la clave. 
 
Si se requiere conocer el camino desde el nodo inicial hasta el nodo solución, cada nodo debe 
mantener una referencia a su nodo padre, o poseer la secuencia de pasos por la cual se llegó hasta 
él, así se podrá determinar cómo fue encontrado.  
 
El esquema secuencial es el siguiente: 
 
Crear lista abierta. 
Crear lista cerrada. 
Insertar (lista abierta, x, h(x)). 
mientras (lista abierta no vacía) y (no encontré solución) 
 
// Extraer el mínimo nodo de la lista abierta, llamémoslo n 
n = EliminarMínimo (lista abierta) 
 
// Si el nodo era la solución, es decir h(n) = 0, termina el algoritmo. 
// Caso contrario se expande n. 
si (EsSolución(n)) 
 solución = n 
sino 
 hijos = Expandir(n) 
 Insertar(lista cerrada,n)  
 
// Un nodo es aceptable si no esta en la lista cerrada, o si está pero con un costo mayor al actual 
 para cada uno de los hijos de n 
  si (EsAceptable(hijo)) 
   Insertar(lista abierta, hijo, h(hijo) + g(n) + 1) 
Retornar solución. 
 
 
 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
VIII Workshop de Procesamiento Distribuido y Paralelo
_________________________________________________________________________
 
 
1304
A* paralelo 
 
La estrategia de paralelización consiste en mantener las listas abierta y cerrada locales para cada 
procesador. Al principio sólo uno de los procesadores tendrá como trabajo el nodo inicial. A medida 
que son generados otros nodos, los procesadores recibirán los mismos para comenzar a trabajar.  
 
Todos los procesadores harán una búsqueda en el ámbito local, construyendo su propia lista cerrada, 
para evitar trabajo repetido localmente, como también su lista abierta local. Los procesadores deben 
comunicarse los valores mínimos de las soluciones encontradas, a fin de minimizar búsquedas 
innecesarias. 
 
La solución paralela planteada no requiere un proceso central, sólo requiere procesos trabajadores 
que realicen la búsqueda en el espacio de estados del problema. Para la implementación del 
algoritmo paralelo se utiliza la técnica de balance de carga distribuida “Asynchronous Round 
Robin” (ARR) y el algoritmo de “Terminación de Dijkstra” modificado [22]. 
 
Dados p procesos trabajadores, cada uno dispondrá de su lista abierta y lista cerrada de nodos, así 
como un valor indicando el costo de la mejor solución encontrada hasta el momento (CMS), que se 
utilizará para acotar la búsqueda. El tablero inicial le es asignado al trabajador 0, proceso que 
también se encarga de detectar la terminación de la búsqueda. 
 
Un proceso que posee trabajo en su lista abierta, a lo sumo procesa una cantidad fija de nodos en 
cada iteración (pasada como parámetro al algoritmo) o procesa nodos hasta encontrar una solución 
o que se vacíe su lista abierta. A continuación el trabajador recibe, si los hay, costos de “mejores 
soluciones” encontradas por los demás y a medida que esto ocurre actualiza (si es necesario) su 
variable CMS. De esta manera los nodos a procesar serán sólo los que tengan costo menor a CMS. 
 
Si el proceso todavía posee trabajo en su lista abierta, entonces examina si otros procesos le 
hicieron pedidos de trabajo, caso en el cual envía nodos del principio y final de su lista abierta al 
trabajador solicitante ocioso. Luego continúa trabajando sobre sus nodos.  
En caso contrario, el proceso está ocioso, por lo que envía un pedido de trabajo a su donador 
siguiendo el algoritmo ARR.  
Si el proceso encuentra una nueva solución, envía a todos los demás procesos el costo de la misma. 
Luego espera los siguientes tipos de mensajes, que serán atendidos sin prioridad alguna: 
 Petición de trabajo: un trabajador ocioso seleccionó a este proceso como su donador.  
 Trabajo: el donador envía el trabajo requerido. Ahora el proceso está activo nuevamente. 
 Rechazo de pedido de trabajo: el donador seleccionado no tiene trabajo. El proceso debe enviar 
un mensaje de pedido de trabajo al próximo donador. 
 Token: recepción del token para detección de terminación. Si es  necesario se actualiza el token 
y se pasa al siguiente proceso. El proceso 0, al recibir el token, chequea la terminación. 
 Nueva solución encontrada por otro: en caso de ser necesario, se actualiza la variable CMS. 
 
Cuando el proceso 0 detecta la terminación, envía un mensaje a los demás procesos avisando el fin 
del cómputo. 
Se utilizó el token de terminación para trasladar los movimientos de la solución de costo mínimo 
hasta el proceso 0, de forma que los mensajes de comunicación de nuevas soluciones encontradas 
durante el algoritmo sólo posean un valor entero, el costo, evitando así overhead de comunicación. 
 
 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
VIII Workshop de Procesamiento Distribuido y Paralelo
_________________________________________________________________________
 
 
1305
3. TRABAJO EXPERIMENTAL REALIZADO  
 
Para las pruebas se dispone de un clúster homogéneo compuesto por 20 procesadores Pentium 4 de 
2.4GHz y 1GB de memoria RAM.  
 
En las pruebas realizadas en este trabajo se utilizaron diferentes tamaños de tableros: 4x4 (15Puzzle), 5x5 (24-Puzzle) y 6x6 (35-Puzzle). Para analizar el comportamiento de la aplicación al 
escalar respecto a la cantidad de procesadores, cada tablero se probó con subconjuntos de P 
máquinas pertenecientes al cluster antes mencionado, donde P = {4, 6, 8, 12, 16}.  
 
El trabajo a realizar en cada prueba depende del tamaño del tablero y de la configuración inicial de 
este, es decir de la posición en que se encuentra cada pieza al iniciar la aplicación. Cabe aclarar, que 
muchos de estos estados iniciales no poseen solución.  
 
Para este trabajo se ha tomado un conjunto de configuraciones iniciales que representan el trabajo 
promedio de aquellas configuraciones que tienen solución, el cual ha sido obtenido en estudios 
anteriores [23].  
Las configuraciones utilizadas en cada tamaño de tablero se muestran en la figura 2.  
 
4 5 6 2
9 14 10 8
1 13 7
15 3 11 12
a
    
1 2 13 3 9
6 7 5 10 4
11 8 19 14 15
16 12 18 20
21 22 17 23 24
b
    
1 2 3 4 5 6
8 21 14 10 11 12
19 13 9 7 17 18
32 20 15 16 23 24
25 31 26 22 28 29
27 33 34 35 30
c
 
Figura 2. Configuración inicial para las pruebas con tableros (a) 4x4, (b) 5x5, (c) 6x6. 
 
   
En las Tablas 1, 2 y 3 se muestran los resultados para las configuraciones de la Figura 2. En cada 
tabla se muestra la cantidad de procesadores usados, el tiempo medido en segundos requerido por la 
aplicación, el speedup alcanzado, y la pseudoeficiencia lograda.  
 
Cantidad Máquinas Tiempo SpeedUp Pseudoeficiencia
Secuencial 2769,3028  --  -4 155,851872 17,76881298 4,442203245
6 153,272189 18,06787509 3,011312515
8 154,163291 17,9634383 2,245429787
12 140,379964 19,72719388 1,643932823
16 216,179074 12,81022587 0,800639117  
 
Tabla 1. Resultado de las pruebas con la configuración de la Figura 2.a 
 
 
 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
VIII Workshop de Procesamiento Distribuido y Paralelo
_________________________________________________________________________
 
 
1306
 
Cantidad Máquinas Tiempo SpeedUp Pseudoeficiencia
Secuencial 173,38081  --  -4 11,784312 14,71284959 3,678212398
6 12,479954 13,89274432 2,315457386
8 13,015765 13,32083131 1,665103914
12 12,957742 13,38048018 1,115040015
16 10,115011 17,14094132 1,071308832  
 
Tabla 2. Resultado de las pruebas con la configuración de la Figura 2.b 
 
Cantidad Máquinas Tiempo SpeedUp Pseudoeficiencia
Secuencial 655,099622  --  -4 130,10891 5,035009685 1,258752421
6 41,846063 15,65498819 2,609164698
8 28,970804 22,61240737 2,826550922
12 32,510075 20,15066474 1,679222062
16 39,065716 16,76916972 1,048073108  
 
Tabla 3. Resultado de las pruebas con la configuración de la Figura 2.c 
 
La Figura 3 muestra el speedup alcanzado en cada prueba en un gráfico comparativo. En este se 
nota que en la mayoría de los casos se alcanza un speedup superlineal, el cual comienza a 
decrementarse al utilizar muchas máquinas debido al incremento de la interacción entre las tareas.   
 
0
5
10
15
20
25
4 6 8 12 16
Cantidad de Procesadores
Sp
ee
du
p
Tablero de 4x4 Tablero de 5x5 Tablero de 6x6
 
Figura 3. Gráfico comparativo del speedup de las pruebas de la tabla 1. 
 
La Figura 4 muestra la pseudoeficiencia lograda. En este caso se puede ver como se va 
decrementando a medida que se agregan procesadores, llegando en algunos casos a ser menor a 1.    
 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
VIII Workshop de Procesamiento Distribuido y Paralelo
_________________________________________________________________________
 
 
1307
00,5
1
1,5
2
2,5
3
3,5
4
4,5
5
4 6 8 12 16
Cantidad de Procesadores
Ps
eu
do
ef
ic
ie
nc
ia
Tablero de 4x4 Tablero de 5x5 Tablero de 6x6
 
Figura 4. Gráfico comparativo de la pseudoeficiencia de las pruebas de la tabla 1. 
 
 
  
4. CONCLUSIONES Y LINEAS DE TRABAJO FUTURO 
 
Se ha presentado un análisis de la solución paralela para el problema del Puzzle N2 -1, analizando 
Superlinealidad y Eficiencia. 
 
Se ha estudiado la evolución de ambos parámetros en función del número de procesadores del 
cluster empleado. 
 
Actualmente se están investigando métricas de estimación del trabajo a desarrollar para predecir el 
tiempo de respuesta en función del número de procesadores utilizados. En estos casos se han 
analizado previamente el espacio de estados iniciales que son posibles para alcanzar alguna 
solución. 
 
Asimismo se tratará de separar los tiempos de procesamiento y comunicación, a fin de estimar la 
pérdida de rendimiento al pasar de una arquitectura de cluster a una de multicluster. 
 
 
