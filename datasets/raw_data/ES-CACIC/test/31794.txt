Controlador neuronal incremental aplicado a un mezclador de flujos
﻿ En este trabajo se diseña e implementa un controlador tipo MIMO 
basado en redes neuronales artificiales, aplicado a un modelo de mezclador de 
corrientes líquidas, configurado sobre el entorno de simulación gráfica de  
Matlab®. Se destaca una particular metodología de entrenamiento del controlador neuronal, basada en un punto de operación genérico asociado a un reducido 
entorno del espacio de datos definidos en forma incremental, permitiendo una 
importante reducción de datos de aprendizaje y esfuerzo computacional. El desempeño del controlador es comparado con otro controlador neuronal similar 
configurado bajo un proceso de entrenamiento estándar. Los resultados obtenidos permiten apreciar las ventajas del método de control incremental. 
Palabras clave. Redes neuronales. Mezclador de flujos. Control. Simulación. 
1 Introducción 
Los dispositivos mezcladores de flujos son sistemas adicionales indispensables en muchos procesos industriales y son objeto de estudio y aplicaciones en diversas investigaciones [1], [2], [3]. Usualmente se complementan con sistemas de control que requieren 
correcciones permanentes, que según la complejidad de la dinámica del proceso podrían 
ser realizadas por un operario experto; o por un sistema de control automático. 
En este trabajo se diseña e implementa un controlador tipo MIMO (Multiple-input 
Multiple-output) basado en redes neuronales, aplicado al modelo de un mezclador de 
corrientes líquidas, configurado sobre el entorno Simulink® de Matlab®. Se destaca una 
particular metodología de entrenamiento del controlador, basada en un punto de operación genérico que incursiona sobre un reducido entorno definido en forma incremental, 
permitiendo una importante minimización de datos requeridos para el aprendizaje de la 
red neuronal. El desempeño del controlador es comparado con otro controlador neuronal similar configurado bajo un proceso de entrenamiento estándar. Los resultados 
obtenidos permiten apreciar las ventajas del método de control incremental. 
1363
2 Proceso a controlar 
Los mezcladores de flujos o de caudales (flow mixers), utilizados en muchos procesos 
industriales, suelen estar sometido a dinámicas exigentes, requiriendo la asistencia de 
sistemas de control automáticos. Un sistema de este tipo, cuyo esquema y modelo gráfico se muestran en la Fig. 1, es utilizado en este trabajo como sistema a controlar. 
  
Ff
Tf
TF
xf xc
Vf Vc
Fc
Tc
corriente fría
corriente caliente
corriente
m
ezcla
 
Fig. 1. Mezclador de caudales en línea. (a) esquema físico, (b) modelo. 
Las entradas reciben las corrientes para la mezcla con caudales y temperaturas 
preestablecidos, y en la salida se obtiene una nueva corriente con propiedades específicas (caudal, presión, temperatura, composición). 
2.1 Modelo del mezclador en línea 
El modelo para el mezclador de flujos en línea se puede representar con el siguiente 
conjunto de ecuaciones: 
 
f f c c .= +F x F x F  (1) 
 
f f f c c c
f f c c
.+=
+
x F T x F TT
x F x F
 (2) 
 
f0 1≤ ≤x  y c0 1≤ ≤x  (3) 
 
donde la corriente de entrada (fría), tiene un caudal máximo Ff y una temperatura Tf. 
Esta corriente es regulada por la apertura xf de la válvula Vf. La otra corriente de entrada (caliente), tiene un caudal máximo Fc y una temperatura Tc. Esta corriente es 
regulada por la apertura xc de la válvula Vc. Las aperturas xf y xc incursionan en el 
intervalo (0, 1), donde 0 corresponde a la válvula completamente cerrada y 1 a la 
válvula completamente abierta, de modo que permite pasar la totalidad del caudal 
asignado. La corriente mezcla presenta a la salida un caudal F y una temperatura T. 
(b) (a) 
1364
2.2 Modelo inverso del mezclador en línea 
Invirtiendo el modelo planteado, se obtiene un sistema de control ideal MIMO que 
proporciona las aperturas de las válvulas (xf y xc), para un caudal de referencia (setpoint) Fsp y para una temperatura de referencia Tsp preestablecidos. El modelo matemático asociado a este sistema inverso está formado por las ecuaciones siguientes: 
 
( )
( )
sp c sp
f
f c f
.
−
=
−
F T T
x
F T T
 (4) 
 
( )
( )
sp sp f
c
c c f
.
−
=
−
F T T
x
F T T
 (5) 
 
f sp c≤ ≤T T T  y sp max0 ≤ ≤F F  (6) 
 
donde Fmax es el máximo valor que puede adoptar Fsp para un dado Tsp. El caudal Fmax 
se obtiene a través de un problema de optimización, cuyo resultado se muestra en (7): 
 
( )
( )
f c f f f c c
f sp
c sp f c
max
c c f
sp f
. si   .
. en otro caso
− +≤ ≤
− +
= 
−

−
F T T F T F TT T
T T F F
F
F T T
T T
 (7) 
3 Sistemas de control 
3.1 RNA como procesadores no lineales 
Las redes neuronales artificiales (RNA), son modelos matemáticos que emulan  
–a nivel básico– la actividad del cerebro humano, dotados de la capacidad de aprender, “memorizar” y generalizar la información aprendida, con elevada tolerancia al 
ruido. Desde un punto de vista general, las RNA se especializan en descubrir y asociar patrones de entrada–salida con relación lineal o no lineal, según sea su arquitectura, configuración de las neuronas y proceso de aprendizaje [4], [5]. La Fig. 2 presenta 
una arquitectura típica de red neuronal feedforward de tres capas, con M neuronas de 
entrada, L neuronas en la capa oculta y N neuronas de salida. 
La primera capa de la RNA –de entrada– se configura con unidades ficticias que 
distribuyen las señales hacia la capa oculta. La salida de cada neurona de esta capa 
responde a la siguiente ecuación: 
 
0
1
con 1,..., .
=
 
= − + =  ∑
M
l l lm m
m
y g w w x l L  (8) 
 
1365
donde xm es la m-ésima componente del patrón de entrada; wlm es el peso de conexión 
entre la neurona l de la capa oculta y la neurona m de la capa de entrada; w0l es el peso 
de ajuste (bias) de las neuronas de la capa oculta; g(·) es la función de transferencia de 
las neuronas ocultas y yl es la salida de la l-esima neurona oculta. La salida de cada 
neurona de la última capa se modela con la ecuación (9): 
 
0
1
con 1,..., .
=
 
= − + =  ∑
L
n n nl l
l
z h v v y n N  (9) 
 
donde yl es el valor de salida de las neuronas de la capa anterior; vnl es el peso de conexión entre la neurona n de la capa de salida y la neurona l de la capa oculta; v0n es el 
peso de ajuste (bias) de las neuronas de la capa de salida; h(·) es la función de transferencia de las neuronas de salida y zn es la n-ésima componente del patrón de salida Z. 
 
w11
wl1
wLM
wlM
wlm
w01
-1
w0l
-1
w0L
-1
x1
xm
xM
v11
v1n
vNM
vnL
wnl
v01
-1
v0n
-1
v0N
-1
z1
zn
zN
y1
yl
yL
 
Fig. 2. Red feedforward tricapa genérica. 
3.2 Controlador neuronal incremental 
Se pueden adoptar dos enfoques generales para la implementación de controladores 
neuronales. En un primer enfoque, la RNA tiene como entrada tanto las variables 
controladas como los correspondientes valores de referencia, mientras que las salidas 
son las variables manipuladas (F, T, Fsp y Tsp en este caso); mientras que las salidas 
son las variables de control (xf y xc). Si se tiene algún conocimiento previo del sistema 
–tal como el modelo del proceso, secuencias históricas o muestras de ejemplo con sus 
correspondientes valores de salida–, se puede utilizar para el entrenamiento de la red. 
En este caso, la RNA aprenderá a asociar cada patrón de entrada con la salida correspondiente, sobre la totalidad del espacio de datos del sistema, dentro de un nivel de 
error predeterminado. 
Aunque este es un enfoque clásico y ampliamente utilizado, tiene algunos inconvenientes que pueden considerarse críticos. El primer inconveniente surge por la gran 
cantidad de información que se requiere para cubrir adecuadamente el espacio de 
datos del sistema, que en muchas ocasiones no están disponibles. Otro inconveniente 
destacable es la compleja arquitectura que puede alcanzar la RNA, eventualmente con 
una importante cantidad de unidades neuronales internas, demandando un elevado 
esfuerzo computacional, que en ciertos casos obliga a aplicar técnicas adicionales para 
reducir el flujo de información a costa de un incremento en el error de aprendizaje [6]. 
1366
En un segundo enfoque para implementar una RNA como controlador, se puede 
considerar la operación de la red bajo un esquema incremental. Para ello, se configura 
la RNA para que las entradas sean los errores de las variables controladas (eF y eT), y 
las salidas sean las correcciones que deben realizarse sobre las variables manipuladas 
(∆xf y ∆xc). Estas nuevas variables se definen como: 
 
F sp0 T sp0 .= − = −e F F e T T  (10) 
 
( ) ( ) ( )f f fx t x t x t t∆ = − − ∆  (11) 
 
( ) ( ) ( )c c cx t x t x t t∆ = − − ∆  (12) 
 
donde t es el tiempo de simulación, y ∆t es el paso de simulación. Con este cambio de 
variables, el punto de operación deseado es aquel que anula los errores. Cualquier 
desviación de este punto de operación, requiere que el controlador realice correcciones sobre las variables controladas. Es decir, cuando ambas entradas de la RNA sean 
nulas, sus salidas también lo serán y no es necesaria ninguna acción de control. En 
cambio cuando una o ambas entradas dejen de ser nulas, las salidas de la RNA deberán proveer las correcciones necesarias sobre las variables de control. 
La conducta descripta es independiente del punto base que se tome. Más aún, si la 
superficie de control es lineal, las magnitudes de las correcciones serán independientes de la posición del punto base. 
En este nuevo esquema de control, no es necesario entrenar a la RNA en toda la región de control. Concretamente, bajo este enfoque se establece un punto de operación 
genérico que representa la situación de referencia general de las variables de control y 
se definen las condiciones de operación sobre un entorno, mediante valores incrementales a partir del punto de operación establecido. En la Fig. 3 se muestra un espacio de 
datos bidimensional genérico con sus límites, un punto de operación base definido y el 
entorno asociado con los respectivos incrementos de las variables de control. 
 
Var1
V
ar
2
Espacio de
datos
Límites
Punto de
operación
V1SP
V2SP
Entorno
incremental
Incremento
Var2
Incremento
Var1
 
Fig. 3. Punto de operación y entorno incremental para un proceso genérico. 
La adecuada implementación de la estrategia de control propuesta requiere algunas consideraciones adicionales. Por un lado está la selección del punto base, cuya 
ubicación no debe sobrepasar los límites del espacio de datos, y debería ser el punto 
1367
establecido por las condiciones nominales de diseño del sistema. Por otro lado, está la 
determinación de la extensión del entorno alrededor del punto base, que debe ser 
suficientemente extensa como para capturar la naturaleza de la superficie de control. 
Un tercer criterio a considerar es el intervalo de subdivisión del entorno de operación: incrementos muy grandes no permiten capturar las variaciones del entorno de la 
superficie de control, generando errores considerables en otras ubicaciones del punto 
base; incrementos muy pequeños producirían gran cantidad de datos innecesarios por 
estar más allá de la sensibilidad de los componentes del sistema. 
4 Desarrollo experimental 
El modelo experimental del mezclador de flujos (Fig. 1) se ha implementado inicialmente para operación manual sobre el entorno Simulink® de Matlab® (Fig. 4) y se ha 
instanciado con los siguientes parámetros: 
• Corriente fría: caudal de entrada Ff = 100 l/min, temperatura Tf = 25 ºC. 
• Corriente caliente: caudal de entrada Fc = 100 l/min, temperatura Tc = 70 ºC. 
 
 
Fig. 4. Modelo Simulink® del mezclador de flujos en línea. 
4.1 Generación de datos 
Para determinar el punto base de operación se utilizó el modelo directo del mezclador, 
definido por las ecuaciones (1) a (3), donde las variables de entrada son las aperturas 
xf y xc, y las variables de salida son el caudal F y temperatura T de la mezcla. Evaluando este modelo para el caso en que ambas válvulas están abiertas a la mitad (xf = xc 
= 0.5), se obtiene a la salida un caudal F = 100 l/min y una temperatura T =47.5 ºC. Este 
punto fue tomado como base para el proceso de entrenamiento de la RNA. 
A continuación se estableció el entorno de operación en ±10% para ambas variables y la variación incremental ∆F y ∆T en el 1%, considerando que es ésta la mínima 
resolución del sistema. De esta manera, cada punto del entorno de operación queda 
definido de la siguiente forma: 
 
1368
( )sp p0 sp0
min max
sp sp
11 con 1,..., 21
90 l/min           110 l/min
i sF F i F F i
F F
= + − ∆ =
= =
 (13)
 
( )sp sp0 sp0
min max
sp sp
11 con 1,...,21
42.75 ºC             52.25 ºC
jT T j T T j
T T
= + − ∆ =
= =
 (14)
 
El entorno de operación queda particionado en 21 intervalos, obteniéndose un total 
de 441 puntos de operación incrementales alrededor del punto base, como se esquematiza en la Fig. 5. 
 
25 30 35 40 45 50 55 60 65 70
0
20
40
60
80
100
120
140
160
180
200
temperatura referencia TSP [ªC]
ca
ud
al
 r
ef
er
en
ci
a 
F S
P 
[l/
m
in
]
UBICACIÓN PUNTO BASE
 
 
Incremento
temperatura
Superficie de control
Incremento
caudal
Punto base
TSP0
FSP0
          Límite 
      caudal 
máximo
Límite 
    caudal 
           máximo
 
Fig. 5. Posición de punto base y entorno incremental del mezclador de flujos. 
Definido el entorno de operación a estudiar, se utilizó el modelo inverso, ecs. (4) a 
(6), para obtener las acciones de control requeridas para cada uno de los puntos incluidos en el entorno del punto base. En este modelo inverso, las variables de entrada 
son el caudal de referencia (Fsp) y la temperatura de referencia (Tsp); mientras que las 
variables de salida son las aperturas xf y xc que permitirán alcanzar el estado deseado. 
Conocidas las acciones de control necesarias para llegar a cada punto del entorno de 
operación, se las expresa como cambios requeridos en función de los errores medidos: 
 
( )F sp0 sp sp011i ie F F i F F= − = − − ∆  (15) 
 
( )T sp0 sp sp011 .= − = − − ∆j je T T j T T  (16) 
 
f f c c0.5. 0.5.∆ = − ∆ = −ij ij ij ijx x x x  (17) 
4.2 Diseño del controlador neuronal incremental 
A partir de una arquitectura neuronal feedforward, los parámetros más significativos a 
considerar son el número de capas y las cantidades de neuronas por capa. La dimen1369
sionalidad de las capas de entrada y salida queda definida por las características del 
problema, siendo cada una bidimensional, en este caso. De acuerdo con la interpretación del teorema de aproximación de Cybenko [7], una capa oculta con una cantidad 
finita de unidades con funciones monótonas crecientes, es suficiente para cualquier 
mapeo no lineal de entrada-salida con un nivel de error suficientemente bajo. 
Luego, el parámetro de mayor criticidad es la cantidad de neuronas ocultas encargadas del procesamiento interno; una cantidad insuficiente de neuronas ocultas puede 
impedir alcanzar el nivel de error deseado, mientras que una cantidad excesiva puede 
disminuir la capacidad de generalización de la red. En muchos casos, la determinación de este parámetro se realiza en forma experimental, aunque existen algunas 
heurísticas dedicadas a la determinación de la cantidad de neuronas ocultas, que aunque no son matemáticamente rigurosas, pueden producir buenas aproximaciones. 
Así por ejemplo, se puede citar a la regla de la pirámide geométrica, donde el 
número de neuronas ocultas (N(o)) se obtiene como una progresión geométrica entre el 
número de neuronas de entrada (N(e)) y el número de neuronas de salida (N(s)), de la 
forma ( ) ( ) ( ).o e sN N N=  [8]. La regla de las capas entrada-oculta establece que el 
número de neuronas ocultas no debe superar dos o tres veces la cantidad de neuronas 
de entrada [9]. Otra regla práctica, utilizada por Goethals et al. [10], sugiere que el 
número de neuronas ocultas (N(o)) se relaciona con el número de neuronas de entrada 
(N(e)) de la forma N(o) = 2×N(e) + 1. 
Bajo las consideraciones anteriores, se definió una RNA feedforward con arquitectura 2+5+2 para actuar como un controlador neuronal incremental tipo MIMO (2 
entradas y 2 salidas), con las siguientes características:  
• 2 neuronas en la capa de entrada. 
• 5 neuronas en la capa oculta. Función de transferencia tangente sigmoide. 
• 2 neuronas en la capa de salida. Función de transferencia lineal. 
Con los parámetros anteriores definidos, la RNA fue entrenada con el algoritmo 
backpropagation obteniéndose los siguientes resultados: 
• Cantidad de iteraciones: 500. 
• Entrenamiento con algoritmo backpropagation, variante LM. 
• Error cuadrático medio (ECM) de entrenamiento: 2.11×10-10. 
4.3 Configuración y operación del sistema 
El modelo experimental del sistema completo (controlador–planta), fue configurado 
en el entorno de simulación gráfica de Matlab® (Fig. 6). En este modelo, el sistema a 
controlar se incorpora como un bloque que recibe los parámetros de caudales de entrada (Ff y Fc), de temperatura (Tf y Tc) de tales caudales y las variables de control (xf 
y xc), produciendo las variables de salida caudal (F) y temperatura (T). 
El controlador neuronal, recibe a la entrada el error de caudal (errF = Fsp – F) y el 
error de temperatura (errT = Tsp – T), ambos modulados por limitadores que mantienen 
a los valores incrementales dentro del entorno definido, mejorando la estabilidad del 
sistema; y genera las variaciones de apertura de la válvula fría (∆xf) y de la válvula 
caliente (∆xc). Estas variaciones se componen con las aperturas del estado anterior 
(xf (k) = xf (k–1) + ∆xf(k) || xc (k) = xc (k–1) + ∆xc(k)) para ser realimentadas al mezclador de flujos, cerrando el lazo de control. 
1370
 
Fig. 6. Modelo experimental del mezclador de flujos con control neuronal. 
4.4 Prueba del sistema 
Para comprobar la operación del sistema, se aplicaron diferentes condiciones en los 
parámetros de referencia (setpoints). En el primer caso, los parámetros de referencias 
requirieron variaciones abruptas para el caudal y la temperatura como muestra la Fig. 7. 
 
 
Fig. 7. Control de caudal y temperatura de salida para referencia tipo escalón. 
 
Se observa que el sistema ejecutó una muy buena acción de control para responder a 
las variaciones abruptas de los valores de referencia de caudal y temperatura.  
En el segundo caso, el parámetro de referencia caudal (Fsp) exigió una variación sinusoidal suave mientras que la temperatura (Tsp) debió mantenerse en un valor constante 
(Fig. 8). En este caso que la variación exigida por la referencia del caudal (Fsp) es 
correctamente seguida por la planta, mientras la temperatura se mantiene constante en 
T = 47.5 ºC como requiere la referencia Tsp. 
1371
 
Fig. 8. Control de caudal y temperatura de salida para referencia tipo sinusoidal. 
En el tercer caso, se provocó una perturbación sinusoidal del 2% en el parámetro 
caudal de corriente caliente (Fc), al mismo tiempo que se aplicó una variación lineal 
tipo rampa a la temperatura de referencia (Tsp), que se inició en 25 ºC, obteniéndose 
los resultados mostrados en la Fig. 9. 
 
 
Fig. 9. Control de caudal y temperatura de salida para perturbación en caudal. 
En este caso la perturbación fue adecuadamente absorbida por el controlador, hasta el instante t = 75.02 min, donde el controlador se satura (la válvula de la corriente 
fría se cierra totalmente, xf = 0) y la temperatura de salida se estabiliza en T = 70 ºC. 
El desempeño del controlador neuronal incremental (CN incremental) desarrollado 
se ha comparado con un controlador neuronal equivalente (CN estándar), con entrenamiento clásico, para la misma planta y con idénticos parámetros [6]. La comparación de los parámetros más representativos se observan en la Tabla 1. 
Los datos de esta tabla, evidencian una indiscutible ventaja del controlador neuronal incremental en varios aspectos, tales como una arquitectura más simple, menor 
cantidad de variables de entrada, gran reducción en la cantidad de datos –sin necesidad de preprocesamiento previo–, menor tiempo de entrenamiento y mejora en el 
error general de aprendizaje. 
1372
Tabla 1. Parámetros de comparación entre controladores equivalentes. 
Parámetro CN incremental CN estándar 
Variables de entrada 2 4 
Variables de salida 2 2 
Cantidad de capas 3 3 
Neuronas ocultas 5 10 
Patrones de  entrenamiento 2×441 4×5034 
ECM de entrenamiento 2.11×10-10 4.83×10-9 
Tiempo de entrenamiento 36 seg 1 min 47 seg 
5 Conclusiones 
Se ha diseñado e implementado en un sistema de simulación gráfica, un controlador 
neuronal MIMO configurado para trabajar por incrementos a partir de un entorno 
genérico predefinido, aplicado a un mezclador en línea de corrientes líquidas. 
La capacidad del conjunto controlador–planta se ha comprobado experimentalmente bajo diversas condiciones, tales como variaciones abruptas y oscilantes de los 
parámetros de referencia y perturbaciones de los parámetros de la planta, mostrando 
un muy buen desempeño del sistema de control neuronal propuesto. 
El controlador neuronal incremental se ha comparado con un controlador neuronal 
estándar equivalente aplicado a la misma planta, poniéndose en evidencia las ventajas 
en diseño, entrenamiento y operación del modelo incremental. 
6
