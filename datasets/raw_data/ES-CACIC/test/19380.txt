Servidor de video para f√∫tbol de robots f√≠sico desarrollado bajo OpenCV y Microsoft Visual Studio
Ôªø El objetivo del presente trabajo es mostrar una alternativa de 
procesamiento de im√°genes con OpenCV y Microsoft Visual Studio para 
realizar un partido de f√∫tbol de robots f√≠sico con visi√≥n global basada en una 
arquitectura de 3 capas: transformaci√≥n, interpretaci√≥n y transmisi√≥n. En el 
presente documento no s√≥lo se enunciar√°n las problem√°ticas encontradas 
dentro de cada capa sino tambi√©n las soluciones utilizadas en el servidor de 
video para cada una de las mismas.  
Keywords: Servidor de video ‚Äì f√∫tbol de robots ‚Äì OpenCV 
 
1 Introducci√≥n 
El f√∫tbol de robots es una actividad que ha congregado a varios investigadores de 
todo el mundo en las √∫ltimas d√©cadas debido a que fusiona lo l√∫dico con los desaf√≠os 
que plantea la rob√≥tica situada como la autonom√≠a, el comportamiento colaborativo, la 
navegaci√≥n y las respuestas en tiempo real. 
Esta investigaci√≥n se centra en la percepci√≥n del ambiente para brindar una 
soluci√≥n ante este interrogante: ¬øC√≥mo obtener una representaci√≥n simb√≥lica de la 
realidad para que cada equipo act√∫e en consecuencia? 
Es por este motivo que se decidi√≥ crear un servidor de video para f√∫tbol de robots. 
Si bien hay algunos servidores de video existentes, resulta pertinente crear uno que, 
aparte de ser funcional y en un futuro extensible, tenga las siguientes caracter√≠sticas: 
f√°cil de instalar y utilizar, de c√≥digo abierto y gratuito.  
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACI√ìN                                                 999
Estas particularidades mencionadas tambi√©n contribuir√≠an a allanar el camino a 
alumnos universitarios y de escuela media para que puedan incursionar en f√∫tbol de 
robots f√≠sico, avoc√°ndose directamente al desarrollo de la inteligencia artificial de sus 
equipos, ya que la percepci√≥n del ambiente estar√≠a resuelta. 
2 Funciones del Servidor de Video 
Un partido de f√∫tbol de robots f√≠sico con visi√≥n global se compone de los robots, la 
pelota, una c√°mara que capta el campo de juego asociada a un servidor de video y las 
m√°quinas cliente que reciben la informaci√≥n del ambiente. Estas √∫ltimas, en funci√≥n 
de los datos recibidos y una heur√≠stica determinada, ordenan a los robots que act√∫en 
acorde a una estrategia definida. 
El objetivo fundamental de un servidor de video de f√∫tbol de robots es proveer a 
las computadoras que controlan a dichos robots la informaci√≥n b√°sica del ambiente 
cuando se juega un partido. Por este motivo se procesan las im√°genes del campo de 
juego provistas por una c√°mara para determinar la posici√≥n y orientaci√≥n de cada 
robot dentro del mismo y la ubicaci√≥n de la pelota. Las funciones que un servidor de 
video debe desarrollar se pueden agrupar en 3 grandes categor√≠as, las cuales fueron 
tomadas como capas de programaci√≥n durante la implementaci√≥n del proyecto. Cada 
capa le presta servicios a la capa superior, y recibe servicios de la capa que tiene por 
debajo. Las funciones deben ser llevadas a cabo en tiempo y forma. Es decir, la 
informaci√≥n obtenida debe representar la totalidad de lo que se quiera transmitir y la 
misma debe llegar a destino lo m√°s r√°pido que se pueda. 
 
Las 3 capas de la arquitectura son: 
‚Ä¢ Capa de transformaci√≥n de datos: 
El objetivo de esta capa es tomar las im√°genes que brinda la c√°mara de video y 
aplicarle todos los filtros que sean necesarios para producir una salida que mantenga 
una relaci√≥n de tama√±os, un aspecto de colores en com√∫n y una calidad suficiente 
para que la siguiente capa pueda utilizarla. 
 
‚Ä¢ Capa de Interpretaci√≥n de Datos 
El objetivo de esta capa es determinar la informaci√≥n relevante a partir de una serie 
de im√°genes con un formato est√°ndar que le otorga la capa anterior. Se entiende por 
informaci√≥n relevante a aquellos datos que sean cruciales para determinar el estado 
del campo de juego. 
 
‚Ä¢ Capa de Transmisi√≥n de datos 
El objetivo de esta capa es transmitir, en el menor tiempo posible, la informaci√≥n 
relevante que se obtiene de la capa anterior, posici√≥n de la pelota y la posici√≥n y la 
orientaci√≥n de cada robot, a las computadoras que controlan a los robots jugadores. 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACI√ìN                                                 1000
3 Capas del Servidor de Video 
En esta secci√≥n se tratar√° en forma espec√≠fica cada una de las capas mencionadas en la 
secci√≥n anterior, detallando para cada una de ellas las complejidades que plantean, las 
funciones a cumplir y las soluciones a los problemas enunciados. 
3.1 Capa de Transformaci√≥n de Datos 
3.1.1 Eliminaci√≥n de Distorsi√≥n Radial  
Las c√°maras con lentes que tienen menor distancia focal producen una imagen 
distorsionada mientras m√°s nos acercamos al borde de la misma. Dicha alteraci√≥n se 
conoce como distorsi√≥n radial y est√° representada por las siguientes formulas: 
       x‚Äô = x + x [k1r2 + k2r4] + [2p1xy + p2(r2 + 2x2)] .                (1)    y‚Äô = y+y [k1r2 + k2r4] + [2p2xy + p2(r2 + 2y2)] .                  (2) 
    r2 = x2 + y2 .                                                                                                                                     (3) 
Siendo  en (1), (2) y (3) x e y las coordenadas del p√≠xel en la imagen sin 
deformaci√≥n, x‚Äô e y‚Äô las coordenadas del p√≠xel en la imagen deformada, k1 y k2 los 
coeficientes de distorsi√≥n radial, p1 y p2 los coeficientes de distorsi√≥n tangencial y r 
la distancia desde el punto central hasta el punto x,y. Tanto los coeficientes de 
distorsi√≥n radial como los de distorsi√≥n tangencial dependen de la lente que tenga la 
c√°mara. 
El servidor de video debe contemplar el escenario en el cual la c√°mara que le 
provea de im√°genes tenga una distancia focal corta (como se muestra en la Fig.1), es 
decir, debe estar preparado para remover la alteraci√≥n causada por la lente. Este 
problema fue solucionado (como se muestra en la Fig.2) implementando los m√©todos 
que la librer√≠a de procesamiento de im√°genes desarrollada por Intel¬Æ llamada 
OpenCV[1] brinda, los cuales est√°n basados en lo explicado anteriormente.  
 
Fig. 1. Imagen con distorsi√≥n radial   Fig. 2. Imagen sin distorsi√≥n radial 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACI√ìN                                                 1001
3.1.2 Correcci√≥n de la Perspectiva de la Imagen 
La c√°mara que provea las im√°genes al sistema debe poder capturar la totalidad del 
campo de juego. La posici√≥n √≥ptima para colocar la c√°mara es perpendicular al piso, 
apuntando al centro del campo de juego, y a una altura tal que tome todas las zonas 
del mismo. Sin embargo, pueden existir situaciones en donde se vea toda la cancha 
s√≥lo desde una posici√≥n no cenital (como se muestra en la Fig.3). Estas situaciones 
ocurren por limitaciones f√≠sicas como por ejemplo la altura del techo o la longitud 
limitada de los cables por lo que el servidor de video debe encargarse de transformar 
la perspectiva para luego poder interpretar las im√°genes. 
Para solucionar √©sto, siempre y cuando la deformaci√≥n de la imagen sea 
√∫nicamente de tipo lineal, hay que tener en cuenta las siguientes ecuaciones: 
 
 = , , ,, , ,, , , .                                        (4) 
    =  .                                                    (5) 
  =  !!‚Ä≤# .                                                   (6) 
  = ‚Ñé .                                                         (7) 
 
Siendo en (4) H una matriz de 3x3, en (5) P un punto en la imagen que se recibe de 
la c√°mara y en (6) M el punto que representa a P en la imagen una vez corregida la 
deformaci√≥n por perspectiva. La matriz H (matriz de homograf√≠a), como se observa 
en (7), al multiplicarse por el punto original (P) se obtiene el punto final (M). 
Para calcular los valores de H se deben tener una serie de puntos conocidos en la 
imagen P y sus equivalentes puntos M en la imagen corregida. Una vez calculada se 
somete a cada punto P de la imagen original a √∫ltima f√≥rmula, obteni√©ndose su 
posici√≥n en la imagen final. Es decir, cada p√≠xel ser√° reubicado seg√∫n los valores 
calculados para H (como se muestra en la Fig.4). 
Para los fines pr√°cticos de lo que debe realizar el servidor de video, no es necesaria 
una posici√≥n sobre el eje Z en la imagen final ya que todo puede hacerlo con una 
imagen plana, por lo que las coordenadas en ese eje pueden ser menospreciadas. 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACI√ìN                                                 1002
                    Fig. 3. Perspectiva no transformada  Fig. 4. Perspectiva transformada 
El aplicar la correcci√≥n de perspectiva trae consigo otros beneficios aparte de 
solucionar las limitaciones f√≠sicas mencionadas anteriormente: 
 
‚Ä¢ Al alinear las esquinas del campo de juego con las esquinas de la imagen, sin 
importar el √°ngulo de percepci√≥n, evita que se produzcan errores de detecci√≥n 
ajenos al campo de juego porque ignora todo lo que se encuentra fuera del √°rea 
transformada. 
‚Ä¢ La imagen que se obtiene luego de la transformaci√≥n mantiene la misma relaci√≥n 
de tama√±os sin importar a qu√© distancia u orientaci√≥n se encuentre realmente la 
c√°mara del campo de juego generando im√°genes est√°ndar que facilitan el an√°lisis 
ulterior.   
3.1.3 Correcci√≥n de Colores de la Imagen 
Por correcci√≥n de colores se entiende a todo proceso cuyo objetivo sea mantener el 
aspecto de los colores de una forma deseada. Es una parte de alta relevancia en la 
preparaci√≥n previa a cualquier an√°lisis de imagen digital pero lamentablemente existe 
una gran cantidad de causas que hacen que haya variaciones indeseadas en los colores 
que se perciben, como por ejemplo el ruido radioel√©ctrico o los cambios de 
iluminaci√≥n y sombras. La capa siguiente espera que las im√°genes que esta capa le 
entrega sean de color uniforme, es decir, que un objeto determinado se vea de la 
misma forma sin importar su ubicaci√≥n ni cu√°ndo sea capturada la imagen. 
Color Mapping 
La primera medida que se toma para compensar los problemas explicados 
previamente es realizar lo que se llama mapeo de colores. Tomando una imagen de 
referencia (Fig.5) y a la imagen capturada (Fig.6) se calculan para cada uno de sus 
canales: % = &‚àë (()*+),-)./ 0   .                                                     (8) 
 1 = ‚àë 2)-)./0  .                                                                  (9) 
 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACI√ìN                                                 1003
Siendo (8) el desv√≠o est√°ndar y (9) el valor promedio del canal. Luego por cada pixel 
de cada canal de la imagen original se determina cu√°ntos desv√≠os est√°ndar se aleja de 
su promedio y se le asigna a la imagen final (Fig.7) el valor equivalente tomando el 
desv√≠o est√°ndar y el promedio de la imagen de referencia. 
 
         Fig. 5. Imagen de referencia Fig. 6. Imagen original         Fig. 7. Imagen final   
 
Umbral de Colores 
Luego, para evitar diferencias de colores a nivel general, tomamos un espectro de 
colores en lugar de un color individual. Todo el sistema est√° construido partiendo de 
la premisa que cuando uno se refiere a un color, en realidad est√° apuntando a varios 
consecutivos dentro del espectro. 
El servidor de video tiene una herramienta de construcci√≥n de umbrales que, dada 
una regi√≥n de la imagen, le permite tomar todos los p√≠xeles que aparezcan en ella a 
medida que cambian dentro del tiempo de calibraci√≥n y calcular un umbral de colores 
en donde todos los colores que aparecieron est√©n incluidos. 
Adem√°s dichos espectros son acumulativos, es decir, pueden tomarse en diversas 
zonas del campo de juego para asegurarse que el espectro resultante incluya a todas 
las variantes de iluminaci√≥n de la cancha. En la pr√≥xima capa se ver√° que un objeto es 
identificable por los umbrales que √©ste posea.  
Reducci√≥n de Ruido 
Otra medida importante para realizar una correcci√≥n de colores que mitigue los 
errores de la capa de interpretaci√≥n es proveer una imagen en la que el impacto del 
ruido radioel√©ctrico sea m√≠nimo en los colores que se perciben. El ruido radioel√©ctrico 
es un fen√≥meno f√≠sico que puede disminuirse consiguiendo cables de menor p√©rdida y 
mejores aislantes, pero es de nuestra consideraci√≥n que el servidor de video debe ser 
lo suficientemente adaptable y robusto para poder funcionar en cualquier condici√≥n 
presentada.  
Hay varias formas mediante software para tratar el impacto del ruido en las 
im√°genes capturadas. Puede utilizarse un histograma como sugieren Bradski y 
Kaehler[02] para detectar de una manera m√°s f√°cil un patr√≥n de variaci√≥n de colores,  
que luego ser√° eliminado o reducido mediante promedios si el cambio de colores es 
estoc√°stico. Tambi√©n pueden utilizarse t√©cnicas de desenfoque artificial como las que 
propone Weickert[03] en las que se reduce el impacto del ruido sin eliminar partes 
significativas de la imagen como los bordes para optimizar el an√°lisis posterior. Si 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACI√ìN                                                 1004
bien la versi√≥n actual del servidor de video no toma medidas propias para evitar la 
incidencia del ruido, utiliza un filtro que fue provisto por el driver del hardware 
capturador. 
3.2 Capa de Interpretaci√≥n de Datos 
Esta capa debe determinar la posici√≥n de la pelota, y la posici√≥n y orientaci√≥n de cada 
robot. Para llevar dicha tarea a cabo hay varias estrategias posibles, pero a la hora de 
implementar el servidor de video, con el objetivo de ganar mayor precisi√≥n en menor 
tiempo de procesamiento, se opt√≥ por las siguientes: 
3.2.1 Determinar la Posici√≥n de los Objetos de Inter√©s 
Lo primero que se hace para determinar la posici√≥n de un objeto de inter√©s es detectar 
movimiento entre un frame y el siguiente. Para hacerlo utilizamos varios de los 
m√©todos provistos por OpenCV, los cuales est√°n basados en los trabajos de Davis y 
Bobick[04]. 
Para detectar el movimiento es necesario simplificar la imagen y pasarla a un solo 
canal (en general en escala de grises). El siguiente paso es generar una m√°scara de 
fondo en la que se ver√° todo lo que no se ha movido. Cuando se genera movimiento, 
el nuevo frame se lo compara con la m√°scara de fondo para generar una imagen 
binaria negra de movimiento acumulativo en la que un color blanco representa s√≥lo 
aquellas secciones en donde hubo movimiento (como se muestra en la Fig.8 y en la 
Fig.9). Una vez identificados todos los movimientos, el servidor de video descarta a 
todos aquellos que cubran un √°rea menor que el objeto de inter√©s m√°s peque√±o (en 
este caso la pelota) para evitar analizar cosas innecesarias como ruido o sombras. 
Luego se analiza cada √°rea en donde hubo movimiento para determinar qu√© objeto es 
el causante del mismo y si √©ste es relevante al sistema. El centro de aquellas secciones 
blancas de la m√°scara binaria ser√° la posici√≥n aproximada de cada objeto de inter√©s 
dentro del plano de la imagen. Luego se realiza un centrado del objeto partiendo que 
todo objeto tiene un c√≠rculo sobre √©l. Esta t√©cnica permite evitar perder los objetos, y 
en caso de perderlos, (por ejemplo si la c√°mara apunta al campo de juego en un 
√°ngulo oblicuo y uno de los jugadores obstruye la visibilidad de la pelota) al moverse 
los objetos que fueron perdidos, autom√°ticamente ser√°n detectados. En caso que no se 
encuentre a uno de los objetos de inter√©s, se realiza un segundo an√°lisis en sus √∫ltimas 
coordenadas conocidas.  
 
 
Fig. 8. M√°scara binaria de un solo color por ausencia de movimientos 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACI√ìN                                                 1005
Fig. 9. M√°scara binaria que 
3.2.2 Parches de los Robots
Es fundamental crear 
robots sean reconocidos ya que el dise√±o y color de los mismos var√≠a seg√∫n su 
creador. El parche dise√±ado para este servidor de video cuenta con 4 colores 
distribuidos de la siguiente forma como se muestra en la 
 
Los colores se distribuyen de la siguiente manera:
 
1. Color de equipo (color en com√∫n para todos los integrantes de un equipo). La base 
de este tri√°ngulo debe coincidir con el frente del robot.
2. Color de robot (color en com√∫n
3. Color de jugador (color en com√∫n para aquellos robots que compartan el n√∫mero 
de jugador).  
4. Negro en com√∫n a todos los robots.
 
El dise√±o del parche tiene dos motivos:
‚Ä¢ El c√≠rculo central es para simplif
distintos movimientos se revisa el color de una serie de p√≠xeles en el centro de 
dicho movimiento. E
color. Los jugadores incorporan este c√≠rculo para que e
utilizar un m√©todo gen√©rico para identificar el tipo de objeto
tratando. 
‚Ä¢ Averiguar la orientaci√≥n del mismo
 
marca la ubicaci√≥n del robot ante la presencia de movimientos
 
un modelo estandarizado de parche para garantizar que los 
(Fig. 10). 
 
Fig. 10. Modelo estandarizado de parche 
 
 
 para todos los robots sin importar su equipo)
 
 
icar la ubicaci√≥n de los robots. Al revisar los 
n caso de ser la pelota se la encontrar√° f√°cilmente
l servidor de video pueda 
 de inter√©s que se est√° 
 mediante an√°lisis de color. 
 
. 
 por su 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACI√ìN                                                 1006
3.2.3 C√°lculo de la O
Para calcular la orientaci√≥n, es decir, el √°ngulo en el cual el robot 
utiliza el esquema de colores del parche, 
el frente del robot. El m√©todo consiste en realizar un muestreo de pixeles a 
regulares hasta cubrir toda la superficie del parche
agrupando las muestras dependiendo de su color. Se toma al color de equipo y al 
color de jugador con m√°s
en que dos jugadores est√©n en contacto y ambos entren dentro del √°rea analizada. 
realiza un promedio de los puntos de dichos colores y se utiliza el resultado de dichos 
promedios para calcular la orientaci√≥n
Fig. 11
3.3 Capa de Transmisi√≥n de datos
En esta capa deben desarrollarse dos tareas de extrema importancia
protocolo se transmitir√°n los datos, y definir el formato en el cual se transmitir√°n. Si 
una de estas dos tareas no es realizada de manera adecuada, las computadoras 
encargadas de controlar a los distintos equipos no podr√°n recibir la informaci√≥n y el 
sistema completo ser√° in√∫til.
  
3.3.1 Protocolo de transferencia
En todo protocolo de transferencia lo primero que se debe determinar es qu
importante: una baja tasa de errores o un bajo retardo de transmisi√≥n. Existen 
protocolos de m√∫ltiples verificaciones
verificaciones consumen tiempo que en ciertos casos es un lujo del que no se dispone.
En este caso es preferible que un env√≠o de datos llegue mal a que todos los env√≠os 
lleguen tarde, por lo que se opt
confirmaci√≥n y no orientado a la conexi√≥n. L
es decir, todos los que quieran escuchar podr√°n escuchar, permitiendo que si un 
equipo tiene m√°s de una m√°quina para controlar a 
problema.  Adem√°s, este mecanismo
partido. 
rientaci√≥n de los Jugadores 
est√° mirando
considerando que el color del equipo 
 (como se muestra en la Fig.
 apariciones dentro de las muestras para contemplar el ca
 mediante c√°lculos trigonom√©tricos. 
 
. Muestreo del parche para calcular su orientaci√≥n 
 
: definir con qu√©
 
 
 y con bajas tasas de error, pero dichas 
√≥ por utilizar UDP que es un protocolo sin 
a transmisi√≥n se efect√∫a como broadcast, 
sus robots no exista ning√∫n tipo de 
 permite asignar m√°s maquinas a monitorear el 
, se 
est√° en 
intervalos 
11) 
so 
Se 
 
√© es m√°s 
 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACI√ìN                                                 1007
3.3.2 Formato de Transferencia de Datos 
Siguiendo con la idea de que el nuevo servidor de video debe ser totalmente adaptable 
se implement√≥ un sistema que permite al usuario armar su propio formato de env√≠o de 
datos utilizando una serie de expresiones que son remplazadas por los datos y son 
definidas como ‚Äú[‚Äú<nombre de objeto>‚Äù.‚Äù<nombre del dato>‚Äù]‚Äù, mientras que todos 
los dem√°s caracteres permanecer√°n como los ingres√≥ el usuario. Por ejemplo ‚Äú[B.X]‚Äù 
para la coordenada en X de la pelota o ‚Äú[T1R0.HRad]‚Äù para la orientaci√≥n del robot 0 
del equipo 1 en radianes. Si el usuario ingresa ‚Äú.-[B.X];[B.Y]-.‚Äù y la pelota se 
encuentra ubicada en el punto (152;203) el dato enviado ser√° ‚Äú.-152:203-.‚Äù. 
  
4 Conclusi√≥n 
El presente trabajo describe una arquitectura de 3 capas satisfactoria para realizar un 
servidor de video b√°sico para f√∫tbol de robots f√≠sico con visi√≥n global as√≠ como 
tambi√©n la complejidad que se trata en cada una de las mismas y qu√© soluciones se 
utilizaron para lograr en tiempo y forma la percepci√≥n del ambiente. Si bien todav√≠a 
se puede optimizar  la correcci√≥n de colores mediante mejores m√©todos de reducci√≥n 
de ruido y agregar mayor funcionalidad al software como poder guardar los partidos 
jugados o automatizar los procesos de calibraci√≥n manuales, se comprob√≥ que es √∫til 
para realizar un partido e iniciarse en el procesamiento de im√°genes de una manera 
amena.  
