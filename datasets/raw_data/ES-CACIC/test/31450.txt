Estimación de H con transformada ondita
﻿ El análisis de tráfico se ha convertido en un proceso fundamental a la hora de 
evaluar la performance de una red. También se ha tornado crítico en la actualidad por la 
presencia de componentes auto-similares en él. Esta componente cambia el paradigma del 
modelo de tráfico utilizado hasta hace unos pocos años con serias dificultades analíticas; por lo 
menos comparándolos con los utilizados hasta el momento. Un parámetro clave en este nuevo 
modelo es el parámetro “H” o de “Hurst” por lo que importa una correcta detección y 
estimación. Presentamos con esa motivación los resultados obtenidos de la aplicación de un 
“script” basado en la transformada ondita o “wavelets”. 
Keywords: tráfico, autosimilaridad, onditas, parámetro H, QoS, performance, modelos 
1   Introducción 
Una actividad fundamental en la evaluación de performance y diseño de las redes 
telemáticas, es el análisis del tráfico que transportan, materializado en parámetros 
tales como, tiempos de arribo, longitud de los mensajes, tiempos de transmisión, 
comportamiento en diferentes escalas de tiempo, etc. Este conocimiento permite 
optimizar los recursos de las redes, y también posibilita, que los servicios ofrecidos, 
cuenten con la calidad requerida. El logro este objetivo, es un área activa de estudio e 
investigación. 
Promediando el año 1990, estudios realizados sobre muestras de tráfico tomadas de 
redes en funcionamiento, han demostrado en forma inequívoca que el tráfico tiene 
propiedades autosimilares, esto es, la existencia de patrones estadísticos o 
comportamientos que se repiten a diferentes escalas de tiempo. Un tráfico con 
características autosimilares, afecta en forma negativa el desempeño de la red. Se 
puede observar que el retardo promedio de los mensajes resulta mucho mayor que lo 
previsto por el análisis de colas tradicional. 
Esto representa un inconveniente por partida doble. Una peor performance y la 
imposibilidad de un tratamiento analítico completo. 
En este escenario, con tráfico originado en diversas fuentes, con sus respectivas 
características y particularidades, abordar un estudio para cuantificar o medir de 
manera apropiada la demanda que los usuarios imponen sobre los recursos de una red, 
requiere del uso de modelos que representen de una manera eficaz y eficiente un 
comportamiento compatible con las características observables en el tráfico real. 
Surgen entonces, dos desafíos de importancia central: 
1087
2      Reinaldo Scappini1, Luis Marrone2, 
− El desarrollo de modelos generales que abarquen las principales características del 
tráfico a estudiar. 
− El desarrollo de aplicaciones, que utilizando esos modelos, permitan obtener 
conclusiones válidas.  
El éxito de los modelos autosimilares radica en su capacidad de capturar las 
complejas dependencias que muestra el tráfico a distintas escalas de tiempo mediante 
el uso de pocos parámetros, en particular el parámetro de Hurst " "H . 
Dada la importancia del mismo en la caracterización del tráfico, es necesaria su 
correcta detección y estimación. 
Si bien este trabajo muestra en forma resumida las ventajas de un método 
particular, todos los detalles y desarrollos teóricos se pueden encontrar en un trabajo 
previo [1] donde se analizaron en mayor profundidad. 
En particular brindaremos los resultados obtenidos aplicando “LDestimate” [2], 
una script para la estimación del parámetro “H” implementada para el software 
Matlab® y basada en la transformada wavelet u ondita. 
2   ¿Por qué utilizar la transformada Ondita (“Wavelets”)? 
En la lectura de diversos estudios e investigaciones realizados en los últimos años 
sobre el tráfico autosimilar en las redes telemáticas, se evidencian las ventajas que 
aportan los métodos basados en las wavelets u onditas, atendiendo a criterios de 
validez, confianza estadística y eficiencia computacional. En consecuencia, la 
utilización de las wavelets se ha convertido en una útil y eficaz herramienta para 
tareas de análisis, detección, estimación, modelado y simulación en el ámbito del 
tráfico autosimilar. 
Como se menciona en las referencias bibliográficas [3] Pág. 84, y [4] Pág. 23; entre 
las ventajas del estudio del tráfico autosimilar por medio de wavelets u onditas 
podemos mencionar: 
• La wavelets u onditas ofrecen un marco teórico que se puede aplicar tanto a 
procesos autosimilares, procesos LRD (Long Range Dependence, o dependencia 
de rango largo), trazas muéstrales etc. Pudiendo hacer un análisis en el dominio de 
la escala, de forma que se adapta “naturalmente” a las necesidades de poder 
estudiar un comportamiento en este dominio. 
• Permite la división controlada de un proceso madre de variabilidad extrema, en 
subprocesos a diferentes escalas tornando manejable su comportamiento, 
aprovechando la independencia de los subprocesos obtenidos, se pueden emplear 
herramientas de la estadística clásica sobre las secuencias de los coeficientes 
wavelets, y de esta forma poder diseñar estimadores simples y eficientes. 
• Los bancos de filtros de análisis y síntesis, proporcionan una forma 
computacionalmente eficiente de llevar a cabo tareas de análisis y síntesis de 
procesos autosimilares. 
1088
Reinaldo Scappini1, Luis Marrone2,      3 
2.1    Relación entre las Wavelets y los procesos Hss, Hsssi y LRD  
Hss es un proceso puramente autosimilar, Hsssi es autosimilar con incrementos 
estacionarios, LRD es cuando presenta dependencia de rango largo.  
Si bien no es motivo de este trabajo, el estudio de la transformada Waveletet u 
Ondita, por cuestiones de contexto es importante señalar que existe un cuerpo teórico 
llamado análisis multiresolución (MRA) que propone la existencia de una función 
llamada Wavelet madre y cuyo producto interno con la señal " "S  representada por el 
procesos estocástico ( )X t , da como resultado dos conjuntos de coeficientes llamados 
aproximación ( , )sa j k  y detalles ( , )sd j k  respectivamente, que preservan las 
características de la señal original y permiten su estudio a distintos niveles de escalas 
frecuenciales y temporales. El parámetro j representa el nivel de escala también 
denominado octava y el parámetro k  la traslación o desplazamiento temporal. 
Si la señal ( )X t es proceso un proceso estocástico que presenta un fenómeno de 
escala representado por el exponente " "α , los coeficientes correspondientes a su 
transformada wavelet, tendrán las siguientes características: 
El conjunto { }( , ), 1,2,... ,Xd j k j J k= ∈ , es un proceso estacionario para 
cada octava j, si el Nº de momentos desvanecientes de la wavelet madre 0ψ , es 
1
2
N α −≥ . La varianza del conjunto ( , )Xd j k  reproduce el comportamiento de 
escala subyacente, dentro de un rango de octavas 1 2j j j≤ ≤ . Dado que el valor 
medio de la wavelet es cero por la condición de admisibilidad, el segundo momento 
de ( , )Xd j k es proporcional a 2
jα , donde 1 2,   j j y α , dependen del tipo de 
fenómeno de escala que exhiba el proceso original ( )X t . Se cumplen entonces, las 
siguientes relaciones entre estos tres parámetros de la siguiente ecuación: 
2( , ) 2 jXE d j k
α  ≈   (1) 
 
Si ( )   2 1,   X t es Hsssi H y jα→ = + − ∞ < < ∞  
Si ( )X t , presenta LRD, 2 1Hα = − ; 2j = ∞ , y 1j debe identificarse en 
función de los datos obtenidos en el análisis. 
En caso de que el proceso obedezca una ley de potencias, pero en un determinado 
rango de frecuencias, 1 2f f f≤ ≤ , ( a este tipo de procesos se los denomina 
genéricamente procesos 1/ f ), γ  corresponde a la ley de potencias expresada y el 
rango de escalas 1 2( , )j j , debe obtenerse partiendo de las frecuencias 1 2( , )f f . 
1089
4      Reinaldo Scappini1, Luis Marrone2, 
3    Estimación mediante la script LDestimate 
La script LDestimate, a diferencia de otras herramientas utilizadas en la estimación 
de “H”, proporciona información extra acerca del contexto en el que se estima “H”, 
esto es, tiene funciones accesorias que nos permiten escoger con bastante certeza la 
octava donde se inicia la alineación descartando las regiones que producen sesgo en el 
resultado, proporcionando además un estadístico que nos indica la “bondad del 
ajuste”, en función de los valores estudiados, y asegura que el rango escogido tenga 
una efectiva alineación, evidenciando el fenómeno de escala y no una simple 
aproximación promediada con eventuales desviaciones propias de la técnica de 
regresión lineal. En los otros métodos la estimación en forma general se hace 
tomando la máxima cantidad de datos y se pueden producir importantes desviaciones 
que no son tenidas en cuenta por carecer de estas funciones tales como mostrar el 
intervalo de confianza y la bondad del ajuste, se muestra a continuación los 
fundamentos del método y unos comentarios acerca de los parámetros involucrados 
3.1    Diagrama Log-escala – Estimación de H 
La gran ventaja estadística del análisis Wavelet en el dominio de las escalas se 
evidencia en la expresión: 
[ ] 1 2( , ) ( , ') ' NX XE d j k d j k k k α − −≈ − ; a medida que 'k k− → ∞  (2) 
Esto nos permite medir los promedios temporales y utilizarlos como estimaciones 
de los promedios estadísticos, y la falta de correlación entre los distintos coeficientes 
wavelets asegura que los estimadores temporales tengan una varianza pequeña. 
Por otra parte la expresión 2 (2 1) 2( , ) 2 (0, )j HX XE d j k E d k
+   =    ; puede 
tomarse como un estimador del espectro de potencia del proceso en las inmediaciones 
de la frecuencia correspondiente a la octava j, y como se demuestra en [1], sec. 3.3.4 y 
3.7, se puede estimar la varianza del proceso ( , )Xd j k , según: 
2
1
1 ( , )
jn
j x
kj
d j k
n
µ
=
= ∑  (3) 
 
Donde jn  es el número de coeficientes en la octava j, y se observa que la varianza 
decrece conforme jn  aumenta, entonces la variable jµ es una forma eficiente de 
representar en forma compacta el comportamiento de segundo orden del proceso 
estudiado ( )tX  en la octava j, y si se tiene en cuenta la expresión, los jµ son 
prácticamente independientes entre sí generando un desacoplamiento del 
comportamiento de ( )tX  en las distintas octavas j, y dado que en el estimador la 
varianza decae hiperbólicamente en función de la octava j, se puede asumir que el 
1090
Reinaldo Scappini1, Luis Marrone2,      5 
exponente de escala del proceso α , lo podemos estimar como una regresión lineal de 
( ) ( )2log jjy µ≡ , como una función de la octava j. 
En general se puede afirmar que un proceso que presenta LRD tiene una densidad 
espectral que obedece a: 
( ) , 0cff cuandoαν ν
ν
≈ →  
(4) 
 
Dondeν es la frecuencia; cf es una constante positiva, y 2 1Hα = − . 
Es sabido que la densidad espectral o potencia del proceso es proporcional al 
segundo momento de la variable y con relación a lo expuesto en el punto 3.1 (eq.1, 2 
y 3), se pueden establecer equivalencias en ambas expresiones y expresar lo siguiente: 
( ) ( )2( , )2 X 2log E d j k j log cα  = +   (5) 
Lo que nos lleva a la siguiente aproximación: 
( ) ( )2 j 2log j log cµ α= +  (6) 
 
A la gráfica de esta recta de regresión (eq.6) acompañada de los correspondientes 
intervalos de confianza en cada punto calculado, se la conoce como Diagrama Logescala y de la pendiente se puede extraer el valor de α  y despejar el valor de H. 
En realidad lo expuesto hasta aquí es el fundamento básico del método, donde la 
pendienteα , se puede estimar en la región del diagrama donde los puntos se alinean 
entre dos octavas 1 2,j j  , dado que es posible que no exista alineamiento en otras 
regiones. 
Según las notas que acompañan esta script, el autor parte de la definición de LRD 
dada en términos del espectro de potencia ( ) ( )  cuando 0f v cf v vα−≈ → , 
donde v , es la frecuencia, α  es el exponente de escala, que es adimensional, y cf es 
un coeficiente con dimensión de varianza y describe aspectos cuantitativos de la 
longitud o extensión del comportamiento LRD, y como ejemplo de la importancia de 
cf expresa que los intervalos de confianza de la estimación de la media de LRD son 
proporcionales a cf . La script entrega una estimación de sendos parámetros 
α y cf junto a otros que toman importancia según el contexto como se muestra a 
continuación. 
• El diagrama Log-escala, nos proporciona una gráfica con la bondad de la 
estimación en cada punto como función de 1j  (figura izquierda), lo que permite 
una mejor elección de las octavas 1, 2j j  
• Diferentes tipos de escala son posibles, sin embargo, el procedimiento de análisis 
es el mismo en cada caso. En primer lugar, el diagrama de Logscale se genera, y 
1091
6      Reinaldo Scappini1, Luis Marrone2, 
examina los datos para encontrar un punto de corte inferior de la escala 1j , y otro 
punto de corte superior 2j , en los que la alineación (línea recta) se observa. Estos 
puntos de corte deben ser experimentados para encontrar un rango que se ajuste a 
la regresión de los intervalos de confianza sobre el Diagrama Logscale (Los 
valores iniciales se deben especificar en la lista de argumentos de "LDestimate", 
pero estos se pueden cambiar interactivamente.). 
• Para cada rango de alineación elegido, la función de los resultados de la estimación 
de la pendiente "alfa", toma valores reales. El valor de alfa, y el rango 1 2,j j , 
ayudará a determinar qué tipo de escala se presenta. 
• Por conveniencia, alfa se transforma en valores de los parámetros relacionados, 
como el parámetro de Hurst H, o la dimensión fractal de la muestra (válida sólo si 
es gaussiana). El usuario debe determinar qué tipo de escala está presente. 
• NOTA: en el caso de LRD, alfa es el parámetro pertinente directamente, sin 
embargo, a veces es reescrita como una «H», pero esta no es la H de auto-similitud 
estricta, es simplemente una convención para reescribir alfa de esta forma para 
procesos LRD. 
• La experimentación con el número momentos desvanecientes N de la wavelet es 
necesario para: (a) asegurarse de que la onda detalles están bien definidas (con 
valores de H altos, serán necesarios valores más altos de N, N = 1 es suficiente 
para estudiar LRD), y (b) eliminar o disminuir la influencia de las tendencias 
deterministas, como ser tendencias lineales o variaciones de nivel medio, que 
pueden estar presentes. En ambos casos es conveniente un aumento de N, hasta 
logar un diagrama Logscale estable. 
• Una estadística de bondad de ajuste ( )1Q j , basado en Chi-Cuadrado se emite 
para ayudar con la elección del rango de escala, y se representa en el título del 
gráfico correspondiente (Fig.1.), como se muestra a continuación:.  
   
Fig. 1.  
Es la probabilidad de observar que los datos, con las estimaciones de la varianza 
en cada escala realmente siga la forma de una recta para asegurar la efectividad 
de la regresión lineal. Un valor superior a 0,05 es aceptable y es aconsejable la 
1092
Reinaldo Scappini1, Luis Marrone2,      7 
elección de ( )1j , a partir de donde se estabiliza el valor de ( )1Q j , La estimación 
visual de la región de alineación es difícil, cuando los intervalos de confianza se 
vuelven muy pequeños, en escalas pequeñas, en este caso la estadística ( )1Q j , 
es una mejor guía. 
4    Utilizando LDestimate 
La script puede utilizarse como una función con 7 argumentos de entrada con la 
siguiente sintaxis: 
 
LDestimate(data,regu,j1,j2,discrete_init,calcj1,printout) 
 
• data = Vector con los datos que se desean analizar (debe ser un vector fila). 
• regu = N o número de momentos desvanecientes de la wavelet, este parámetro está 
relacionado con la regularidad de la estimación, a mayor valor mejoramos la 
bondad del ajuste Q, la variable regu está disponible desde 1 a 10. (sugiero 
empezar con 1 e ir aumentando para observar la variación de Q y el grafico de 
regresión respectivamente). 
• j1 = octava de corte inferior debe ser 1≥ . 
• j2 = octava de corte superior, su valor máximo está relacionada con la longitud de 
los datos, pero se puede cambiar interactivamente durante la ejecución de la script, 
sugiero arrancar con el valor 2 y luego ir probando otros valores. 
• discrete_init = con el valor 1 realiza la inicialización MRA para datos 
intrínsecamente discretos si el valor es cero, asume la de entrada de datos ya 
inicializado (es decir, ya está calculada la aproximación de secuencia o se utiliza 
un vector correspondiente a una aproximación). 
• calcj1 = con el valor 1 realiza el cálculo de j1 optimo utilizando la script 
newchooseJ1 mencionada más arriba, si el valor es cero omite el cálculo. (sugiero 
dejarlo en 1).  
• printout = con el valor 1 realiza los dos gráficos correspondientes a “Q” y la 
regresión del diagrama Log-escala. Con el valor cero no realiza los gráficos y 
solamente entrega los valores calculados. 
5    Análisis realizado 
A continuación y a manera de muestra de las posibilidades de estudio que brinda 
esta metodología, se analizan una serie de trazas que están disponibles para su uso en 
la investigación conforme las políticas de cada fuente (más detalle a continuación en 
las correspondientes descripciones).  
 
El análisis se realiza sobre muestras tomadas de siete tipos de enlaces: 
 
1093
8      Reinaldo Scappini1, Luis Marrone2, 
1. Ethernet 10 Mbits. 
2. Ethernet 100 Mbits. 
3. Ethernet 1 Gbits. 
4. Ethernet 10 Gbits. 
5. OC12 
6. OC48 
7. OC192 
 
• Trazas Ethernet 10 Mb: Son las clásicas trazas utilizadas en muchísimos trabajos y 
que fueran utilizadas en el trabajo seminal de Leland et.al [5]; Si bien trabajo es de 
mucha antigüedad, es considerado como el punto de partida en este campo de 
análisis y es muy útil como referencia, pues casi todos los estudios comparativos 
realizados por distintos investigadores lo utilizan 
• Trazas Ethernet 100 Mb: Las trazas pertenecen a la colección: “WIDE-TRANSIT 
100 Megabit Ethernet Trace (Anonymized).”. Se encuentran disponibles en [6]. 
• Trazas Gigabit Ethernet: Estas trazas corresponden a capturas realizadas por 
NLANR PMA, mediante una tarjerta Endace DAG4.2GE dual Gigabit Ethernet 
network. Las trazas encuentran disponibles en la página del proyecto en el link [7]. 
• Trazas 10 Gigabit Ethernet Cluster TeraGrid SDSC: Estas trazas se recogieron 
mediante un monitor del proyecto PMA [8] (Passive Measurement and Analysis) 
• Trazas sobre Fibra Óptica:  Tres grupos de trazas sobre fibra óptica, OC12 – OC48, 
y OC192; fueron facilitadas por el Proyecto CAIDA [9] (CAIDA: The Cooperative 
Association for Internet Data Analysis). 
5.1 Procedimiento previo aplicado a las trazas 
Debido al importante tamaño de los archivos de las trazas (típicamente del orden 
de los gigabytes), para poder procesarlos con PC’s convencionales, a todas las trazas 
se las sometió al siguiente tratamiento: Se utiliza el software Wireshark [10], que es 
un conocido analizador de protocolos basado en tcpdump, que permite manipular 
trazas que utilicen formato compatible con el tcpdump y además cuenta con una 
utilidad de línea de comandos llamada Tshark [11], que resulta particularmente 
apropiada para esta tarea como se muestra a continuación: 
 
• Se toma el primer millón de tramas de la traza y se lo convierte en un archivo con 
la extensión .pcap. La sintaxis del comando es: Tshark –r [nombre de la traza] –c 
1000000 –w [nombre.pcap]. 
• Si se quiere trabajar con los tiempos entre arribos, creamos el archivo 
correspondiente, de la siguiente manera: Tshark –r [nombre.pcap] –e 
frame.time_delta –T fields > nombre.txt. Esto lo que hace es, leer el archivo .pcap 
que se creo con el millón de trazas, y lo filtra mediante el contenido del campo 
timestamp, del que a su vez establece la diferencia con la lectura anterior creando 
el valor tiempo entre arribos para cada trama y luego guarda el archivo en formato 
ASCII. 
• Del mismo modo si se desea trabajar con la longitud en bytes de la trama, se utiliza 
el campo frame.len para el filtrado de la siguiente forma: Tshark –r [nombre.pcap] 
1094
Reinaldo Scappini1, Luis Marrone2,      9 
–e frame.len –T fields > nombre.txt. Obteniendo de esta forma la salida en formato 
ASCII que es la más cómoda para poder utilizarla con el Matlab. 
 
Aclarados todos los detalles que permitirán repetir los análisis aquí expuestos, a 
continuación se muestra el resumen de los resultados del análisis efectuado a estas 
trazas, con el primer millón de datos para cada una de ellas, los datos corresponden a 
tiempos entre arribos y se muestran en la siguiente tabla. 
6    Resultados obtenidos 
Se exhiben los resultados de la estimación del parámetro H realizada con la script de 
Darryl Veitch, tomando una muestra de cada traza, conforme se describe 
anteriormente. Se aclara que las condiciones iniciales para todas las estimaciones son 
las mismas, es decir inicialmente se fijan los parámetros como: N= 4 momentos 
desvanecientes, 1 22; 20j j= = y los tres parámetros restantes igual a uno, esto 
significa que la script calculará en función de los resultados iniciales para cada caso lo 
siguiente: El mejor valor para 1j  como función del 2j que se encuentre como óptimo. 
Tomando los valores sugeridos por la script para 1 2 y j j , se repite la estimación 
obteniendo los datos que se muestran en la tabla 1: 
 
Traza                                      
Parámetro j1 j2 α α [95%] H H [95%]
10 Mbit. pAug89.TL 9 16 0,642 [0.590, 0.693] 0,821 [0.795, 0.846]
10 Mbit. pOct89.TL 6 16 0,51 [0.494, 0.527] 0,755 [0.747, 0.763]
100 Mbit. Tokio (200701090800) 8 16 0,315 [0.280, 0.349] 0,657 [0.640, 0.675]
100 Mbit. Tokio (200701091200) 6 16 0,304 [0.288, 0.321] 0,652 [0.644, 0.661]
Gigabit-Ethernet (20040130-132000-0) 10 16 0,557 [0.479, 0.634] 0,778 [0.740, 0.817]
10 Gigabit Ethernet (20040212-130000-0) 10 14 0,508 [0.286, 0.731] 0,754 [0.643, 0.865]
ampath-oc12.20070109.dag0.20070109-0000.anon 10 16 0,693 [0.616, 0.771] 0,847 [0.808, 0.885]
ampath-oc12.20070109.dag0.20070109-1500.anon 12 16 0,303 [0.106, 0.499] 0,651 [0.553, 0.750]
OC48-20020814-103000-0-anon.pcap 5 16 0,195 [0.184, 0.207] 0,598  [0.592, 0.603]
OC48-20020814-115000-0-anon.pcap 4 16 0,175 [0.167, 0.183] 0,588 [0.584, 0.592]
equinix-chicago.dirA.20090115-060100.UTC.anon 9 16 0,461 [0.410, 0.512] 0,73 [0.705, 0.756]
equinix-chicago.dirB.20090115-060100.UTC.anon 8 16 0,282 [0.248, 0.317] 0,643 [0.624, 0.659]  
Table 1.  
6.1 Tabla Comparativa de Resultados Obtenidos con Distintos Métodos de 
Estimación de “H”. 
La  tabla 2, muestra los resultados de la estimación deH , utilizando las 
aplicaciones desarrolladas en [1], junto al resultado obtenido mediante la script de 
Darryl Veitch. 
1095
10      Reinaldo Scappini1, Luis Marrone2, 
 
Table 2.  
Resaltados en cursiva, se encuentran los 
resultados de la estimación de H, por el método 
del diagrama log-escala implementado mediante 
la script LDestimate de Darryl Veitch, que es el 
de mayor precisión y menor sesgo. 
