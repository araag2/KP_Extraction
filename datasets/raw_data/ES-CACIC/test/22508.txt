Optimización sistólica sobre GPUs
﻿En este trabajo se estudia una nueva aproxima
ión algorítmi
a basada en un modelo de pro
esamiento paralelo 
ono
ido 
omo

omputa
ión sistóli
a. Este algoritmo se eje
uta sobre una Unidad de
Pro
esamiento Grá
o empleando CUDA (Compute Unied Devi
e Ar
hite
ture). El algoritmo se 
ompone de una matriz de 
eldas, donde

ada una de ellas trabaja sobre una solu
ión, realizando opera
iones que
la modi
an para luego moverla a la 
elda 
ontigua y repetir el pro
eso. Hemos evaluado el 
omportamiento del algoritmo sobre diferentes
instan
ias del problema de la mo
hila multidimensional. La evalua
ión
experimental sobre las instan
ias sele

ionadas demuestra la e
ien
ia y

ompetitividad de nuestra aproxima
ión.
Keywords: Computa
ión Sistóli
a, CUDA, Optimiza
ión, GPU
1. Introdu

ión
El interés en la 
omputa
ión paralela ha ido 
re
iendo progresivamente desde
la primera apari
ión de los ordenadores. La ne
esidad de resolver problemas de
forma 
ada vez más rápida ha llevado a los investigadores a 
rear nuevo hardware y, así mismo, a desarrollar nuevas herramientas de software para afrontar
las demandas de eje
u
ión en diversos ámbitos tales 
omo la físi
a, simula
ión,
bioinformáti
a, 
omuni
a
iones y otros 
ampos de investiga
ión y nego
ios [8℄.
Uno de los enfoques paralelos implementados en la literatura ha sido la
Computa
ión Sistóli
a. La Computa
ión Sistóli
a fue desarrollada en la Universidad de Carnegie-Mellon por Kung y Leiserson en 1979 [10℄. La idea bási
a
se 
entra en la 
rea
ión de un ve
tor 
onformado por diferentes pro
esadores, y
donde 
ada uno de ellos realiza opera
iones simples de 
ómputo. La informa
ión
se mueve a 
ontinua
ión al pro
esador 
ontiguo para repetir el pro
eso, generando así un 
ontinuo ujo de informa
ión en toda la estru
tura. Sin embargo,
esta arquite
tura presentó diferentes di
ultades en el pasado para la 
onstru

ión de ordenadores sistóli
os y, sobre todo, para programar algoritmos de alto
nivel sobre una arquite
tura de bajo nivel. No obstante, hoy en día, los avan
es
te
nológi
os han he
ho emerger nuevas plataformas de 
ómputo tales 
omo las
Unidades de Pro
esamiento Grá
o (GPUs, por sus siglas en inglés), las 
uales
están espe
ialmente diseñadas para trabajar 
on paralelismo masivo y propor
ionan un entorno donde es posible desarrollar diferentes modelos algorítmi
os.
Re
ientemente, se ha propuesto explotar la 
apa
idad 
omputa
ional disponible en las tarjetas grá
as de las 
omputadoras personales, a n de solu
ionar
problemas de propósito general [12℄. Desde enton
es los investigadores han 
onsiderado a las GPUs 
omo un área de investiga
ión prometedora.
En este trabajo, presentamos una nueva aproxima
ión llamada Systoli
 Neighborhood Sear
h (SNS, por sus siglas en inglés), la 
ual utiliza 
on
eptos de la

omputa
ión sistóli
a implementados sobre la arquite
tura de la GPU. Por 
onsiguiente, nuestra primera 
ontribu
ión es 
onsiderar la GPU 
omo una plataforma ade
uada para llevar a 
abo lo que denominamos optimiza
ión sistóli
a. Este
tipo de modelo ha demostrado ser e
az en otros problemas de optimiza
ión 
omo se muestra en [2℄. El modelo se basa en una estru
tura de malla donde 
ada

omponente tiene asignada una solu
ión en parti
ular. Cada 
elda realiza perturba
iones simples sobre la solu
ión y después se desplaza a la 
elda 
ontigua
para repetir el pro
eso. Al realizar perturba
iones simples y mover solu
iones
entre 
eldas se bus
a un pro
esamiento rápido y un 
ontinuo des
ubrimiento en
el espa
io de búsqueda, intentando tener un impa
to dire
to sobre la 
alidad
de las solu
iones. Utilizamos el problema de la mo
hila multidimensional para
evaluar el 
omportamiento numéri
o y también, 
omparamos los resultados 
on
los obtenidos por una implementa
ión de la búsqueda aleatoria en CPU y GPU.
El trabajo está estru
turado de la siguiente manera. En la se

ión 2 se expli
a
detalladamente la idea de de 
omputa
ión sistóli
a y el trabajo rela
ionado. En
la se

ión 3 se desarrolla el 
on
epto de GPU y de la plataforma CUDA. En la
se

ión 4 se introdu
e el nuevo algoritmo desarrollado y se detallan aspe
tos del
mismo. En la se

ión 5 se presenta el problema y las instan
ias sele

ionadas,
luego se des
ribe los experimentos realizados y posteriormente se analizan los
resultados obtenidos. Por último, la se

ión 6 in
luye 
on
lusiones y se sugieren
futuras líneas de investiga
ión.
2. Computa
ión Sistóli
a
Figura 1: Ve
tor
Sistóli
o
La 
omputa
ión sistóli
a es un modelo real que fusiona
los 
on
eptos de pipelining, paralelismo y 
onexión entre elementos. Un algoritmo sistóli
o utiliza un ve
tor de elementos
(
eldas) inter
one
tados entre sí llamado ve
tor sistóli
o. El
trabajo de 
ada 
elda es el mismo y se 
entra en realizar
opera
iones muy simples, por ejemplo suma o multipli
a
ión.
Luego de 
ada opera
ión, la informa
ión se traslada a la 
elda 
ontigua para volver a realizar otra opera
ión simple. La
Figura 1 muestra la entrada de los datos d y e en 
ada 
elda
o, en 
ada una de ellas se realiza la misma opera
ión sobre
los datos y luego se traslada la informa
ión a otra 
elda según
un ujo predenido sín
rono. La idea es que el ve
tor sistóli
o
mantenga un ujo 
onstante de la informa
ión y que la misma
se vaya transformando hasta produ
ir una salida deseable.
En la literatura se han registrado apenas algunas implementa
iones en el

ampo de optimiza
ión [4℄ [11℄ sin mayor notoriedad ni 
ontinua
ión del trabajo
debido a los in
onvenientes de programar en hardware.
3. Unidades de Pro
esamiento Gra
o
Las GPUs son 
onsideradas 
omúnmente 
omo un dispositivo, usado 
omo

opro
esador grá
o de la CPU. Con este tipo de arquite
tura se bus
a aliviar
la 
arga 
omputa
ional de la CPU. Los modelos a
tuales de GPU suelen tener
una gran 
antidad de pro
esadores, los 
uales están optimizados para eje
utar
una instru

ión simple sobre 
ada elemento de un extenso 
onjunto de elementos
(SIMD, por sus siglas en inglés).
Para poder utilizar ade
uadamente la 
apa
idad de 
ómputo de la GPU,
NVIDIA ha desarrollado una herramienta de programa
ión llamada CUDA [1℄.
CUDA permite a los programadores implementar fun
iones llamadas kernels. Un
kernel 
ontiene la por
ión de 
ódigo que sera eje
utada en la GPU. Esta fun
ión
es invo
ada desde el host y se despliega en la GPU. CUDA nos da la posibilidad
de implementar los kernels usando lenguaje C estándar más algunas extensiones
de NVIDIA. Además, nos permite organizar el paralelismo en tres niveles: rejilla,
bloque e hilo. Cada vez que se invo
a un kernel, se 
rea una rejilla de bloques,
los 
uales a su vez agrupan múltiples hilos (ver Figura 2).
Figura 2: Arquite
tura de la GPU
Durante la eje
u
ión del kernel, 
ada hilo tiene a

eso a diferentes tipos de
memoria dentro de la GPU, según una jerarquía predenida por NVIDIA. Esta
jerarquía abar
a registros, memoria lo
al y 
ompartida, luego 
ontinua 
on la
memoria global, 
onstante y texturas (siguiendo un planteamiento abajo-arriba).
Los registros proveen le
tura/es
ritura para 
ada hilo, mientras que la memoria 
ompartida es utilizada por aquellos hilos dentro de un mismo bloque. La
memoria global es la más grande dentro del dispositivo GPU, sin embargo, existen espa
ios reservados en ella para otros tipos de memoria tales 
omo la lo
al,

onstante o para texturas. La memoria 
ompartida y los registros son las más
rápidos, pero su tamaño está limitado por estar dentro del 
ir
uito integrado
de la GPU. Por otra parte, la memoria lo
alizada en la tarjeta del dispositivo
(lo
al, global, 
onstante y texturas) es grande pero presenta mayor laten
ia en
los a

esos, en 
ompara
ión 
on las dos anteriores.
4. Systoli
 Neighborhood Sear
h
El objetivo de esta se

ión es presentar nuestra propuesta algorítmi
a, llamado Systoli
 Neighborhood Sear
h (SNS). La idea esen
ial trabaja 
on una malla
toroidal donde las solu
iones se en
uentran lo
alizadas en 
ada 
elda. En 
ada
una de las 
eldas se realiza una opera
ión simple de perturba
ión sobre la solu
ión y el resultado se mueve a la 
elda 
ontigua para realizar el mismo pro
eso.
Las solu
iones se mueven a través de toda la la sufriendo múltiples 
ambios
en 
ada 
elda 
on el objetivo de mejorar su 
alidad. El poten
ial del algoritmo
se basa en la explora
ión del espa
io de búsqueda de manera e
iente y estru
turada mediante la eje
u
ión de 
ontinuas modi
a
iones en las solu
iones de
manera sistemáti
a.
El pseudo
ódigo del SNS se detalla en el Algoritmo 1. El SNS 
omienza deniendo el tamaño de la malla de a
uerdo al tamaño del problema a resolver. El
SNS genera aleatoriamente 
ada solu
ión y posteriormente evalúa 
ada una de
ellas. A 
ontinua
ión, se realizan diversas opera
iones en 
ada 
elda bus
ando
mejorar la solu
ión residente a
tual. El SNS trabaja 
on base a tres 
omponentes prin
ipales: una topología denida, la 
omputa
ión en 
eldas y el ujo
de informa
ión. Cada uno de ellos es expli
ado a 
ontinua
ión. Asimismo, estas
opera
iones se en
uentran en el pseudo
ódigo presentado en el Algoritmo 1.
Figura 3: Systoli
 Neighborhood Sear
h
Topología El SNS utiliza una malla toroidal para ubi
ar las solu
iones. La
Figura 3 muestra la disposi
ión de las 
eldas y solu
iones. La malla está denida
por un tamaño a × b. Las dimensiones se denen 
on base al número n de
elementos dado por un problema que se va a resolver. De esta manera, a y b son

onguradas de a
uerdo al valor de n (tamaño del problema).
Cómputo en Celdas Una vez denida la malla, es ne
esario expli
ar la 
ongura
ión de las opera
iones realizadas en 
ada una de las 
eldas. Cada solu
ión
Algorithm 1 Pseudo
ódigo del SNS 
anoni
o
1: Denir variables a y b dependiente del tamaño del problema
2: Denir malla M de tamaño a× b
3: para todo soli ∈M ha
er en paralelo
4: soli ←generarSolu
ion(soli);
5: soli ←evaluarSolu
ion(soli);
6: n for
7: mientras (no se 
umpla 
riterio de parada) ha
er
8: para todo soli ∈M ha
er en paralelo
9: Cal
ular la posi
ión (x, y) para 
ada soli
10: sol′i ← soli
11: para init = 0 a (x− 1) ha
er
12: sol′i ← apli
ar opera
iones de 
ambio sobre la posi
ión (y+init) en el ve
tor de valores
13: n para
14: sol′i ← parcial_eval(sol
′
i)
15: si sol′i MEJOR QUE soli enton
es
16: soli ← sol′i
17: n si
18: esperar la termina
ión de todas las opera
iones en todas las 
eldas (entre lineas 8-17)
19: 
al
ular sigPosicion = (y + 1) mód n
20: sol(x,sigPosicion) = sol(x,y)
21: n for
22: n mientras
23: getBest(M).
soli esta 
onformada por un ve
tor solu
ión, que 
ontiene la espe
i
a
ión de

ada solu
ión. En 
ada 
elda se eje
uta una opera
ión simple de perturba
ión
sobre un 
ierto grupo de 
omponentes en el ve
tor solu
ión.
El pro
eso se ini
ia realizando una 
opia llamada sol′i de la solu
ión original
soli. Los 
ambios que se produ
en sobre sol′i son denidos a partir de los parámetros (x, y) (es el índi
e para 
ada 
elda). El parámetro x dene el número de
valores a 
ambiar en 
ada solu
ión, de esta forma, a medida que el número de la
la va aumentando, también lo ha
e el número de elementos que 
ambiar dentro
de 
ada solu
ión. El parámetro y indi
a a partir de qué posi
ión se produ
irán
los 
ambios en el ve
tor solu
ión. Por ejemplo, si tenemos una solu
ión sol(3,2),
se modi
arán tres valores a partir de la posi
ión 2. De ahí, la importan
ia de
tener una malla 
on dimensiones iguales al tamaño del problema, que busque
evaluar todos los grupos posibles de 
ambios sobre el ve
tor solu
ión, partiendo
de 
ada posi
ión fa
tible dentro del mismo.
Una vez realizados los 
ambios, pro
edemos a re-evaluar sol′i, usando una
fun
ión de evalua
ión par
ial para no 
onsumir demasiado tiempo de 
ómputo
realizando una re-evalua
ión 
ompleta de toda la solu
ión. De esta manera, solo
se evalúan aquellas partes de la solu
iones que han sufrido modi
a
iones. Sí
sol′i es mejor que soli, se remplaza soli 
on la 
opia, de otra forma, la solu
ión
antigua queda sin sufrir ningún 
ambio.
Flujo de Informa
ión El SNS mueve 
ada solu
ión a la siguiente 
elda de
manera sín
rona al mismo tiempo. De esta forma, al tener una malla 
on n

olumnas se pueden perturbar todos los grupos posibles de 
omponentes dentro
de las solu
iones.
5. Experimenta
ión
En esta se

ión presentamos y analizamos los resultados obtenidos por el
SNS al resolver instan
ias del Problema de la Mo
hila Multidimensional. Para
ello pro
ederemos en tres etapas, abordando el estudio de la e
ien
ia numéri
a, seguido de un análisis del 
onsumo de tiempo eje
u
ión de los algoritmos
examinados, para nalizar 
on una dis
usión del 
omportamiento del modelo
propuesto.
Hemos organizado esta se

ión en tres subse

iones. La primera formaliza el
problema estudiado y las instan
ias sele

ionadas. En la segunda expondremos
los parámetros utilizados para la eje
u
ión de los algoritmos, mientras que en
la ter
era estudiaremos los resultados obtenidos por los diferentes algoritmos en

ada instan
ia.
5.1. Problema de la Mo
hila Multidimensional (MKP)
El MKP es un problema de optimiza
ión 
ombinatoria que ha re
ibido amplia
aten
ión de la 
omunidad investigadora, ya que el planteamiento matemáti
o de
mu
hos problemas prá
ti
os de la vida 
otidiana lleva al modelo del MKP, por
ejemplo, [6℄ [7℄ [13℄ .
maximizar
n
∑
j=1
pjxj (1)
sujeto a
n
∑
j=1
wijxj ≤ Ci, i ∈ I, I={1,...,m} (2)
xjǫ {0,1}, j ∈ J, J={1,...,n} (3)
Este problema está formado por un 
onjunto n de elementos y un 
onjunto
m de mo
hilas. El parámetro pj indi
a el bene
io del elemento j, wij indi
a el
peso del elemento j respe
to a la mo
hila i y Ci es la 
apa
idad de la mo
hila i.
Se bus
a en
ontrar un ve
tor x = (x1, x2, ..., xj), que maximi
e la e
ua
ión 1, y
al mismo tiempo 
umpla las restri

iones de la e
ua
ión 2.
Aquellas solu
iones que no 
umplen las restri

iones de la e
ua
ión 2 se 
onvierten en solu
iones no fa
tibles. Nosotros hemos utilizado una fun
ión presentada por Gottlieb [9℄ para penalizar las solu
iones no fa
tibles:
penalizacionx =
pmax + 1
wmin
.max{CV(x,i)| i ǫ I} (4)
donde CV(x,i) = max(0,
∑
jǫJ wij ∗ xj −Ci) e indi
a la 
antidad de restri

iones
violadas para una restri

ión i ∈ I, wmin = min{wij|i ∈ I, j ∈ J} indi
a el
mínimo peso que se puede tener y nalmente el máximo bene
io es representado
por pmax = max{pj |j ∈ J}. (pmax +1)/wmin tiene 
omo nalidad 
orrela
ionar
la fun
ión objetivo sobre la base de los bene
ios 
on la demanda de re
ursos que
superan las limita
iones de las mo
hilas. Esta fun
ión se basa en una estima
ión
pesimista de los bene
ios que se perderían sí los elementos fueran retirados de
la mo
hila 
on el n de obtener solu
iones fa
tibles. Para más detalles, ver [9℄.
Las instan
ias sele

ionadas están in
luidas dentro de las propuestas por
Chu y Beasly en la OR-Library [5℄. Hemos sele

ionado 3 instan
ias llamadas
WEISH18 = {n = 105,m = 2}, 10.250.0 = {n = 250,m = 10}, 10.500.0 = {n =
500,m = 10}. Hemos utilizado trabajos anteriores existentes en la literatura para

omparar 
on los mejores óptimos 
ono
idos [15℄ [16℄, estos valores se muestran
en la Tabla 1a, en la la Optimo.
5.2. Parametriza
ión
Con el n de ha
er una 
ompara
ión justa entre todos los algoritmos hemos
utilizado un número dinámi
o de evalua
iones, para garantizar una explora
ión
similar en el espa
io de búsqueda en 
ada algoritmo. Para ello, se han tomado

omo base trabajos previos sobre MKP [5℄ [14℄ [3℄. Dado el valor resultante de
evals = n ∗ 5000, el número de evalua
iones es:
maxEvals =





n ∗ 5000,si(evals >= 400000)&(evals <= 3000000)
400000,si(evals < 400000)
3000000,si(evals > 3000000)
(5)
La búsqueda aleatoria (RS, por sus siglas en inglés) en CPU (RSCPU ) utilizada para 
omparar es la version 
anóni
a existente en la literatura y se usa
para asegurar que el SNS tiene un 
omportamiento inteligente no trivial. Con
respe
to a la versión en GPU (RSGPU ), esta fun
iona 
on una pobla
ión de
tamaño n. Bási
amente, 
ada solu
ión es administrada por un hilo de la GPU.
Cada hilo apli
a en paralelo el pro
eso de una RS 
anóni
o sobre 
ada solu
ión.
Cuando la 
ondi
ión de parada es al
anzada, el algoritmo sele

iona la mejor
solu
ión vista en la vida del algoritmo.
Se han realizado 30 eje
u
iones independientes para 
ada algoritmo en 
ada
instan
ia. Para obtener resultados estadísti
amentes signi
ativos en primer lugar, la prueba de Kolmogorov-Smirnov se lleva a 
abo 
on el n de 
omprobar si
los valores de los resultados siguen una distribu
ión normal (Gaussiana) o no. Si
la distribu
ión es Normal, enton
es se apli
a el test de Levene para 
omprobar
la homogeneidad de las varianzas. Sí las muestras tienen varianzas iguales (test
de Levene positivo), una prueba de ANOVA se lleva a 
abo, de lo 
ontrario una
prueba de Wel
h se lleva a 
abo. Para distribu
iones no Normales, la prueba
no paramétri
a de Kruskal-Wallis se utiliza para 
omparar las medianas de los
algoritmos. En este trabajo siempre tenemos en 
uenta un nivel de 
onanza del
95%. Ésto signi
a que podemos garantizar que las diferen
ias de los algoritmos
de 
ompara
ión son signi
ativas o no 
on una probabilidad del 95%.
Las pruebas se han eje
utado sobre un PC 
on un pro
esador Intel (R) i7
CPU 920, 
on 4096 MB de RAM. El sistema operativo Ubuntu Lu
id 10.04.2.
Para el 
aso de la GPU, hemos usado una NVIDIA GeFor
e GTX 285 
on 1024
MB de DRAM. Hemos utilizado CUDA versión 3.1 y el 
ontrolador para la
tarjeta grá
a es la versión 257.21.
5.3. Resultados Experimentales
A 
ontinua
ión abordaremos los resultados de tness y tiempo obtenidos
para 
ada algoritmo. Los resultados de tness se resumen en las Tablas 1a,
donde 
ada la indi
a el tness promedio de las 30 eje
u
iones independientes
obtenido respe
to de 
ada algoritmo en 
ada instan
ia. Con letra negrita y
resaltado en gris apare
en los mejores valores obtenidos. La ultima la indi
a si
existe signi
an
ia estadisti
a (
on el signo +) o no (signo −).
Tabla 1: Resultados de tness y tiempo de los algoritmos para 
ada instan
ia
(a) Resultados de Fitness
Algoritmo
Instan
ias
WEING7 10.250.0 10.500.0
RSCPU 933266,800 31590,000 85620,000
RSGPU 931947,967 36030,000 86166,000
SNSCPU 1086461,333 40577,750 88173,200
SNSGPU 1089370,833 41696,667 89833,333
Optimo 1095445,000 58097,000 119215,000
+ + +
(b) Resultados de Tiempo
Algoritmo
Instan
ias
WEING7 10,250,0 10,500,0
RSCPU 0,668 9,307 35,542
RSGPU 1,406 10,098 20,181
SNSCPU 0,684 9,727 42,490
SNSGPU 0,080 1,082 4,339
El primer resultado observable en la Tabla 1a es que ninguno de los algoritmos
eje
utados al
anza el mejor óptimo 
ono
ido. Entre los algoritmos, el SNSGPU
desta
a por tener valores de tness muy 
er
anos al óptimo 
on respe
to a los
otros algoritmos. Como segundo resultado vemos que el SNSCPU también obtiene valores apenas por debajo del SNSGPU . Las versiones del RS han quedado
muy por debajo de los valores de tness de las dos versiones SNS. Ésto nos indi
a
que el esquema del algoritmo SNS obtiene ventaja en la explora
ión del espa
io
de búsqueda a través de los 
ambios sistemáti
os realizados en 
ada 
elda y el
movimiento 
ontinuo de informa
ión a través de la malla. Los resultados además
indi
an que la estru
tura del SNS puede realizar una explora
ión inteligente del
espa
io de búsqueda respe
to de la búsqueda aleatoria.
La Figura 2a muestra la evolu
ión del promedio de los valores tness por la
del SNSGPU . La gura indi
a en 
olor gris las peores solu
iones y a medida que
las solu
iones mejoran el 
olor se va a
larando hasta indi
ar las mejores solu
iones en blan
o. El SNSGPU presenta una rápida evolu
ión en la 
alidad de las
solu
iones en las primeras las (1 a 10 aproximadamente). Los 
ambios de grupos pequeños de elementos en las solu
iones durante la evolu
ión del algoritmo
produ
e un in
remento promedio en la 
alidad de las solu
iones. La modi
a
ión
de pequeños grupos evita también el 
aer en óptimos lo
ales o en 
aso de 
aer,
el poder salir explorando zonas 
ontiguas en el ve
tor solu
ión. Por otro lado, se
observa que los 
ambios produ
idos en el resto de las las no tiene un impa
to
dire
to sobre la 
alidad de la mejor solu
ión e in
lusive no se apre
ia una mejora
importante en la 
alidad media de estas las.
La Tabla 1b presenta el promedio de los tiempos obtenidos (expresados en
segundos) durante las 30 eje
u
iones independientes. Con letra negrita y resaltado en gris apare
en los mejores valores valores obtenidos de tiempo para
las instan
ias eje
utadas. Los resultados de esta tabla indi
an 
laramente que el
Tabla 2: Resultados de tness y tiempo de los algoritmos para 
ada instan
ia
(a) ResultadosdeF itness (b) ResultadosdeT iempo
menor tiempo de eje
u
ión es obtenido por el SNS en GPU. Asimismo, obtiene
una diferen
ia signi
ativa respe
to a los otros algoritmos, en espe
ial de las
versiones del RS y SNS en CPU a medida que aumenta el número de elementos
en las instan
ias.
La Figura 2b indi
a la a
elera
ión del SNSGPU 
on respe
to al resto de algoritmos. Esta medida es una métri
a muy usada para 
omparar la a
elera
ión
entre versiones en CPU y GPU. La métri
a divide el tiempo trans
urrido al eje
utar un algoritmo respe
to a la versión SNSGPU . De esta forma, un valor sobre
1.0 signi
a un mayor e
ien
ia de tiempo del SNSGPU respe
to del otro algoritmo. En general la a
elera
ión del SNSGPU 
on respe
to a los otros algoritmos
se en
uentra entre 8 y 17.5 ve
es, demostrando la e
ien
ia del modelo y 
ómo
éste maximiza la e
ien
ia de la arquite
tura GPU. En parti
ular, vemos que el
RSGPU redu
e la diferen
ia respe
to del SNSGPU a medida que el número de
elementos aumenta.
6. Con
lusiones y Trabajos Futuros
En este trabajo hemos estudiado una aproxima
ión algorítmi
a espe
ialmente
pensada para el hardware de una GPU, utilizando un nuevo diseño 
on base en
el modelo sistóli
o. Las prin
ipales 
ara
terísti
as del SNS son la simpli
idad
en las opera
iones realizadas en 
ada 
elda y el 
ontinuo ujo de informa
ión a
través de la malla toroidal.
Se han realizado experimentos sobre el SNS utilizando diversas instan
ias del
MKP, obteniendo solu
iones de alta 
alidad y tiempos de eje
u
ión muy rápidos,
sobre todo en la versión SNSGPU .
La naturaleza inherentemente paralela del SNS aprove
ha al máximo los re
ursos de la GPU en este tipo de problema, aunque es ne
esario estudiar sí este

omportamiento se mantiene para otros problemas.
Como futuro trabajo se estudiarán nuevas versiones del SNS, variando tanto
el tamaño de la malla 
omo las opera
iones que se realizan en 
ada 
elda.
Agrade
imientos
Los autores agrade
en el apoyo del Ministerio español de Cien
ia e Innova
ión
Europea FEDER bajo el 
ontrato TIN2008-06491-C04-01 (M* proje
t) así 
omo
del TIN2011-28194 (RoadMe proje
t), y del CICE, Junta de Andalu
ía según el

ontrato P07-TIC-03044 (DIRICOM proje
t). También a la Universidad de la
Patagonia Austral, por el 
ontinuo apoyo re
ibido.
Referen
ias
1. NVIDIA CUDA Compute Unied Devi
e Ar
hite
ture - Programming Guide, 2007.
2. Enrique Alba and Pablo Vidal. Systoli
 optimization on gpu platforms. In EUROCAST (1), pages 375383, 2011.
3. Wilbaut C. and Said Hana. New 
onvergent heuristi
s for 01 mixed integer
programming. European Journal of Operational Resear
h, pages 62  74, 2009.
4. Heming Chan and Pinaki Mazumder. A systoli
 ar
hite
ture for high speed hypergraph partitioning using a geneti
 algorithm. In Xin Yao, editor, Progress in
Evolutionary Computation, volume 956 of Le
ture Notes in Computer S
ien
e, pages 109126. Springer Berlin / Heidelberg, 1995.
5. P.C. Chu and J.E. Beasley. A geneti
 algorithm for the multidimensional knapsa
k
problem. Journal of Heuristi
s, 4:6386, 1998.
6. B. Gavish et al. Allo
ation of data bases and pro
essors in a distributed 
omputting
system. Management of Distributed Data Pro
essing, page 215231, 1982.
7. P. C. Gilmore and R. E. Gomory. The theory and 
omputation of knapsa
k fun
tions. Operations Resear
h, 14(6):10451074, 1966.
8. Ananth Grama, George Karypis, Vipin Kumar, and Anshul Gupta. Introdu
tion
to Parallel Computing (2nd Edition). Addison Wesley, 2003.
9. Gottlieb J. On the feasibility problem of penalty-based evolutionary algorithms
for knapsa
k problems. In Appli
ations of Evolutionary Computing, Le
ture Notes
in Computer S
ien
e, pages 5059. 2001.
10. H. T. Kung. Let's design algorithms for vlsi systems. In Pro
. Conf. Very Large
S
ale Integration: Ar
hite
ture, Design, Fabri
ation, pages 6590, Jan. 1979.
11. G.M. Megson and I.M. Bland. Synthesis of a systoli
 array geneti
 algorithm. In
Parallel Pro
essing Symposium, 1998. IPPS/SPDP 1998. Pro
eedings of the First
Merged International ... and Symposium on Parallel and Distributed Pro
essing
1998, pages 316 320, mar-3 apr 1998.
12. John D. Owens, David Luebke, Naga Govindaraju, Mark Harris, Jens Krüger,
Aaron E. Lefohn, and Timothy J. Pur
ell. A survey of general-purpose 
omputation
on graphi
s hardware. Computer Graphi
s Forum, pages 80113, 2007.
13. Wei Shih. A bran
h and bound method for the multi
onstraint zero one knapsa
k
problem. J. Operational Resear
h So
iety, 30(4):369378, 1979.
14. Mi
hel Vasquez and Yanni
k Vimont. Improved results on the 0-1 multidimensional
knapsa
k problem. European Journal of Operational Resear
h, 165:7081, 2005.
15. Xiaoxia Zhang, Zhe Liu, and Qiuying Bai. A new hybrid algorithm for the multidimensional knapsa
k problem. In Bio-Inspired Computing and Appli
ations, Le
ture
Notes in Computer S
ien
e, pages 191198. 2012.
16. Qian Zhou and Wenjian Luo. A novel multi-population geneti
 algorithm for
multiplehoi
e multidimensional knapsa
k problems. In Zhihua Cai, Chengyu
Hu, Zhuo Kang, and Yong Liu, editors, Advan
es in Computation and Intelligen
e,
volume 6382 of Le
ture Notes in Computer S
ien
e, pages 148157. Springer Berlin
/ Heidelberg, 2010.
