Comparación de modelos de comunicación sincronización en programación paralela sobre cluster de multicores
﻿ Teniendo en cuenta el auge de la arquitectura de cluster de 
multicores, en este trabajo se analiza la utilización de los diferentes modelos de 
comunicación (Pasaje de Mensajes, Memoria Compartida, combinación de 
ambos) para aprovechar eficientemente la potencia de la arquitectura.  
Como caso de prueba se utiliza el Algoritmo de Smith-Waterman para 
determinar el grado de similitud de dos secuencias de ADN, cuya paralelización 
se basa en un esquema de pipeline debido a la dependencia de datos del 
problema. 
Finalmente se mencionan las líneas de investigación futuras tendientes a 
mejorar el uso óptimo de los niveles de memoria de la arquitectura.  
Palabras Claves: cluster de multicores, modelo de comunicación híbrido, 
pipeline, Smith-Waterman.  
1 Introducción 
La investigación en Sistemas Distribuidos y Paralelos es una de las líneas de mayor 
desarrollo en la Ciencia Informática actual [1][2]. En particular la utilización de 
arquitecturas multiprocesador configuradas en clusters, multiclusters y grids y 
soportadas por redes de diferentes características y topologías se ha generalizado, 
tanto para el desarrollo de algoritmos paralelos como para el de servicios WEB 
distribuidos [3][4][5]. En la misma línea están los desarrollos en cloud computing [6]. 
El cambio tecnológico, fundamentalmente a partir de los procesadores multicore, 
ha impuesto la necesidad de investigar en modelos mixtos o híbridos, en los cuales 
coexisten esquemas de memoria compartida con mensajes [7][8].  
Es importante en este contexto investigar la modelización del comportamiento de 
esta clase de sistemas paralelos, así como desarrollar nuevos paradigmas y 
herramientas para la programación eficiente de aplicaciones [9][10][11]. 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACIÓN                                                 201
1.1 Cluster de multicores 
Un procesador multicore  surge a partir de integrar dos o más núcleos 
computacionales dentro de un mismo “chip” [12]. La motivación de su desarrollo se 
basa en los problemas de consumo de energía y generación de calor que aparecen al 
escalar la velocidad de un procesador.  
Un procesador multicore incrementa el rendimiento de una aplicación al dividir el  
trabajo de cómputo entre los núcleos disponibles [13]. 
Un cluster es un  sistema de procesamiento paralelo compuesto por un conjunto de 
computadoras interconectadas vía algún tipo de red, las cuales cooperan configurando 
un recurso que se ve como “único e integrado”, más allá de la distribución física de 
sus componentes. Cada “procesador” puede tener diferente hardware y sistema 
operativo, e incluso puede ser un “multiprocesador” [14].  
1.2 Aplicación a investigar 
Una de las áreas de mayor interés y crecimiento en los últimos años dentro del 
procesamiento paralelo es la de tratamiento de grandes volúmenes de datos, tales 
como las secuencias de ADN. El tipo de procesamiento extensivo de comparación 
para analizar patrones genéticos requiere un esfuerzo importante en el desarrollo de 
algoritmos paralelos eficientes [15]. 
En parte, el centro de todas las operaciones y análisis en el mundo bioinformático, 
lo tiene el Alineamiento de Secuencias, tanto para búsqueda de patrones entre 
secuencias de aminoácidos y nucleótidos, como para la búsqueda de relaciones 
filogenéticas entre organismos. El algoritmo de Smith-Waterman para alineamiento 
local es uno de estos métodos, el cual se centra en regiones de similitud sólo en partes 
de las secuencias, es decir que la función del algoritmo es hallar regiones pequeñas 
con similitud local. Este método se ha empleado como base para muchos algoritmos 
posteriores y a menudo se utiliza como patrón con el que comparar diferentes técnicas 
de alineación. Si las longitudes de las secuencias involucradas son N y M, la 
complejidad del algoritmo es O(NxM). Esto lleva a que el problema escale en forma 
cuadrática al tamaño de las secuencias [16].  
Teniendo en cuenta que  las secuencias pueden tener hasta 109  nucleótidos cada 
una, el tiempo y memoria requeridos para resolver este problema en forma secuencial 
es impracticable. Esto conlleva a paralelizar el algoritmo para ejecutar sobre potentes 
arquitecturas paralelas. 
1.3 Comparación de secuencias de ADN sobre cluster de multicores 
Teniendo en cuenta el auge de la arquitectura de cluster de multicores, es importante 
el estudio de nuevas técnicas para la programación de algoritmos paralelos que 
aprovechen eficientemente la potencia de la arquitectura combinando memoria 
compartida y pasaje de mensajes. 
En particular, el enfoque de la aplicación a estudiar tiene el atractivo de su 
complejidad y la posibilidad de descomponer la concurrencia del algoritmo paralelo 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACIÓN                                                 202
en “bloques” de diferente dimensión, adaptando en forma óptima la misma a la 
arquitectura de soporte del cluster de multicores. 
La arquitectura utilizada en este trabajo consiste de un Blade de 8 hojas. Cada hoja 
posee 2 procesadores quad core Intel Xeón e5405 de 2.0 GHz, con 2 Gb de memoria 
RAM (compartido entre ambos procesadores) y cache L2 de 2 x 6Mb entre par de 
cores [17][18]. Esta arquitectura permite una investigación exhaustiva de los tres 
enfoques (Mensajes, Memoria Compartida, Híbrido). 
En la Sección 2 se explica el algoritmo de Smith-Waterman junto con la solución 
secuencial y paralela utilizada en este trabajo. La Sección 3 describe el trabajo 
experimental realizado, y en la Sección 4 se muestran y analizan los resultados 
obtenidos. La Sección 5 presenta las conclusiones y las líneas de trabajo futuras en 
relación a este trabajo. 
2 Definición del algoritmo de Smith-Waterman 
Este método permite alinear dos secuencias de ADN insertando gaps (en caso de ser 
necesario) con el fin de detectar regiones de similitud local que indiquen la presencia 
de una relación entre ambas secuencias, por medio de la asignación de un puntaje de 
similitud. Si es necesario abrir gaps, es decir no aparear ciertos elementos de las 
secuencias para lograr mejores alineamientos, se debe penalizar dicha acción. 
El algoritmo calcula el puntaje de similitud entre dos secuencias, y luego, de ser 
necesario, emplea un retroceso para crear la alineación óptima [14].  
A continuación se realiza una explicación del funcionamiento del algoritmo para 
encontrar el puntaje de similitud entre dos secuencias de ADN. 
Dadas dos secuencias: A = a1a2a3…aM   y   B = b1b2b3…bN, se construye una 
matriz H de (N+1)x(M+1), de tal forma que las bases nucleótidos que forman la 
secuencia A etiquetan las filas (a partir de la 1) y los de B las columnas (a partir de la 
1). A través de los siguientes pasos de calculan los valores de H que darán el puntaje 
de similitud entre A y B: 
a. Inicializar en 0 la fila 0 y la columna 0 de H, como se indica en la Ecuación 1. 
MjNiHH ji  0y0para000
                     (1) 
b. Calcular el valor de Hij para i  [1,..,N] y j  [1,..,M] por medio de la 
Ecuación 2. Este valor indica la máxima similitud entre dos segmentos que 
terminan en ai y bj respectivamente. 










ji
ji
jiji
ji
F
C
baVH
H
),(
0
max
1,1                                  (2) 
 V(ai, bj) es la función de coincidencias que indica el puntaje dado por hacer 
coincidir a ai y bj. Se basa en una tabla de valores llamada matriz de 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACIÓN                                                 203
sustitución que describe la probabilidad de que una base nucleótida de la 
secuencia A en la posición i, tenga ocurrencia en la secuencia B en la 
posición j. La matriz más común es aquella que premia con un valor positivo 
cuando ai y bj son idénticos, y castiga con un valor negativo en caso 
contrario.  
 Cij es el puntaje considerando un gap en la columna j, y se calcula por medio 
de la Ecuación 3.                                    
)}({max ,1 kgHC jkiikji  
                             (3) 
 Fij es el puntaje considerando un gap en la fila i, y se calcula por medio de la 
Ecuación 4. 
       )}({max ,1 lgHF ljijlji  
                               (4) 
 g(x) es la función de penalidad por un gap de longitud x, y se obtiene por 
medio de la Ecuación 5, siendo q la penalidad por la apertura de un gap y r 
por la prolongación del mismo.    
     )0;0()(  rqxrqxg                          (5) 
c. Obtener el puntaje de similitud como se indica en la Ecuación 6.  
}{max )0)(0( jiMjNi HG 
                                   (6)    
d. A partir de la posición de la matriz H donde se encontró el valor G (que 
representa el final del alineamiento de puntuación más elevada entre las dos 
secuencias) se realizar un proceso de retroceso para obtener el par de segmentos 
con máxima similitud, hasta que se llega a una posición cuyo valor es 0, siendo 
este punto el inicio del segmento.   
2.1 Solución secuencial del algoritmo Smith-Waterman 
En esta sección se analiza la solución secuencial del algoritmo Smith-Waterman con 
el objetivo de determinar el puntaje de similitud entre dos secuencias de ADN. Esto 
significa que no se tiene en cuenta el proceso de retroceso para obtener el segmento 
que representa la alineación óptima (no se realiza el punto d. del algoritmo explicado 
en la sección anterior). 
 Secuencia A 
S
ec
u
en
ci
a
 B
    
C
ij
 (
g
a
p
) 
 
 
    
  Hd  
Fij (gap) Hij  
     
Fig. 1. Esquema de dependencia de datos. 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACIÓN                                                 204
En la Figura 1 se muestra la dependencia de datos que existe para calcular los 
valores de la matriz. Para obtener Hi,j se requiere el resultado de Hi-1,j-1 (Hd en la 
Figura 1) y se necesita saber el puntaje al considerar un gap en la fila i y otro en la 
columna j. Esta restricción nos lleva a calcular los valores de H de arriba hacia abajo 
y de izquierda a derecha (H11, H12, H13, …H21, H22, H23, …..). 
Teniendo en cuenta que no se realiza el paso d del algoritmo, no es necesario 
almacenar la matriz H completa, en su lugar se necesita: 
 Un vector h de longitud M+1 que mantiene en cada posición el valor  obtenido 
en la última fila procesada sobre esa columna. En la Ecuación 7 se indican los 
valores de h en el ejemplo de la Figura 1.  





 1
1
,1
,
jkH
jkHh
ki
ki
k
                  (7) 
 Un elemento e para guardar en forma temporal el último valor calculado en la 
fila que se está procesando. En la Figura 1,  e = Hi,j-1. 
 Un vector c de longitud M+1 que mantiene en cada posición el máximo 
puntaje considerando un gap en esa columna. En la Ecuación 8 se indican los 
valores de c en el ejemplo de la Figura 1. 




 jkC
jkCc
ki
ik
k
,1
                   (8) 
 Un elemento f que mantiene el máximo puntaje considerando un gap en la fila 
que se está procesando. En el ejemplo de la Figura 1, f = Fi, j-1. 
2.2 Solución paralela general del algoritmo Smith-Waterman 
La dependencia de datos mencionada en la sección anterior lleva a resolver el 
problema con un esquema de pipeline en el que las E etapas realizan el mismo trabajo 
sobre diferentes subconjuntos de nucleótidos consecutivos de la primera secuencia (A 
en Figura1). En cada ciclo la etapa eti (para i  [1, E-1]) recibe un bloque de datos de 
ei-1 y a partir de ellos resuelve parte de su trabajo, y a continuación envía esos 
resultados a ei+1 (excepto la última etapa que no necesita enviarle los resultados a 
ninguna otra). La primera etapa (e0) sólo realiza su trabajo enviando los resultados 
parciales (correspondientes a un bloque) a su sucesor. 
Un punto importante de esta solución es seleccionar la cantidad (TB) de elementos 
de la secuencia B que forman los bloques de datos que se comunican entre procesos 
consecutivos, teniendo en cuenta que: 
 Recién se comienza a aprovechar al máximo el paralelismo del pipeline 
cuando han pasado E-1 ciclos. Es decir cuando a todas las etapas les ha llegado 
trabajo. Cuanto más grande es TB, mayor es el tiempo que tarda en llenarse el 
pipe, y por consiguiente menor el aprovechamiento del mismo. Desde este 
punto de vista, TB debe tender a 1. 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACIÓN                                                 205
 Si el tamaño TB es muy chico, las etapas pasan más tiempo comunicando 
resultados parciales que procesando información. Desde este punto de vista TB 
debe tender a N. 
Se debe encontrar un tamaño de bloque adecuado de manera que se pueda solapar 
la comunicación de los datos con el procesamiento de los mismos. El tamaño óptimo 
no sólo depende de la arquitectura utilizada, sino también del modelo de 
comunicación  empleado. 
2.2.1 Pasaje de Mensajes como modelo de comunicación 
En este caso, cada etapa del pipeline se lleva a cabo por un proceso pi (para i  [0, E1]) diferente, y la comunicación de los resultados parciales se realiza enviando 
mensajes entre procesos consecutivos. La primera secuencia (A en Figura1) es 
distribuida por p0 entre los E procesos que forman el pipeline. 
2.2.2 Memoria Compartida como modelo de comunicación 
En este caso, cada etapa del pipeline se lleva a cabo por un hilo ti (para i  [0, E-1])  
diferente. En lugar de comunicar los resultados parciales por medio del pasaje de 
mensajes, estos se mantienen en la memoria compartida como una única estructura 
(como en el algoritmo secuencial). Se usa sincronización entre hilos consecutivos 
para indicar que se puede comenzar a trabajar con un nuevo bloque de datos. 
2.3 Paralelización híbrida del algoritmo integrando Pasaje de Mensaje y 
Memoria Compartida  
Al utilizar una arquitectura híbrida se debe tener en cuenta los diferentes niveles de 
memoria (entre núcleos de una misma hoja) y la red de interconexión (entre núcleos 
de diferentes hojas) para determinar el tamaño TB óptimo. Esto lleva a plantear una 
solución que combina el uso de Pasaje de Mensajes con Memoria Compartida.  
Esta solución híbrida se basa en usar un pipeline de P etapas como el descrito en 
la Sección 2.2.1, empleando en cada una de ellas un pipeline de T fases como el 
detallado en la Sección 2.2.2.   
Al comenzar cada proceso pi (para i  [0, P-1]) genera T-1 hilos para resolver en 
conjunto los bloques de datos correspondientes a los diferentes ciclos. Esto lleva a 
trabajar con PxT  hilos (los P procesos más los T-1 hilos generados por cada uno de 
ellos), por lo que el conjunto de nucleótidos de la primera secuencia (A en la figura 1) 
es distribuido equitativamente entre los PxT  hilos.   
Cuando el proceso pi (para i  [0, P-1]) debe resolver un bloque de datos (de TBpm 
elementos), lo divide en subbloques de TBmc nucleótidos cada uno para ser resuelto 
por el pipeline correspondiente a ese proceso. Para aprovechar las características de la 
arquitectura hay que determinar los valores de TBpm y TBmc que resulten óptimos en 
cada caso.  
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACIÓN                                                 206
3 Trabajo Experimental 
En este trabajo se utiliza el lenguaje C con las librerías OpenMPI y/o Pthreads para el 
manejo de threads y el pasaje de mensajes respectivamente. 
Como se menciono en la introducción, para realizar la experimentación se ha 
utilizado un Blade de 8 hojas, con 2 procesadores quad core Intel Xeón e5405 de 2.0 
GHz en cada una de ellas. Cada hoja tiene 2 Gb de memoria RAM (compartido entre 
ambos procesadores) y cache L2 de 2 x 6Mb entre par de cores. 
Se realizaron dos tipos de pruebas:  
 Usando una hoja del Blade. Probando en este caso los algoritmos paralelos 
puros para determinar los tamaños adecuados de los bloques de datos. 
 Usando la arquitectura completa. Probando en este caso el algoritmo híbrido y 
el que usa sólo pasaje de mensajes para comparar el comportamiento de 
ambos. 
3.1 Pruebas con una hoja del Blade 
Se realizaron pruebas sobre una única hoja del Blade (utilizando los 8 núcleos) para 
analizar el comportamiento de los algoritmos paralelos puros descritos en la Sección 
2.2.1 y 2.2.2.  
Las pruebas realizadas varían en cuanto a la longitud de las secuencias (N = 
65536, 131072, 262144, 524288, 1048576) y el tamaño de los bloques (TB = 8, 16, 
32, 64, 128, 256, 512, 1024, 2048). 
Como resultado de estas pruebas se pudo apreciar que la eficiencia lograda por el 
algoritmo que utiliza Memoria Compartida es levemente superior a la solución que 
emplea Pasaje de Mensajes. Esto lleva a plantear el uso del algoritmo híbrido descrito 
en la Sección 2.3 para aprovechar la arquitectura en forma completa.   
Además, a partir de los resultados obtenidos se pudo determinar como valor ideal 
para TBmc =16 y para TBpm =128. Los detalles de los resultados se encuentran en [19].    
3.2 Pruebas con la arquitectura completa 
Para analizar el comportamiento del algoritmo híbrido se compara con el algoritmo 
que emplea sólo Pasaje de Mensajes, utilizando los 8 núcleos de distinta cantidad de 
hojas (4 u 8). Al igual que en la Sección 3.1, se varía la longitud de las secuencias (N 
= 65536, 131072, 262144, 524288). A continuación se describen las pruebas 
realizadas: 
 PM : se usa el algoritmo que sólo usa pasaje de mensajes variando el tamaño 
de los bloques (TB = 128, 256, 512, 1024, 2048). 
 HI: se usa el algoritmo híbrido con un proceso pi y 3 hilos por cada procesador 
de cada hoja. Es decir que cada pipeline de memoria compartida utiliza una 
procesador quad core completo. En las pruebas se mantiene fijo el valor de 
TBmc y se varía el tamaño de bloque del pipeline de pasaje de mensajes (TBpm = 
128, 256, 512, 1024, 2048).  
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACIÓN                                                 207
4 Resultados 
Para evaluar el comportamiento de los algoritmos desarrollados al escalar el problema 
y/o la arquitectura se analiza la eficiencia (en este caso sobre arquitecturas 
homogéneas dado que todos los núcleos son iguales) [1][2][20]. La Ecuación 9 indica 
la forma de calcular esta métrica donde p es la cantidad total de núcleos usados.    
p
SpeedupEficiencia 
                      (9) 
En la Figura 2 se muestra la eficiencia lograda por los algoritmos PM y HI 
detallados en la Sección 3.2 para aquellos tamaños de bloque más significativos (TBpm 
= 128, 512 y 2048). Por legibilidad, en este gráfico sólo se muestran los resultados 
utilizando las 8 hojas de la arquitectura, dado que al utilizar 4 de ellas se tiene un 
comportamiento similar con un leve incremento de la eficiencia.   
 
Fig. 2. Eficiencia lograda por los algoritmos PM y HI para diferentes valores de TBpm y N, 
usando 64 núcleos (los 8 cores de las 8 hojas). 
En el gráfico se puede observar que ambos algoritmos incrementan la eficiencia al 
aumentar el tamaño del problema (longitud de las secuencias). Por otra parte, estos 
resultados permiten confirmar que para el algoritmo PM  el tamaño de bloque ideal es 
128. En cambio el híbrido (HI) tiende a mejorar la eficiencia al aumentar el tamaño de 
los bloques, de tal manera que al comparar los algoritmos utilizando un tamaño de 
bloque de  2048, HI  logra una mayor eficiencia.   
En la Figura 3 se presenta un resumen de la mejor eficiencia lograda por cada uno 
de los algoritmos (PM y H1) al utilizar 4 y 8 hojas de la arquitectura. En el caso del 
algoritmo PM (PM-4 y PM-8 para 4 y 8 hojas respectivamente) se consigue con el 
tamaño de bloque TB = 128. Para HI se logra al utilizar TBpm = 2048.   
Este gráfico permite identificar que el algoritmo que PM logra una mayor 
eficiencia que los híbridos, disminuyendo la diferencia a medida que crece el 
problema. Por otro lado, como es de esperar en la mayoría de los sistemas paralelos, 
la eficiencia se reduce al incrementar la cantidad de núcleos usados.  
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACIÓN                                                 208
 Fig. 3. Resumen de la mejor eficiencia lograda por cada uno de los algoritmos con 4 y 8 hojas 
de la arquitectura. 
En esta figura también se puede observar que al incrementar la cantidad total de 
núcleos utilizados, aumenta la diferencia entre la eficiencia lograda por PM y HI. En 
sentido inverso, al aumentar el tamaño del problema, se reduce dicha distancia.  
5 Conclusiones y Trabajos Futuros 
En este trabajo se paraleliza el algoritmo de Smith-Waterman para alineación de 
secuencias de ADN por medio de un esquema de pipeline debido a la dependencia de 
datos inherente al problema. Se utiliza como arquitectura de experimentación un 
cluster de multicores (8 hojas con 8 núcleos cada una). 
Dadas las características de la arquitectura se implementó - inicialmente - el 
pipeline con dos modelos de comunicación diferentes: Pasaje de Mensajes (PM) y 
Memoria Compartida (MC). Se comparó la eficiencia de ambos algoritmos al utilizar 
una única hoja de la arquitectura, logrando una leve ventaja de MC respecto a PM. 
Al no poder utilizar el algoritmo MC en toda la arquitectura (por no tener una 
memoria compartida entre las diferentes hojas) se implementó una tercera opción (HI) 
usando como modelo de comunicación un hibrido que combina de Pasaje de Mensaje 
y Memoria Compartida. Esta versión tiene un esquema de pipeline entre procesos que 
se comunican por pasaje de mensaje, y dentro de cada etapa existe un pipeline de 
memoria compartida para resolver cada bloque de datos. 
Se analizó el comportamiento de este algoritmo respecto a PM utilizando 4 y 8 
hojas completas de la arquitectura. Como resultado de este análisis se obtiene que PM 
logra una mayor eficiencia que HI. Esto se debe a que el tamaño de bloque óptimo 
para PM (TB = 128) no puede utilizarse en el pipeline de HI (TBpm>> 128) porque no 
se podrían generar suficientes subbloques para que se ejecute en forma eficiente el 
pipeline interno de memoria compartida con su tamaño de bloque óptimo (TBmc = 16).    
Una línea de I/D es el análisis y optimización de soluciones híbridas, para 
determinadas clases de problemas y especialmente para los que admiten una solución 
paralela compuesta (combinando más de un paradigma). Por otra parte interesa 
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACIÓN                                                 209
investigar la escalabilidad del problema estudiado, asegurando un determinado nivel 
de eficiencia.  
References 
1. Grama A., Gupta A., Karypis G., Kumar V., “An Introduction to Parallel Computing. 
Design and Analysis of Algorithms. 2nd Edition”. Pearson Addison Wesley. 2003. 
2. Jordan H, Alaghband G., “Fundamentals of parallel computing”. Prentice Hall. 2002. 
3. Dongarra J., Foster I., Fox G., Gropp W., Kennedy K., Torczon L., White A., “The 
Sourcebook of Parallel Computing”. Morgan Kauffman Publishers. Elsevier Science. 2003. 
4. Juhasz Z. (Editor), Kacsuk P. (Editor), Kranzlmuller D. (Editor), “Distributed and Parallel 
Systems: Cluster and Grid Computing”. Springer; First Edition. 2004. 
5. Di Stefano M., “Distributed data management for Grid Computing”. John Wiley & Sons 
Inc. 2005. 
6. Miller M., “Cloud Computing: Web-Based applications that change the way you work and 
collaborate online”. QUE Publishing. 2008. 
7. Mc Cool M., “Programming models for scalable multicore programming”. 2007.  
http://www.hpcwire.com/features/17902939.html  
8. Chai L., Gao Q., Panda D. K., “Understanding the impact of multi-core architecture in 
cluster computing: A case study with Intel Dual-Core System”. IEEE International 
Symposium on Cluster Computing and the Grid 2007 (CCGRID 2007), pp. 471-478. 2007.  
9. De Giusti L., Chichizola F., Naiouf M., De Giusti A., Luque E., “Automatic Mapping 
Tasks to Cores - Evaluating AMTHA Algorithm in Multicore Architectures”. IJCSI 
International Journal of Computer Science Issues, Vol. 7, Issue 2, No 1. 2010. 
10. Olszewski M., Ansel J., Amarasinghe S., “Kendo: Efficient Determistic Multithreading in 
Software”. Architectural Support for Programming Languages and Operating Systems 
(ASPLOS „09). 2009. 
11. Bertogna M., Grosclaude E., Naiouf M., De Giusti A., Luque E., “Dynamic on Demand 
Virtual Clusters in Grids”. 3rd Workshop on Virtualization in High-Performance Cluster 
and Grid Computing (VHPC 08). España. 2008. 
12. AMD, “Evolución de la tecnología de múltiple núcleo”. 2009. http://multicore. 
amd.com/es-ES/AMD-Multi-Core/resources/Technology-Evolution. 
13. Burger T. W., “Intel Multi-Core Processors: Quick Reference Guide”. 
http://cachewww.intel.com/cd/00/00/23/19/231912_231912.pdf 
14. Grid Computing and Distributed Systems (GRIDS) Laboratory - Department of Computer 
Science and Software Engineering (University of Melbourne), “Cluster and Grid 
Computing”. 2007. http://www.cs.mu.oz.au/678/. 
15. Attwood T. K., Parry-Smith D. J., “Introducción a la Bioinformática”. Pearson Educación 
S.A. 2002. 
16. Zhang F., Qiao X., Liu Z., “A Parallel Smith-Waterman Algorithm Based on Divide and 
Conquer”. Proceeding of the Fifth International Conference on Algorithms and 
Architecture for Parallel Processing. 2002.  
17. HP, “HP BladeSystem”. http://h18004.www1.hp.com/products/blades/components/cclass.html. 
18. HP, “HP BladeSystem c-Class architecture”. http://h20000.www2.hp.com/bc/docs/support 
/SupportManual/c00810839/c00810839.pdf. 
19. Rucci Enzo, “Modelos de Comunicación en BLADE”. Reporte técnico III-LIDI. 2010. 
20. Leopold C., “Parallel and Distributed Computing. A survey of Models, Paradigms, and 
Approaches”. Wiley, New York. 2001.  
CACIC 2010 - XVI CONGRESO ARGENTINO DE CIENCIAS DE LA COMPUTACIÓN                                                 210
