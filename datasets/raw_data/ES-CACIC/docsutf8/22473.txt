Reconocimiento de d√≠gitos manuscritos usando la transformada wavelet continua en 2 dimensiones y redes neuronales
Ôªø
In this paper we present a preprocessing method for handwritten numerals recognition, based on a two dimensional continuous wavelet transform. We use the wavelet transformed digits to input into a multilayer feed
forward neural network, trained with backpropagation algorithm. Our preliminary results are promising.
Keywords: Neural Networks, Continuous Wavelet Transform
Resumen
En este trabajo presentamos un m√©todo de preprocesamiento para el reconocimiento de d√≠gitos manuscritos,
basado en la aplicaci√≥n de la transformada wavelet continua en dos dimensiones. Los datos preprocesados
son utilizados como entrada de una red neuronal del tipo feed forward multicapa, la cual es entrenada con el
algoritmo de backpropagation. Nuestros resultados preliminares son alentadores.
Palabras claves: Redes Neuronales, Transformada Wavelet Continua
818
1. INTRODUCCI√ìN
El reconocimiento de d√≠gitos manuscritos es un problema que fue tratado ampliamente, con t√©cnicas muy diversas. Tiene varias aplicaciones de inter√©s, siendo una de ellas la lectura autom√°tica de
c√≥digos postales. Entre las metodolog√≠as usadas, se encuentran aquellas basadas en redes neuronales.
El desempe√±o de una red neuronal depende fuertemente de c√≥mo se representa cada d√≠gito, a
trav√©s de caracter√≠sticas extra√≠das en la etapa de preprocesamiento. Se han utilizado diferentes tipos
de preprocesamiento de los datos, antes de ingresarlos a una red neuronal. En [9] y [10] se utiliz√≥ el
an√°lisis de componentes principales, con el objetivo de reducir la dimensionalidad de los datos. En
[11] y [3] se utilizaron m√°scaras de Kirsch, para extraer caracter√≠sticas direccionales.
La transformada wavelet es una herramienta id√≥nea para reconocimiento de bordes y texturas
en im√°genes. Sus propiedades la convierte en una herramienta apta para el preprocesamiento de los
datos. En [2] se aplica una transformada wavelet di√°dica ortogonal de una dimensi√≥n, sobre los contornos representados con 2 vectores x e y, extra√≠dos previamente de los d√≠gitos. En [1] se utiliza
una transformada multiwavelet, de una dimensi√≥n, que tambi√©n se aplica sobre los contornos de los
d√≠gitos.
Si a la transformada wavelet continua para datos bidimensionales, se le agrega una rotaci√≥n con
√°ngulo determinado, se convierte en una transformada anisotr√≥pica que depende de 4 par√°metros.
Entonces se tienen 2 representaciones posibles de una imagen transformada: la representaci√≥n posicional, y la representaci√≥n en escala‚Äì√°ngulo. En [7] y [8] se utilizan ambas representaciones (en
distintos pasos) para el reconocimiento de patrones en una imagen. En este trabajo utilizaremos una
transformada wavelet continua con la representaci√≥n posicional, para valores de escala y de √°ngulo
fijos, como m√©todo de preprocesamiento sobre im√°genes de d√≠gitos manuscritos.
Las im√°genes de d√≠gitos fueron obtenidas de la base de datos de n√∫meros manuscritos de la universidad de Concordia (Canad√°). Esta base de datos est√° compuesta por 6000 d√≠gitos escritos a mano,
provistos por el Servicio Postal de los Estados Unidos, y extra√≠dos de c√≥digos postales manuscritos
en los sobres de la correspondencia. De la totalidad de los patrones, 4000 fueron utilizados para el
entrenamiento (400 patrones por d√≠gito) los cuales forman el llamado conjunto de entrenamiento, y
2000 para el testeo (200 patrones por d√≠gito) que forman el conjunto de testeo. En las figuas 1 y 2
se muestran algunos d√≠gitos elegidos al azar, pertenecientes al conjunto de entrenamiento y de testeo,
en ellas se puede observar la caracter√≠stica de ‚Äúescritura irrestricta‚Äù de los mismos. Cabe mencionar
que ambos conjuntos incluyen ejemplos que son ambiguos, inclasificables y a√∫n mal clasificados. La
base de datos presenta im√°genes de patrones de diferentes tama√±os, conformadas por ceros y unos.
Durante la etapa de preprocesamiento √©stos son normalizados a un tama√±o de 16x16 pixeles, luego del
proceso de normalizaci√≥n se aplica la transformada wavelet continua en dos dimensiones. Los datos
preprocesados son la entrada de un sistema de reconocimiento implementado con una red neuronal
del tipo feed forward multicapa la cual es entrenada con el algoritmo de backpropagation.
Este trabajo est√° organizado de la siguiente manera: En la secci√≥n 2 se explicar√°n las nociones
b√°sicas de la transformada wavelet continua en dos dimensiones, en la secci√≥n 3 se explicar√° la arquitectura del sistema de reconocimiento, en la secci√≥n 4 se mostrar√°n los resultados obtenidos y en
la secci√≥n 5 se dar√°n las conclusiones.
819
Figura 1: Muestras pertenecientes al conjunto de entrenamiento
Figura 2: Muestras pertenecientes al conjunto de testeo
820
2. TRANSFORMADA WAVELET CONTINUA EN 2 DIMENSIONES
La transformada wavelet ha dado excelentes resultados en distintas aplicaciones de procesamiento
de im√°genes. Su excelente localizaci√≥n espacial y su buena localizaci√≥n frecuencial hacen de ella una
herramienta apta para el preprocesamiento de los d√≠gitos. La transformada wavelet di√°dica discreta,
m√°s frecuentemente utilizada, incluye submuestreos y no es invariante a traslaciones. Nuestro objetivo
es conseguir un preprocesamiento que arroje los mismos valores para un d√≠gito o para una copia del
mismo que ha sido trasladada en uno o varios p√≠xeles. Es por eso que elegimos una transformada
wavelet continua, que es invariante frente a traslaciones.
Sea s una funci√≥n de dos variables a valores reales, de cuadrado integrable, es decir, s ‚àà L2(<2).
Definimos la transformada wavelet de s ([7] y [8]) con respecto a una funci√≥n wavelet œà : <2 ‚Üí <
de la siguiente forma:
S(b, a, Œ∏) = a‚àí1
‚à´
<2
œà(a‚àí1 r‚àíŒ∏(b‚àí x)) s(x) dx, (1)
donde b = (bx, by) ‚àà <2 es un vector de traslaci√≥n, a ‚àà < es la escala (a > 0), Œ∏ es un √°ngulo
y rŒ∏(x) es el operador de rotaci√≥n con √°ngulo Œ∏, que act√∫a sobre un vector x = (x1, x2) ‚àà <2 de la
manera siguiente:
rŒ∏(x) = (x1 cos Œ∏ ‚àí x2 sin Œ∏, x1 sin Œ∏ + x2 cos Œ∏), 0 ‚â§ Œ∏ ‚â§ 2pi. (2)
En este marco te√≥rico no hay multiresoluci√≥n, a diferencia de la transformada wavelet discreta. Los
requerimientos que se imponen a la funci√≥n œà, para asegurar la recuperaci√≥n de la funci√≥n a partir de
su transformada, son:
œà(x) debe ser de cuadrado integrable: œà ‚àà L2(<2)
œà debe ser admisible, es decir, la siguiente integral debe ser finita:
cœà =
‚à´
<2
|œàÃÇ(œâ)|2
dœâ
|œâ|
<‚àû, (3)
donde œàÃÇ(œâ) es la transformada de Fourier de œà(x). Esa condici√≥n implica que
œàÃÇ(0) = 0, (4)
lo que es equivalente a la condici√≥n de media cero
‚à´ +‚àû
‚àí‚àû
‚à´ +‚àû
‚àí‚àû
œà(x)dx = 0. (5)
Como podemos ver, la funci√≥n (1) tiene cuatro variables bx, by, a, Œ∏: esto origina un problema en
la visualizaci√≥n del resultado y en el c√≥mputo de la misma. Para obtener una herramienta manejable,
se fijan algunas de las variables y se obtiene as√≠ una funci√≥n de una o dos variables. De esto √∫ltimo
surgen dos representaciones:
1. Representaci√≥n posicional
SaŒ∏(bx, by) = S(bx, by, a, Œ∏) a y Œ∏ fijos (6)
821
Observar que es una funci√≥n de dos variables, es decir, tanto a como Œ∏ est√°n fijos por lo tanto
el resultado es una funci√≥n en bx y by. Con esta representaci√≥n se analiza a la se√±al con una
wavelet rotada en un √°ngulo Œ∏ y escalada en un factor a. Dicha wavelet se va desplazando en los
ejes x e y acorde al valor de las variables bx y by. Dicho de otra forma cada valor de SaŒ∏(bx, by)
ser√° el c√°lculo de (1) en bx, by, a y Œ∏.
2. Representaci√≥n Escala - √Ångulo
Sbxby(a, Œ∏) = S(bx, by, a, Œ∏) bx y by fijos (7)
Observar que en este caso tambi√©n tenemos una funci√≥n de dos variables s√≥lo que ahora est√°n
fijos bx y by quedando la funci√≥n en t√©rminos de a y Œ∏. En contraste al caso anterior, en esta
representaci√≥n se analiza a la se√±al con una wavelet situada en una posici√≥n fija (bx y by) pero
la misma va sufriendo cambios en la rotaci√≥n y en la escala acorde al valor de las variables Œ∏ y
a respectivamente.
En nuestro caso las se√±ales a analizar ser√°n im√°genes de d√≠gitos manuscritos binarias de tama√±o
16x16 pixeles. El m√©todo de preprocesamiento que hemos elegido es la aplicaci√≥n de (6) a dichas
im√°genes utilizando una wavelet discretizada que adem√°s est√° escalada en un factor a y rotada en
un √°ngulo Œ∏. Observar que el resultado es otra imagen bidimensional con valores reales, es decir, no
necesariamente ceros y unos. Como √∫ltimo paso del m√©todo de preprocesamiento se aplica un umbral
a la imagen resultado para obtener valores binarios. Como hemos mencionado anteriormente para el
c√°lculo de (6) es necesario saber calcular (1), y para esto se realiza el producto, componente a componente, entre œà(a‚àí1 r‚àíŒ∏(b‚àí x)) y s(x) y luego se suman para estimar la integral. Adem√°s, para poder
implementar (6) es necesario elegir una funci√≥n wavelet, una escala, un √°ngulo y valores discretos
para bx y by. En nuestro caso la funci√≥n wavelet utilizada es la llamada Mexican Hat direccional, cuya
f√≥rmula es la siguiente:
œàmh(x, y) = (2‚àí (x
2 +
y2

))e‚àí
(x2+ y
2
 )
2 (8)
Para bx se tomaron 16 valores en el intervalo [‚àí32, 32], lo mismo para by, esto nos da una imagen
cuya dimensi√≥n es 16x16. La escala elegida fue de 0.8 y el √°ngulo de 135o (en el sentido antihorario)
ya que esa es la orientaci√≥n que se observ√≥ en la mayor√≠a de los d√≠gitos. En las figuras 3 y 5 se puede
ver el dibujo de la wavelet utilizada, junto con sus curvas de nivel, para a = 1, Œ∏ = 0 y  = 1. Para
obtener una wavelet anisotr√≥pica se da un valor distinto de 1 a . En las figuras 4 y 6 se muestra el
dibujo, junto con sus curvas de nivel, de la wavelet rotada a 135o (en el sentido antihorario), escalada
en un factor de 0.8, para  = 5. Por otro lado, en las figuras 7-14 se muestran ejemplos de la aplicaci√≥n
del m√©todo de preprocesamiento a varias im√°genes de d√≠gitos manuscritos.
822
Figura 3: Mexican Hat con a = 1, Œ∏ = 0o y  = 1.
La misma esta evaluada en el intervalo [‚àí5, 5] con
128 muestras
Figura 4: Mexican Hat con a = 0.8, Œ∏ = 135o
y  = 5. La misma est√° evaluada en el intervalo
[‚àí5, 5] con 128 muestras
Figura 5: Curvas de nivel deMexican Hat con a =
1, Œ∏ = 0o y  = 1
Figura 6: Curvas de nivel deMexican Hat con a =
0.8, Œ∏ = 135o y  = 5
823
Figura 7: Un d√≠gito 0 sin procesar
Figura 8: Un d√≠gito 2 sin procesar
Figura 9: Un d√≠gito 5 sin procesar
Figura 10: Un d√≠gito 8 sin procesar
Figura 11: El d√≠gito 0 preprocesado
Figura 12: El d√≠gito 2 preprocesado
Figura 13: El d√≠gito 5 preprocesado
Figura 14: El d√≠gito 8 preprocesado
824
3. SISTEMA DE RECONOCIMIENTO
El sistema de reconocimiento ha sido implementado utilizando una red feedforward multicapa.
Un ejemplo de arquitectura de este tipo de redes puede observarse en la figura 15.
La red implementada presenta una capa de entrada de 256 neuronas, este n√∫mero se corresponde
con la dimensi√≥n de las im√°genes preprocesadas (16x16). Luego presenta una capa oculta de 160
neuronas. Como no existe un m√©todo exacto para establecer la cantidad de neuronas en la capa oculta,
la misma tiene que ser determinada en base a pruebas, en nuestro caso el mejor resultado fue obtenido
con una cantidad de 160 para una capa oculta. Esta arquitectura fue seleccionada entre varias, a trav√©s
de la utilizaci√≥n de un conjunto de validaci√≥n en la etapa de entrenamiento. Se han realizado pruebas
con redes de 1 y 2 capas ocultas, y distintas cantidades de unidades para cada capa. Por √∫ltimo est√° la
capa de salida con 10 neuronas, una por cada d√≠gito a reconocer. Cada unidad de la red est√° totalmente
conectada con las unidades (neuronas) de la capa siguiente, a trav√©s de los pesos sin√°pticos w. Por
cada patr√≥n ingresado se calculan las salidas de cada unidad hasta obtener la salida real de la red.
Definimos para una iteraci√≥n o tiempo t:
wij peso que conecta a la unidad i de la capam con la unidad j de la capam‚àí 1
hi =
‚àë
j‚ààJ wijVj entrada neta a la unidad i, J incluye a todas las neuronas de la capa anterior
a la de la unidad i
Vi = g(hi) salida de la unidad i, donde g es la funci√≥n de activaci√≥n asociada a dicha unidad.
Si Vi est√° en la capa de entrada de la red, entonces toma los valores del patr√≥n ingresado.
œÇi salida esperada en la unidad i, forma parte del r√≥tulo de cada patr√≥n
Oi salida real de la red para la unidad i
E(t) = 12
‚àë
i‚ààC(œÇi ‚àí Oi)
2 donde C incluye a todas las neuronas de la capa de salida de la red,
es el error en la iteraci√≥n t
Definimos la funci√≥n de costo de la siguiente manera
E(w) = 1N
‚àë
¬µ‚ààP,i‚ààC(œÇ
¬µ
i ‚àí O
¬µ
i )
2 donde C incluye a todas las neuronas de la capa de salida de
la red y P incluye a todos los patrones de entrenamiento.
La red fue entrenada con el algoritmo de backpropagation estoc√°stico con momentum ([5] y [6]). El
objetivo del algoritmo es obtener un conjunto de pesos, asociados al conexionado, que minimice la
funci√≥n costo. Por cada patr√≥n de entrenamiento ingresado, se calcula la salida de la red y luego el
error cometido por √©sta. Este error se propaga hacia atr√°s, capa por capa, lo que permite calcular las
derivadas parciales de la funci√≥n de error con respecto a los pesos (estimaci√≥n del vector gradiente).
De esta manera, el ajuste de los pesos para el patr√≥n ingresado en la iteraci√≥n t se calcula como,
wij(t+ 1) = wij(t) + ‚àÜwij(t)
‚àÜwij(t) = ‚àíŒ∑
‚àÇE(t)
‚àÇwij(t)
+ Œ±‚àÜwij(t‚àí 1)
Donde Œ± es el par√°metro de momentum o inercia (el mismo hace que el cambio realizado en los
pesos sea en la direcci√≥n de descenso promedio, acelerando la convergencia) y Œ∑ es el coeficiente
de velocidad de aprendizaje, en nuestro caso esos valores fueron de 0.9 y 0.01 respectivamente. El
aprendizaje de la red se desarrolla durante una cierta cantidad de √©pocas (en cada √©poca se ingresa
825
todo el conjunto de entrenamiento), que en nuestro caso fue de 3500, hasta lograr minimizar la funci√≥n
de costo. En la capa oculta y en la de salida la funci√≥n de activaci√≥n utilizada fue la llamada Log√≠stica
Sigmoidea definida por
g(h) =
1
1 + e‚àíh
(9)
Figura 15: Ejemplo de arquitectura de red feedforward multicapa
4. RESULTADOS
En esta secci√≥n se muestran los resultados obtenidos, luego de clasificar el conjunto de patrones
preprocesados utilizando la red neuronal descripta en la secci√≥n anterior. Dichos resultados se presentan en las tablas 1 y 2 con el siguiente formato: en la primer columna se especifica el d√≠gito, en
la segunda la cantidad de muestras de ese d√≠gito que fueron mal clasificadas, en la tercer columna
la cantidad de muestras reconocidas para ese d√≠gito y en la √∫ltima columna se muestra el porcentaje
correspondiente a la cantidad de muestras reconocidas para ese d√≠gito. En la √∫ltima fila se muestran
los porcentajes totales por d√≠gito y sobre todo el conjunto de patrones.
El porcentaje de patrones correctamente clasificados fue de 99.17% y 90.20% para el conjunto
de entrenamiento y testeo respectivamente. Este resultado es alentador, ya que mejora el porcentaje obtenido por la misma arquitectura de red entrenada con el mismo conjunto de patrones pero
sin preprocesar (87.1% de patrones de testeo reconocidos). Asimismo, el resultado obtenido para el
conjunto de testeo preprocesado es comparable al presentado por otros autores [1] [2] que utilizan
t√©cnicas basadas en la transformada wavelet para extraer caracter√≠sticas de los patrones de entrada, y
luego entrenan una red feedforward multicapa como clasificador.
826
D√≠gito Mal Clasificados Bien Clasificados % Reconocidos
0 5/400 395/400 98,75
1 1/400 399/400 99,75
2 4/400 396/400 99,00
3 4/400 396/400 99,00
4 4/400 396/400 99,00
5 1/400 399/400 99,75
6 4/400 396/400 99,00
7 6/400 394/400 98,50
8 2/400 398/400 99,50
9 2/400 398/400 99,50
TOTAL 33/4000 3967/4000 99,17
Cuadro 1: Resultados obtenidos sobre el conjunto de entrenamiento.
D√≠gito Mal Clasificados Bien Clasificados % Reconocidos
0 20/200 180/200 90,00
1 6/200 194/200 97,00
2 18/200 182/200 91,00
3 32/200 168/200 84,00
4 7/200 193/200 96,50
5 30/200 170/200 85,00
6 17/200 183/200 91,50
7 15/200 185/200 92,50
8 36/200 164/200 82,00
9 15/200 185/200 92,50
TOTAL 196/2000 1804/2000 90,20
Cuadro 2: Resultados obtenidos sobre el conjunto de testeo.
5. CONCLUSIONES
Hemos presentado un m√©todo de preprocesamiento basado en la transformada wavelet continua en
dos dimensiones que nos ha permitido entrenar una red neuronal feedforward multicapa como clasificador de d√≠gitos manuscritos, utilizando la base de datos de la Universidad de Concordia, Canad√°. Los
resultados obtenidos son comparables a los de otros autores [1] [2], que utilizan t√©cnicas de preprocesamiento basadas en la transformada wavelet y tambi√©n entrenan una red neuronal feed forward como
clasificador. Los trabajos citados utilizan wavelets o multiwavelets de una dimensi√≥n, y requieren la
identificaci√≥n del contorno del d√≠gito como paso previo, lo cual no es necesario en nuestro caso.
Tambi√©n hemos logrado un representaci√≥n de los d√≠gitos que es invariante frente a traslaciones,
con resultados alentadores. Como trabajo futuro pensamos extraer caracter√≠sticas de los d√≠gitos que
tambi√©n sean invariantes frente a cambios de escala y de orientaci√≥n, utilizando propiedades de la
misma transformada, con la idea de mejorar el desempe√±o de nuesto clasificador.
827
