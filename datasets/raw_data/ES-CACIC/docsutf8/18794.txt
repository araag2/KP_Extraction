Control vía Internet de un robot ubicado en un sitio remoto aplicando una interfase cerebro máquina
﻿ En este artículo se describe el trabajo de investigación que en la actualidad 
se está desarrollando dentro del área de la comunicación de humanos a robots, sobre la 
base de bioseñales cerebrales y puntualmente en sitios remotos. Para esta investigación 
se aplican tecnologías, interfases disponibles y protocolos de comunicación estándar 
que facilitan la lectura de las señales del cerebro del usuario, su asociación a comandos 
explícitos y la comunicación entre los sitios remotos.  
 
Keywords: Robots, Brain Machine Interface, Bio-Electrical Signal, Human 
Machine Interfaces. 
1 Introducción  
  En este artículo se extiende nuestros trabjos realizados en materia de control de 
robots aplicando bioseñales [1] [2],[3], incorporado en esta oportunidad el control a 
través de un robot ubicado en un sitio remoto, con la aplicación de interfaces cerebromáquina(BMI).  
  Todo organismo viviente genera, desde origen, señales biológicas, las cuales 
proporcionan un potencial eléctrico que puede ser capturado a través de distintas 
herramientas usadas en medicina: el electromiograma, el electrooculograma, y el 
electroencefalograma entre otros. Los mismos y respectivamente capturan señales que 
son originados por los músculos, ojos y cerebro. 
 
  La aplicación de bioseñales para el control de sistemas, robots, aplicaciones, juegos 
y otros dispositivos, presenta un enfoque novedoso al abrir las puertas para la 
interacción entre humanos y computadoras en una nueva dimensión, donde se 
explotan específicamente estos biopotenciales eléctricos registrados en el usuario. 
CACIC 2011 - XVII CONGRESO  ARGENTINO DE CIENCIAS DE LA COMPUTACIÓN 1373
 
  La idea de mover robots o facilitar la aplicación de dispositivos para discapacitados 
sin aplicar controles manuales y alcanzar el control sólo a través de la actividad 
mental, fascinó a los investigadores. En este orden, se presentaron diversos trabajos: 
los primeros, recurrieron a implantar electrodos intracraneales en la corteza motora de 
primates [4], [5]. Los trabajos no invasivos para humanos recurrieron a señales de 
Electroencefalogramas (EEG), aplicados a ejercicios de comandos mentales, como 
mover el cursor de una computadora [6], [7] basados en el empleo de Brain-Machine 
Interface (BMI). Millan et. al. [8] demuestra como dos personas pueden mover un 
robot usando un simple electroencefalograma, sobre la base de reconocer tres estados 
mentales, los que se asocian a comandos del robot. Los trabajos de Saulnier et. al. [9] 
se enfocaron en controlar la velocidad de un robot y extender su aplicación para 
inferir el nivel de stress del usuario, y a partir de éste influir en el comportamiento 
social de robots domésticos, en este caso una aspiradora robot. 
 
 En la anterior investigación se trabajó en la ejecución de un patrón de navegación por 
parte de un robot.[1]. En el mismo presentamos una mejora en los tiempos de control 
mental ejecutando el mismo patrón de navegación la que hemos denominado control 
mental con auto foco. 
 
 
 Se utilizó como brain-machine interface (BMI) el Neural impulse actuator (NIA) 
[10], Éste se compone de una unidad de control (figura 1) y una banda con tres 
sensores en forma de diamantes que se coloca sobre la frente del usuario (figura 2), 
fabricados con nanotecnología de fibra de carbono. La unidad de control se conecta a 
la computadora y alimenta a través de una conexión USB 2.0, el software que 
acompaña a NIA permite la calibración, entrenamiento, definición de profiles de 
control que se integran a las aplicaciones. 
 
    
             Fig. 1. BMI-NIA–               Fig. 2. Banda – NIA 
 
  La preparación del profile para controlar al robot requiere pensar en la intuición del 
comportamiento del robot que se desea controlar. Las capacidades de BMI son 
diferentes a la de un teclado, por lo que las estrategias de control se deben ajustar de 
manera consecuente para aprovechar los tiempos de reacción más reducidos y de 
mayor nivel de inmersión en el comportamiento del robot. 
 
 El BMI-NIA cuenta con una aplicación que tiene un panel de control y configuración 
para permitir la auto calibración de las bioseñales registradas (Fig 3.) a través de sus 
componentes: electro-oculograma que detecta la mirada, (actividad del movimiento 
CACIC 2011 - XVII CONGRESO  ARGENTINO DE CIENCIAS DE LA COMPUTACIÓN 1374
ocular), el electro-encefalograma que registra las ondas cerebrales alfa (9-13 Hz, que 
se presentan en situaciones del tipo: despierto, estado de alerta normal, consciente) y 
las ondas beta (14-30 Hz que se presentan en situaciones del tipo: relajado, calmo, 
lucido, no está pensando), y finalmente a través del electro-miograma, que detecta la 
amplitud muscular. Además la aplicación cuenta con herramientas para la creación y 
edición de profiles que permiten la asociación de bioseñales con comandos de teclado. 
 
 
Fig. 3. Panel de Bioseñales 
 
  Para la creación de profiles en el BMI de NIA, se considera en primer lugar eventos 
de cambio o switch, éstos están pensados para la selección de acciones que requieren 
una sincronización precisa para eventos de cambio, como por ejemplo saltar en un 
juego de acción, girar a la derecha para un robot móvil o paso a la derecha para un 
robot bípedo. Los eventos de cambio además se pueden asignar a una única 
transferencia de datos, vinculados sólo a un click o una tecla o una función de 
retención. En este último caso la acción vinculada a la tecla continuará ejecutándose 
todo el tiempo que el evento de cambio permanezca activo. El BMI-NIA nos permite 
vincular el profile hasta con tres eventos de cambio diferentes. El BMI-NIA considera 
como segundo paso para la creación de un profile, la creación de hasta un máximo de 
cuatro joysticks (horizontales, verticales o paralelos). Cada joystick vertical permite la 
definición de hasta cuatro zonas diferentes, por cada zona se pueden declarar hasta 
tres eventos de cambio, además cada zona esta también asociada a un modo 
(activar/desactivar, retener la tecla durante un tiempo, un solo clic, retrasar la 
activación por un tiempo definido, repetir con un intervalo definido, repetir y retener, 
etc).Cada una de las bioseñales pueden utilizarse en un joysticks o más en paralelo 
que utilicen la misma bioseñal de entrada, el resultado es el mismo que pulsar de 
forma simultánea dos o tres teclas en un teclado. Al joystick horizontal se le puede 
asignar también cuatro zonas, dos a la izquierda y dos a la derecha, este se aplica con 
la bioseñal proveniente del electrooculograma denominada glance (mirada), la cual 
CACIC 2011 - XVII CONGRESO  ARGENTINO DE CIENCIAS DE LA COMPUTACIÓN 1375
sigue los movimientos laterales del ojo y se podría utilizar para que el robot gire a la 
derecha o al izquierda. Al igual que el joystick vertical se definen hasta tres eventos 
de cambios y modos para cada zona. Para cada joystick se puede ajustar en forma 
independiente el nível, amplificación, y suavizado de las bioseñales.  
 
  En este orden también se desarrollaron las primeras experiencias con el BMI-Emotiv 
[11], este se caracteriza por estar constituido de unos brazos de plástico maleable que 
garantizan la correcta ubicación de los sensores sobre el cuero cabelludo y possen una 
almohadilla humedecida en una solución salina en cada contacto para favorecer la 
conducción. 
 
Además  de los electrodos, el casco  Emotiv  Epoc (Fig 4) contiene  un  giróscopo 
compuesto por dos acelerómetros que facilitan información sobre los movimientos 
que el usuario realiza con su cabeza y un transmisor inalámbrico mediante el cual 
 mantiene un enlace con el receptor USB conectado a la computadora, todo esto 
alimentado por una batería recargable también vía USB. 
 
Tanto  desde  la  API  como   desde  el   software (Fig 5)   incluido  en  el  kit  de 
 desarrollo  se  puede monitorear  el nivel de contacto de los electrodos, el 
movimiento del giróscopo, la intensidad de la señal inalámbrica y la carga de la 
batería. 
 
  Durante las primeras prácticas se pudo comprobar el correcto funcionamiento del 
equipamiento según lo especificado en el manual de usuario. Además se pudo 
constatar que el casco registra tanto la parte cognitiva como la expresiva. 
 
 
 
 
Fig.4 . Interfase Emotiv Epoc 
 
CACIC 2011 - XVII CONGRESO  ARGENTINO DE CIENCIAS DE LA COMPUTACIÓN 1376
 
 
Fig.5 . Software de configuración del Emotiv Epoc 
2 Problema  
El objetivo fue conseguir una solución de ingeniería que nos permitiera alcanzar 
una integración primaria de un BMI para realizar el control de un  robot ubicado en 
un sitio remoto. Considerando que el robot en el sitio remoto  pueda ser operado por 
un usuario que no requiera tener experiencia previa con técnicas de meditación o 
entrenamiento específico de concentración mental y especialmente que la 
comunicación sea sobre protocolos de ya existentes y que puedan ser implementados 
en múltiples plataformas. 
3 Solución propuesta 
Para mantener la premisa de que el control mental pueda ser usado por un usuario 
sin experiencia en controles BMI se plantearon dos comandos: uno que permitiese 
controlar la selección de comportamientos y otro, la ejecución de los mismos sobre la 
base de sus propios controladores (por ejemplo moverse hacia adelante o girar a la 
derecha).  
 
Se estableció una arquitectura experimental que contempla dos vías de 
comunicación, la primera vía la denominamos vía de comunicación de alto nivel ó 
“usuario-computadora”. Esta vía, al igual que en las investigaciones previas se 
instrumentó con un BMI de bajo costo OCZ NIA [10], de empleo experimental en 
video juegos, que permitió la asociación de patrones de señales mentales con el 
teclado de la computadora. Sobre estas facilidades determinamos un perfil simple 
CACIC 2011 - XVII CONGRESO  ARGENTINO DE CIENCIAS DE LA COMPUTACIÓN 1377
para el manejo del robot, que asocia y caracteriza en primer lugar, el control para la 
ejecución del comando mental sobre la base de la detección de señales musculares, en 
nuestro caso a través de un leve movimiento de los párpados. En segundo lugar la 
selección de los comandos de alto nivel del robot, en este caso se trabajó sobre la base 
de las ondas cerebrales Alfa. Este tipo de bioseñales no aseguraron un adecuado 
control al usuario en los desplazamientos, a través de un panel ú de selección de 
comandos del framework de control del robot. Frente a esta razón se implementó en el 
framework la opción de aplicación de auto foco .[1],. para el modo control mental, a 
fin de mejorar el gobierno del usuario en el proceso de selección de comandos. 
 
  La segunda vía de comunicación, denominada vía de comunicación de bajo nivel 
“computadora–robot”. Se efectuó a través de comunicación en Bluetooth la cual es 
nativa en el kit del robot Lego NXT y para la cual hay una gran cantidad de librerías 
disponibles para su comunicación con una computadora. 
 
 Por último, ambas vías de comunicación fueron implementadas mediante un servicio 
web el cual recibe los comandos del cliente remoto y los transfiere vía HTTP, 
utilizando el protocolo de comunicación SOAP,conectando a  una capa que controla 
la conexión bluetooth del Lego NXT [12], y sus primitivas de movimiento. Esta capa 
fue implementada por medio de las librerías AForce [13], que facilitan el dominio de 
un robot NXT con el Framework .NET de Microsoft. 
 
  Se presentan muestra en la Fig 6 la arquitectura conceptual implementada para  
alcanzar la integración entre el BMI del usuario que efectúan el control de un  robot 
ubicado en un sitio remoto 
 
 
 
 
 
Fig.6. Integración de BMI-NIA y Robot ubicado en un sitio remoto  
CACIC 2011 - XVII CONGRESO  ARGENTINO DE CIENCIAS DE LA COMPUTACIÓN 1378
  El siguiente paso de la investigación fue desarrollar un sistema de control remoto de 
la interface que permita manejar un robot en un sitio distante por medio de una 
conexión a internet. 
 
  Para llegar a este cometido se desarrolló una arquitectura por medio de un web 
service el cual recibe los comandos de las primitivas de conexión y de movimiento y 
los envía a un robot NXT por medio de una interface bluetooth que corre desde una 
computadora remota con bluetooth. Tomando como base  para el desarrollo del 
framework de control, la interface diseñada anteriormente [1] [2],[3], para las pruebas 
con BMI-NIA  
 
  Se presenta la interfase gráfica del cliente (Fig 7) con los controles para las 
primitivas de movimiento, así como también los parámetros de configuración del 
puerto de comunicación del NXT en el servidor. 
 
 
 
Fig. 7. Interfase cliente 
 
En el servidor remoto se encuentra el web service, el cual recibe los comandos del 
cliente y los traduce a las instrucciones para el NXT. Se eligió implementar un web 
service para tener una conexión segura, con un protocolo conocido de 
comunicaciones y porque permite que se desarrolle el cliente en varios lenguajes de 
programación y para múltiples plataformas. Para la prueba del web service se 
incorporó un frontend (Fig 8) que permite ver las tramas recibidas, ejecutadas por el 
NXT  y los datos de conexión. 
 
  La visualización de los movimientos del robot en el sitio remoto se efectuaron 
inicialmente mediante un cliente de video llamadas estándar. 
 
  La razón por la que no se implementó la transmisión de video en el framework de 
comunicación, es debido a que de esta manera se pueden utilizar diversos dispositivos 
CACIC 2011 - XVII CONGRESO  ARGENTINO DE CIENCIAS DE LA COMPUTACIÓN 1379
para transmitir el video, como por ejemplo: webcams, teléfonos inteligentes, tablets, 
etc.  
 
 
 
Fig. 8. Front-end de control del Web Service 
 
 
Finalmente se realizaron diversas pruebas registradas en video (control remoto 
manual y control remoto con BMI integrado) [14]. 
 
 
4 Conclusiones y Futuras Lineas de Investigaciòn  
 
  Debido a las experimentaciones anteriores con el BMI de NIA no se han tenido 
problemas con la adaptación con este nuevo proyecto, al igual que en nuestros 
trabajos anteriores, el NIA requiere de una calibración cada vez que se utiliza, y si 
bien se encontró que la calibración no ha sido siempre necesaria, lo mejor es hacerlo 
antes de cada período de sesiones de pruebas y siempre con el perfil de cada usuario. 
 
  Un factor que se agregó en este nuevo desarrollo es el retardo en las acciones del 
robot con respecto a la ejecución por parte del usuario. El tiempo que tarda en 
transmitirse el comando desde el cliente hasta el sitio remoto, sumado a la transmisión 
de video genera en el usuario una cierta incertidumbre de que el sistema no esté 
funcionando de manera correcta, el usuario se tensiona y afecta los comandos que 
genera el BMI. Por lo tanto, se requiere que el usuario este consciente de esta 
situación e intente relajarse más de lo normal para evitar estos episodios. 
 
 La conexión con el servicio web no generó ningún tipo de inconveniente, una vez 
emparejado el robot móvil con la computadora mediante bluetooth el funcionamiento 
fue óptimo, solamente se generan inconvenientes cuando se envían comandos muy 
seguidos. Antes de realizar las pruebas con el BMI incorporado al framework se 
testeó la comunicación con el servicio web por medio de una red local y luego por 
CACIC 2011 - XVII CONGRESO  ARGENTINO DE CIENCIAS DE LA COMPUTACIÓN 1380
medio de internet. En ambos casos los tiempos de ejecución y respuesta fueron muy 
similares.  
 
 Las pruebas actuales con un servicio dedicado de videoconferencia resultaron 
satisfactorias, la imagen no tenía retardos, asegurando una respuesta adecuada en el 
ciclo observación-control del robot en el sitio remoto, a través de las bioseñales del 
cliente.  
 
 Actualmente se encuentra en estudio y migración del BMI de NIA al BMI de 
EMOTIV con el que se implementaran mayores prestaciones de control extendidas 
tanto a robots como dispositivos remotos de control infrarrojo (Aire Acondicionado, 
TV, entre otros dispositivos., que se integraran al framework de control facilitando a 
personas discapacitadas el control, al igual que la interacción y control  de estos 
usuariso con dispositivos ubicados en sitio remotos  
 
 En la actualidad esta línea de investigación está vinculada al PID de FICCTE–UM, la 
integran cuatro investigadores y cinco estudiantes de tesis de grado, orientadas al 
control remoto de robots por Bioseñales vía Internet, agregando futuras  líneas de 
investigación de aprendizaje por refuerzo de robots a través de bioseñales.  
 
 Este proyecto se encuentra financiado por la Facultad de Informática, Ciencias de la 
Comunicación y Técnicas Especiales de la Universidad de Morón. A su vez propicia 
la formación de recursos, con la participación de estudiantes de grado para la 
continuación de las líneas de investigación relacionadas.  
7
