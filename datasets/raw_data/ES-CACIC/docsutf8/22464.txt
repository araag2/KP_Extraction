Interacciones sobre grafos mediante dispositivos no convencionales
﻿
Interactions in Visualization become an essential need because they enable the user to adapt the
visual representation to their own needs, allowing him/her to explore the space of underlying
information. Using non-conventional devices to do this reveals a new field of development opening
a wider fan of possibilities. Nevertheless, it does not exist an agreed base theory from which to
describe the processes involved in the data transformation of the visualization pipeline. From the
interactions point of view, a classification does not exist that allows to present them from a unified
optics.
The objective of this work is to contribute to develop a Graph Visualization base theory in order to
classify and define the most representative interactions of the area and consequently to lay the
foundations to reach a systematic development of interactive visualization tools using non
conventional devices. Then we propose a taxonomy of interactions over graphs, each category is put
in the reference model context and the most relevant aspects to design visualization using non
conventional devices are analyzed.
Keywords: Interactions, Graph Visualization, Information Visualization, HCI, Devices
Resumen
Las interacciones en Visualización se constituyen en una necesidad esencial al permitir al usuario
adaptar la representación visual a sus necesidades y ser el medio por el cual se explora el espacio de
información subyacente. La posibilidad de hacerlo mediante dispositivos no convencionales abre un
nuevo campo de desarrollo al ofrecer un abanico más amplio de posibilidades. Sin embargo aún no
existe una teoría de base consensuada a partir de la cual describir los procesos involucrados en la
transformación que sufren los datos a lo largo del pipeline de visualización. Desde el punto de vista
de las interacciones tampoco se cuenta con una clasificación que permita plantearlas desde una
óptica unificada.
El objetivo de este trabajo es contribuir al desarrollo de una teoría de base en Visualización de
Grafos en el marco de la cual clasificar y definir las interacciones más representativas del área y
consecuentemente sentar las bases para lograr el desarrollo sistemático de herramientas de
visualización interactivas usando dispositivos no convencionales. Para ello se plantea una
taxonomía de interacciones sobre grafos, se ubica cada categoría en el contexto de un modelo de
referencia y se analizan los aspectos más relevantes a la hora de diseñar visualizaciones utilizando
dispositivos no convencionales.
Palabras claves: Interacciones, Visualización de Grafos, Visualización de Información, HCI,
Dispositivos
                                                
* El presente trabajo fue parcialmente financiado por los PGI 24/N015 y 24/Zn12, Secretaría General de Ciencia y
Tecnología, Universidad Nacional del Sur, Bahía Blanca, Argentina.
771
1   Introducción
Hasta no hace mucho tiempo el volumen de información manejado en los dominios de aplicación
científicos y de negocios era bastante reducido. Una manipulación directa de los datos se hacía
viable y era lo más común a la hora de analizar y procesar la información. Sin embargo, conforme
se genera más y más cantidad de información, se hace indispensable la incorporación de técnicas
que permitan el procesamiento y el análisis de los datos de manera adecuada. Analizar directamente
grandes volúmenes de información se torna inmanejable y es preciso obtener vistas de los datos
bajo ciertas perspectivas que permitan al usuario resaltar los aspectos que le son de interés.
En este contexto, la Visualización provee alternativas adecuadas para lograr una exploración de un
conjunto de datos de manera más efectiva. A partir de una representación visual de los datos se
facilita la tarea de identificar patrones y extraer conclusiones sobre los mismos.
Sin embargo, dicha representación debe tener la habilidad de adaptarse a las necesidades del usuario
y por ende no puede constituir una construcción estática. La visualización debe acompañar al
usuario conforme explora la representación de los datos. Para ello, debe proveer interacciones
mediante las cuales el usuario manifieste sus necesidades y a partir de las cuales obtenga la
perspectiva deseada del conjunto de datos. Tradicionalmente se concebía a la visualización como el
proceso de construcción de una vista sobre un conjunto de datos particular. La obtención de una
imagen estática que captura ciertos aspectos de la información subyacente, si bien permite obtener
conclusiones relevantes, es un enfoque limitado cuando lo comparamos con la posibilidad de que la
visualización provea al usuario mecanismos para que este navegue los datos e interactúe con la
misma.
La Visualización de Grafos constituye un área de gran importancia dentro del campo de la
Visualización de Información. En la Visualización de Grafos, el conjunto de datos puede modelarse
mediante un grafo que luego se visualiza. Los datos se representan mediante nodos del grafo y los
arcos del mismo se utilizan para representar relaciones entre dichos datos. En este contexto
particular, la visualización también debe proveer interacciones adecuadas que den lugar a que el
usuario adapte la visualización de la manera antes mencionada.
En este trabajo se plantea una clasificación de interacciones sobre grafos ubicando cada categoría de
interacción en el marco del Modelo Unificado de Visualización, un modelo de referencia para
Visualizaciones. Posteriormente se analiza un caso concreto de aplicación de interacciones en
grafos mediante dispositivos no convencionales.
2   Interacciones en Visualización de Grafos
El proceso cognitivo de explorar un conjunto de datos partiendo de una vista simplificada de los
mismos e introducirse paulatinamente en los detalles de la representación no es posible sin el
soporte para las interacciones necesarias.
A diferencia de lo que sucede en el área de Visualización de Información, las aplicaciones en
Visualización de Grafos comparten un conjunto más o menos estable de interacciones básicas, sobre
las cuales existe un consenso generalizado en el área. En Visualización de Información, la gran
diversidad de dominios de aplicación existentes dificulta la identificación de un conjunto de ese
tipo.
Ciertas interacciones presentes en las aplicaciones de Visualización de Grafos, trascienden dicha
área y se hallan presentes también en otros dominios de la Visualización de Información. Este tipo
de interacciones están relacionadas con la metáfora presentada al usuario más que con el
772
formalismo de representación; el posicionar una cámara en el espacio de representación, por
ejemplo, si bien se provee como interacción en Visualización de Grafos, trasciende el mencionado
dominio. En general, todas las interacciones que involucren un cambio en el punto de vista del
usuario, en el foco de interés del mismo o en el nivel de detalle visualizado operan
independientemente de si lo que se representa visualmente es un grafo o no.
Otras interacciones están más relacionadas con el formalismo de representación: en este caso el
grafo. Es común que este tipo de interacciones sea definido en términos de los elementos del
mismo: nodos, arcos, etiquetas, etc. Como ejemplo de estas interacciones se puede citar la selección
de un nodo, un arco o un camino. Si bien la selección de elementos visuales se hace presente en
aplicaciones que van más allá de la Visualización de Grafos, y podría considerarse una interacción
más general, los elementos a seleccionar dependen del dominio de aplicación. Como resultado de
ello, la selección se traduce en instanciaciones concretas particulares de cada dominio. En el caso
concreto de grafos, los elementos visuales pueden ser, por ejemplo, nodos o arcos. En consecuencia,
se habla en términos de seleccionar dichos nodos o arcos en lugar de seleccionar elementos visuales
en general.
El conjunto de interacciones mencionado se encuentra en la mayoría de las herramientas de
Visualización de Grafos. Sin embargo, aún no se cuenta con una metodología que defina claramente
el proceso de construcción de una Visualización. Actualmente, existen herramientas aisladas
construidas con enfoques independientes y sin un marco general que las ubique en un contexto
común.
La existencia de un modelo de referencia que brinde ese marco, es de gran importancia para que los
usuarios provenientes de distintos dominios de aplicación logren interacciones efectivas basándose
en un único modelo mental y los diseñadores de visualizaciones expresen claramente las
transformaciones que deben sufrir los datos hasta la obtención de la vista, las operaciones que deben
proveerse y la manera en que debe interactuarse sobre la visualización.
3   El Modelo Unificado de Visualización (MUV)
El Modelo Unificado de Visualización [6] es un modelo de referencia que permite reflejar las
transformaciones que sufren los datos desde su obtención hasta la construcción de su representación
visual, y las interacciones existentes entre la visualización y el usuario de la misma. Establece un
marco conceptual en términos del cual definir estados intermedios, transformaciones, operadores y
operandos de manera independiente de todo dominio de aplicación (Figura 1).
Figura 1: El Modelo Unificado de Visualización
El Modelo Unificado de Visualización [6] constituye un modelo que es consistente con las posibles
intenciones de los usuarios y brinda un marco en el que es claro cómo interactúan las posibles
transformaciones y operaciones provistas. Por otro lado, también beneficia a los diseñadores al
momento de extender un sistema de visualización para incorporar nuevos dominios de aplicación,
brindando un marco de referencia que les define cuáles son las transformaciones que deben sufrir
773
los datos y el conjunto básico de operaciones que se deberían proveer. Además, la separación del
proceso en etapas, posibilita asociar ciertos operadores a determinadas instancias de dicho proceso,
permitiendo que procesos de visualización de dominios de aplicación diferentes que comparten
estados intermedios queden modelados de manera uniforme.
El modelo propone un conjunto de operadores y operandos denominados de bajo nivel que son
aplicables a las distintas etapas y transformaciones, así como también un conjunto de interacciones
generales de alto nivel características de todo proceso de visualización.
4   Clasificación de Interacciones sobre Grafos
Las interacciones en el contexto del MUV pueden expresarse en términos de las etapas que éstas
afectan y que deben reejecutarse para ajustar la visualización a los nuevos requerimientos del
usuario. Por ello, contar con un modelo de referencia como el MUV, además de brindar un marco
teórico en el cual ubicar los procesos que sufren los datos desde su obtención hasta su
representación visual, permite poner en contexto las interacciones al definir de manera precisa las
etapas que modifican.
Ortogonalmente al modelo de referencia, es preciso contar con una taxonomía de interacciones que
facilite su estudio y caracterice sus similitudes y diferencias. Agrupar las interacciones en categorías
permite identificar y aplicar criterios comunes a los miembros da cada categoría. Esta uniformidad
es beneficiosa ya que dichos criterios conformarían la base para definir metodologías de diseño de
Visualizaciones que realicen un tratamiento sistemático de las interacciones en contraposición con
los intentos “ad-hoc” aislados existentes en la actualidad.
A continuación se propone una clasificación de Interacciones sobre Grafos. Cada categoría no sólo
rescata ciertos aspectos de las interacciones que la componen sino que también reciben un
tratamiento uniforme en el marco ofrecido por el MUV; para cada categoría se define en qué etapa
del mismo debe resolverse. En el caso de interacciones que afectan múltiples etapas del modelo, la
reejecución se realiza a partir de la etapa más temprana.
4.1   Interacciones de Exploración
Este conjunto de interacciones permite al usuario explorar sus datos para asistir en el proceso
cognitivo que el mismo desarrolla mientras utiliza la visualización. Bajo esta categoría se agrupan
todas aquellas interacciones que brindan distinto grado de detalle bajo demanda. Dicha
modificación del nivel de detalle puede estar acompañada de un cambio en los datos que se
muestran o en la representación de los mismos.
El zoom semántico nos permite cambiar el nivel de detalle de los elementos de la vista. Por ejemplo,
es posible obtener mayor información asociada a un conjunto de nodos o arcos al deslizar el cursor
sobre los mismos o variar la cantidad de información que se muestra, asociada a ellos. Variar la
información que se muestra puede involucrar incluso un cambio de representación. Relacionado con
ello, el clustering permite reducir el número de elementos visuales construyendo agrupaciones o
clusters a partir de los mismos. Las interacciones asociadas al clustering pueden pensarse como un
tipo de zoom semántico ya que permiten obtener menor o mayor detalle. Por ejemplo interacciones
como colapsar o expandir uno o varios nodos de un grafo se consideran en esta categoría.
El filtrado determina las entidades que serán visualizadas. Éste, a diferencia del zoom semántico, no
modifica el nivel de detalle de las entidades individualmente sino que le permite al usuario cambiar
el grado de detalle de la vista en el sentido de que agrega o elimina elementos visuales a la misma.
774
Un posible filtrado que se puede realizar es en base a métricas: dada una distancia respecto de un
nodo, por ejemplo, se podrían visualizar los nodos que se encuentran a una distancia menor de éste.
También es posible visualizar sólo aquellos elementos cuyos datos asociados cumplen con
determinado criterio semántico. Por ejemplo, si se está representando una red de sucursales
bancarias mediante un grafo, es posible visualizar solamente las sucursales de determinada ciudad.
Las interacciones de Exploración se resuelven en la Transformación de Datos Abstractos a Datos a
Visualizar. Al cambiar el grado de detalle de la información que se muestra o al realizar filtrados, se
están modificando los datos que se muestran y es necesario elegir un nuevo conjunto de Datos a
Visualizar, decisión que se realiza en dicha transformación. Por ejemplo, si el usuario desea obtener
la información asociada a un determinado nodo (una forma de zoom-in semántico), se reemplaza su
representación actual por otra que contiene la información solicitada. Si el usuario realiza algún
filtrado sobre los nodos del grafo que está visualizando, de acuerdo a una métrica, es necesario
reemplazar el conjunto de nodos visualizados actualmente por el conjunto de nodos que cumplen
con dicha métrica.
4.2   Interacciones de Selección
Este tipo de interacciones permiten distinguir un subconjunto de elementos presentes en la vista de
los restantes, para llevar a cabo alguna tarea sobre ellos. Luego de la interacción de selección,
usualmente se realizan una o varias interacciones correspondientes a otras categorías de la
clasificación.
Este conjunto de interacciones involucra no sólo proveer realimentación al usuario acerca de los
elementos que seleccionó, sino también distinguir dichos elementos, a nivel del conjunto de datos
subyacentes, de modo tal que sea posible mantener la selección realizada para interacciones futuras.
En la visualización de grafos es posible seleccionar un nodo, un arco, un camino o en general
subgrafos o conjuntos de nodos y/o arcos. Las selecciones pueden ser disparadores de otras
interacciones que requieran la intervención del usuario, o derivar en la ejecución de acciones sin
intervención del mismo. Por ejemplo, el usuario puede seleccionar un conjunto de nodos y luego
cambiar algún atributo visual como color, forma, etc. También existen herramientas que al
seleccionar un nodo, actualizan automáticamente el nivel de localidad del grafo. De esta manera,
luego de la selección del nodo, sin la intervención del usuario, la visualización se ajusta para
mantener el foco de atención del mismo.
Las interacciones de selección se resuelven a partir del conjunto de Datos a Visualizar. De acuerdo
con la definición del MUV todos los datos presentes en este estado deben estar representados en la
vista. Como puede haber más de una vista de un mismo conjunto de Datos a Visualizar surge la
necesidad de asegurar consistencia entre los datos seleccionados en las mismas; por este motivo, el
marcado de los datos seleccionados debe realizarse en este conjunto. Adicionalmente, se redefine la
Transformación de Mapeo Visual  para distinguir este subconjunto de elementos del resto,
proveyendo la realimentación necesaria al usuario.
4.3   Interacciones de Representación
Todos los datos presentes en una visualización son representados mediante elementos visuales con
determinadas propiedades gráficas. Estos elementos se disponen en el espacio definiendo el sustrato
espacial. Usualmente, la disposición espacial de los elementos visuales que representan a los datos
775
queda determinada en función de un subconjunto de atributos, constituyendo un aspecto crítico del
mapeo visual.
Las propiedades gráficas de los elementos visuales, pueden definirse arbitrariamente o pueden ser
usadas para representar los restantes atributos asociados a los datos. Las interacciones de
representación permiten cambiar tanto la definición del sustrato espacial, como la representación
visual de los datos; el cambio en la representación visual puede involucrar modificar los elementos
visuales o sus atributos gráficos. Dentro de esta categoría el usuario puede reposicionar nodos,
seleccionar con qué elementos visuales se van representar nodos y arcos o modificar propiedades
gráficas de dichos elementos como color, forma, etc. Adicionalmente, puede modificar la forma en
la que están representadas las etiquetas asociadas a nodos y arcos variando además del color y la
forma, las propiedades textuales como la tipografía, el tamaño de letra, el estilo de la misma, etc.
También dentro de esta categoría el usuario puede reposicionar las etiquetas en relación al nodo o
arco al que están asociados.
Las interacciones de representación se resuelven en la Transformación de Mapeo Visual. Esta
transformación agrega a los datos, características que definen cómo se van a representar
visualmente. Si el usuario modifica estas características, es necesario volver a aplicar la
transformación de manera que el mapeo visual se corresponda con las necesidades del mismo. Por
ejemplo, si el color está siendo usado para representar algún atributo de los nodos y el usuario desea
modificar la escala de colores utilizada, es necesario cambiar la función transferencia que se aplica
en la Transformación de Mapeo Visual.
4.4   Interacciones de Navegación
A diferencia de las interacciones de exploración, las interacciones de navegación permiten al
usuario explorar el espacio de representación de sus datos, modificando el área mostrada
actualmente. En toda visualización, se identifica un área de la representación como el foco de
atención del usuario que es observado desde cierto punto de vista. Las interacciones de navegación
permiten modificar tanto el foco de atención del usuario como su punto de vista. Estas
modificaciones pueden ser realizadas en forma libre o dirigida, por medio de la imposición de
restricciones.
En esta categoría es posible, por ejemplo, fijar el objetivo de la cámara en un determinado nodo –
(foco de atención del usuario) restringiendo todos los movimientos de la misma de manera tal que
dicho foco esté siempre visible (navegación dirigida). Otro ejemplo de navegación dirigida consiste
en restringir las traslaciones de la cámara evitando que la misma se desplace fuera de la estructura
del grafo.
Las interacciones de navegación se resuelven en el estado de Datos Visualizados. Este conjunto de
interacciones es el único que no requiere la reejecución de etapas anteriores, sino que se resuelve en
la misma etapa en la que el usuario interactúa. Una vez aplicada la Transformación de
Visualización, se obtiene la representación visual de los datos. El último paso del pipeline del
modelo se realiza en el estado de Datos Visualizados y es el procesamiento gráfico de la
representación obtenida. Las interacciones de navegación condicionan dicho procesamiento pero no
la representación visual en sí misma. Es por eso que interacciones tales como zoom geométrico,
traslación o rotación de la cámara se resuelven en la vista.
776
5   Interacciones y dispositivos
Interacción se define como la acción de ejercer una acción o influencia recíproca. En el contexto de
Visualización de Información, se refiere al proceso por el cual el usuario y la visualización se
afectan mutuamente. El usuario afecta a la visualización mediante instrucciones que modifican
algunos de sus parámetros y la visualización afecta al usuario proporcionándole otra óptica sobre
los datos, en respuesta a las acciones que éste realiza.
En este proceso de ida y vuelta, se identifican dos componentes bien diferenciados: los dispositivos
de entrada (mediante los cuales el usuario afecta la visualización) y los dispositivos de salida
(mediante los cuales el usuario obtiene la vista deseada de los datos). Lo más común es contar con
un display como dispositivo de salida y de mouse y teclado como dispositivos de entrada. Esta
combinación de dispositivos limita la interacción humano-computadora al restringir la misma al
espacio bidimensional del escritorio y a un único cursor o puntero con el cual afectar la vista.
Numerosos dispositivos que buscan evitar estas limitaciones son objeto de desarrollo y
perfeccionamiento día a día. Pantallas táctiles, displays holográficos, cascos de realidad virtual son
sólo ejemplos de algunos de estos dispositivos. Desde el punto de vista de las interacciones, por
ejemplo, contar con la posibilidad de operar un puntero 3D permitiría una interacción más natural
en espacios de representación de tercera dimensión o disponer de múltiples punteros sobre un
mismo entorno permitiría a múltiples usuario cooperar en la manipulación de la representación de
los datos, constituyendo una visualización multiusuario.
En este contexto se puede identificar una clara separación entre la representación visual de los datos
generada por la visualización y el proceso de representación en el dispositivo de salida particular
(desde el punto de vista de la salida de la visualización) y también entre la acción ejercida sobre
determinado dispositivo de entrada y la interacción que provee la visualización. Consideremos, por
ejemplo, una visualización de grafos 3D. La visualización construye inicialmente una
representación 3D del grafo a partir de la cual el usuario puede interactuar. Si se cuenta con un
monitor convencional, el pipeline gráfico se encargará de proyectar esa geometría a un espacio 2D y
luego rasterizar los fragmentos obtenidos para la generación de una imagen compuesta de pixels en
el monitor. Sin embargo, si se contara con un casco de Realidad Virtual, el mapeo entre la
representación 3D y la representación 2D es diferente ya que el espacio 3D generado por la
visualización puede representarse en dicho dispositivo. En lo que respecta a la entrada sucede algo
similar; consideremos el mismo caso de la visualización de grafos 3D. En este ejemplo supongamos
que se define la interacción de seleccionar determinado nodo en el grafo. El usuario posiciona el
cursor del mouse sobre el nodo elegido y cliquea sobre el mismo. Esto desencadena un proceso en
el que se transforma la coordenada 2D del cursor del mouse en pantalla (se realiza la proyección
inversa) a coordenadas 3D en el espacio de representación y, en base a esa nueva posición, se
procede a seleccionar el nodo. Si contáramos con un dispositivo de entrada 3D, la transformación
de 2D a 3D no sería necesaria.
Claramente, debido a la diversidad de dispositivos existentes resulta conveniente realizar una
separación entre la construcción de la vista y el proceso por el cual la misma es representada en
cada dispositivo, y entre la interacción provista por la visualización y la implementación en los
dispositivos de dicha interacción.
6   Dispositivos no convencionales. El guante P5
Con el objetivo de realizar una aproximación inicial a las interacciones mediante dispositivos no
convencionales, se implementó un prototipo de herramienta de visualización de grafos que
777
Figura 2: El Guante P5
incorpora la posibilidad de interactuar con la misma mediante el guante P5 (Figura 2). A partir de
esta aproximación inicial se han obtenido algunos resultados, se han reconocido aspectos
importantes del problema y se han extraído conclusiones que se detallan a lo largo de las secciones
subsiguientes. La elección del dispositivo se hizo exclusivamente en base a la disponibilidad del
mismo.
El guante P5 consta de un sensor infrarrojo que se ubica en el escritorio y un “guante” que se coloca
en la mano del usuario. El guante se conecta al sensor vía un cable y éste al sistema mediante la
interfaz USB. El guante permite capturar la posición de la mano del
usuario en el espacio 3D, la rotación de la misma respecto de los ángulos
de pitch, yaw y roll (mediante el sensor en el escritorio) y además, para
cada uno de los dedos de la mano permite obtener una cuantificación de su
flexión. Adicionalmente cuenta con cuatro botones programables para
asignar funciones. La información posicional y rotacional se determina en
función de la señal captada por el sensor infrarrojo. Tanto la flexión de los
dedos como la información de los botones son provistas mediante el cable
que conecta el guante propiamente dicho con el sensor en el escritorio.
A diferencia de lo que sucede con un mouse tradicional en donde se
mapea un espacio bidimensional (normalmente la superficie de la mesa o pad) en otro (la pantalla),
con el guante P5 es posible mapear un espacio 3D en otro 3D. La posibilidad de realizar
movimientos variando intuitivamente la tercera coordenada, dota a la aplicación con la que se está
interactuando de un mayor grado de libertad. Además, dado que el guante permite capturar la
rotación de la mano en el espacio y la flexión de los dedos, el abanico de posibilidades es mucho
más rico.
Para dar idea al usuario de dónde está ubicado se hace preciso dotar a la visualización de un cursor
3D. Si la entrada es mediante el guante, como en el caso del prototipo planteado, pero la salida se
sigue realizando mediante un monitor o pantalla convencional, es preciso añadir elementos visuales
que ayuden al usuario a resolver la ambigüedad existente cuando se intenta representar un espacio
3D en uno 2D como el monitor. En el caso del prototipo, estas ayudas consisten en un cursor cúbico
(su tamaño relativo ayuda a resolver la profundidad), un sistema de ejes ortogonales que se mueven
con el cursor (ayudan a resolver la posición del mismo en el espacio de representación) y
adicionalmente, con el objetivo de facilitar la selección de nodos, se resalta el nodo más cercano al
cursor 3D. Con esta ayuda, el usuario sabe con certeza en todo momento cuál nodo resultaría
seleccionado luego de una selección. Esto puede apreciarse en la Figura 3.
Figura 3: Ayudas visuales para la interacción en 3D. En la captura de la aplicación implementada se aprecia la forma
cúbica del cursor, el sistema de ejes ortogonal y la esfera que constituye el cursor de preselección.
778
Sin embargo, el guante P5 como dispositivo posee limitaciones. El hecho de tener que colocar el
guante en el rango de detección del sensor agrega al usuario la sobrecarga de preocuparse  de que
ningún objeto (incluyendo su propia mano) se interponga entre el guante y el sensor; esto le  quita
cierto grado de naturalidad a las interacciones provistas ya que condicionan su comportamiento.
Otra limitación la constituye el hecho de que con el tiempo de uso el dispositivo se vuelve
incómodo. Tener que mantener el brazo en el “aire” por tiempos prolongados produce cansancio y
esto termina afectando la interactividad buscada. Además, dado que para cada dedo se captura una
cuantificación de la flexión y no su posición relativa respecto de la mano no es posible, por
ejemplo, capturar gestos específicos como el de tomar un objeto pequeño con la punta de los dedos
pulgar e índice o el de capturar el grado de separación entre los dedos.
Sin embargo, a pesar de estas limitaciones propias del dispositivo, el mismo brinda posibilidades
adicionales a la combinación teclado y mouse para ser utilizado como dispositivo de entrada en una
visualización, que merecen ser exploradas.
7   MAPEANDO GESTOS A INTERACCIONES
En secciones anteriores se enfatizó la conveniencia de separar el espacio de representación
generado por la visualización de la representación propia de dicho espacio en un dispositivo de
salida particular, así como también la conveniencia de hacer la misma separación entre la
interacción provista por la visualización y su implementación en dispositivos de entrada
particulares. A raíz de esto, en función de los dispositivos disponibles y la visualización existente se
definen asociaciones entre las vistas generadas por la visualización y sus representaciones en ciertos
dispositivos de salida (a cargo del pipeline gráfico) y asociaciones entre las interacciones provistas
por la visualización y las implementaciones de las mismas en dispositivos particulares.
En esta sección se propone una asociación entre ciertas interacciones provistas en el prototipo de
visualización de grafos y sus respectivas implementaciones para el guante P5. A las
implementaciones de las interacciones en el guante las llamaremos gestos. El enfoque adoptado
para definir el mapeo entre gestos e interacciones persigue como objetivo principal el dotar de
naturalidad a la interacción entre el usuario y la visualización. Sin embargo al ser un campo
relativamente no explorado, no se cuenta con metodologías que orienten su diseño.
La relación entre gestos e interacciones debe ser una función. Para cada gesto, debe quedar
unívocamente determinado a qué interacción queda asociado. Sin embargo, es posible que más de
un gesto desencadene la misma interacción o que queden interacciones sin gestos asociados o
viceversa.
En ciertos dispositivos, la unicidad en la determinación de la interacción asociada a partir de un
gesto se implementa directamente. Por ejemplo un drag con botón derecho de un mouse, se
distingue claramente de un drag con botón izquierdo. Sin embargo, en el caso de un dispositivo
como el guante, que brinda muchas más posibilidades, las condiciones que definen un gesto deben
plantearse explícitamente para asegurar la exclusión mutua de las mismas. Concretamente en el
caso del P5, para cada gesto hay que definir claramente la posición y rotación del guante con
respecto al sensor, la flexión de cada dedo y el estado de los botones.
Otra consideración que se hace explícita en dispositivos no convencionales es cuál de los
parámetros de captura del dispositivo se asociará a los parámetros propios de la interacción. Por
ejemplo, si consideramos una interacción que permite rotar la cámara determinado ángulo, dicho
ángulo será modificado en función de determinado parámetro del dispositivo de control. En el
779
mouse normalmente se mapea el valor de determinada coordenada de la posición del mismo al valor
del ángulo. En otro tipo de dispositivos como el guante se podría, de igual manera, mapear una
coordenada de la posición al ángulo de la cámara. Sin embargo, también es posible mapear cierto
ángulo de rotación del guante o la magnitud de la flexión de cierto dedo al parámetro de la
interacción.
Más generalmente, cada dispositivo de entrada tiene un conjunto de parámetros que transmite a la
aplicación. De ese conjunto de parámetros, algunos serán destinados a determinar la interacción
asociada provista por la visualización que será disparada, otros se asociarán a parámetros propios de
la interacción elegida y un tercer grupo de parámetros puede ser ignorado para cierta interacción en
particular.
Teniendo en cuenta todas estas consideraciones, podemos definir el soporte de interacciones
provistas por el prototipo de Visualización de Grafos implementado y los gestos del guante
asociados. El conjunto de interacciones elegidas representa un subconjunto básico presente en la
mayoría de las herramientas de Visualización de Grafos. Las interacciones del prototipo que se han
soportado mediante el guante son las de navegación y las de selección. Concretamente, mediante el
guante es posible posicionar la cámara en el espacio de representación del grafo 3D tanto de manera
libre como dirigida y es posible seleccionar el nodo que será el foco de interés del usuario. Para
lograr navegación dirigida se restringe el foco de la cámara de manera tal que apunte al nodo actual
(el último en haber sido seleccionado) que representa el foco de atención del usuario. En la variante
libre, no se restringe el foco ni la posición de la cámara.
En lo referente al diseño de gestos, es importante notar que en todo sistema interactivo debe
definirse un gesto neutro. Es decir al menos un gesto que no se halle asociado a interacción alguna.
El usuario no efectúa operaciones todo el tiempo que utiliza la visualización. En esos casos debe
proveérsele una forma de no interactuar con la aplicación de manera de poder apreciarla sin afectar
la vista generada. En el caso del prototipo y el guante P5, esto se consigue extendiendo todos los
dedos (Figura 4a). Al igual que sucede con el mouse mientras no se pulsa ninguno de sus botones,
durante el gesto neutro del guante, la visualización sólo se limita a desplazar el cursor por el espacio
de representación.
Manteniendo extendidos los dedos pulgar, índice y mayor y flexionando el anular y el meñique es
posible re-posicionar el guante frente al sensor sin modificar la posición del cursor de manera
análoga al efecto que se logra al levantar el mouse de la superficie de apoyo (Figura 4b). Este gesto
de reposicionamiento está preimplementado en el guante y resulta útil para reubicarlo cuando nos
salimos del rango del sensor infrarrojo.
Con respecto a la selección, ésta se limita a un único nodo: el nodo actual. El gesto asociado implica
efectuar el movimiento de click con el dedo índice (los demás dedos deben estar extendidos) de
manera análoga a si se utilizara el mouse pero sin ningún botón sobre el cual clickear (Figura 4e).
Una vez realizado el gesto asociado a la selección, el nodo más cercano a la posición 3D del cursor
pasa a ser el nodo actual seleccionado.
En las interacciones de navegación es posible, mediante el gesto de grab, manipular directamente el
grafo y posicionarlo (sólo en navegación libre) y rotarlo arbitrariamente (Figuras 4c y 4d
respectivamente). Básicamente, el gesto implica cerrar el puño completamente como “tomando” el
grafo y a partir de allí se permite trasladarlo y rotarlo conforme se traslade o rote el guante frente al
sensor. En el caso de navegación dirigida, el grafo estará anclado por el nodo actual y sólo podrán
efectuarse rotaciones.
Adicionalmente es posible, mediante ciertos gestos, posicionar la cámara modificando su acimut,
elevación y distancia al foco (dolly). En estos casos debe flexionarse el pulgar y mantenerse
780
extendidos los demás dedos y además, el plano de la mano debe ser ortogonal al sensor. Los
movimientos de la mano en sentido de la palma o su reverso se traducen en modificaciones en los
ángulos de acimut o elevación o en la distancia al objetivo de la cámara (Figuras 4f, 4g y 4h).
Figura 4: El diseño de gestos para el guante P5
La efectividad de las interacciones mediante dispositivos no convencionales depende en gran
medida de la naturalidad de los gestos asociados. Con gestos que resulten intuitivos y que mapeen
sus parámetros a los parámetros de la interacción de una manera esperada, es posible mejorar la
usabilidad facilitando al usuario la tarea de interactuar con la representación.
En este sentido, para lograr naturalidad a la hora de diseñar los gestos, resulta esencial plantear la
interacción como si la representación visual 3D fuera un objeto tangible del mundo real y en
función de ello diseñar los gestos pensando en las formas en que el usuario interactuaría con dicho
objeto en la realidad. Tomar elementos de la realidad que le son familiares al usuario permite
construir metáforas muy efectivas ya que aprovechan la familiaridad mencionada para lograr una
interacción mucho más natural.
También se hace necesario mantener una semántica unívoca y clara para los gestos, que no de lugar
a confusiones. En este sentido, como se dijo anteriormente, lograr exclusión mutua en los mismos
es esencial pero en un escenario como el planteado, es una tarea dificultosa. Si además se
incorporan tolerancias a los valores que definen los gestos para quitarle rigidez a la interacción, el
escenario se torna aún más complejo.
Otro aspecto a tener en cuenta es la precisión en la interacción. Si bien un gesto asociado a
determinada interacción puede resultar muy natural, pierde utilidad si no se le permite al usuario
efectuarla con cierta precisión. En este sentido, se ha observado que el humano está mejor
preparado para realizar movimientos precisos que para medir intervalos de tiempo precisos. Por
ello, para lograr una determinada interacción con la representación, resulta más preciso mapear un
movimiento del dispositivo, por ejemplo, que controlar el tiempo que se mantiene presionado un
botón. En concordancia con dicha premisa y aprovechando esta característica perceptual, en el
diseño de gestos del prototipo se ha mapeado el movimiento del guante para realizar el movimiento
del cursor y las rotaciones y traslaciones de la representación.
781
8   Conclusiones y Trabajo Futuro
En este trabajo se ha planteado una taxonomía de interacciones y se han clasificado las más
representativas del área de Visualización de Grafos. Dicha clasificación puede expresarse de
manera muy natural en términos del MUV. Esto permite ubicar las interacciones en el contexto de
dicho modelo permitiendo expresar el impacto que tienen en el proceso de Visualización, las etapas
que se ven afectadas y las transformaciones que deben ser recalculadas. Contar con este marco de
referencia en el planteamiento de las interacciones posibilita contar con el vocabulario común
buscado que permita compatibilizar las necesidades del usuario con las tareas del diseñador de una
Visualización.
En este sentido se espera que, a partir de contar con taxonomías de interacciones en diversas áreas
de la Visualización de Información, se pueda unificar y extraer las características comunes para
construir una taxonomía general de interacciones en Visualización. Este trabajo aporta una
taxonomía para grafos, uno de los elementos necesarios para ello.
Respecto a las interacciones no convencionales y tendiendo a contribuir en la construcción de una
teoría de base que oriente desarrollos futuros, se implementó un prototipo de herramienta de
Visualización de Grafos que soporta la interacción mediante un dispositivo particular. A partir de
esta experiencia concreta fue posible comenzar a identificar los aspectos relevantes del problema y
aquellas consideraciones de diseño que contribuyen a mejorar la calidad de la herramienta. En este
sentido, por ejemplo, la separación entre la interacción provista por la visualización y la
implementación en determinado dispositivo permite modelar y atacar el problema de una manera
más modular al independizarse de los dispositivos de entrada-salida para plantear la interacción y al
abstraerse de los demás dispositivos a la hora de implementar para uno en particular.
Ciertos aspectos sólo surgen a partir del desarrollo de una herramienta de este tipo. De allí la
importancia de contar con una implementación concreta. A partir de unificar y generalizar estos
aspectos es posible comenzar a delinear una teoría de base como la buscada. A partir de la
experimentación con el uso de la herramienta implementada se concluye que contar con
dispositivos no convencionales permite brindar mayor naturalidad en la interacción. La posibilidad
de plantear metáforas de interacción más cercanas al usuario facilita el uso de una visualización y
disminuye la curva de aprendizaje de la misma. Sin embargo, si bien el diseño de interacciones
mediante dispositivos no convencionales ofrece un nuevo horizonte de posibilidades, también
plantea nuevos desafíos. También se identifican como puntos centrales el hecho de mantener un
significado claro de cada interacción y la precisión de las mismas.
Contar con una implementación concreta permite evaluar la herramienta desde el punto de vista de
la usabilidad y medir el impacto en la interacción humano-computadora que se establece. En este
sentido, se planea realizar tests de usabilidad que permitan cuantificar la magnitud de la mejora
resultante de usar el guante en un caso concreto de Visualización de Grafos respecto de la
combinación tradicional de mouse y teclado medir así el impacto que tiene la tecnología de
interacción sobre diversos tipos de grafos y con diversas tareas típicas del área. En este sentido, el
hecho de que la gran mayoría de los potenciales usuarios de estos sistemas ya tenga un grado de
acostumbramiento al mouse deberá ser contemplado a la hora de evaluar un dispositivo totalmente
nuevo para ellos.
La ausencia de guías de diseño que orienten el desarrollo de gestos y la asociación con interacciones
más adecuada, plantea un escenario artesanal en lo que al diseño e implementación de gestos y sus
asociaciones con interacciones se refiere. La gran diversidad de dispositivos existentes y los usos
particulares en cada dominio de aplicación plantean un escenario muy heterogéneo. Sin embargo,
este tipo de intentos aislados permitirán extraer los aspectos de relevancia con el objetivo último de
782
unificar los aspectos comunes y sentar las bases para definir metodologías que dicten los pasos a
seguir en el proceso, de una manera más sistemática.
