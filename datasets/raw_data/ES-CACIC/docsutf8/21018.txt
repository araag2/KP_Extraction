Aplicabilidad de los métodos de síntesis cuantitativa de experimentos en Ingeniería de Software
﻿ La síntesis cuantitativa [1] consiste en combinar los resultados de 
varios estudios experimentales con el objeto de generar nuevas piezas de 
conocimiento. Estas nuevas piezas de conocimientos serán más generales y 
fiables que los resultados obtenidos por los estudios  individuales, ya que dichas 
piezas de conocimiento están sustentadas por una mayor cantidad de evidencia 
empírica. El objetivo del presente trabajo es determinar cuáles de los métodos 
de agregación conviene aplicar en el contexto experimental que hoy día 
presenta la Ingeniería de Software Experimental.  
 
Palbaras clave. Agregación de experimentos. Síntesis Cuantitativa. Metodo de 
Monte Carlo. Ingeniería de software Experimental. 
1. Introducción 
La síntesis cuantitativa [1] consiste en combinar los resultados de varios estudios 
experimentales con el objeto de generar nuevas piezas de conocimiento. Estas nuevas 
piezas de conocimientos serán más generales y fiables que los resultados obtenidos 
por los estudios  individuales, ya que dichas piezas de conocimiento están sustentadas 
por una mayor cantidad de evidencia empírica. En Ingeniería del Software (SE), la 
síntesis cuantitativa, se ha popularizado en los últimos años desde que fue propuesta 
por Basilli [2] en 1996 y el primer trabajo de meta-Análisis que se conoce es el 
desarrollado por Miller [3] que logró combinar 4 experimentos en 1999. A semejanza 
de lo que se hace en medicina, en SE, se utilizan las Diferencia Medias Ponderadas 
(WMD) [4] como método de síntesis. Es de hacer notar que para que el método WMD 
pueda aplicarse de forma fiable requiere que el conjunto de estudios a agregar 
cumplan ciertas restricciones, entre otras: contener un número mínimo de 
experimentos, homogéneos y que reportan todos los parámetros estadísticos 
necesarios (medias, varianzas o desvíos estándar y cantidad de sujetos 
experimentales). Estas restricciones limitan fuertemente su aplicabilidad en el actual 
contexto experimental de la SE, donde las replicaciones de experimentos son muy 
reducidas [5;6] y los estudios no proporcionan los parámetros estadísticos necesarios 
 debido a problemas de reporte [7;8]. Este hecho  provoca disfunciones en la síntesis. 
Por ejemplo, en [9; 10] si bien se identificó un conjunto de experimentos importante, 
no se llego a agregar los resultados de los estudios identificados debido a la falta de 
estandarización de variables respuesta y la baja calidad de los reportes publicados; en 
[3] solo se pudieron agregar de cuatro estudios experimentales y solo en [11] se logró 
hacer una síntesis realmente valiosa combinando 15 estudios experimentales.  
Si bien WMD es el método de síntesis cuantitativa más difundido y recomendado 
en la mayoría de las ciencias [12], no es el único que existe. Restringiéndonos 
únicamente a los métodos cuantitativos, en [4] se propone el método Conteo de Votos 
Estadístico (SVC) como una alternativa menos restrictiva al WMD, mientras que en 
[13] se propone el Response Ratio (RR) como método alternativo al WMD. Pero, a la 
fecha, no se conoce ningún caso de aplicación de estos métodos en SE. 
Dado que en algunos trabajos [14; 15] se ha observado que el desempeño de los 
métodos de Meta-Análisis varía con la cantidad de experimentos incluidos, así como 
también con la cantidad de sujetos que estos experimentos incluyen, y que en algunos 
casos el tamaño de la varianza puede cambiar la fiabilidad de los métodos, el objetivo 
del presente trabajo es determinar cuál o cuáles de los métodos conviene aplicar en el 
contexto experimental que hoy día presenta la SE. Este trabajo se encuentra 
estructurado de la siguiente forma: la sección 2 describe en que consiste la síntesis 
cuantitativa de experimentos y se detallan las principales características de los 
métodos a evaluar; la sección 3 describe la metodología de análisis a aplicar; la 
sección 4 se presenta los resultados obtenidos en el proceso de simulación; en la 
sección 5 detallan las conclusiones obtenidas. 
2. Estado de La cuestión 
2.1. Síntesis Cuantitativa de estudios Experimentales 
La síntesis cuantitativa de estudios experimentales, también llamada agregación de 
experimentos o Meta-Análisis, consiste en la integración de los resultados de un 
conjunto de experimentos, previamente identificados, que analizan el desempeño de 
un par de tratamientos predefinidos con el fin de dar una estimación cuantitativa 
sintética de todos los estudios disponibles [16]. Como el objeto de estudio de este tipo 
de trabajo son los estudios experimentales previamente desarrollados y analizados por 
sus autores, a este tipo de estudio también se lo conoce con el nombre de “MetaAnálisis”, que significa “después del análisis” [17].  
Si todos los estudios incluidos en el proceso de Meta-Análisis fueran igualmente 
precisos y utilizaran exactamente las mismas variables respuesta, bastaría con 
promediar los resultados de cada uno de ellos para obtener así una conclusión final 
[18]. Sin embargo, en la práctica no todos los estudios tienen la misma precisión, por 
ello cuando se los combine se debe asignar un mayor peso a los estudios que permiten 
obtener información más fiable. Esto se logra combinando los resultados mediante un 
promedio ponderado [19]. Por otra parte, para poder solucionar los problemas 
vinculados a la no uniformidad de las variables respuesta, los métodos MetaAnalíticos expresan sus resultados mediante un índice de “Tamaño de Efecto”, el cual 
 es un estimador no escalar de la relación entre una exposición y un efecto [16] y es 
aplicable a cualquier medida de  diferencia de los resultados de dos grupos.  
El método de síntesis cuantitativa para variables continuas (las mas utilizadas en 
SE) más utilizado es diferencias medias ponderadas (WMD) [4] (recomendado por 
organismos internacionales como Cochrane Collaboration [16]). No obstante existen 
otros métodos alternativos menos difundidos para el cálculo del tamaño de efecto, 
como son: el Response Ratio (RR) versión paramétrica propuesto por [13],  el Vote 
Counting (VC ) propuesto por [4] y el Response Ratio (RR) versión no paramétrica 
propuesto por [13].  Estos métodos se describen a continuación. 
2.1.1 Diferencia Medias Ponderadas 
Este método es conceptualmente sencillo: el estimador de efecto individual 
(representa la tasa de mejora de un tratamiento respecto del otro en cada 
experimentos) se estima como el cociente de las diferencias entre las medias y el 
desvío estándar conjunto. Esta función, desarrollada por Glass [17], fue optimizada 
por Hedgges y Olkin [4] quienes incorporaron un factor de corrección que aumenta la 
fiabilidad cuando se trabaja con pocos estudios. Convirtiendo a la nueva función en el 
método  de Meta-Análisis mas difundido en la actualidad y el recomendado para ser 
utilizado en SE [2].  
Una vez estimado el tamaño de efecto para cada estudios, puede estimarse el efecto 
global (representa la tasa de mejora de un tratamiento respecto del otro a nivel 
general) el cual se calcula como una media ponderada de los estimadores de efecto de 
los estudios individuales [4]: 
∑∑= )(/1
)(/
* 2
2
d
dd
d
i
ii
σ
σ  d* es el tamaño de efecto global ∑ )(/ 2 dd ii σ  es la suma de los efectos individuales 
∑ )(/1 2 diσ  es la suma de la inversa varianza 
 
 
(1) 
Para mayores detalles de cómo aplicar las formulas indicadas remitirse a [4]. 
2.1.2 Response Ratio Paramétrico (PPR) 
El PRR consiste en estimar un índice de efecto, o Ratio, entre dos tratamientos 
mediante el cociente de ambas medias [20]. Este cociente estima la proporción de 
mejora existente entre ambos tratamientos [21]. Así, por ejemplo, un ratio de 1.3 
indicará que el tratamiento principal es un 30% mejor que el secundario, o un ratio de 
1 indicará que no hay diferencias en el desempeño de ambos tratamientos. 
La aplicación del método es similar a WMD. Primeramente se debe estimar el 
Ratio de cada uno de los experimentos (RR = YE / YC) y luego, en base a estos, se 
estima el Ratio global mediante un promedio ponderado de los ratios individuales: 
∑
∑
=
=
=
k
i i
k
i
ii
W
LW
L
1
*
1
*
*  
L* es el efecto global 
Li es el efecto de cada estudio 
Wi es el factor de peso = 1/v  
 
(2) 
Donde cada estudio es ponderado en base a la inversa de su varianza: 
 CC
C
EE
E
Yn
S
Yn
S
v
22
+=  
 
v es el error típico 
S2‘s  son las varianzas de los estudios 
Y‘s  son las medias de los estudios 
n‘s  son las cantidades de sujetos  
 
(3) 
Para que la combinación de un conjunto de estudios sea más precisa se incorporó 
al método el logaritmo natural, el cual aplicado a los efectos de los estudios 
individuales permite linealizar los resultados y normalizar su distribución. Para 
mayores detalles de cómo aplicar las formulas indicadas remitirse a [21]. 
2.1.3 Conteo de Votos Estadístico (SVC) 
El SVC es un método que requiere muy poca información para poder ser aplicado. 
Solo precisa conocer si existe o no diferencia entre las medias de los tratamientos (a 
lo cual llamaremos “voto”) y la cantidad de sujetos experimentales utilizados en cada 
estudio (utilizado como ponderador del “voto”) [4]. En base a estos datos se realiza un 
proceso de inferencia estadística con el objeto de determinar que tamaño de efecto (en 
general seleccionado de una lista que va desde -0,5 a 0,5) tiene la mayor probabilidad 
de ser el tamaño de efecto real que se hubiera estimado mediante WMD si se contara 
con todos los datos para poder hacerlo. La función principal de estimación es: 
( )[ ]
( ) ( )∑= ⎪⎭
⎪⎬
⎫
⎪⎩
⎪⎨
⎧
−−
+−−
=
k
i i
i
i
ñX
ñX
XXL
1
1
ln1
1ln
),.....,|(
δφ
δφ
δ
 
L(δ|X1,….Xn) es la probabilidad de tamaño de efecto 
δ es el tamaño de efecto a testear 
Xi es el valor del voto de cada estudio 
ñ = (nE+nC) / (nE*nC) donde n’s son las cantidades 
de sujetos experimentales de cada estudio 
 
 
(4) 
Para mayores detalles de cómo aplicar las formulas indicadas remitirse a [4]. 
2.1.4  Response Ratio No Paramétrico 
Esta versión del RR es similar a la versión paramétrica, siendo su principal 
diferencia la forma en que pondera a los estudios. En lugar de utilizar la inversa de la 
varianza, el NPRR  utiliza la cantidad de sujetos experimentales [21]: 
)(2
)( 2
ECCE
EC
nn
RRLn
nn
nn
v ++
+=  v es el error típico n‘s  son las cantidades de sujetos  
RR es el Ratio  
 
(5) 
La principal ventaja de este método, desde el punto de vista de su aplicación, consiste 
en no requerir conocer las varianzas de los tratamientos ni requerir que exista 
normalidad y homeosticidad, lo cual aumenta enormemente sus probabilidades de 
aplicación. Para mayores detalles de cómo aplicar las formulas indicadas remitirse a 
[21]. 
3. Metodología 
El objetivo de este trabajo es desarrollar un proceso de simulación, 
complementario a los anteriores [14, 15], para evaluar el desenvolvimiento de los 
 cuatro métodos de Meta-Análisis (WMD, PRR, SVC y NPRR) de forma exhaustiva 
(variando: los tamaños de efectos y la cantidad de experimentos, la cantidad de 
sujetos por experimento), en un contexto experimental como el que hoy día presenta 
la SE. Donde, si bien la cantidad de experimentos ha venido creciendo 
significativamente en los últimos años (pasando de aproximadamente tres estudios 
experimentales por año a principio de los 90’ a más de veinte estudios por año, 
publicados en los principales congresos y revistas, a principio del años 2.000 [22]), 
todavía existen pocos experimentos y los mismos, en general, utilizan pocos sujetos 
experimentales (por ejemplo: [23] utiliza 4 sujetos experimentales) y tienen falencias 
en sus reportes (es común que no se publiquen las varianzas de los tratamientos 
analizados como sucede por ejemplo en: [24]). 
De forma similar a como se hizo en [14] y [15], para desarrollar el proceso de 
simulación utilizaremos la técnica de Monte Carlo. La simulación de Monte Carlo es 
una técnica que combina conceptos estadísticos (muestreo aleatorio) con la capacidad 
que tienen los ordenadores para generar números pseudo-aleatorios siguiendo una 
distribución de probabilidad normal. En este contexto, se utilizó esta técnica para 
simular los valores que hubieran generado los distintos sujetos en la aplicación de los 
tratamientos, en base a los cuales, luego, se estimaraon la media y la varianza de cada 
experimento. 
El primer paso del desarrollo del proceso de simulación consiste en definir los 
valores poblacionales a partir de los cuales se obtienen los valores de la muestra para 
simular el Meta-Análisis. Para ello se siguieron las recomendaciones de los anteriores 
trabajos de simulación [14] y [15] e información relevante de cómo son típicamente 
los estudios hechos en el ámbito de la. Los tamaño de efecto poblacional a analizar 
son los mismo que se definen en [21] bajo (0,2), medio (0,5)  y alto (0,8),  mas la 
incorporación del tamaño de efectos muy alto (1,2), ya que se ha observado que 
varios estudios [25; 26] hechos en SE tienden a dar tamaños de efectos muy altos.  
La media poblacional del tratamiento secundario ( cμ ) es fijada en 100 y los 
desvíos estándar como se hizo en [21] son fijado en los siguientes porcentajes 
respecto de la media de dicho tratamiento: 10% al cual llamaremos varianza baja; 
40% al cual llamaremos varianza media; y 70% al cual llamaremos varianza alta. Por 
su parte la media poblacional del tratamiento principal se estimará de la siguiente 
forma σδμ *100+=E  y el ratio poblacional que se utilizará para validar los 
resultados que generen el RR paramétrico y no paramétrico será estimado: RR = Eμ  
/ cμ . 
Por otra parte, la cantidad de experimentos a agregar en cada proceso de 
agregación irá desde 2 a 10 incrementándose de dos en dos, por considerar que el 
contexto experimental de la SE no aporta hoy día muchos experimentos 
potencialmente agregables mediante Meta-Análisis, tal y como puede comprobarse en 
las revisiones sistemáticas hechas hasta el momento [9; 10].  De igual modo, 
consideramos un número reducido se sujetos por experimento, en el rango de 4 – 20. 
Las variables respuesta resultado de la simulación serán también las utilizadas en 
los estudios de Lajenouse [14] y Friedrich y colegas [15], esto es, el error de tipo I y 
II ó, para ser mas exacto, su inversa: (1-α) o precisión y (1 - β) o poder estadístico. 
Estas variables son adecuadas para nuestro propósito ya que determinan cuantas veces 
 se equivoca un método de Meta-Análisis a la hora de determinar si existe (error de 
tipo I) o no (error de tipo II) una diferencia significativa entre dos tratamientos. Por 
último, siguiendo las recomendaciones de [14] para cada combinación de valores de 
las variables se construirán 1.000 simulaciones, tras lo cual se calcularan los valores 
de las variables respuesta. 
4. Resultados 
Los resultados detallados de la simulación se presentan en las tablas 1 a 6 (al final 
del trabajo). Las tablas vinculadas a la fiabilidad indican el porcentaje de veces que el 
intervalo de confianza estimado (a un nivel de α = 0.05) contuvo el valor del tamaño 
de efecto poblacional, mientras que las tablas vinculadas a la potencia estadística 
indican el porcentaje de veces que dicho intervalo de confianza no contuvo el valor 0 
para los métodos WMD y SVC y el valor 1 para los métodos RR paramétricos y no 
paramétricos. Para facilitar la compresión de las mismas, se han resaltado las celdas 
en las cuales los porcentajes estimados superaban al valor mínimo fijado, 1 - α = 95% 
para la fiabilidad y 1 – β = 80% (el cual es el valor típicamente recomendado [27]) 
para la potencia estadística.  
Respecto del desempeño de cada uno de los métodos podemos decir que: 
• Es fiable utilizar el método WMD en contextos experimentales donde los tamaños 
de efecto poblacionales son bajos o medios, siendo su condición óptima de 
aplicación cuando los efectos son medios y el conjunto de experimentos a agregar 
superen a los 112 sujetos experimentales. Cuando los efectos poblacionales son altos 
o muy altos, el método tiende a perder fiabilidad sobre todo cuando se incrementa la 
cantidad de experimentos y la cantidad de sujetos experimentales.  
• Es aconsejable utilizar el método PRR, siempre y cuando los estudios a agregar 
posean más de 4 sujetos experimentales. El método mostró ser robusto ante los 
cambios en la varianza, tamaños de efecto y cantidad de experimentos a agregar. Su 
condición óptima de aplicación varía en función del tamaño de efecto poblacional y 
la cantidad de sujetos experimentales que los estudios totalicen, observando que: 
para efectos muy altos se requieren por lo menos 80 sujetos experimentales, para 
efectos altos se requieren como mínimo 100 sujetos experimentales y para un efecto 
medio se requieren como mínimo 140 sujetos experimentales, para que el método 
posea fiabilidad y potencia estadística. 
• Es fiable utilizar el método SVC, solo cuando el tamaño de efecto es medio se 
cuenta con experimentos que totalicen más de 80 sujetos experimentales. Su falta de 
fiabilidad es compensada en parte con su alta potencia, pero se debe tener mucho 
cuidado con el uso del mismo sobre todo en contextos experimentales donde el 
tamaño de efecto poblacional es bajo. En contextos de tamaños de efectos altos, la 
perdida de fiabilidad es compensada en parte con la alta potencia estadística. 
• El método NPRR ha sido el método más fiable de todos los analizados. Su mayor 
problema está dado por la baja potencia estadística que se acentúa en contextos 
donde la población tiene baja varianza. Esto se debe en parte a que en contexto de 
baja varianza no se requiere que la diferencia entre las medias sea excesiva para que 
el efecto sea alto. Su condición óptima de aplicación varía en función de la varianza 
 poblacional, el tamaño de efecto poblacional y la cantidad de sujetos experimentales 
que los estudios totalicen observando que: para varianzas poblacionales medias y 
tamaños de efecto poblacionales altos o muy altos se requieren como mínimo 100 
sujetos experimentales, para varianzas poblacionales altas con tamaños de efecto 
poblacionales muy altos se requieren como mínimo 48 sujetos experimentales, para 
efectos poblacionales medios se requieren como mínimo 80 sujetos experimentales 
y para efectos poblacionales altos se requieren como mínimo 16 sujetos 
experimentales, para que el método posea fiabilidad y potencia estadística. 
5 Conclusión 
A modo de conclusion preliminar podemos decir que dentro de los parámetros 
normales que hoy presenta la Ingeniería de Software Empírica [5] el método WMD ha 
mostrado comportarse de forma confiable, por lo que no es necesario utilizar el 
método PRR como método alternativo al mismo. Por otra parte, en los casos en que 
los reportes experimentales no sean completos, el método NPRR mostró un 
comportamiento mucho mas fiables que el SVC que, en general, no dio buenos 
resultados. 
No obstante esto, si se trabaja en un entorno donde los tamaños de efecto son altos, 
el contexto cambia drásticamente, ya que aquí el método WMD deja de ser fiable, lo 
cual implica que los tamaños de efectos estimados pueden no ser correctos, por tal 
motivo el método PRR, que si ha mostrado ser fiable cuando los tamaños de efecto 
son altos, se convierte en el método mas recomendable cuando los reportes son 
completos, mientras que el método NPRR sigue siendo el mejor método cuando los 
reportes no son completos.  
6
