Aprendizaje de juegos mediante cúmulos de partículas con tamaño de población variable
﻿
Game learning has encouraged the development of several Artificial Intelligence strategies. Even 
though there exist different approaches, the adaptation to the information environment is an 
expected characteristic when we are to solve a complex problem, since it is unnecessary to count 
with the codification of any type of initial knowledge. 
In this area, neural networks have provided excellent results though with a generally high 
computational cost. There exists previous work in which population heuristics have been used to 
reduce the training times. 
In particular, the use of evolving strategies based on fixed-size particle swarms has rendered 
successful results. This paper proposes to modify the size of the population during the adaptation 
process, adding and deleting individuals in function of their skills to solve the problem. 
The proposed method has been applied in a neural networks training to play the game TicTaeToe. 
The results obtained have been compared to those of a strategy based on particle swarms with 
fixed-size population. Finally, conclusions and some future lines of work are presented 
Keywords: Swarm Intelligence, Particle Swarm Optimization, Neural Networks,  
 
Resumen 
El aprendizaje de juegos ha motivado el desarrollo de numerosas estrategias de Inteligencia 
Artificial. Si bien existen diferentes enfoques, la adaptación al entorno de información es una 
característica deseable cuando se busca resolver un problema complejo ya que hace innecesaria la 
codificación de cualquier tipo de conocimiento inicial.  
En esta área, las redes neuronales han brindado excelentes resultados pero generalmente con un  
costo computacional elevado. Existen trabajos previos donde se han utilizado heurísticas 
poblacionales, para reducir el tiempo de entrenamiento.  
En particular, el uso de estrategias evolutivas  basadas en cúmulos de partículas de tamaño fijo ha 
producido resultados satisfactorios. Este artículo propone modificar el tamaño de la población 
durante el  proceso de adaptación, agregando y eliminando individuos en función de su aptitud para 
resolver el problema planteado. 
El método propuesto ha sido aplicado en el entrenamiento de una red neuronal para jugar el juego 
de TaTeTi. Los resultados obtenidos han sido comparados con los de una estrategia basada en 
cúmulos de partículas con tamaño de población fija. Finalmente se exponen las conclusiones así 
como algunas líneas de trabajo futuras. 
Palabras Claves: Optimización mediante Cúmulos de Partículas (PSO), Redes Neuronales 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
VIII Workshop de Agentes y Sistemas Inteligentes
_________________________________________________________________________
 
 
1441
 1. Introducción 
Desde los principios de la Inteligencia Artificial, los investigadores han intentado desarrollar 
estrategias que les permitan a las computadoras aprender de una manera automática. En general se 
busca crear algoritmos capaces de generalizar comportamientos a partir de una información no 
estructurada suministrada en forma de ejemplos.  De esta manera, a semejanza del aprendizaje de 
los seres humanos, para aprender no se requiere conocer la solución específica del problema sino 
que la misma es extraída de la información disponible. Si bien estas estrategias poseen una amplia 
gama de aplicaciones, el aprendizaje de distintos tipos de juegos ha sido motivo de inspiración 
continua y aun lo sigue siendo. 
Muchos algoritmos de juegos tradicionales basan su funcionamiento en un árbol de jugadas. Esta 
estructura les permite seleccionar el próximo movimiento a realizar. Sin embargo, más allá de las 
complicaciones que implica la construcción del árbol y los esfuerzos realizados tanto para reducir 
su tamaño como para mejorar las estrategias sobre él aplicadas, resultan inapropiados cuando el 
espacio de búsqueda es amplio y complejo. 
Como alternativa a este tipo de soluciones se propone el uso de estrategias inteligentes que permitan 
desarrollar agentes capaces de aprender un juego basados únicamente en sus reglas y teniendo 
conocimiento del estado actual del mismo.  
En esta dirección existen soluciones basadas en Redes Neuronales que han producido excelentes 
resultados pero generalmente con un  costo computacional elevado. Existen trabajos previos donde 
se han utilizado heurísticas poblacionales, para reducir el tiempo de entrenamiento. En particular, la 
optimización mediante cúmulos de partículas (PSO - Particle Swarm Optimization)  ha producido 
resultados satisfactorios en una amplia gama de problemas de optimización, incluyendo el 
entrenamiento de redes neuronales  y la minimización de funciones. En todos los casos, el tamaño 
de la población utilizada permanece fijo durante el proceso adaptativo. 
Este artículo se propone diseñar un agente basado en una red neuronal entrenada mediante cúmulos 
de partículas con tamaño de población variable donde los individuos serán incorporados y 
eliminados en función de su aptitud para resolver el problema planteado. Esto se realiza a través del 
concepto de edad que permite determinar el tiempo de vida de cada elemento de la población. Si 
bien existen distintas formas para estimar el tiempo que cada individuo permanecerá dentro de la 
población, se utilizará el definido en [Lan01] ya que ha demostrado ser capaz de considerar  
adecuadamente la aptitud de los individuos. 
Con la intención de no poblar excesivamente un mismo lugar del espacio de soluciones, se utilizará 
una técnica de nichos de construcción dinámica definida en [Bir06]. En ella, se realiza un análisis 
estadístico de la población para definir la distancia adecuada entre dos individuos que pertenecen al 
mismo nicho.  
Este artículo se encuentra organizado de la siguiente forma: … 
 
2. Algoritmos basados en Cúmulos de Partículas 
Un algoritmo basado en Cúmulos de Partículas, también llamado Particle Swarm Optimization 
(PSO), es una técnica heurística poblacional donde cada individuo representa una posible solución 
del problema y realiza su adaptación teniendo en cuenta tres factores: su conocimiento sobre el 
entorno (su valor de fitness), su conocimiento histórico o experiencias anteriores (su memoria), el 
conocimiento histórico o experiencias anteriores de los individuos situados en su vecindario 
[Ken95]. Su objetivo es evolucionar su comportamiento de manera de asemejarse a los individuos 
con más éxito dentro de su entorno. En este tipo de técnica, cada individuo permanece en continuo 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
VIII Workshop de Agentes y Sistemas Inteligentes
_________________________________________________________________________
 
 
1442
 movimiento dentro del espacio de búsqueda y nunca muere. Por su parte, la población puede verse 
como un sistema multiagente donde cada individuo o partícula se mueven dentro del espacio de 
búsqueda guardando y eventualmente comunicando, la mejor solución que han encontrado.  
Existen distintas versiones de PSO; las más conocidas son gBest PSO que utiliza como criterio de 
vecindad a la población completa y lBest PSO que, por el contrario, utiliza un tamaño de vecindad 
pequeño [Ken95][Shi99]. El tamaño de la vecindad influye en la velocidad de convergencia del 
algoritmo así como es la diversidad de los individuos de la población. A mayor tamaño de vecindad, 
la convergencia del algoritmo es más rápida pero la diversidad de individuos es menor. 
Cada partícula pi está compuesta por tres vectores y dos valores de fitness: 
 El vector xi = (xi1, xi2, …, xin) almacena la posición actual de la partícula en el espacio de 
búsqueda. 
 El vector pBesti = (pi1, pi2, …, pin) almacena la posición de la mejor solución encontrada por la 
partícula hasta el momento. 
 El vector velocidad vi = (vi1, vi2, …, vin) almacena el gradiente (dirección) según el cual se 
moverá la partícula. 
 El valor de fitness fitness_xi almacena el valor de aptitud de la solución actual (vector xi). 
 El valor de fitness fitness_pBesti almacena el valor de aptitud de la mejor solución local 
encontrada hasta el momento (vector pBesti) 
La posición de una partícula se actualiza se la siguiente forma 
xi(t+1) = xi(t) + vi(t+1)        (1) 
Como se explicó anteriormente,  el vector velocidad se modifica teniendo en cuenta su experiencia 
y la de su entorno. La expresión es la siguiente: 
vij(t+1) = w . vi(t) + ϕ1 . rand1 . (pBesti – xi(t)) + ϕ2 . rand2 . (gi – xi(t))   (2) 
donde w representa el factor de inercia [Shi98],  ϕ1 y ϕ2 son constantes de aceleración, rand1 y  
rand2 son valores aleatorios pertenecientes al intervalo (0,1) y gi representa la posición de la 
partícula con el mejor pBest_fitness del entorno de pi (lBest o localbest) o de todo el cúmulo (gBest 
o globalbest). Los valores de w, ϕ1 y ϕ2 son importantes para asegurar la convergencia del 
algoritmo. Para más detalles sobre la elección de estos valores puede consultar  [Cle02] y [Ber02].  
La figura 1 contiene el algoritmo PSO básico 
Figura 1 
S ← InicializarCumulo()
while no se alcance la condición de terminación do
    for i = 1 to size(S) do
       evaluar la partícula xi del cúmulo S 
   if fitness(xi) es mejor que fitness(pBesti) then
             pBesti ← xi; fitness(pBesti) ← fitness(xi) 
        end if 
    end for 
    for i = 1 to size(S) do
        Elegir gi según el criterio de vecindad utilizado 
        vi ← w . vi + ϕ1 . rand1 . (pBesti – xi) + ϕ2 . rand2 . (gi – xi) 
        xi ← xi + vi
    end for 
end while 
Salida : la major solución encontrada
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
VIII Workshop de Agentes y Sistemas Inteligentes
_________________________________________________________________________
 
 
1443
 3. Cúmulos de Partículas con tamaño de población variable 
El algoritmo descripto en la sección anterior trabaja sobre una población de tamaño fijo. En este 
artículo se propone utilizar un cúmulo de tamaño variable buscando mejorar la relación de 
compromiso existente entre la velocidad de convergencia y la diversidad de la población. 
La variación en el tamaño de la población se logra permitiendo que las partículas se reproduzcan y 
mueran durante el proceso de adaptación. Esto requiere la definición de dos criterios: uno que 
permita saber si un individuo existente puede generar nuevos descendientes  y otro que indique 
como quitar elementos de la población. 
3.1. Criterio de reproducción 
La reproducción busca incrementar la velocidad de convergencia incorporando individuos en las 
zonas menos pobladas. Debe ser aplicada con moderación a fin de no aumentar excesivamente la 
cantidad de individuos dentro del espacio de búsqueda. Por lo tanto, es preciso analizar la 
distribución de las partículas dentro de dicho espacio para luego determinar si la reproducción 
puede llevarse a cabo o no. 
Para calcular la probabilidad de reproducción de cada una de las n partículas de la población S, se 
analizará su entorno tomando un radio de distancia r calculado de la siguiente forma [Bir06]: 
di = min{|| xi – xj || ; ∀j xi, xj ∈ S ^  xi ≠ xj}     con i = 1..n     (3) 
n
d
r
n
i
i∑
=
=
1            (4) 
El valor de r a utilizar es el mismo para todas las partículas. 
La probabilidad de reproducción de la i-ésima partícula se calcula de la siguiente forma [Fer05]: 
Probi = 1 – (CantVecinosExistentesi  / MAX_CANTIDAD)   con i = 1..n   (5) 
siendo CantVecinosExistentes la cantidad de partículas encontradas dentro del entorno del i-ésimo 
individuo de la población S y MAX_CANTIDAD es un parámetro del algoritmo que representa la 
máxima cantidad de individuos permitida. 
Para aquellos casos en que la medida de distancia de (3) no resulte apropiada para la  representación 
del espacio de búsqueda seleccionada, pueden verse otras alternativas en [Ert02]. 
Cada individuo de la población, según su probabilidad de reproducción, podrá generar un único 
descendiente aplicando mutación uniforme sobre los pesos de la red neuronal y copiando en el 
nuevo individuo su vector velocidad y su conocimiento social. 
 
3.2. Cálculo del tiempo de vida 
La permanencia de los individuos dentro de la población depende de su tiempo de vida. Dicho valor 
se expresa en cantidad de iteraciones, transcurridas las cuales, la partícula es eliminada. Este valor 
tiene  una estrecha relación con la aptitud de la partícula y permite que los mejores individuos 
permanezcan en la población por mayor tiempo, influenciando el comportamiento del resto. 
Para estimar el tiempo de vida de cada individuo de la población de utilizó el método de asignación 
por clases definido en [Lan01] ya que ha demostrado poseer la capacidad de brindar buenos 
resultados con una cantidad de individuos muy inferior a la empleada por los métodos 
convencionales. 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
VIII Workshop de Agentes y Sistemas Inteligentes
_________________________________________________________________________
 
 
1444
 En [Lan01] los individuos de la población son agrupados según su valor de aptitud en k clases 
utilizando un método de clustering competitivo del tipo winner-take-all, por ejemplo k-medias. 
Sobre el resultado de este agrupamiento puede aplicarse uno de los siguientes métodos: 
a) Asignación de tiempo de vida fijo por clase 
Se divide el máximo tiempo de tiempo de vida a asignar por la cantidad de clases, k. Esto permite 
saber el rango de tiempo que le corresponde a cada clase. Dentro de una misma clase, sus 
individuos recibirán un tiempo de vida proporcional a la clase a la que pertenecen y a la cantidad de 
individuos que se encuentran en su misma clase, de la siguiente forma: 
AnchoClase := MAX_LT / k 
TVClasesAnt := (ClaseMasCercana - 1)* AnchoClase 
TVClaseActual  := AnchoClase
Desplazamiento  = ( fitness[i] - Clase[ClaseMasCercana].MinFit ) / 
             abs(Clase[ClaseMasCercana].MaxFit - Clase[ClaseMasCercana].MinFit)) 
TiempoDeVida[i] := trunc(TVClasesAnt + WidthClass * Desplazamiento)  
donde 
- AnchoClase  es el rango del tiempo de vida asignado a cada clasen (dada por MAX_LT / 
Número de clases) 
- ClaseMasCercana es el número de clase a la que pertenece cada individuo. 
- TVClaseActual es el rango de tiempo de vida de la clase a la pertenece el individuo. 
- TVClasesAnt es el rango de tiempo de vida asignado a las clases anteriores a ClaseMasCercana. 
- Clase[ClaseMasCercana].MinFit y Clase[ClaseMasCercana].MaxFit son los valores de aptitud 
mínimo y máximo de la clase a la que pertenece el individuo en consideración. 
- Fitness[i] es el valor de aptitud del i-ésimo individuo de la población. 
 
b) Asignación de tiempo de vida proporcional a la cantidad de individuos de cada clase 
Cada clase recibe un rango de tiempo de vida proporcional a la cantidad de elementos que contiene. 
Es decir, que los individuos pertenecientes a las clases numerosas podrán tener un rango de tiempo 
de vida más amplio. El cálculo es el siguiente: 
TotalAnt := 0 
for i:=1 to ClaseMasCercana-1 do TotalAnt := TotalAnt + Clase[i].Cantidad 
TVAnterior := MAX_LT * TotalAnt / TotalIndiv 
TVClaseActual  := MAX_LT * Clase[ClaseMasCercana].Cantidad/TotalIndiv
Desplazamiento  = ( fitness[i] - Clase[ClaseMasCercana].MinFit ) / 
             abs(Clase[ClaseMasCercana].MaxFit - Clase[ClaseMasCercana].MinFit)) 
TiempoDeVida[i] := trunc(TVAnterior + WidthClass * Desplazamiento)  
donde 
- Clases[ClaseMasCercana].Cantidad representa la cantidad toal de individuos de la clase más 
cercana. 
- TotalIndiv es la cantidad total de individuos de la población. 
 
Estas dos formas de calcular los tiempos de vida de los individuos deben combinarse a fin de lograr 
una asignación correcta. Se propone aplicar la asignación b) durante un cierto porcentaje de  la 
cantidad de generaciones máximas del algoritmo y en las restantes utilizar a). Esto se debe a que los 
agrupamientos iniciales se realizan sobre individuos que aun no están lo suficientemente adaptados 
y por consiguiente dan lugar a agrupamientos de tamaños muy disímiles. Si sobre estos 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
VIII Workshop de Agentes y Sistemas Inteligentes
_________________________________________________________________________
 
 
1445
 agrupamientos se aplicara directamente la distribución indicada en a) muchos individuos recibirían 
tiempos de vida similares llevando al algoritmo a incrementar innecesariamente la cantidad de 
individuos de la población. 
 
3.3. Algoritmo propuesto 
El algoritmo comienza con una población de N individuos generados al azar dentro del espacio de 
búsqueda y calcula para cada uno de ellos su fitness y tiempo de vida correspondientes. 
Una vez medida la aptitud de todos los individuos de la población se calcula el radio según la 
ecuación (4). Esta medida será utilizada para estimar la cantidad de vecinos de cada individuo y 
tendrá una fuerte incidencia en la probabilidad de reproducción de cada uno de ellos ya que se 
utilizará la ecuación (5).  
La inercia utilizada para actualizar los vectores velocidad es ajustada durante el algoritmo de la 
siguiente forma [Mei02]: 
 
ctualIteracionA
TOTALESSITERACIONE
ww
ww endstartstart ._
)( −
−=      (6) 
 
donde wstart es el valor inicial de w y wend es el valor final.  
El uso de un peso de inercia variable facilita la adaptación de la población. Un valor de w alto al 
comienzo de la evolución le permite a las partículas realizar movimientos grandes ubicándose en 
distintas posiciones del espacio de búsqueda. A medida que avanza el número de iteraciones, el 
valor de w se reduce permitiéndoles realizar un ajuste más fino. 
El cálculo del valor de fitness depende del tipo de problema a resolver y será explicado con detalle 
en la sección de resultados. 
En cada iteración y utilizando la probabilidad de reproducción de cada individuo, existe la 
posibilidad de que se incorporen nuevos. Si esto ocurre, se define una nueva red neuronal copiando 
la red del padre (individuo original) con una mínima mutación uniforme y manteniendo el  mismo 
vector velocidad. 
Finalmente, el algoritmo termina cuando se cumple una de las siguientes condiciones: 
 Se alcanzó la cantidad máximas de iteraciones indicadas inicialmente 
 El mejor individuo no se ha modificado durante el 20% de las iteraciones totales 
 La población se ha quedado sin individuos. 
La figura 2 contiene un pseudocódigo del algoritmo descripto. 
 
4. Resultados 
El algoritmo propuesto en este trabajo fue utilizado para entrenar una población de redes neuronales 
para jugar el juego de TaTeTi. 
Es decir que cada individuo es una red feedforward totalmente interconectada con 9 entradas, una 
para cada posición del tablero e igual número de salidas. La función de transferencia utilizada en la 
capa oculta y en la capa de salida fue la sigmoidal, con la distinción que las salidas fueron 
redondeadas a modo de que pudiera interpretarse como una variable booleana. Se utilizó una 
codificación especial para los valores de entrada para permitirle a la red interpretar cuáles son sus 
posiciones ocupadas, cuáles las libres y cuáles las ocupadas por su oponente en el tablero, estando 
cada uno representado con el valor 1, 0 y -1, respectivamente. Sus pesos fueron adaptados mediante 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
VIII Workshop de Agentes y Sistemas Inteligentes
_________________________________________________________________________
 
 
1446
 el proceso evolutivo. Las mediciones realizadas acerca de la cantidad de neuronas de la capa oculta 
demuestran que los mejores resultados se obtienen utilizando entre 5 y 7 unidades.  
 
 
Figura 2 
 
// --- Población Inicial --- 
S ← {} 
for i = 1 to N do 
    xi ← Red Neuronal inicializada al azar con pesos ∈ (-1,1). 
    vi ← inicializar al azar entre el rango mínimo y máximo especificado.  
   evaluar el fitness de la partícula xi
   pBesti ← xi  
   fitness(pBesti) ← fitness(xi) 
   S ← S ∪ { (xi, vi, pBesti, fitness(xi), fitness(pBesti)) } 
end 
Calcular el Tiempo de Vida de cada partícula según 3.2.b)  
w ← INERCIA_MAXIMA
while no se alcance la condición de terminación do
    Calcular el radio r según la ecuación (4)  
    for i = 1 to size(S) do
       Elegir LBesti,la partícula con mejor fitness del entorno de xi
       vi ← w . vi + ϕ1 . rand1 . (pBesti – xi) + ϕ2 . rand2 . (LBesti – xi) 
       xi ← xi + vi
       Probi ← Calcular la probabilidad de reproducción de xi  
       //-- Reproducción -- 
       if rand < Probi then  
           Obtener x’i aplicando mutación uniforme sobre xi  
           Calcular el fitness de x’i 
           S ← S ∪ { (x’i, vi, pBesti, fitness(x’i), fitness(pBesti)) } 
             if (IteracionActual >  al 20% de las ITERACIONES_TOTALES)) 
   Calcular el Tiempo de Vida de x’i según 3.2.a) 
             Else 
   Calcular el Tiempo de Vida de x’i según 3.2.b) 
        end if 
        Disminuir en 1 el tiempo de vida de xi
        Si Tiempo_de_vida(xi)=0 then  
               S ← S - { (xi, vi, pBesti, fitness(xi), fitness(pBesti)) } 
    end for 
    w ← modificar dinámicamente la inercia
end while 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
VIII Workshop de Agentes y Sistemas Inteligentes
_________________________________________________________________________
 
 
1447
 Para evaluar el fitness de cada partícula se la hace jugar 7 veces contra otros individuos de la 
población elegidos al azar. En cada una de estas competencias también se selecciona al azar la 
partícula que comienza el juego. Cada red recibirá como resultado de cada enfrentamiento un 
puntaje que se irá acumulando a lo largo de las 7 pruebas. Los valores asignados son: 1 si gana el 
partido, -2 si pierde y 0 si empata. Aquellas situaciones en las que el juego no se haya resuelto en un 
número máximo de jugadas indicado a priori, serán consideradas equivalentes a haber perdido, es 
decir, que el puntaje asignado será -2. Esto último se relaciona con la aplicación de este algoritmo a 
otro tipo de juego de tablero distintos del TaTeTi.  En este caso particular el límite de jugadas 
impuesto para este caso es el doble del tamaño del tablero, es decir, 18.  
Los errores cometidos por la red durante el entrenamiento son considerados de manera aislada. Se 
considera error a aquellas situaciones en las que la red no brinda una jugada válida ya sea porque 
sugiere jugar en una posición ocupada o bien porque no indica ninguna salida. En estos casos se 
suman al total de errores de la res los valores 0.025 y 0.5 respectivamente. 
En resumen, la función de fitness utilizada es la siguiente 
 
       1 / ( 1 + (CantDeJuegosJugados+ ValorDelContadorDePuntaje) + ErroresDeLaRed )   (7) 
 
donde  CantDeJuegosJugados vale 7, ValorDelContadorDePuntaje es el resultado acumulado de 
los 7 juegos efectuados y ErroresDeLaRed es el valor acumulado de los errores producidos durante 
los 7 enfrentamientos. 
Se realizaron distintas pruebas utilizando una cantidad máxima de 300 iteraciones porque en 
ninguno de los casos se observaron mejoras significativas en el fitness más allá de ese valor. 
Los valores de aprendizaje cognitivo y social utilizados, ϕ1 y ϕ2  descriptos en la ecuación (2), 
fueron  ambos en 0.05. Los valores de inercia entre 0.05  y 0. El uso de valores tan pequeños 
lentifica el movimiento de las partículas impidiendo que se dispersen y caigan en la reproducción 
excesiva. 
La cantidad de vecinas máximas permitidas para la reproducción es 2. Las pruebas demuestran que, 
con hasta 3 vecinos el crecimiento se mantiene controlado. Sin embargo, un excesivo números de 
individuos no garantiza alcanzar el óptimo sino más bien, lentificar el algoritmo por lo que el 
número de vecinos permitidos fue 2. 
La cantidad de clases utilizadas para calcular el tiempo de vida de los individuos fue 4. Se 
realizaron pruebas con valores entre 2 y 10 confirmando que un valor alto para el número de clases, 
mejora la distinción del fitness entre los individuos pero incrementa sensiblemente el tamaño de la 
población. Por el otro lado, si la cantidad de clases es muy baja, la población puede llegar a 
desaparecer. Un valor de 4 clases es adecuado para el problema que se busca resolver. 
 
En la figura 3 pueden observarse los resultados alcanzados con un rango de velocidades mínimo de 
-0.05 y máximo de 0.05 y una probabilidad de mutación igual a 0, para evitar el movimiento 
excesivo y, por consiguiente, la superpoblación como se ha mencionado. Como puede verse, las 
soluciones basada en cúmulos de partículas (PSO) con tamaño de población variable permiten 
obtener redes con un fitness más alto que gBest PSO y lBest PSO. También se observa que PSO 
variable logra valores de fitness equivalentes a sus pares de población fija en un número de 
generaciones mucho menor. 
 
Las figuras 4 y 5 muestran la evolución de la diversidad de la población para las soluciones basada 
en cúmulos de partículas (PSO) con tamaño de población variable mostrando que están lejos de la 
convergencia prematura. 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
VIII Workshop de Agentes y Sistemas Inteligentes
_________________________________________________________________________
 
 
1448
 0,0000
0,1000
0,2000
0,3000
0,4000
0,5000
0,6000
0 12 24 36 48 60 72 84 96 10
8
12
0
13
2
14
4
15
6
16
8
18
0
19
2
20
4
21
6
22
8
24
0
25
2
26
4
27
6
28
8
M
e
jor
 
fit
ne
ss
Generaciones
Comparación de Todos los Algoritmos
gBest PSO  20 particulas
lBest PSO 20 particulas
lBest PSO variable 20 particulas
gBest PSO 16 particulas
lBest PSO 16 particulas
lBest PSO variable 16 particulas
 
Figura 3 
 
0,0000
0,0500
0,1000
0,1500
0,2000
0,2500
0,3000
0,3500
0,4000
0,4500
0,5000
1 12 23 34 45 56 67 78 89 100 111 122 133 144 155 166 177 188 199 210 221 232 243 254 265 276 287 298
Fi
tn
es
s
Generaciones
Evolución de la diversidad con 16 partículas
 
Figura 4 
 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
VIII Workshop de Agentes y Sistemas Inteligentes
_________________________________________________________________________
 
 
1449
 0,0
0,1
0,1
0,2
0,2
0,3
0,3
0,4
0,4
0,5
0,5
1 12 23 34 45 56 67 78 89 100 111 122 133 144 155 166 177 188 199 210 221 232 243 254 265 276 287 298
Fi
tn
e
ss
Generaciones
Evolución de la diversidad con 20 partículas
 
Figura 5 
 
5. Conclusiones 
Se ha presentado una estrategia basada en cúmulos de partículas de tamaño variable que permite 
entrenar redes neuronales. El mecanismo utilizado para incorporar nuevos individuos así como la 
forma de calcular el tiempo de vida preserva la diversidad de la población sin generar una cantidad 
excesiva de individuos. 
Su aplicación en la resolución del juego de TaTeTi ha sido comparada con gBest PSO y lBest PSO.  
Los resultados obtenidos muestran claramente que la estrategia propuesta en este artículo permite 
obtener redes con un mejor valor de aptitud que las producidas por ambas versiones de PSO con 
tamaño de población fijo. Es importante destacar que el algoritmo aquí propuesto genera redes 
neuronales con un valor de fitness equivalente a sus pares de población fija en una cantidad de 
generaciones muy inferior. 
Aun resta evaluar el comportamiento de la estrategia propuesta en la resolución de algunas 
funciones complejas clásicas como las empleadas en [Lan00].  Actualmente se está aplicando este 
algoritmo en el aprendizaje de juegos de tablero más complejos.  
 
 
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
VIII Workshop de Agentes y Sistemas Inteligentes
_________________________________________________________________________
 
 
1450
 6.
