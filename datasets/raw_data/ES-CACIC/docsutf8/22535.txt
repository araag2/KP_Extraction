Obtención de reglas de clasificación usando SOM PSO
﻿ Los mapas auto-organizativos (SOM – Self organizing maps) son un 
tipo de red neuronal ampliamente conocido por su capacidad para preservar la 
topología de los datos de entrada permitiendo mapear un espacio n-dimensional 
en otro de dos dimensiones. Luego de entrenar la red, las neuronas competitivas 
que la forman agrupan la información disponible facilitando de esta forma la 
identificación de similitudes; esto ha motivado su estudio como base para la 
obtención de reglas de asociación y clasificación. Este artículo presenta un 
nuevo método capaz de obtener reglas de clasificación que operan tanto sobre 
atributos numéricos como nominales, denominado SOM+PSO, que combina 
una red SOM con una metaheurística basada en cúmulo de partículas (variante 
de PSO - Particle swarm optimization). El método propuesto ha sido comparado 
con PART y  medido sobre 19 bases del repositorio UCI con resultados 
satisfactorios. 
Keywords: Reglas de clasificación, mapas auto-organizativos, inteligencia de 
cúmulo, minería de datos 
1. Introducción 
La Minería de Datos engloba un conjunto de técnicas capaces de modelizar la 
información disponible. Es una de las etapas más importantes del proceso de 
extracción de conocimiento y se caracteriza por obtener información útil y novedosa 
sin disponer de una hipótesis previa. Entre las técnicas preferidas por quienes tienen 
que tomar decisiones se encuentran las reglas de asociación.  
Una regla de asociación es una expresión de la forma SI condic1 ENTONCES condic2 
donde ambas condiciones son conjunciones de proposiciones de la forma 
                                                          
1 Becario CIN. Auxiliar docente. Fac.de Informática. UNLP 
2 Becario de postgrado UNLP Tipo A. Auxiliar docente. Fac.de Informática. UNLP 
3 Prof.Titular. Fac. De Informática. UNLP 
4 Docente UNTDF - Ushuaia 
  
(atributo=valor) y cuya única restricción es que los atributos que intervienen en el 
antecedente de la regla no formen parte del consecuente. Cuando el conjunto de reglas 
de asociación presenta en el consecuente el mismo atributo se dice que se trata de un 
conjunto de reglas de clasificación [1] [2]. 
Este artículo presenta un nuevo método de obtención de reglas de clasificación que 
combina una red neuronal con una técnica de optimización. El énfasis está puesto en 
alcanzar una buena cobertura utilizando un número reducido de reglas. 
La sección 2 describe brevemente algunos trabajos relacionados. Las secciones 3 y 4 
describen la red neuronal y la metaheurística utilizadas, respectivamente. La sección 5 
detalla el método propuesto. La sección 6 expone los resultados obtenidos y la 
sección 7 resume las conclusiones y describe algunas líneas de trabajo futuras. 
2. Trabajos relacionados 
Existen diversos métodos de construcción de reglas. Cuando se trata de obtener reglas 
de asociación puede utilizarse el método a priori [3] o algunas de sus variantes. En 
este caso se trata de identificar los conjuntos de atributos más frecuentes para luego 
combinarlos para obtener las reglas. Existen variantes del método a priori 
generalmente orientadas a reducir el tiempo de cálculo.  
Si se trabaja con reglas de clasificación, la literatura contiene distintos métodos de 
construcción basados en árboles como el C4.5 [4] o en árboles recortados como el 
método PART [5]. En cualquiera de los casos, lo fundamental es obtener un conjunto 
de reglas que cubra los ejemplos cumpliendo con una cota de error preestablecida. 
Los métodos de construcción de reglas a partir de árboles son partitivos y se basan en 
distintas métricas de los atributos a fin de estimar su capacidad de cobertura.  
Este artículo presenta un enfoque diferente basado en cúmulos de partículas (PSO -  
Particle Swarm Optimization) para determinar las reglas. Si bien existen métodos de 
obtención de reglas utilizando PSO [6], cuando se opera sobre atributos nominales es 
preciso contar con suficientes ejemplos como para cubrir todas las zonas del espacio 
de búsqueda y esto no siempre es factible. El resultado es una pobre inicialización de 
la población lo que da lugar a la convergencia prematura. Como forma de resolver 
este problema y a la vez reducir el tiempo de obtención, el estado inicial se obtiene de 
una red neuronal competitiva SOM (Self Organizing Map). Existen en la literatura 
métodos que utilizan PSO como forma de determinar la cantidad óptima de neuronas 
competitivas a utilizar en la red, como por ejemplo [7]. Esta no es la propuesta de este 
trabajo ya que la red SOM utilizada, si bien es dimensionada a priori, podría ser 
reemplazada por una red competitiva dinámica como la definida en [8]. 
3. SOM (Self-Organizing Maps) 
La red neuronal SOM (Self Organizing Maps) fue definida por Kohonen en 1982 [9]. 
Su aplicación principal es el agrupamiento de la información disponible y se 
caracteriza por su capacidad para preservar la topología de los datos de entrada.  
Puede ser representada como una estructura de dos capas: la capa de entrada cuya 
función es sólo permitir el ingreso de la información a la red y la capa competitiva 
que es la encargada de realizar el agrupamiento. Las neuronas que forman esta 
  
segunda capa se encuentran conectadas y poseen la capacidad de identificar la 
cantidad de “saltos” o conexiones que la separan de cada una de las restantes dentro 
de este nivel. Cada neurona competitiva lleva asociado un vector de pesos o centroide 
representado por los valores de los arcos que llegan a ella desde la capa de entrada.  
De esta forma, la red SOM maneja dos estructuras de información: una referida a los 
centroides asociados a las neuronas competitivas y otra encargada de determinar la 
proximidad entre neuronas. Esto, a diferencia de un método del estilo “winner-takeall” como el método k-medias, brinda información adicional con respecto a los 
agrupamientos ya que neuronas cercanas dentro de la arquitectura representarán 
agrupamientos similares en el espacio de los datos de entrada. 
Inicialmente los pesos de la red, almacenados en una matriz que se denominará W, 
son aleatorios y se adaptan con las sucesivas presentaciones de los datos de entrada. 
Por tratarse de una estructura competitiva, cada vector de entrada se considera 
representado por (o asociado con) la neurona competitiva que posea el vector de pesos 
más parecido según una medida de similitud dada. El valor final de W se obtiene 
mediante un proceso iterativo que se repite hasta que los vectores de pesos no 
presenten modificaciones significativas o lo que es lo mismo, hasta que cada vector 
de entrada sea representado por la misma neurona competitiva que en la iteración 
anterior. En cada iteración, para cada vector de entrada se determina la neurona que lo 
representa. A esta neurona se le llama neurona ganadora ya que es la que gana la 
competencia por la representación del vector (es la más parecida hasta el momento). 
Luego se actualiza el vector de peso de dicha neurona y de su vecindad según la 
ecuación (1) 
niwxww ijiijij ..1)( =−+= α  (1) 
siendo n la dimensión del espacio de entrada, j la neurona competitiva cuyo vector se 
desea actualizar y α un valor entre 0 y 1 que representa la velocidad de aprendizaje.  
La ecuación (1) tiene variantes que pueden consultarse en [10]. 
El concepto de vecindad es utilizado para permitir que la red se adapte 
adecuadamente. Esto implica que neuronas competitivas vecinas representen patrones 
de entrada similares. Por tal motivo, durante el proceso de entrenamiento (obtención 
de los valores de W) se comienza con una vecindad amplia para luego ir reduciéndola 
a lo largo de las iteraciones. 
4. PSO aplicado a la obtención de reglas 
La optimización mediante cúmulo de partículas o PSO (Particle Swarm Optimization) 
es una metaheurística poblacional propuesta por Kennedy y Eberhart [11] donde cada 
individuo de la población, denominado partícula, representa una posible solución del 
problema y se adapta siguiendo tres factores: su conocimiento sobre el entorno (su 
valor de aptitud), su conocimiento histórico o experiencias anteriores (su memoria) y  
el conocimiento histórico o experiencias anteriores de los individuos situados en su 
vecindario (su conocimiento social). 
PSO fue definido originalmente para trabajar sobre espacios continuos pero si se trata 
de operar sobre un espacio discreto es preciso tener en cuenta algunas 
consideraciones. Por tal motivo, Kennedy y Eberhart definieron en [12] una versión 
binaria del método PSO. Uno de los problemas centrales que presenta este último 
  
método es su dificultad para cambiar de 0 a 1 y de 1 a 0 una vez que se ha 
estabilizado. Esto ha dado lugar a distintas versiones de PSO binario que buscan 
mejorar su capacidad exploratoria. En particular, en este trabajo se utiliza la variante 
definida por Lanzarini et al. en [13]. 
La obtención de reglas de clasificación utilizando PSO, capaces de operar sobre 
atributos nominales y numéricos, requiere de una combinación de los métodos citados 
anteriormente ya que es preciso decir cuáles serán los atributos que formarán parte del 
antecedente (discreto) y cuál es el valor o rango de valores que podrán tomar 
(continuo). En este artículo se ha decidido adoptar el enfoque Michigan [14] es decir 
que cada partícula de la población representa una única regla. Por simplicidad, el 
consecuente de la regla no será codificado en el individuo y por lo tanto, todas las 
partículas buscarán obtener reglas de una misma clase decidida a priori. A fin de no 
perder diversidad, se aplicará el método propuesto de manera iterativa hasta lograr la 
cobertura total buscada obteniendo una única regla en cada iteración: el mejor 
individuo de la población. 
Para desplazarse en un espacio n-dimensional, cada partícula pi está compuesta por  
 indivBinarioi = (indBini1, indBini2, …, indBinin) almacena la posición actual de 
la partícula.  
 veloc1i = (v1i1, v1i2, …, v1in) y veloc2i = (v2i1, v2i2, …, v2in) se combinan para 
determinar la dirección en la cual se moverá la partícula. 
 pBestBinarioi = (pBini1, pBini2, …, pBinin) almacena la mejor solución 
encontrada por la partícula hasta el momento. 
 fitnessi es el valor de aptitud del individuo. 
 fitness_pBesti es el valor de aptitud de la mejor solución local encontrada (vector 
pBestBinarioi) 
 indivReali = (indRi1, indRi2, …, indRin) sólo se utiliza para los atributos 
numéricos y contiene los límites actuales de los intervalos.  
 velocReali = (vi1, vi2, …, vin) indica la dirección de cambio de indivReali. 
 pBestReali = (pReali1, pReali2, …, pRealin) almacena la mejor solución 
encontrada por la partícula para los límites de los intervalos. 
Cada vez que la i-ésima partícula se mueve se modifica su posición actual y los 
intervalos correspondientes a los atributos numéricos siguiendo los correspondientes 
vectores de velocidad, de la siguiente forma: 
 
Parte binaria 
v1ij(t+1)=wbin.v1ij(t)+ϕ1.rand1.(2*pBinij -1)+ϕ2.rand2.(2*localBestij -1) (2) 
donde, wbin representa el factor de inercia,  rand1 y rand2 son valores aleatorios con 
distribución uniforme en [0,1] y ϕ1 y ϕ2 son valores constantes de indican la 
importancia que se desea darle a las respectivas soluciones halladas previamente. Los 
valores pBinij y localBestij corresponden al  j-ésimo dígito de los vectores binarios 
pBestBinarioi  y localBesti respectivamente. En el método propuesto, cada partícula 
tendrá en cuenta la posición de su vecino más cercano con un valor de aptitud 
superior al suyo; por lo tanto el valor de localBesti  corresponde al vector de 
  
indivBinario de la partícula más cercana a pi con un valor de fitness superior a fitnessi 
usando distancia euclídea. 
Nótese que, a diferencia del PSO Binario de [12], el desplazamiento del vector 
veloc1i en las direcciones correspondientes a la mejor solución encontrada por la 
partícula y al mejor local no dependen de la posición actual de dicha partícula, como 
se indica en [13]. Luego, cada elemento del vector velocidad veloc1i es controlado 
según (3) 





−≥−
>
=
contrariocasoentv
deltatvsidelta
deltatvsidelta
tv
ij
jijj
jijj
ij
)(1
1)(11
1)(11
)(1  (3) 
donde                      
2
1lim1lim
1
infsup jj eriorerior
j
iteite
delta
−
=  (4) 
Es decir que, el vector velocidad veloc1i se calcula según (2) y se controla según (3). 
Su valor se utiliza para actualizar el valor del vector velocidad veloc2i, como se 
indica en (5). 
)1(1)(2)1(2 ++=+ tvtvtv ijijij  (5) 
El vector veloc2i también se controla de manera similar al vector veloc1i cambiando 
limite1superior j y limite1inferior j por limite2superior j y limite2inferior j respectivamente. Esto 
dará lugar a delta2j que será utilizado como en (3) para acotar los valores de veloc2i. 
Luego se le aplica la función sigmoide (6) y se calcula la nueva posición de la 
partícula según (7). 
xexsig −+= 1/1)(  (6) 


 +<
=+
nosi
tvsigrandsi
tioindivBinar ijijij 0
))1(2(1
)1(  (7) 
donde  randij es un número aleatorio con distribución uniforme en [0,1]. 
 
Parte continua  
indRij(t+1) = indRij(t) + vij(t+1) (8) 
  vij(t+1)=wReal.vij(t)+ϕ3.rand3.(pRealij–indRij(t))+ϕ4.rand4.(lBestRealij–
indRij(t)) 
(9) 
donde nuevamente, wReal representa el factor de inercia,  rand3 y rand4 son valores 
aleatorios con distribución uniforme en [0,1] y ϕ3 y ϕ4 son valores constantes de 
indican la importancia que se desea darle a las respectivas soluciones halladas 
previamente. En este caso, lBestReal corresponde al vector indivReal de la partícula 
más cercana a pi con un valor de fitness superior a fitnessi usando distancia euclídea. 
Esta es la misma partícula de la que se tomó el vector indivBinario para realizar el 
ajuste de veloc1i en (2). 
Los valores asignados a  wReal [15], ϕ1, ϕ2, ϕ3 y ϕ4 son importantes para garantizar la 
convergencia del algoritmo. Puede encontrar información más detallada referida a la 
selección de estos valores en [11] y [16]. 
  
Además, es importante remarcar que la incorporación de la función sigmoide (6) 
cambia radicalmente la manera de utilizar el vector velocidad para actualizar la 
posición de la partícula. En PSO continuo, el vector velocidad toma valores mayores 
al inicio para facilitar la exploración del espacio de soluciones y al final se reduce 
para permitir que la partícula se estabilice. En PSO binario ocurre precisamente todo 
lo contrario. Los valores extremos, al ser mapeados por la función sigmoide, producen 
valores de probabilidad similares, cercanos a 0 o a 1, reduciendo la chance de cambio 
en los valores de la partícula. Por otro lado, valores del vector velocidad cercanos a 
cero incrementan la probabilidad de cambio. Es importante considerar que si la 
velocidad de una partícula es el vector nulo, cada uno de los dígitos binarios que 
determina su posición tiene probabilidad 0.5 de cambiar a 1. Es la situación más 
aleatoria que puede ocurrir. 
En este trabajo, los valores de limite1 y limite2 son iguales para todas las 
dimensiones; estos son [0,1] y [0,6] respectivamente. Por lo tanto, los valores de los 
vectores velocidad veloc1 y veloc2 fueron limitados a los rangos [-0.5, 0.5] y [-3,3] 
respectivamente. Es decir que pueden obtenerse probabilidades en el intervalo  
[0.0474, 0.9526]. Los valores para ϕ1, ϕ2, ϕ3 y ϕ4 fueron establecidos en 0.25, 0.25, 
0.5 y 0.25 respectivamente. Los valores de wbin y wReal fueron establecidos entre 1.25 
y 0.25 de manera lineal y proporcional a la cantidad de iteraciones realizadas, en 
forma ascendente para wbin y  en forma descendente para wReal. 
El fitness de cada partícula se calcula en base al soporte, la confianza de la regla y la 
cantidad de atributos utilizados en el antecedente de la siguiente forma: 
Fitness = penalizacion * (soporte/L) * confianza – factor * NumAtribs/MaxAtribs (10) 
donde soporte y confianza son las métricas correspondientes a la regla que representa 
la partícula, L es la cantidad de ejemplos a considerar, factor es una constante que 
cuantifica la importancia que se le da a la longitud del antecedente, NumAtribs es la 
cantidad de comparaciones que intervienen en el antecedente de la regla (una por 
atributo) y MaxAtribs es la máxima cantidad de comparaciones que podrían 
presentarse. 
La penalización es un valor entre 0.1 y 1 que reduce el producto de soporte y 
confianza si es necesario. Se calcula de la siguiente forma: 
Function Penalizar(VALOR, UMBRAL1, UMBRAL2, MIN,MAX) 
  if (VALOR < UMBRAL1),  
       rta = MIN; 
  elseif (VALOR < UMBRAL2) 
       rta = MIN+(MAX-MIN)*[(VALOR-UMBRAL1)/(UMBRAL2-UMBRAL1)+UMBRAL1]; 
  else rta = 1; 
  end 
  return(rta) 
end 
 
SOP_MIN1 = max(2, 5% de los ejemplos de la clase); 
SOP_MIN2 = max(4, 7.5% de los ejemplos de la clase); 
Pena_SOP = Penalizar(soporte, SOP_MIN1, SOP_MIN2,0.1,0.75); 
CONF_MIN1 = límite de confianza inferior (ej: 0.4);  
CONF_MIN2 = límite de confianza superior (ej: 0.7); 
Pena_CONF = Penalizar(confianza, CONF_MIN1, CONF_MIN2,0.1,0.7); 
  
Penalizacion = min(Pena_SOP, Pena_CONF) 
5. SOM+PSO. Método de obtención de reglas propuesto 
Las reglas se obtienen a través de un proceso iterativo que analiza los ejemplos no 
cubiertos de cada clase comenzando por las más numerosas. Cada vez que se obtiene 
una regla, los ejemplos cubiertos correctamente por dicha regla son retirados del 
conjunto de datos de entrada. El proceso continúa hasta lograr cubrir todos los 
ejemplos o hasta que la cantidad de ejemplos no cubiertos de cada clase se encuentre 
por debajo del respectivo soporte mínimo establecido o hasta que se hayan realizado 
la máxima cantidad de intentos por obtener una regla, lo que ocurra primero. Es 
importante tener en cuenta es que, dado que los ejemplos son retirados del conjunto 
de datos de entrada a medida que son cubiertos por las reglas, las mismas constituyen 
una lista de clasificación. Es decir que, para clasificar un ejemplo nuevo, las reglas 
deben ser aplicadas en el orden en que fueron obtenidas y el ejemplo será clasificado 
con la clase correspondiente al consecuente de la primera regla cuyo antecedente se 
verifique para el ejemplo en cuestión. 
Antes de comenzar con el proceso iterativo de obtención de reglas, el método inicia 
con el entrenamiento no supervisado  de una red SOM utilizando el conjunto 
completo de ejemplos que se espera cubrir. La red se entrena de manera no 
supervisada siguiendo el algoritmo descripto en la sección 2 y su función es 
identificar las zonas más prometedoras del espacio de búsqueda. 
Dado que la red SOM sólo opera con datos numéricos, los atributos nominales son 
representados en forma binaria. Además, antes de iniciar el entrenamiento, cada 
dimensión correspondiente a un atributo numérico es escalada linealmente en [0,1]. 
La medida de similitud utilizada es distancia euclídea. Una vez finalizado el 
entrenamiento, cada centroide contendrá aproximadamente el promedio de los 
ejemplos que representa.  
Para obtener cada una de las reglas se determina, en primer lugar, cual es la clase 
correspondiente al consecuente. Buscando obtener reglas con soporte alto, el método 
propuesto comenzará a analizar primero las clases que posean un mayor número de 
ejemplos no cubiertos. El soporte mínimo que debe cumplir una regla es proporcional 
a la cantidad de ejemplos no cubiertos de la clase al momento en que fue obtenida. Es 
decir, que el soporte mínimo requerido para cada clase disminuye a lo largo de las 
iteraciones, a medida que los ejemplos de la clase correspondiente se van cubriendo. 
De esta forma, es de esperar que las primeras reglas posean mayor soporte que las 
últimas. 
Una vez seleccionada la clase, queda determinado el consecuente de la regla. Para 
obtener el antecedente  se optimizará, utilizando el algoritmo descripto en la sección 
3, una población de partículas inicializada con la información de todos los centroides 
capaces de representar un número mínimo de ejemplos de la clase seleccionada y sus 
vecinos inmediatos.  La información del centroide se utiliza para determinar el vector 
veloc2 descripto en la sección 3. Si se trata de un atributo nominal, la información del 
centroide se escala linealmente al intervalo [limite2inferior j , limite2superior j] pero si se 
trata de un atributo numérico el valor a escalar es (1-1.5*desviacionj) siendo 
desviacionj la j-ésima dimensión de la desviación de los ejemplos representados por 
el centroide. En ambos casos se pretende operar con un valor entre 0 y 1 que mida el 
  
grado de participación del atributo (si es numérico) o del valor del atributo (si es 
nominal) en la construcción del antecedente de la regla. Cuando se trata de atributos 
nominales es claro que el promedio indica la proporción de elementos representados 
por el centroide que coinciden en el mismo valor pero cuando son numéricos, esta 
proporción no se encuentra presente en el centroide sino en la desviación de los 
ejemplos (siempre considerando una dimensión específica). Si la desviación en cierta 
dimensión es cero, todos los ejemplos coindicen en el valor del centroide pero si es 
demasiado amplia, debería entenderse que no es representativo del grupo y por lo 
tanto no sería conveniente incluirlo en el antecedente de la regla. Utilizando 
(1-1.5*desviacionj) si la desviación es alta, el valor de la velocidad veloc2, argumento 
de la función sigmoide, será menor y se reducirá la probabilidad de que el atributo sea 
utilizado. En todos los casos la velocidad veloc1 se inicializa en forma aletoria en  
[limite1inferior j , limite1superior j]. La figura 1 muestra el pseudocódigo del método 
propuesto. 
 
Entrenar la red SOM utilizando todos los ejemplos de entrenamiento. 
Calcular el soporte mínimo para cada clase. 
Mientras (no se alcance el criterio de terminación) 
 Elegir la clase con mayor nro.de ejemplos no cubiertos 
 Construir una población reducida de individuos a partir de los centroides 
 Evolucionar la población utilizando PSO según lo visto en la sección 4.3 
 Obtener la mejor regla de la población 
 Si (la regla cumple con el soporte y la confianza pedidos) entonces 
  Agregar la regla al conjunto de reglas 
Considerar como cubiertos los ejemplos correctamente clasificados 
por la regla anterior. 
   Recalcular el soporte mínimo para esta clase. 
Fin Si 
Fin mientras 
Fig.1: Pseudocódigo del método propuesto 
6. Resultados obtenidos 
En esta sección se compara la performance del método propuesto con el método 
PART definido por Frank y Witten en [5] en la obtención de las reglas de 
clasificación para un conocido conjunto de bases de datos del repositorio UCI [17].  
Para ello, se realizaron 10 corridas independientes de cada método y se utilizó una red 
SOM de 30 neuronas organizadas en 6 filas y 5 columnas con 4 vecinos por neurona. 
El método PART fue ejecutado con un factor de confianza de 0.3 para el podado del 
árbol y con el resto de sus parámetros con sus valores por defecto. 
La Tabla 1 resume los resultados obtenidos al aplicar ambos métodos. En cada caso se 
ha considerado no sólo la precisión de la cobertura del conjunto de reglas sino 
también la claridad del modelo obtenido; esto último se refleja en la cantidad 
promedio de reglas obtenidas y en la cantidad promedio de términos utilizados para 
formar el antecedente. Se ha realizado en cada caso un test de Student de diferencia 
de medias de dos colas con un nivel de significación de 0.05 donde la hipótesis nula 
  
implica que las medias son iguales. Cuando la diferencia es significativa, según el 
nivel indicado, se ha marcado en la tabla la mejor opción en negrita. 
Tabla 1 : Resultados  obtenidos al aplicar los métodos SMO+PSO y PART a un conjunto de 
bases del repositorio UCI. Se ha medido la precisión, la longitud promedio del antecedente de 
cada regla y la cantidad de reglas utilizadas en cada caso. Se indica en negrita la mejor solución 
utilizando un test Student con nivel de significación 0.05. 
 
 
Como puede observase, en los 6 casos en los que la precisión de PART es superior a 
la del método propuesto, la cobertura obtenida por SOM+PSO es muy buena si se 
tiene en cuenta el reducido número de reglas que utiliza. Por ejemplo, para la base 
‘balance_scale’, SOM+PSO tiene una precisión inferior a PART en aprox. un 8% 
pero utiliza un quinto de la cantidad de reglas con menos consultas en cada 
antecedente. Algo parecido ocurre en los otros 5 casos donde PART posee una 
precisión superior a SOM+PSO. Esto se debe al énfasis puesto en la simplificación 
del modelo. En los 13 casos restantes o no hay diferencias significativas en la 
precisión alcanza o SOM+PSO es mejor. Independientemente de la precisión, la 
longitud promedio del conjunto de reglas siempre ha sido menor en el método 
propuesto. 
7. Conclusiones 
Se ha presentado un nuevo método de obtención de reglas de clasificación que utiliza 
una variante de PSO binario cuya población de inicializa con la información de los 
centroides de una red SOM previamente entrenada permitiendo, a través de esta 
combinación, operar con atributos numéricos y nominales. 
Las mediciones realizadas permiten afirmar que el método SOM+PSO obtiene un 
modelo más simple ya que en promedio utiliza aproximadamente el 20% de la 
  
cantidad de reglas que genera PART, con antecedentes formados por pocas 
condiciones y una precisión aceptable. 
Si bien no han sido incluídas en este artículo, las mediciones realizadas aplicando el 
método propuesto pero omitiendo la optimización que introduce PSO ha dado lugar a 
un conjunto de reglas de precisión similar pero con una cardinalidad ligeramente 
superior a PART. Esto demuestra que las pocas iteraciones que se realizan con PSO a 
la información de los centroides es fundamental para determinar un adecuado 
conjunto de reglas. 
Actualmente, si bien en base a las pruebas realizadas no se ha evidenciado ninguna 
dependencia entre los resultados obtenidos y el tamaño inicial de la red SOM, se 
considera de interés repetir las mediciones utilizando una red SOM dinámica.  
References 
1. Witten Ian H., Frank Eibe, Hall Mark A.. Data Mining: Practical Machine Learning Tools 
and Techniques. 3rd Edition. Elsevier. 2011. ISBN 978-0-123-74856-0. 
2. José Hernández Orallo, M. José Ramírez Quintana, Cèsar Ferri Ramírez. Introducción a la 
Minería de Datos. 1ra Edición. Pearson, 2004. ISBN 978-8-420-54091-7. 
3. Rakesh Agrawal, Ramakrishnan Srikant. Fast Algorithms for Mining Association Rules in 
Large Databases. 20th International Conference on Very Large Data Bases, VLDB, pages 
487-499, Santiago, Chile, September 1994. 
4. Quinlan John Ross. C4.5: Programs for Machine Learning. Morgan Kaufmann Publishers, 
San Mateo, CA, 1993. 
5. Frank Eibe, Witten Ian H. Generating Accurate Rule Sets Without Global Optimization. 
Fifteenth International Conference on Machine Learning, 144-151, 1998. 
6. Wang Ziqiang, Sun Xia y Zhang Dexian. A PSO-Based Classification Rule Mining 
Algorithm. Advanced Intelligent Computing Theories and Applications. LNCS 2007. 
Springer. Pag.377-384. Vol 4682. ISBN 978-3-540-74201-2. 
7. Hung Chihli, Huang Lynn. Extracting Rules from Optimal Clusters of Self-Organizing 
Maps. 2nd International Conference on Computer Modeling and Simulation – Vol.1, pag. 
382-386.2010. 
8. Hasperué W, Lanzarini L. Dynamic Self-Organizing Maps. A new strategy to upgrade 
topology preservation. XXXI Conf. Latinoamericana de Informática, CLEI 2005 
9. Kohonen Teuvo. Self-organized formation of topologically correct feature maps. 
Biological Cybernetics. Springer Berlin/ Heidelberg. Vol43, nro. 1. Pp.59-69. Ed. 1982.  
10. Kohonen Teuvo. Self-organizing Maps. 3th Edition. Springer. 2001. ISBN 3-540-67921-9. 
11. J. Kennedy and R. Eberhart. Particle swarm optimization. IEEE International Conference 
on Neural Networks, IV:1942–1948, 1995. 
12. J. Kennedy and R. C. Eberhart. A discrete binary version of the particle swarm Algorithm. 
Conference on Systems, Man, and Cybernetics, p. 4104-4109, 1997 
13. Lanzarini L, López J., Maulini J., De Giusti A. A new Binary PSO with velocity control. 
Advances in Swarm Intelligence. LNCS 2011, Vol 6728/2011, 111-119. Springer 2011. 
14. J. H. Holland. Escaping brittleness: the possibilities of general-purpose learning 
algorithms applied to parallel rule-based systems. Machine Learning, an artificial 
intelligence approach: Volume II. Morgan Kaufmann, Los Alamos, CA, 1986. 
15. Shi Y., Eberhart R. Parameter Selection in Particle Swarm Optimization. 7th International 
Conference on Evolutionary Programming. pp. 591-600. Springer Verlag 1998.  
16. J. Kennedy and R. Eberhart. Swarm Intelligence. Morgan Kaufmann Publishers, Inc., San 
Francisco, CA, 2001. 
17. UC Irvine Machine Learning Repository. http://archive.ics.uci.edu/ml/ 
