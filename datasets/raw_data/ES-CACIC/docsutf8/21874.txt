Eligiendo raíces para el Árbol de aproximación espacial
﻿
Many computational applications need to search information in a database. At the present time the predominance of multimedia databases does that the similarity search or proximity search, that is to look for elements
of the database that are similar to a given query element, becomes a preponderant concept.
The Spatial Approximation Trees have shown to be competitive for similarity search in spaces with medium
to high dimensionality (“difficult” spaces) or for queries with low selectivity. Nevertheless, for its construction
its root was chosen randomly and it completely determines the tree, not only in its shape but also in its searching
performance. Thus, our interest was to optimize searches in this data structure trying to choose the tree root in
a way that the characteristics of indexed space can be reflected. We consider that, by this way, the data structure
can adapt itself better to the dimension of the considered metric space, which results in more efficient similarity
searches.
Keywords: similarity search, metric spaces, databases, algorithms.
Resumen
Muchas aplicaciones computacionales necesitan buscar información en una base de datos. En la actualidad el
predominio de las bases de datos multimedia hace que la búsqueda por similitud o búsqueda por proximidad,
es decir buscar elementos de la base de datos que sean similares a un elemento de consulta dado, se vuelva un
concepto preponderante.
El Árbol de Aproximación Espacial ha demostrado ser muy competitivo para la búsqueda por similitud en
espacios métricos de media a alta dimensionalidad (espacios “difíciles”) o para responder a consultas con baja
selectividad. Sin embargo, para su construcción se elegía su raíz al azar y ello determinaba completamente el
árbol tanto en su forma como en su desempeño. Así, nuestro interés fue el de optimizar las búsquedas en dicha
estructura tratando de que la raíz sea elegida de manera tal que refleje alguna de las características propias
del espacio métrico a indexar. Creemos que de esta forma permitimos que la estructura se adapte mejor a la
dimensión intrínseca del espacio métrico considerado, lo cual redunda en búsquedas más eficientes.
Keywords: búsqueda por similitud, espacios métricos, bases de datos, algoritmos.
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
365
1. INTRODUCCIÓN Y MOTIVACIÓN
Con la evoluci·on de las tecnolog·as de informaci·on y comunicaci·on, han surgido almacenamientos
no estructurados de informaci·on. No s·olo se consultan nuevos tipos de datos tales como texto libre,
im·agenes, audio y v·deo; sino que, en algunos casos, no se puede estructurar m·as la informaci·on
en claves y registros. Estos tipos de datos son dif·ciles de estructurar para adecuarlos al concepto
tradicional de b·usqueda. A·un cuando sea posible una estructuraci·on cl·asica, nuevas aplicaciones tales
como la miner·a de datos requieren acceder a la base de datos por cualquier campo y no s·olo los
marcados como claves. As·, han surgido aplicaciones en grandes bases de datos donde se desea
buscar objetos similares. Este tipo de b·usqueda se conoce con el nombre de b·usqueda aproximada o
b·usqueda por similitud y tiene aplicaciones en numerosos campos.
Como en toda aplicaci·on que realiza b·usquedas, surge la necesidad de tener una respuesta r·apida
y adecuada. El planteo general del problema es: existe un universo U de objetos y una funci·on de
distancia positiva d: U×U→ R+ denida entre ellos. Esta funci·on de distancia satisface los axiomas
que hacen que el par (U, d) sea un espacio m·etrico: positividad estricta (d(x, y) = 0 ⇔ x = y),
simetr·a (d(x, y) = d(y, x)) y desigualdad triangular (d(x, z) ≤ d(x, y) + d(y, z)). Mientras m·as
similares sean dos objetos menor ser·a la distancia entre ellos. Tenemos una base de datos nita
S ⊆ U que puede ser preprocesada (v.g. para construir un ·ndice). Luego, dado un nuevo objeto del
universo (una query q), debemos recuperar todos los elementos similares que se encuentran en la base
de datos. Existen dos consultas b·asicas de este tipo:
Búsqueda por rango: recuperar todos los elementos de S a distancia a lo m·as r de un elemento q
dado.
Búsqueda de k vecinos más cercanos: dado q, recuperar los k elementos m·as cercanos a q en S.
La distancia se considera costosa de evaluar (por ejemplo, comparar dos huellas dactilares). Por
lo tanto, es usual denir la complejidad de la b·usqueda como el n·umero de evaluaciones de distancia
realizadas, dejando de lado otras componentes. Entonces, el objetivo es generar un ·ndice que permita
reducir al m·axino el c·alculo de distancias durante una b·usqueda.
Un caso particular de este problema surge cuando el espacio es un conjunto D-dimensional de
puntos y la funci·on de distancia pertenece a la familia Lp de Minkowski: Lp = (
∑
1≤i≤d |xi−yi|p)1/p.
Existen m·etodos efectivos para buscar sobre espacios D-dimensionales, tales como Kdtrees [2, 3] o
R-trees [8]; pero, para 20 dimensiones o m·as dejan de trabajar bien. Aunque nos dedicamos a espacios
m·etricos generales, las soluciones planteadas son adecuadas para espacios Ddimensionales.
En [6, 4, 5] se muestra que el concepto de dimensionalidad intr·nseca se puede entender a·un en
espacios m·etricos generales, se da una denici·on cuantitativa de ella y se muestra anal·ticamente la
raz·on para la llamada maldici·on de la dimensionalidad. Es interesante notar que el concepto de
dimensionalidad est·a relacionado con la facilidad o dicultad para buscar en un espacio vectorial
D-dimensional. Se dice que un espacio m·etrico general es m·as dif·cil (dimensi·on intr·nseca m·as
alta) que otro cuando su histograma de distancia es m·as concentrado. Esto hace que el trabajo de
cualquier algoritmo de b·usqueda por similitud sea m·as dicultoso. En el caso extremo tenemos un
espacio donde d(x, x) = 0 y ∀y 6= x, d(x, y) = 1. En este caso, la consulta q debe ser exhaustivamente
comparada contra cada elemento en el conjunto.
De las situaciones descriptas vemos que necesitamos contar con ·ndices que permitan responder
ecientemente a cada consulta. Existen numerosos m·etodos para preprocesar un conjunto a n de
reducir el n·umero de evaluaciones de distancia y, en general, todos ellos se basan en dividir la base de
datos, lo que se ha heredado de las ideas cl·asicas de dividir para conquistar y de la b·usqueda de datos
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
366
t·picos (v.g. ·arboles de b·usqueda binaria). Uno de estos m·etodos que sigue un enfoque distinto y que
ha demostrado ser eciente es el ·Arbol de Aproximaci·on Espacial (SAT por su sigla en ingl·es), ver
[12], que se basa en la aproximaci·on espacial. Esta estructura de datos es est·atica; es decir, necesita
contar con los elementos de la base de datos de antemano para construir el ·ndice que luego permita
responder consultas por similitud. Nuestro trabajo consisti·o en optimizar esta estructura de datos a n
de mejorar, principalmente, su desempeno en las b·usquedas.
El SAT ha demostrado ser muy competitivo en espacios m·etricos de media o alta dimensionalidad
o para responder a consultas con baja selectividad. Sin embargo, para su construcci·on se eleg·a su ra·z
al azar y ello determinaba completamente el ·arbol tanto en su forma como en su desempeno [9, 13].
As·, nuestro inter·es fue el de optimizar las b·usquedas en dicha estructura seleccionando de diferente
manera la ra·z del ·arbol, de forma tal que reeje alguna de las caracter·sticas propias del espacio
m·etrico a indexar. Creemos que vale la pena tomarse el trabajo de elegir mejor la ra·z y de esta forma
permitir que la estructura se adapte mejor a la dimensi·on intr·nseca del espacio m·etrico considerado,
lo cual redunda en b·usquedas m·as ecientes.
2. ÁRBOL DE APROXIMACIÓN ESPACIAL
El m·etodo de aproximaci·on espacial comienza la b·usqueda en alg·un punto del espacio y trata de
acercarse espacialmente a la consulta q. La estructura de datos que utiliza este m·etodo de b·usqueda
es el SAT. Comenzaremos viendo en qu·e consiste la aproximaci·on espacial.
Consideremos un espacio m·etrico (U, d) y a S ⊆ U que ser·a nuestra base de datos. Para describir
la idea b·asica de la aproximaci·on espacial analizaremos las consultas de 1-vecino m·as cercano o
1-NN. Al buscar el vecino m·as cercano a q nos posicionamos en un elemento a ∈ S elegido al azar, y
nos acercarmos cada vez m·as y m·as a q movi·endonos a otro elemento b ∈ S tal que d(b, q) < d(a, q).
Cuando no podamos acercarnos m·as a q ser·a porque encontramos el elemento m·as cercano a ·el. Este
proceso debe hacerse entre elementos que son vecinos, o sea, estando en a s·olo podemos acercarnos
a q por medio de alguno de los vecinos de a, conjunto denotado de aqu· en adelante como N(a).
De acuerdo a esto, la estructura que m·as naturalmente se adapta a la restricci·on de movernos s·olo
hacia los vecinos de un elemento es un grafo dirigido, en donde los nodos se corresponden con los
elementos de S y existen arcos entre un elemento y cada uno de sus vecinos. Los arcos denotan los
posibles movimientos que podemos hacer para acercarnos a q. Concretamente, existe un arco desde a
hasta b si es posible moverse de a a b en un ·unico paso. En un espacio vectorial, el grafo minimal que
buscamos corresponde a la triangulaci·on cl·asica de Delaunay (un grafo donde los elementos que son
vecinos de Voronoi est·an conectados). As· la respuesta ideal en t·erminos de complejidad de espacio es
el grafo de Delaunay (generalizado para espacios arbitrarios), y permitir·a tambi·en b·usquedas r·apidas.
Lamentablemente no en todos los espacios m·etricos se puede construir un grafo de aproximaci·on
espacial. Esto nos lleva a realizar simplicaciones que nos permitir·an resolver consultas del vecino
m·as cercano a un q ∈ S usando un ·arbol en lugar de un grafo, el SAT.
La construcci·on del SAT comienza con la selecci·on, de manera aleatoria, de un elemento a ∈ S
que ser·a la ra·z o nodo de inicio del ·arbol, es decir el elemento desde el cual comienzan todas nuestras
b·usquedas. Luego se selecciona un conjunto adecuado de vecinos N(a), que veriquen:
Condici·on 2: (dados a ∈ S) ∀x ∈ S, x ∈ N(a)⇔ ∀y ∈ N(a)− {x}, d(x, y) > d(x, a).
As·, los elementos de la base de datos que integran el conjunto N(a) son aquellos que se encuentran m·as cerca de a que de cualquier otro elemento de la base de datos. Si comenzamos con
el nodo ra·z a debemos considerar la bolsa B(a) para a, que inicialmente mantiene los elementos
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
367
en S − {a}. Se ordena el conjunto B(a) por distancia a a de manera creciente, quedando primero
el elemento que espacialmente es el m·as cercano a a. Sea N(a) inicialmente vac·o, se considera en
orden cada elemento b ∈ B(a); si ocurre que b es m·as cercano al nodo a que a cualquier elemento ya
presente en N(a), entonces se agrega b a N(a). Analizados todos los b ∈ B(a), se habr·a determinado
un conjunto N(a) adecuado. Ahora hay que ocuparse de los elementos que fueron descartados como
vecinos de a. Para ello se coloca cada elemento b ∈ S − (a ∪ N(a)) en la bolsa B(c) del elemento
c ∈ N(a) m·as cercano a b. Ya ubicado cada elemento en su bolsa, se considera a cada vecino de a
como una ra·z y se procesan recursivamente los elementos de su bolsa de la manera mencionada.
El algoritmo de la Figura 1 detalla este proceso de construcci·on. Para construir un SAT ·este se
debe invocar inicialmente con BUILDTREE(a, S − a), en donde a ser·a la ra·z del ·arbol.
BuildTree(Nodo a, Conjunto de Elementos S)
1. N(a) ← ∅ /* vecinos de a */
2. R(a) ← 0 /* radio de cobertura */
3. Ordenar S por distancia a a (m·as cercano primero)
4. For v ∈ S
5. R(a) ← máx(R(a), d(v, a))
6. If ∀b ∈ N(a), d(v, a) < d(v, b) Then
7. N(a) ← N(a) ∪ {v}
8. For b ∈ N(a) S(b) ← ∅ /* sub·arboles */
9. For v ∈ S −N(a)
10. Sea c ∈ N(a) el que minimiza d(v, c)
11. S(c) ← S(c) ∪ {v}
12. For b ∈ N(a) BuildTree(b,S(b)) /* construir subarboles */
Figura 1: Algoritmo para construir un SAT.
Para evitar algunas comparaciones de distancia durante las b·usquedas, se almacena en cada nodo
b del ·arbol su radio de cobertura R(b), que es la m·axima distancia entre b y un elemento del sub·arbol
del cual b es la ra·z.
Una vez denida la estructura que nos va a permitir buscar por aproximaci·on espacial, consideraremos las b·usquedas por rango con radio r. La clave es que aunque q 6∈ S, la respuesta a la b·usqueda
son elementos q′ ∈ S. La idea es usar el ·arbol para simular que buscamos un q ′ ∈ S desconocido. Se sabe que d(q, q′) ≤ r y que por la desigualdad triangular ∀x ∈ U , d(x, q) ≤ d(x, q ′) +
d(q′, q). Pero, como d(q, q′) ≤ r, podemos reemplazar d(q, q′) por r y manteniendo la desigualdad
d(x, q)− r ≤ d(x, q′) . Por otro lado, por desigualdad triangular tenemos que d(x, q ′) ≤ d(x, q) + r.
Si buscamos un q conocido, vamos directamente al vecino de a m·as cercano a q. Al ser q ′ desconocido no sabemos cu·al es el vecino de a m·as cercano a q ′. Entonces, estando en un nodo a, debemos
determinar el vecino c m·as cercano a q entre los elementos de {a}∪N(a). As·, para b ∈ {a}∪N(a) se
cumple que d(c, q) < d(b, q). Pero es posible que d(c, q ′) > d(b, q′) y por lo tanto no encontraremos a
q′ si solamente buscamos dentro del sub·arbol de c. Entonces, debemos ingresar en todos los vecinos
b ∈ N(a) que cumplan que d(q′, b) ≤ mín d(c, q) + 2r, c ∈ {a} ∪ N(a). En otro caso, no estamos
seguros de ello y debemos entrar al sub·arbol de b; porque el q ′ que estamos buscando puede diferir de
q en a lo m·as r, por lo que podr·a haber sido insertado dentro de los sub·arboles de aquellos vecinos b.
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
368
Por lo tanto, lo que fue concebido como una b·usqueda por aproximaci·on espacial siguiendo un
·unico camino, ahora se combina con backtracking para que busquemos por varios caminos.
Se puede mejorar el algoritmo si consideramos que cuando buscamos un elemento q ∈ S seguimos
un ·unico camino desde la ra·z hasta q pero sabemos que, si la b·usqueda se encuentra en el nodo a
del ·arbol, se puede evitar entrar en cualquier elemento x ∈ N(a) tal que d(q, x) > 2r + mín{d(q, c),
c ∈ {a′} ∪ N(a′), a′ ∈ A(a)}, donde A(a) es el conjunto de ancestros de a (incluyendo a a) y
N(A(a)) =
⋃
a′∈A(a) N(a′), debido a que se puede mostrar, usando la desigualdad triangular, que
ning·un q′ con d(q, q′) ≤ r se pudo almacenar dentro de x.
Otra posibilidad de optimizar las b·usquedas es usando la informaci·on almacenada sobre el radio
de cobertura R(a) de un nodo a, que nos permiten podar cierta parte del ·arbol, ya que no deber·amos
ingresar a un sub·arbol con ra·z a que verica que d(q, a) > R(a) + r, porque esto implica que
d(q′, a) > R(a) para cualquier q′ tal que d(q, q′) ≤ r. Por la forma en que hemos denido R(a), q ′ no
puede encontrarse en el sub·arbol de a.
Las Figuras 2 y 3 ilustran las situaciones con las que nos podemos encontrar durante las b·usquedas.
(a) (b)
Figura 2: En (a) se cumple que d(a, q) > R(a) + r, por lo que no debemos entrar en el subárbol de a ya que
ninguno de sus elementos va a estar dentro del rango de la consulta. En (b) se cumple que d(a, q) ≤ R(a) + r,
así debemos entrar en el subárbol de a ya que es posible (no seguro) que alguno de sus elementos se encuentre
dentro del rango.
Figura 3: En este caso se cumple que d(a, q) ≤ R(a) + r y se observa que aunque debemos entrar en el
subárbol de a, no existe ningún elemento en ese subárbol que esté dentro del rango de búsqueda.
En [12] se muestra que el SAT posee mejor desempeno en las b·usquedas respecto de otras estructuras. El algoritmo de la Figura 4 describe el proceso de b·usqueda que hemos explicado.
3. SELECCIÓN DE LA RAÍZ PARA EL SAT
Como se ya se mencion·o, al construir el SAT ·este queda completamente determinado por la elecci·on de la ra·z; es decir que, si para la misma base de datos tom·aramos otro objeto como la ra·z el
·arbol resultante ser·a distinto. Como esta elecci·on se realiza al azar, es posible encontrar buenas ra·ces
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
369
B·usqRango (Nodo a, Query q, Radio r, Distancia dmín)
1. If d(a, q) ≤ R(a) + r Then
2. If d(a, q) ≤ r Then Informar a
3. dmín ← mín {dmin} ∪ {d(q, c), c ∈ N(a)}
4. For b ∈ N(a)
5. If d(b, q) ≤ dmín + 2r Then B·usqRango (b,q,r,dmín)
Figura 4: Algoritmo para buscar q con radio r en un SAT.
logrando que el ·arbol generado se comporte mejor principalmente durante las b·usquedas, pero tambi·en podemos encontrar ra·ces poco convenientes. La Figura 5 muestra un ejemplo de un espacio y
dos posibles ·arboles para dicho espacio generados a partir de la elecci·on de diferentes ra·ces.
Sin embargo, elegir la ra·z aleatoriamente es atractivo porque no hay costos adicionales, la elecci·on es gratis dado que medimos nuestros costos en cantidad de evaluaciones de la funci ·on de distancia. Por otra parte, parece razonable utilizar informaci·on de la base de datos para seleccionar una
buena ra·z a costa de pagar un cierto costo en evaluaciones de distancia, esperando que ·este se compense al disminuir principalmente los costos de las b·usquedas, o al menos de la construcci·on.
6
p14p7
p10
p9
p8
p15
p5
p1
p13
p12
p11
p2
p4
p3
p 6
p14p7
p10
p9
p8
p15
p5
p1
p13
p12
p11
p2
p3
p4 p 6
p14p7
p10
p9
p8
p15
p5
p1
p13
p12
p11
p2
p3
p4 p
(a) (b) (c)
Figura 5: En (a) vemos un posible espacio de puntos, en (b) se muestra el SAT obtenido para ese espacio
tomando como raíz al punto p6, y en (c) se ve el SAT generado eligiendo a p12 como raíz.
3.1. Métodos de Selección de la Raíz
Aqu· asumiremos que un elemento es mejor ra·z que otro si en el ·arbol, que desde ·el se genere, se
obtienen mejores costos principalmente en las b·usquedas. El ·enfasis estar·a puesto en las b·usquedas,
porque al ser el SAT una estructura est·atica, no admite ni inserciones ni eliminaciones, la selecci·on de
la ra·z se realiza una ·unica vez antes de construir el ·arbol.
Hemos estudiado diferentes m·etodos para seleccionar un elemento como ra·z en el SAT y a trav·es
del an·alisis experimental determinamos qu·e m·etodo obtiene los mejores costos de b·usqueda. Aunque
nos interesar·an m·as los costos de las b·usquedas, destacamos para cada m·etodo el costo de la elecci·on
de la ra·z medido en cantidad de evaluaciones de la funci·on de distancia. En algunos de ellos subyacen
ideas de teor·a de grafos, otros son adaptaciones de m·etodos usados en otras estructuras para efectuar
procesos similares y el m·etodo CSA, propuesto en [13], pensado espec·camente para el SAT.
Los m·etodos considerados son: M·etodo CSA (Centroid Selection Algorithm), Aleatorio, Sampling, M-LB-DIST (Maximum Lower Bound on DISTance), mM-LB-RAD (minimun Maximun
Lower Bound RADius), mM-AVG-RAD (minimun Maximun Average RADius).
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
370
Los ·ultimos cuatro m·etodos se han adaptado desde m·etodos utilizados en el Mtree para seleccionar el centro de un nuevo nodo luego de una operaci·on de split [7]. Fueron adaptados de manera tal
que pudieran usarse en el SAT para elegir una ra·z, manteniendo los costos razonables. Para identicar
f·acilmente cada m·etodo del Mtree hemos mantenido sus nombres originales.
A continuaci·on se har·a una breve descripci·on de cada uno. Para el an·alisis de los costos de selecci·on de la ra·z, y suponiendo que S ⊆ U es nuestra base de datos, consideramos N = |S|.
3.1.1. M·etodo CSA (Centroid Selection Algorithm)
Este m·etodo propuesto para elegir la ra·z del SAT, fue presentado por Penarrieta, Morriber·on y
Cuadros-Vargas en [13]. La idea subyacente es que un elemento que podr·a ser una buena ra·z para el
SAT ser·a aqu·el que es cercano al centroide ideal de la base de datos. Est·a basado en el algoritmo HF
presentado en la Familia Omni [14] y se reeja en el siguiente algoritmo:
1. Seleccionar aleatoriamente un elemento s ∈ S.
2. Encontrar el elemento m·as lejano e1 de s.
3. A partir de e1 determinar su elemento m·as distante e2.
4. Seleccionar como ra·z al elemento c que satisfaga que d(e1, c) ' (e2, c) y que minimice
|d(e1, e2)− (d(e1, c) + d(e2, c))|.
Este ·ultimo paso es muy importante porque pueden existir varios candidatos para c, pero se elige
aqu·el que minimice el per·metro del tri·angulo formado por e1, e2 y c y que adem·as no se encuentre
retirado del centro del tri·angulo. La Figura 6 permite visualizar los pasos a desarrollar en el algoritmo.
Este m·etodo necesita realizar 3N evaluaciones de distancia.
s
c
e
e2
1
Figura 6: Idea geométrica que da origen al Método CSA.
3.1.2. M·etodo Sampling
Es una pol·tica aleatoria que trabaja sobre una muestra de objetos de S de tamano jo s > 1.
Seleccionamos al azar s objetos de la base de datos, y elegimos como ra·z al elemento que tenga
menor distancia m·axima a los s − 1 objetos restantes. Es f·acil observar que en este caso se realizan
s ∗ (s− 1)
2 c·alculos de la funci·on de distancia, lo que nos dar·a un costo de O(s
2). Con el n de
mantener este costo lineal respecto de la cardinalidad de S, elegimos a s =
√
N ; as· el m·etodo debe
realizar N c·alculos de distancia para elegir la ra·z.
3.1.3. M·etodo M-LB-DIST (Maximum Lower Bound on DISTance)
Esta pol·tica diere de la anterior en que necesita utilizar todo el conjunto de elementos. Elegimos
un objeto al azar y calculamos las distancias a todos los dem·as objetos, luego seleccionamos el objeto
m·as distante como ra·z. Formalmente, elegimos un elemento x ∈ S aleatoriamente y determinamos
el y ∈ S tal que d(x, y) = máxz∈S{d(x, z)}. Claramente este proceso realiza N evaluaciones de
distancia para obtener la ra·z.
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
371
3.1.4. M·etodo mM-LB-RAD (Minimun Maximun Lower Bound Radius)
Se elige un objeto x ∈ S al azar, y se calculan las distancias de todos los elementos z ∈ S a
x, luego elegimos como ra·z el objeto y para el que máxz∈S{|d(y, x) − d(z, x)|} sea m·nimo. Este
criterio selecciona un elemento y que est·a a una distancia intermedia de x. Aunque la manera en que
se elige a un elemento y como ra·z es m·as compleja que en el m·etodo anterior, la cantidad de c·alculos
de distancia es tambi·en N .
3.1.5. M·etodo mM-AVG-RAD (Minimun Maximun Average Bound Radius)
Este m·etodo surgi·o como una alternativa al anterior y trata de ser neutral con respecto a la informaci·on de los l·mites superior e inferior, tomando el promedio y aplicando el criterio de selecci·on
mín−máx. As·, elegimos nuevamente al azar un elemento x ∈ S, calculamos para todo z ∈ S la
distancia d(x, z) y elegimos un elemento y como ra·z tal que máxz∈S{(d(y, x) + d(z, x))/2} sea
m·nimo. Este m·etodo tambi·en necesita N c·alculos de distancia para poder seleccionar la ra·z.
4. RESULTADOS EXPERIMENTALES
Para analizar el desempeno de cada uno de los m·etodos de selecci·on de la ra·z del SAT se realizaron experimentos sobre diferentes espacios m·etricos, para as· poder estudiar el comportamiento de
cada uno de ellos de manera m·as objetiva. Consideramos principalmente los costos de las b·usquedas,
sin embargo analizamos tambi·en qu·e sucede con los costos de construcci·on y por ende con los costos
de selecci·on de la ra·z. Los espacios m·etricos considerados son los siguientes:
Espacio de Palabras: formado por un diccionario de 69.069 palabras del Ingl·es y la distancia de
edici·on, que es el m·nimo n·umero de inserciones, supresiones y/o reemplazos de caracteres necesarios
para hacer una palabra igual a otra. Esta distancia es ·util para tratar con deletreo o reconocimiento de
palabras, recuperaci·on de texto, escritura y errores en reconocimiento ·optico de caracteres (OCR).
Espacio de Vectores de Imágenes de la NASA: un conjunto de 40.700 vectores de caracter·sticas de
20 componentes, generados desde im·agenes descargadas desde el sitio de la NASA 1. La distancia
Eucl·dea es utilizada como la funci·on de distancia sobre este espacio.
Espacio de Histogramas de Imágenes: un conjunto de 112.682 vectores, formado por histogramas de
color 8-D de 112 componentes para cada imagen 2. La distancia deb·a ser de la familia de Minkowski,
as· se elegi·o la distancia Eucl·dea como la alternativa m·as simple y signicativa.
Espacio de Documentos: formado por un conjunto de 1.265 documentos y la funci·on de distancia
coseno, muy utilizada en recuperaci·on de la informaci·on [1]. Los documentos son obtenidos de la
colecci·on TREC- 3 3 y son vistos como vectores (cada t·ermino de los documentos es una coordenada).
Espacio de Vectores de Coordenadas de Dimensión 15: es un espacio integrado por 100.000 vectores
de dimensi·on 15, con componentes reales en el cubo unitario y distancia Eucl·dea. Para este espacio
hemos generado 100.000 puntos al azar con distribuci·on uniforme en el espacio [0, 1]15. Lo trataremos
como a un espacio m·etrico, desechando la informaci·on que brindan las coordenadas. Esto nos permite
controlar la dimensionalidad exacta con la que trabajaremos, lo que no es f·acil en un espacio m·etrico
general o si los vectores provienen desde una situaci·on real.
Los experimentos consisten en ejecutar la construcci·on del SAT para los diversos algoritmos de selecci·on de ra·ces y en cada espacio m·etrico considerado, y luego buscar en ellos. Para la construcci·on
1Disponible en: http://www.dimacs.rutgers.edu/Challenges/Sixth/software.html
2Disponible en http://www.dbs.informatik.uni-muenchen.de//seidl/DATA/histo112.112682.gz
3Disponible en: http://trec.nist.gov
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
372
del ·ndice se usa el 90 % de los elementos del espacio m·etrico. El 10 % restante se utilizan como objetos de b·usqueda. Realizamos varias ejecuciones de cada experimento sobre permutaciones distintas
de la base de datos; por lo tanto, los resultados exhibidos corresponden a valores medios obtenidos.
Para el Espacio de Palabras en Ingl·es, con funci·on de distancia discreta, los radios de b·usqueda utilizados en los experimentos fueron de 1 a 4, que recuperan en promedio aproximadamente
el 0.00003 %, el 0.00037 %, el 0.00326 % y el 0.01757 % respectivamente. Los radios de b·usqueda
utilizados en los espacios con distancia continua, son los siguientes:
a) Espacio de Vectores de Im·agenes de la NASA: 0.605740, 0.78 y 1.009.
b) Espacio de Histogramas de Im·agenes: 0.051768, 0.082514 y 0.131163.
c) Espacio de Documentos: 0.189441, 0.222466 y 0.600048.
d) Espacio de Vectores de Dimensi·on 15: 0.686576, 0.833130 y 1.019767.
Estos radios recuperan en promedio aproximadamente el 0.01 %, 0.1 %, 1 % elementos de la base
de datos, respectivamente.
4.1. Comparación General de los Métodos
Comparamos todas las t·ecnicas en cada espacio particular, para ver cu·ales son las que mostraron
menor n·umero de evaluaciones de distancia en las consultas. Se agregan en las gr·acas resultados de
m·etodos de M·nimas y M·aximas distancias que no fueron considerados como m·etodos alternativos
en este trabajo por ser demasiado costosos, pero que sirven como referencia para los dem·as m·etodos.
4.1.1. Espacio de Palabras
De la comparaci·on se observa que aqu·, de los m·etodos considerados, los que tienen menor costo
para las b·usquedas son CSA y Sampling. Cabe destacar que el m·etodo de selecci·on de la ra·z Aleatorio
no parece obtener un buen ·arbol, desde el punto de vista de las b·usquedas, dado que casi todas las
dem·as maneras de elegir la ra·z, logran superarlo para los cuatro radios considerados. La Figura 7
muestra estos resultados.
 5000
 10000
 15000
 20000
 25000
 30000
 35000
 40000
 45000
 50000
 1  2  3  4
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Radio de Busqueda
Costo de Consulta para n = 69.069 palabras
Min Max
Max Max
Med Min
Aleatorio
M-LB-DIST
Sampling
mM-LB-RAD
mM-AVG-RAD
Metodo CSA
Figura 7: Comparación de los costos de búsqueda para todos los métodos sobre el Espacio de Palabras.
4.1.2. Espacio Vectores de Im·agenes de la NASA
En este espacio el m·etodo que tuvo mejor desempeno en las b·usquedas es el M-LB-DIST. Los
m·etodos mM-LB-RAD y mM-AVG-RAD obtuvieron id·enticos desempenos. Nuevamente aqu· se ve
que el m·etodo Aleatorio no produce el mejor ·arbol para las b·usquedas. En la Figura 8 podemos
apreciar este analisis.
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
373
 6000
 6500
 7000
 7500
 8000
 8500
 9000
 9500
 0.01  0.1  1
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Porcentaje Recuperado por Radio de Busqueda
Costo de Consulta para n = 40.700 Vectores de Imagenes (NASA)
Med Max
Med Min
Aleatorio
M-LB-DIST
Sampling
mM-LB-RAD
mM-AVG-RAD
Metodo CSA
Figura 8: Comparación de los costos de búsqueda para todos los métodos sobre el Espacio de Vectores de
Imágenes de la NASA.
4.1.3. Espacio de Histogramas de Im·agenes
En este espacio m·etrico se comprob·o que el m·etodo m·as econ·omico en las b·usquedas fue el
Aleatorio y a continuaci·on, con muy poca diferencia, la t·ecnica CSA. Es llamativo que sea el m·etodo
Aleatorio el que produce el menor costo en cantidad de evaluaciones en las b·usquedas, siendo ·este un
algoritmo de costo O(1) en cantidad de c·alculos de distancia, y sumamente simple en su elaboraci·on.
Sin duda las caracter·sticas de este espacio hacen que resulte infructuoso usar nuestras t·ecnicas, pero
claramente no ha sido el caso en la mayor·a de los espacios utilizados. La Figura 9 reeja estos hechos.
 10000
 15000
 20000
 25000
 30000
 35000
 0.01  0.1  1
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Porcentaje Recuperado por Radio de Busqueda
Costo de consulta para n = 112.682 Histogramas de Imagenes
Med Max
Med Min
Aleatorio
M-LB-DIST
Sampling
mM-LB-RAD
mM-AVG-RAD
Metodo CSA
Figura 9: Comparación de los costos de búsqueda para todos los métodos sobre el Espacio de Histogramas de
Imágenes.
4.1.4. Espacio de Documentos
En este espacio, el mejor m·etodo en las b·usquedas para todos los radios y que adem·as obtuvo un
buen costo en la construcci·on es el m·etodo CSA, aunque las diferencias entre los distintos m·etodos
no son demasiado signicativas, ya que entre el mejor y el peor costo de b·usqueda para cada radio la
diferencia es cercana a 50 evaluaciones de distancia. En la Figura 10 es posible observar esta situaci·on.
4.1.5. Espacio Vectores de Dimensi·on 15
En los experimentos se observa que existe una gran similitud entre los costos de las b·usquedas de
casi todos los m·etodos, no existiendo pr·acticamente diferenciaci·on entre ellos. El ·unico m·etodo que
se destaca como menos costoso, por escasa diferencia de evaluaciones de los dem·as m·etodos, es CSA
en todos los radios considerados. Sin embargo, aunque CSA haya mostrado mejor desempeno en las
b·usquedas, result·o ser el peor en cuanto a costos de construcci·on. Si no se est·a dispuesto a pagar tanto
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
374
 320
 340
 360
 380
 400
 420
 440
 0.01  0.1  1
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Porcentaje Recuperado por Radio de Busqueda
Costo de Consulta para n = 1.265 Documentos
Med Max
Med Min
Aleatorio
M-LB-DIST
Sampling
mM-LB-RAD
mM-AVG-RAD
Metodo CSA
Figura 10: Comparación de los costos de búsqueda para todos los métodos sobre el Espacio de Documentos.
en la construcci·on de la estructura una muy buena alternativa ser·a el m·etodo de Sampling porque su
desempeno en las b·usquedas es muy similar y su costo de construcci·on es mucho menor. La Figura 11
permite observar gr·acamente estos resultados.
 50000
 55000
 60000
 65000
 70000
 75000
 80000
 85000
 0.01  0.1  1
Ev
al
ua
ci
on
es
 d
e 
Di
st
an
cia
Porcentaje Recuperado por Radio de Busqueda
Costo de Consulta n = 100.000 Vectores de Dimension 15
Min Max
Med Min
Aleatorio
mM-AVG-RAD
mM-LB-RAD
Sampling
M-LB-DIST
Metodo CSA
Figura 11: Comparación de los costos de búsqueda para todos los métodos sobre el Espacio de Vectores de
Dimensión 15.
5. CONCLUSIONES
El ·Arbol de Aproximaci·on Espacial (SAT) ha mostrado ser muy competitivo en espacios m·etricos
de media a alta dimensionalidad o respondiendo a consultas con baja selectividad [12][9]. Un an·alisis
detallado muestra que la selecci·on de la ra·z del ·arbol es uno de los procesos que se podr·an optimizar, dado que ·este es el que determina completamente al SAT y originalmente se realizaba al azar.
Otros autores se han dedicado a este tema [13]. Sin embargo creemos que nuestro trabajo brinda m·as
informaci·on debido a que se estudiaron y compararon m·as m·etodos, la mayor·a de los cuales fueron
disenados o adaptados por nosotros para esta estructura, y se realizaron m·as experimentos.
Hemos conseguido construir un ·arbol m·as eciente para las b·usquedas, s·olo pagando algunos
c·alculos de distancia adicionales respecto del SAT original y manteniendo la correctitud de la estructura. Demostramos experimentalmente que un mayor conocimiento sobre el espacio m·etrico particular permite mejorar la estructura, y que los algoritmos de selecci·on de la ra·z propuestos logran
mejorar tanto costos de b·usqueda como los costos de construcci·on del SAT original. Aunque nuestros
resultados son aplicables principalmente al SAT, algunos podr·an serlo en otras estructuras arb·oreas.
De la misma manera que se mejor·o la versi·on est·atica de SAT eligiendo la ra·z de modo diferente
al original, se podr·a intentar adaptar alguna de las t·ecnicas a la versi·on din·amica del SAT [10, 11].
XIII Congreso Argentino de Ciencias de la Computación
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 
IV Workshop de Ingeniería de Software y Bases de Datos
_________________________________________________________________________
 
 
375
Hasta ahora el SAT trabaja en memoria principal; la posibilidad que la selecci·on de una mejor ra·z
resulte en un ·arbol m·as balanceado, podr·a hacer que su almacenamiento en memoria secundaria fuera
m·as eciente.
