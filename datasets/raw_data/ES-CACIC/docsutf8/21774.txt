Reconstrucción 3D de la adquisición a la visualización
﻿
 
Los dispositivos de escaneo tridimensional permiten obtener modelos de objetos utilizando distintas 
técnicas de captura.  Una técnica muy utilizada consiste en realizar la reconstrucción mediante el 
uso de estereovisión y luz estructurada.  De esta forma, proyectando un patrón de luz conocido 
sobre una escena es posible determinar la correspondencia de puntos entre ambas imágenes. El 
presente trabajo detalla los resultados reales de las pruebas realizadas utilizando el prototipo  de 
adquisición 3D desarrollado, el cual permite obtener modelos tridimensionales y visualizarlos como 
una nube de puntos en un entorno de realidad virtual. 
  
Palabras claves: estereovisión, escáner tridimensional, reconstrucción 3D, proyección de luz 
 
 
Abstract 
 
The 3D scanning devices allow obtaining object models using various capture techniques. A widely 
used technique is to undertake reconstruction using stereo vision and structured light. Thus, 
projecting a known pattern of light on a scene is possible to identify correspondence points between 
the two images. This paper describes the actual results of tests carried out using the developed 3D 
acquisition prototype, which generates three-dimensional models, and visualize them as a point 
cloud in a virtual reality environment. 
 
Keywords: stereovision, three-dimensional scanner, 3D reconstruction, light projection 
  
                                                 
1 Esta investigación es financiada por la Agencia Española de Cooperación Internacional AECI programa de 
cooperación interuniversitaria e investigación científica. Proyecto A/7155/06 – Diseño de un sistema de reconstrucción 
3D mediante cámaras estereoscópicas y luz estructurada. 
 
1  INTRODUCCIÓN 
 
 
En la actualidad existen distintos sistemas de digitalización 3D.  Según el método de interacción 
con el objeto a digitalizar, éstos pueden ser divididos en dos grandes grupos: sistemas con o sin 
contacto [1]. 
 
Los sistemas de digitalización por contacto son los más antiguos y obtienen las coordenadas de los 
puntos gracias al desplazamiento de una punta sobre la superficie a digitalizar.  Poseen una elevada 
precisión; pero tienen una velocidad de adquisición de datos muy baja.  Para emplear estos 
sistemas, se necesita además que las piezas tengan la rigidez suficiente para que no se deformen por 
el contacto de la punta.  En ocasiones,  debido a la geometría de las piezas, es imposible digitalizar 
ciertas ranuras y ángulos interiores. 
 
Los sistemas de digitalización sin contacto presentan la ventaja de lograr una velocidad de 
adquisición de datos muy superior a las de los digitalizadores por contacto.  Se pueden dividir las 
técnicas de digitalización sin contacto en dos grupos: de visión pasiva y de visión activa.   
 
Las técnicas de visión pasiva se basan en utilizar dos o mas puntos de vista de un mismo objeto para 
encontrar las coordenadas tridimensionales [2]. La principal complejidad de este método es la 
correspondencia de puntos en cada una de las imágenes monoculares.  Muchas de las técnicas 
encargadas de realizar esta tarea presentan un elevado costo computacional. 
 
Las técnicas de visión activa son las que hacen intervenir una fuente de luz específica para 
determinar las coordenadas tridimensionales de los puntos de medida.  Constan como mínimo de un 
emisor de luz y uno o más receptores.  Conociendo la dirección del rayo emitido y la del recibido se 
obtienen las dimensiones del triángulo formado y por lo tanto se logra determinar la profundidad 
del punto inspeccionado.  Ejemplos de esta técnica son los sistemas que usan algún tipo de 
proyección de luz estructurada [3] o iluminación láser [4] sobre la superficie que se intenta 
reconstruir, como es el caso del prototipo desarrollado. 
 
El resto de este trabajo se encuentra organizado de la siguiente forma: La sección 2 discute los 
sistemas actuales de adquisición.  La sección 3 expone el prototipo de captura desarrollado.  La 
sección 4 menciona las técnicas involucradas y el procesamiento requerido según los diferentes 
métodos de adquisición de datos del prototipo.  En la sección 5 se pueden observar los resultados 
obtenidos.  Finalmente, en la sección 6 se presentan las conclusiones y el trabajo a futuro. 
 
 
2  COMPARACIÓN DE LOS SISTEMAS DE ADQUISICIÓN 
 
Todos los sistemas de digitalización cuentan con un método de captura de la escena y de cálculo de 
correspondencia con el fin de adquirir las coordenadas 3D del objeto que se intenta reconstruir.  La 
tabla 1 presenta un resumen de trabajos categorizados según los métodos y hardware utilizados.  El 
sistema desarrollado en el presente trabajo utiliza un láser como fuente lumínica y un sistema de 
cámaras estéreo conformado por dos cámaras web. 
 
 
 
 
2
Método / Hardware utilizado Calibración necesaria 
1 cámara fija, 1 láser.  Barrido láser sobre el 
objeto a adquirir. [4, 5, 6, 7] 
Calibración intrínseca y extrínseca de la 
cámara.  Calibración o autocalibración del 
láser. 
1 cámara, 1 láser, 1 estructura de referencia 
(doble cuadro).  Barrido láser sobre el objeto 
a adquirir. [8] 
No necesita que la cámara y el láser se 
encuentren fijos. 
1 cámara, 1 proyector de luz estructurada.  
Proyección sobre el objeto a adquirir. [3, 9] 
Dependiendo del sistema, necesita o no 
calibración intrínseca y extrínseca del 
proyector y la cámara. 
1 cámara.  Conjunto de imágenes.  [10, 11]. No necesaria, pero asume una escena rígida 
y limitaciones de los parámetros intrínsecos.
2 cámaras, 1 láser [12, 19] Calibración intrínseca y extrínseca de las 
cámaras. 
Tabla 1.  Resumen de trabajos relacionados. 
 
 
3  PROTOTIPO 
 
El prototipo de hardware desarrollado para el sistema de captura (figura 1) cuenta con dos cámaras 
web, un láser, dos motores, y un módulo de comunicación que conecta la computadora y con la 
estructura que lo soporta.     
 
La estructura metálica es robusta y flexible; sobra la misma se encuentran montadas las cámaras, los 
motores y los accesorios regulables tanto horizontal como verticalmente. La estructura fue pensada 
para permitir un sencillo armado y desarmado a fin de facilitar su portabilidad. 
 
El módulo de comunicación utiliza el puerto paralelo para recibir/enviar información desde/hacia la 
computadora.  Al mismo también se conectan los motores y los demás accesorios del prototipo.  
Permite controlar el motor de la base donde se coloca el objeto, el motor del láser, así como también 
la activación del láser. 
 
Los dos motores utilizados son de tipo paso a paso de 200 pasos por revolución. El motor de la base 
(encargado de girar la base en donde se ubica el objeto a escanear) cuenta con una precisión de 
7700 pasos en un giro.  El motor del láser (encargado de realizar el barrido sobre el objeto) tiene 
una precisión de 13000 pasos en un giro.  Ambos motores poseen sensor de "fin de carrera", es 
decir, detección de giro realizado. 
 
Las cámaras son modelo Unibrain FireWire WebCam - Fire-i Digital Camera [13], y pueden 
adquirir hasta 15 cuadros por segundo con una resolución de 640x480 píxeles en formato RGB, o 
hasta 30 cuadros por segundo con una resolución de 640x480 píxeles en formato YUV 4:1:1.  Su 
precio en el mercado es de $350 aproximadamente. 
 
El láser es de tipo CLASS IIIA [14, 15], color rojo y con una potencia menor a 5mW.  El mismo 
cuenta con diferentes patrones de luz: punto, línea o cruz.  Su precio en el mercado es de $70. 
 
Con el prototipo desarrollado se logra la automatización total del proceso de escaneo: activación de 
las cámaras y del láser, la rotación de este último y de la base (según el método de adquisición de 
datos elegido, explicado en el apartado 4.2), además de otras funciones secundarias. 
 
 
3
 
Figura 1.  Prototipo de captura. 
 
 
4  DETALLE DEL PROCEDIMIENTO 
 
 
4.1 Técnicas involucradas 
 
La adquisición 3D se basa principalmente en el concepto de visión estéreo [16].  Los ojos humanos, 
debido a su separación, obtienen dos imágenes de una misma escena con pequeñas diferencias entre 
ellas.  El cerebro procesa las diferencias entre ambas imágenes y las interpreta de forma que 
percibimos la sensación de profundidad, lejanía o cercanía de los objetos que nos rodean. Este 
proceso se denomina estereopsis. 
 
Las técnicas estereoscópicas intentan reproducir la sensación de profundidad de la visión 
estereoscópica natural. Si se obtienen dos fotografías con una separación adecuada, 
correspondientes a la visión que se obtendría con cada ojo, es posible reconstruir la profundidad 
[17, 18]. 
 
Sin embargo, una vez que se cuenta con dos puntos de vista de la escena, el problema consiste en 
calcular las correspondencias entre los puntos de dichas vistas.  Una forma de simplificar este 
proceso, es utilizar una fuente lumínica (láser, luz estructurada) sobre el objeto.  Así, los puntos 
iluminados son individualizados en cada una de las vistas, reduciendo drásticamente el costo 
computacional de la estimación de las correspondencias. 
 
 
4
El sistema desarrollado utiliza dos cámaras web y un láser para adquirir las imágenes del objeto a 
escanear [19].  Luego, estas imágenes son procesadas mediante una técnica de filtrado por color 
(umbralización RGB) con el fin de descartar los puntos no pertenecientes a zonas del objeto 
iluminadas por el láser. 
 
Una vez filtrados los puntos en ambas imágenes, se estiman las correspondencias y se aplican los 
conceptos de la visión estereoscópica, obteniéndose una nube de puntos tridimensionales. 
 
Tanto las técnicas de filtrado como las estereoscópicas se encuentran desarrolladas utilizando la 
librería OpenCV [20].  Esta librería es una es potente y versátil herramienta de trabajo que permite 
abstraerse de los problemas típicos del procesamiento de imágenes. 
 
 
4.2 Métodos de adquisición de datos 
 
El sistema fue pensado a fin de incorporar dos métodos de adquisición de datos.  En ambos casos, el 
sistema de cámaras estéreo requiere una calibración inicial, tanto intrínseca como extrínseca [21, 
22].  La aplicación presenta un módulo de calibración específico con esta finalidad.   
 
Cabe destacar que de no modificarse la posición de las cámaras, el proceso de calibración no debe 
realizare nuevamente antes de cada captura.  
 
A continuación, se describen las características de los métodos de adquisición desarrollados. 
  
 Adquisición de datos mediante barrido láser: en este caso, el objeto a reconstruir permanece 
inmóvil, mientras que se releva la superficie del mismo barriendo el área de escaneado con un 
láser.  Pensado para objetos sin volumen de revolución o cuyo contenido se presenta 
mayormente sobre una sola cara.  
 
 Adquisición de datos mediante objeto giratorio: en este caso, el láser permanece inmóvil, siendo 
el objeto quien realiza un giro sobre su eje a fin de relevar la superficie del mismo.  Ideal para 
objetos con volumen de tipo cilíndrico, como vasijas, tazas, etc. 
 
Las imágenes que se pueden observar en las figuras 2 y 3 muestran una secuencia de imágenes que 
ejemplifican la captura de ambos mecanismos.  La primera presenta la adquisición mediante barrido 
láser, mientras que la segunda presenta la secuencia mediante objetivo giratorio. 
 
 
 
Cuadro 30 Cuadro 60 Cuadro 90 Cuadro 120 
Figura 2. Barrido láser (video izquierdo, 130 cuadros) 
 
 
 
5
 
Cuadro 5 Cuadro 50 Cuadro 100 Cuadro 130 
Figura 3. Objetivo giratorio (video izquierdo, 360 cuadros) 
 
 
4.3 Detalle del proceso de reconstrucción 
 
Luego de realizar la captura de los videos utilizando uno de los métodos descritos en el punto 
anterior, es posible iniciar el proceso de reconstrucción.  El mismo cuenta con una serie de pasos 
que se detallan a continuación: 
 
1. Dado que las cámaras se encuentran en una misma línea y con idéntica orientación, idealmente 
no debería existir un desplazamiento vertical entre ellas.  Sin embargo, en la práctica puede 
existir un pequeño desplazamiento del orden de unas pocas filas.  Con el objetivo de 
incrementar la robustez del sistema, se calcula dicho valor tomando en cuenta la mediana del 
desplazamiento vertical a lo largo de los videos capturados. 
 
2. Se toma un par de imágenes estéreo de la secuencia y se realiza el filtrado RGB a fin de obtener 
los puntos del objeto en donde la luz del láser ha sido proyectada.   
 
3. Se toma el primer punto filtrado en la imagen izquierda y se hace lo propio en la imagen 
derecha, teniendo en cuenta el desplazamiento vertical calculado en el primer paso.  Utilizando 
los puntos seleccionados en ambas imágenes junto a la información adquirida en el proceso de 
calibración, se realiza la triangulación del punto en el espacio tridimensional.  En el caso del 
método mediante objeto giratorio, la reconstrucción del punto se realiza contemplando el ángulo 
de giro entre frame y frame. 
 
4. Se repite lo realizado en el punto anterior para cada uno de los siguientes puntos de la imagen, 
los cuales corresponden al resto de la proyección del láser sobre el objeto.  Una vez finalizado el 
procesamiento de todos los puntos, se toma el siguiente par de imágenes estéreo y se repiten los 
pasos 2, 3 y 4. 
 
Al finalizar el procesamiento de todas las imágenes se cuenta con una nube de puntos 
tridimensionales.  La misma puede ser almacenada en un formato de archivo .XYZ para luego ser 
renderizada en el entorno de visualización 3D desarrollado [19].  También es posible realizar la 
conversión a formato .WRL para su visualización en un entorno de realidad virtual. 
 
 
4.4 Detalles técnicos 
 
Previamente a realizar la captura de los videos de prueba, los dispositivos que conforman el 
prototipo fueron configurados de la siguiente manera: 
 
 
6
 El balance de blancos fue especificado de forma manual e independientemente en cada una de 
las cámaras, con el objetivo de lograr imágenes equivalentes.  De manera similar se realizó la 
configuración del tinte y de la saturación. 
 
 Las cámaras fueron configuradas para realizar la captura de video utilizando el modelo de color 
YUV 4:1:1, con una resolución de 640 x 480 píxeles.  De esta forma, fue posible adquirir 30 
cuadros por segundo, permitiendo un detalle de malla considerable. 
 
 La distancia de las cámaras a los objetos escaneados en las pruebas abarcaron un rango de 
distancias desde los 10 cm. hasta los 40 cm. 
 
 El láser fue configurado para proyectar la luz en forma de línea vertical sobre el objeto. 
 
 
5  RESULTADOS 
 
Se realizaron una serie de pruebas variando la posición y orientación de las cámaras, así como 
también la distancia del objeto a las mismas. Los mejores resultados se obtuvieron ubicando las 
cámaras a la menor distancia posible entre ellas y de forma paralela.  Por otra parte, la variación de 
la ubicación del láser no produjo mayores incidencias en los resultados de la reconstrucción.  La 
figura  4 presenta ejemplos de las pruebas realizadas, junto con sus resultados. 
 
Imagen izquierda Imagen derecha Imagen izquierda Imagen derecha 
Nube de puntos Nube de puntos 
Figura 4.  Adquisición de puntos 3D y su visualización (rostro y taza) 
 
 
Para facilitar las pruebas que permiten medir el error cometido, se utilizó como modelo un poliedro 
de 70 x 70 x 80 milímetros (figura 5).  Se realizó una serie de capturas sobre el objeto, tomando el 
promedio de los valores obtenidos, a fin de contrastar las dimensiones reales con las reconstruidas.  
 
7
Las tablas 2 y 3 detallan las coordenadas de los vértices reconstruidos y las distancias entre los 
mismos, las cuáles permiten realizar la comparación mencionada. 
 
 
Imagen izquierda Imagen derecha 
 
Figura 5.- Poliedro utilizado para la medición del error cometido. 
 
 
Coordenada X Y Z 
1 151,2 -109,78 382,585 
2 92,92 -108,485 343,38 
3 149,53 -42,85 401,685 
4 89,705 -38,42 349,215 
5 188,96 -105,005 313,945 
6 184,4 -33,75 328,42 
Tabla 2.- Coordenadas de los 6 puntos relevados (promedio de las series de prueba). 
 
 
Lado de 70 mm 
Coordenada 1 Coordenada 2 Distancia Error relativo promedio 
1 3 69,62 
2 4 70,38 
5 6 72,85 
1,50 % 
Lado de 80 mm 
Coordenada 1 Coordenada 2 Distancia Error relativo promedio 
1 5 78,49 
3 6 81,65 
1,97 % 
Tabla 3.  Distancia euclídea entre los puntos analizados. 
 
 
8
El tiempo de procesamiento de la secuencia de video capturada promedió 35,3 segundos a lo largo 
de la serie de pruebas realizadas. 
 
 
6  CONCLUSIONES 
 
La solución software/hardware explicada en el presente trabajo detalla los avances al proceso de 
investigación llevado a cabo anteriormente [19], el cual solo contemplaba pruebas  en un ambiente 
controlado mediante simulaciones. 
 
Los resultados que arrojan las pruebas reales efectuadas demuestran que la precisión del sistema así 
como los tiempos de procesamiento son más que aceptable para el costo del prototipo desarrollado. 
 
La conversión a formato WRML brinda un grado más de versatilidad, permitiendo visualizar los 
resultados en cualquier navegador que soporte esta característica. 
 
El escenario a futuro prevé llevar a cabo dos tareas principales.  Por un lado, la utilización de 
técnicas especiales de estimación de desplazamiento para determinar la correspondencia de puntos a 
fin de evitar el uso de un láser, simplificando de manera considerable el hardware necesario.  Por 
otro lado, implementar una solución a medida que permita realizar la conversión de nube de puntos 
a mallado triangular de los objetos escaneados. 
 
 
8 
