Expert and construct validity of the Simbionix GI Mentor II endoscopy simulator for colonoscopy
Objectives The main objectives of this study were to establish expert validity (a convincing realistic representation of colonoscopy according to experts) and construct validity (the ability to discriminate between different levels of expertise) of the Simbionix GI Mentor II virtual reality (VR) simulator for colonoscopy tasks, and to assess the didactic value of the simulator, as judged by experts.
Training skills in endoscopy for diagnostic and therapeutic procedures is essential and requires a great deal of hands-on training [1]. Virtual reality (VR) simulators offer a promising option to train these skills extensively prior to training in real-life colonoscopy, without jeopardizing patients or causing them unnecessary discomfort [2]. The use of VR training prior to performing real flexible endoscopy on patients enables novice endoscopists to go through part of their proficiency curve before submitting patients to their relatively insufficient endoscopy skills. This might not only be advantageous for the patients undergoing endoscopy, but might also prevent complications and potential consequences resulting in medicolegal litigation. One of the simulators in the field of flexible endoscopy is the GI Mentor II (see Figure 1). VR simulators have been used extensively in different fields of expertise before applying these procedures to patients. In the United States of America simulator training is mandated by the Accreditation Council for Graduate Medical Education (ACGME) in laparoscopic procedures for surgical residents [3]. The first step is to validate the simulator construct properly and verify its didactic value, before implementing simulators in teaching programmes or developing a new curriculum for flexible endoscopy around them.
Figure 1.The GI Mentor II virtual reality simulator, the setup for training in lower endoscopy.
Some studies have already been published on this subject [4–6], but the presented outcomes lacked power due to their relatively small sample sizes. In addition, some cases did not study the validity of endoscopy, but for example only the EndoBubble module, a computer simulation skills test measuring how long it takes a person to pop 20 balloons in a virtual tunnel.
Objective
The main objectives of this study were: (1) to establish the degree of representation of real-life colonoscopy on the Simbionix GI Mentor II VR colonoscopy simulation, as judged by experts (expert validity), (2) to determine whether the GI Mentor II simulator can distinguish between various degrees of expertise in endoscopy, judged by novice, intermediate experienced, experienced and expert endoscopists performing VR colonoscopy (construct validity), and (3) to assess the didactic value of the simulator, as judged by experts.
Material and Methods
Simulator
The simulator used in this study was the Simbionix GI Mentor II (Simbionix Ltd. Israel, software version 2.7.3.0) (Figure 1). The GI Mentor II can simulate upper GI tract endoscopies such as esophagogastroduodenoscopy, endoscopic retrograde cholangiopancreatographies, and endoscopic ultrasound. The lower GI tract endoscopies it simulates are sigmoidoscopy and colonoscopy. The simulator records a range of parameters upon each exercise, which can be used to assess performance objectively. The endoscope used is a customized Pentax ECS-3840F endoscope.
Participants
Participants were allocated to four groups to assess the validity and didactic value of the GI Mentor II simulator. The first group, the novices, was defined as participants without any flexible endoscopy experience; they were all medical interns or residents. The second group was intermediate experienced, with fewer than 200 colonoscopies performed before. In the third group experienced participants all performed more than 200 colonoscopies but fewer than 1,000. The fourth group consisted of experts, all of whom had performed more than 1,000 colonoscopies. These categories were chosen based upon several other studies, the demands for Dutch accreditation for colonoscopy, and the accreditation demands of the British Society of Gastroenterology, which advocates 200 colonoscopies under supervision during training [4, 6–8]. All persons were either invited to participate within our hospital, or participated during a national congress of the Dutch Society of Gastroenterology in spring 2006.
The groups consisted of at least 28 persons to ensure sufficient statistical power [9]. A post hoc sample size calculation based on the results for time to finish the EndoBubble task showed a minimal sample of 26 participants in the novices group to achieve a power of 0.95. Originally, the intermediate experienced and experienced participants formed one group, but as the expertise level and performance within this group varied considerably, this groups was split. A schematic setup of the study design is presented in Figure 2.
Figure 2.The study design.
Questionnaire
All participants were asked to fill out a questionnaire on demographics and their general medical and endoscopy experience. It also included the number of endoscopies performed annually and number of years registered as a skilled professional endoscopist.
After the simulator run the participants were asked to answer questions about their appreciation of the realism of the colonoscopy exercises performed. Appreciation was expressed on a four-point Likert scale [10] varying from very unrealistic (1) to very realistic (4). Questions were asked about the realism of imaging, simulator setup, endoscope control and both haptic and visual feedback. Experts were asked whether the GI Mentor II could be used as a teaching device for novice endoscopists and whether experience on the simulator could be useful in practice.
Simulation modules
All participants first performed the hand–eye coordination task (EndoBubble level 1) of popping all 20 balloons in the test as quickly as possible, without touching the walls. Next, the participants performed VR case numbers 1 and 3, both from colonoscopy module 1. These cases were carefully selected for their discriminative value; both cases are straightforward colonoscopies, without any abnormalities such as polyps, tumours, or inflammation. Case number 1 is a relatively easy colonoscopy to perform, whereas case number 3 is more difficult, requiring the endoscopist to apply techniques such as straightening the endoscope during loop formation and applying torque to the endoscope shaft. The assignment given for the VR colonoscopies was to reach the cecum as quickly as possible with as little patient discomfort as possible. Patient discomfort was defined as the estimated percentage of time the virtual patient was in excessive pain and the number of times excessive local pressure was caused. Other relevant test parameters were the percentage of time spent with clear view and the number of times view of the lumen was lost. The task was considered accomplished when the cecum was reached.
Data analysis
SPSS 13.0 software was used to perform descriptive statistics and Kruskal–Wallis tests for statistic analysis of the data. A separate analysis between groups was performed using a two-tailed Mann–Whitney exact U test. A p-value of less than 0.05 was considered significant. The data showed a nonparametric distribution, therefore the median and range of performance parameters are presented as primary values.
Results
Participants
Thirty-five novices, 15 intermediates, 20 experienced, and 35 expert endoscopists participated in the study. The average number of colonoscopies performed annually by experts was 445, and their mean number of years registered as a gastroenterologist was 7.7 (range 0–35 years).
Construct validity
Data output by the simulator are presented in Tables 1 and 2. The EndoBubble task was completed faster by the experts and experienced endoscopists than by novices, with fewer wall collisions. These differences were statistically significant (Kruskal–Wallis test) (Table 1). Also the colonoscopy tasks were completed faster (p < 0,001, Kruskal–Wallis test), with less patient comfort and better visibility by experts and experienced endoscopists (Table 3). Novice endoscopists (N = 35) reached the cecum in a mean time of 29:57 (min:sec) in colonoscopy case 3, intermediate experienced (N = 15) in 5:45, experienced (N = 20) in 4:19, and experts (N = 35) in 4:56. Novices lost view of the lumen significantly more often than the other groups.
Table 1.EndoBubble hand–eye coordination taskExperienceTime to finish (min:sec)Number of times wall touchedNovice N = 35Mean6:561.9Median5:581.0Range1:24–20:250–20Intermediate N = 15Mean1:561.1Median1:410.0Range0:54–4:020–5Experienced N = 20Mean1:370.9Median1:210.0Range0:43–5:330–9Expert N = 35Mean1:240.3Median1:130.0Range0:49–3:250–2Kruskal-WallisChi- square63.1519.374Asymp. sign.0000.025Table 2.Colonoscopy module 1, cases 1 and 3ExperienceTime to reach cecum (hour:min:sec)% of time spent with clear viewLost view of lumenExcessive local pressure% of time patient was in painExcessive loop formedCase 1Novice N = 35Mean6:47960.40.513.30.83Median6:169700110Range 1:53–15:08 82–99 0–30–30–44 0–6Intermediate N = 15Mean1:36970080.6Median1:40980050Range0:55–2:5291–100000–300–3Experienced N = 20Mean1:239800.29.20.7Median1:21980081Range0:48–2:4389–10000–10–270–3Expert N = 35Mean1:23980014.51.49Median1:179800121Range0:42–3:1694–1000–100–570–10Case 3Novice N = 35Mean29:57863.23.892.24.77Median23:42853301Range4:48–1:28:1972–960–121–140–240–34Intermediate N = 15Mean5:45891.12.10.91.13Median4:21921200Range2:28–13:4178–970–40–60–40–8Experienced N = 20Mean4:19910.61.91.01.6Median3:50910101Range2:27–7:0273–990–30–80–40–9Expert N = 35Mean4:56890.91.622.51Median4:0390111Range1:38–15:3968–990–40–60–100–12Table 3.Statistics colonoscopy module 1, cases 1 and 3Time to reach cecum% of time spent with clear viewLost view of lumenExcessive local pressure% of time patient was in painExcessive loop formedCase 1Chi square69.04313.88918.41519.7837.10110.691Asymp. sig.0.0000.0030.0000.0000.0690.014Case 3Chi Square65.5596.97841.93628.7944.2844.856Asymp. sig.0.0000.0730.0000.0000.2320.183Kruskal-Wallis test
A separate analysis between groups using a Mann–Whitney exact U test demonstrated no significant difference between the intermediate, experienced and expert groups on all parameters. They all completed the task faster than the novices (see Table 4).
Table 4.Differences between groups module 1, cases 1 and 3Time to reach cecum% of time spent with clear viewEost view of lumenExcessive local pressure% of time patient was in painExcessive loop formedCase 1Novice vs. intermediate0.0000.1770.0390.0130.0700.743Intermediate vs. experienced0.1660.6171.0000.2440.3850.547Experienced vs. expert0.9620.6211.0000.0430.0770.020Intermediate vs. expert0.1410.2591.0001.0000.0180.009Case 3Novice vs. intermediate0.0000.1040.0000.0040.5840.040Intermediate vs. experienced0.2570.3940.2850.5030.7710.184Experienced vs. expert0.9690.2970.1530.9420.1540.726Intermediate vs. expert0.3260.7570.8700.4160.1110.090Mann–Whitney two-tailed test, exact significance
Expert validity
The group of expert endoscopists rated the colonoscopy simulation 2.95 on a four-point Likert scale for overall realism. Anatomical representation was rated 2.58, and the simulator setup 3.14. Endoscope control scored 3.21. Haptic feedback was rated 2.57.
Didactic value
Expert opinion was that the GI Mentor II simulator should be included in the training of novice endoscopists (3.51 on a four-point Likert scale) and that expertise gained on the simulator was considered applicable in a clinical curriculum (rated 3.29 out of 4). The simulator was not considered suitable for certification of trained endoscopists (rated 2.29 out of 4).
Discussion
This study represents the largest and most detailed study on the validity of this type of colonoscopy simulator so far. The data show that the simulator can discriminate clearly between endoscopists of different expertise levels performing different colonoscopy tasks. Differences were statistically significant using relatively large sample sizes in all three exercises, the EndoBubble task as well as cases number 1 and 3. The difference between our study and previous studies by others is that we focused on the basic aspects of navigation for colonoscopy itself, rather than on the hand–eye coordination task alone, used for example in the study by Ritter et al. [4], and that we included more participants in four separate groups with different levels of expertise [4–6, 11, 12]. in this way we were able to demonstrate that the GI Mentor II can distinguish between expertise levels up to the level of an intermediate experienced endoscopist, who has performed around 200 colonoscopies. In a similar study Sedlack et al. [5] describe a limited construct for a different simulator (AccuTouch, Immersion Medical). Felsher et al. [11] demonstrated differences between novices and experts in large sample sizes but did not compare novices to intermediate levels of expertise. In this study we have demonstrated convincing expert validity for colonoscopy on the GI Mentor II virtual simulator. This in contrast to other studies focusing on the EndoBubble task as a validation study [4] and not dealing with the subject of expert validity [4, 6, 7, 11, 12].
The colonoscopy tasks were considered as accomplished once the participants reached the cecum. Asking the participants to inspect the mucosa on the way back through the colon does not, in our opinion, provide a proper representation of the endoscopist’s skills in manoeuvring through the colon, as other aspects besides the basic navigation skills of the endoscopist could influence the performance parameters provided by the simulator considerably in this case. This might lead to very different end times depending, for example, on the carefulness of the endoscopist.
This study demonstrates that the GI Mentor II simulator offers a convincing, realistic representation of colonoscopy according to experts. The overall assessment was good. Expert opinion was that the simulator can be used as a teaching tool for novice endoscopists. The simulator’s haptic feedback is doubtful. Inexperienced residents can be trained in the skills necessary in flexible endoscopy such as steering control, straightening the endoscope during loop formation and applying torque up to a certain level.
Conclusion
The current study demonstrates that the GI Mentor II simulator offers a convincing, realistic representation of colonoscopy according to experts (expert validity) and that the simulator can discriminate up to the level of intermediate experienced endoscopists (construct validity) in colonoscopy. In the cases used the simulator could not discriminate between intermediate, experienced and expert endoscopists. The next step will be a study to determine whether novice endoscopists can develop a learning curve that will actually improve their endoscopic skills applied to real patients.