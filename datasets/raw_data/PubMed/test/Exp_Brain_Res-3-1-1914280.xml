<?xml version="1.0" ?>
<!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd">
<pmc-articleset><article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
  <?properties open_access?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Exp Brain Res</journal-id>
      <journal-title>Experimental Brain Research. Experimentelle Hirnforschung. Experimentation Cerebrale</journal-title>
      <issn pub-type="ppub">0014-4819</issn>
      <issn pub-type="epub">1432-1106</issn>
      <publisher>
        <publisher-name>Springer-Verlag</publisher-name>
        <publisher-loc>Berlin/Heidelberg</publisher-loc>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">17279379</article-id>
      <article-id pub-id-type="pmc">1914280</article-id>
      <article-id pub-id-type="publisher-id">881</article-id>
      <article-id pub-id-type="doi">10.1007/s00221-007-0881-8</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Auditory grouping occurs prior to intersensory pairing: evidence from temporal ventriloquism</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name name-style="western">
            <surname>Keetels</surname>
            <given-names>Mirjam</given-names>
          </name>
          <xref ref-type="aff" rid="Aff1"/>
        </contrib>
        <contrib contrib-type="author">
          <name name-style="western">
            <surname>Stekelenburg</surname>
            <given-names>Jeroen</given-names>
          </name>
          <xref ref-type="aff" rid="Aff1"/>
        </contrib>
        <contrib contrib-type="author" corresp="yes">
          <name name-style="western">
            <surname>Vroomen</surname>
            <given-names>Jean</given-names>
          </name>
          <address>
            <phone>+31-13-4662394</phone>
            <fax>+31-13-4662370</fax>
            <email>j.vroomen@uvt.nl</email>
          </address>
          <xref ref-type="aff" rid="Aff1"/>
        </contrib>
        <aff id="Aff1">Department of Psychology, Tilburg University, Warandelaan 2, Tilburg, The Netherlands </aff>
      </contrib-group>
      <pub-date pub-type="epub">
        <day>6</day>
        <month>2</month>
        <year>2007</year>
      </pub-date>
      <pub-date pub-type="ppub">
        <month>7</month>
        <year>2007</year>
      </pub-date>
      <volume>180</volume>
      <issue>3</issue>
      <fpage>449</fpage>
      <lpage>456</lpage>
      <history>
        <date date-type="received">
          <day>13</day>
          <month>9</month>
          <year>2006</year>
        </date>
        <date date-type="accepted">
          <day>9</day>
          <month>1</month>
          <year>2007</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>&#xA9; Springer-Verlag 2007</copyright-statement>
      </permissions>
      <abstract>
        <p>The authors examined how principles of auditory grouping relate to intersensory pairing. Two sounds that normally enhance sensitivity on a visual temporal order judgement task (i.e. temporal ventriloquism) were embedded in a sequence of flanker sounds which either had the same or different frequency (Exp. 1), rhythm (Exp. 2), or location (Exp. 3). In all experiments, we found that temporal ventriloquism only occurred when the two capture sounds differed from the flankers, demonstrating that grouping of the sounds in the auditory stream took priority over intersensory pairing. By combining principles of auditory grouping with intersensory pairing, we demonstrate that capture sounds were, counter-intuitively, more effective when their locations differed from that of the lights rather than when they came from the same position as the lights.</p>
      </abstract>
      <kwd-group>
        <title>Keywords</title>
        <kwd>Multisensory perception</kwd>
        <kwd>Auditory grouping</kwd>
        <kwd>Intersensory pairing</kwd>
        <kwd>Temporal order judgment</kwd>
        <kwd>Temporal ventriloquism</kwd>
      </kwd-group>
      <custom-meta-wrap>
        <custom-meta>
          <meta-name>issue-copyright-statement</meta-name>
          <meta-value>&#xA9; Springer-Verlag 2007</meta-value>
        </custom-meta>
      </custom-meta-wrap>
    </article-meta>
  </front>
  <body>
    <sec id="Sec1" sec-type="introduction">
      <title>Introduction</title>
      <p>Sense organs like the ears and eyes are continuously bombarded with information. Yet, observers perceive distinct objects or events. The way information is assigned to objects has, for vision, been described with Gestalt principles like &#x2018;similarity&#x2019;, &#x2018;good continuation&#x2019;, or &#x2018;common fate&#x2019;, and similar principles have also been discovered for audition (Bregman <xref ref-type="bibr" rid="CR6">1990</xref>). It occurs, for instance, when a sequence of alternating high- and low-frequency tones is played at a certain rate. When the frequency difference between the tones is small, listeners group the tones into a single stream, but at bigger frequency differences, the sequence splits into two streams, one high and one low in pitch. Typically, these grouping principles apply within a single modality like vision or audition. However, sense organs not only work in isolation, they also have to cooperate to form a coherent multisensory representation of the environment. The notion on how information from different sense organs is assigned to a multisensory event is usually referred to as the &#x2018;assumption of unity&#x2019;. It states that as events from different modalities share more amodal properties, in particular space and time, it is more likely that they originate from a common object or source (e.g. Welch and Warren <xref ref-type="bibr" rid="CR27">1980</xref>; Bedford <xref ref-type="bibr" rid="CR2">1989</xref>; Stein and Meredith <xref ref-type="bibr" rid="CR18">1993</xref>; Radeau <xref ref-type="bibr" rid="CR14">1994</xref>; Bertelson <xref ref-type="bibr" rid="CR3">1999</xref>; Welch <xref ref-type="bibr" rid="CR26">1999</xref>). Following this notion, the assignment of information from different modalities to a single multisensory event will be reduced or absent when stimuli are too far apart in space or time, because in that case two objects or events will be perceived rather than a single multimodal one.</p>
      <p>Here, we explored how principles of auditory grouping relate to intersensory pairing. Previous work on this topic suggests that auditory grouping may take priority over intersensory pairing. For example, Vroomen and de Gelder (<xref ref-type="bibr" rid="CR21">2000</xref>) used a task in which participants had to detect a visual target in a rapidly changing sequence of visual distracters. They observed that a high tone embedded in a sequence of low tones enhanced detectability of a synchronously presented visual target. There was no such intersensory enhancement when the tone was embedded in a sequence of tones with the same frequency or when the tone was part of a melody. The cross-modal enhancement thus only occurred when the sound segregated from the sound sequence in which it was embedded. Similar results were obtained by Watanabe and Shimojo (<xref ref-type="bibr" rid="CR25">2001</xref>). They explored how the &#x2018;bounce illusion&#x2019; is affected by contextual auditory information. The bounce illusion is a cross-modal phenomenon in which a &#x2018;collision&#x2019; sound presented near the crossover of two moving balls enhances the perception of the balls &#x2018;bouncing&#x2019;, whereas the absence of the sound results in a &#x2018;streaming&#x2019; percept. The authors showed a reduction of the bounce illusion when the sounds were embedded in a sequence of similar sounds, as opposed to when the sounds were flanked by sounds of a different frequency.</p>
      <p>Here we tested the generality of these findings by examining how auditory grouping affects auditory&#x2013;visual (AV) pairing in the temporal domain using the so-called temporal ventriloquist effect (Scheier et&#xA0;al. <xref ref-type="bibr" rid="CR17">1999</xref>; Fendrich and Corballis <xref ref-type="bibr" rid="CR8">2001</xref>; Aschersleben and Bertelson <xref ref-type="bibr" rid="CR1">2003</xref>; Bertelson and Aschersleben <xref ref-type="bibr" rid="CR4">2003</xref>; Morein-Zamir et&#xA0;al. <xref ref-type="bibr" rid="CR12">2003</xref>; Vroomen and de Gelder <xref ref-type="bibr" rid="CR22">2004</xref>; Stekelenburg and Vroomen <xref ref-type="bibr" rid="CR20">2005</xref>; Vroomen and Keetels <xref ref-type="bibr" rid="CR23">2006</xref>). Temporal ventriloquism refers to the phenomenon that when a sound and light are presented at slightly different onset times (usually in the order of &#x223C;100&#xA0;ms), the sound will attract the temporal occurrence of the light. This phenomenon can be demonstrated in a visual temporal order judgment (TOJ) task in which participants are presented two lights at various stimulus onset asynchronies (SOAs) and judge, which came first. By presenting a sound before the first and after the second light, the just noticeable difference (JND) improves (i.e., participants become more sensitive), presumably because the two sounds attract the temporal occurrence of the two lights, and thus effectively pull the lights further apart in time (Scheier et&#xA0;al. <xref ref-type="bibr" rid="CR17">1999</xref>; Morein-Zamir et&#xA0;al. <xref ref-type="bibr" rid="CR12">2003</xref>; Vroomen and Keetels <xref ref-type="bibr" rid="CR23">2006</xref>). Judgments about which light came first are therefore more accurate if there is a &#x223C;100&#xA0;ms interval between the sounds and lights rather than when the sounds are presented simultaneously with the lights.</p>
      <p>Here we asked what happens if the sounds that capture the onset of the lights are assigned to a stream of other sounds with which they form a well-formed sequence. If auditory grouping takes priority over intersensory pairing, one expects an improvement on the visual TOJ task only if the capture sounds segregate from the auditory stream. Alternatively, though, audio&#x2013;visual pairing might take priority over auditory grouping in which case observers should improve on the visual TOJ task no matter whether the sounds segregate or not.</p>
      <p>In Experiment 1, these predictions were tested with two capture sounds that were embedded in a sequence of flanker sounds, which either had the same or a different frequency. When the frequency of the flanker and the capture sounds were the same, the sequence was heard as a single stream which, following previous findings (Vroomen and de Gelder <xref ref-type="bibr" rid="CR21">2000</xref>; Watanabe and Shimojo <xref ref-type="bibr" rid="CR25">2001</xref>), should prevent temporal ventriloquism to occur. When the flankers differed from the capture sounds, stream segregation was more likely to occur in which case the two sounds could possibly interact with the lights and thus improve performance on the visual TOJ task. Other stream segregation cues besides the frequency of the flanker and capture sounds were further explored in Experiment 2 (rhythm) and Experiment 3 (sound location).</p>
    </sec>
    <sec id="Sec2">
      <title>Experiment 1: Capture and flanker sounds with the same or different frequency</title>
      <p>Participants performed a visual TOJ task in which they decided which of two lights appeared first. Two task-irrelevant high tones were presented either simultaneously with the lights (i.e., the &#x223C;0&#xA0;ms AV interval), or the first tone was presented &#x223C;100&#xA0;ms before the first light and the second tone &#x223C;100&#xA0;ms after the second light (i.e., the &#x223C;100&#xA0;ms AV interval). The two high tones were embedded in a sequence of other tones, which either had the same (high) or a different (low) frequency (see Fig.&#xA0;<xref rid="Fig1" ref-type="fig">1</xref>a for a schematic overview of the conditions).
<fig id="Fig1"><label>Fig.&#xA0;1</label><caption><p><bold>a</bold> A schematic illustration of a trial. Lights were presented with a particular SOA ranging between &#x2212;75 and 75&#xA0;ms, with negative values indicating that the lower light was presented first. Two capture sounds were presented either simultaneously with the lights (&#x223C;0&#xA0;ms AV-interval), or &#x223C;100&#xA0;ms before the first and &#x223C;100&#xA0;ms after the second light (&#x223C;100&#xA0;ms AV-interval). The capture sounds were embedded in a sequence of flanker sounds which either had the same or a different frequency (Exp1), rhythm (Exp 2), or location (Exp 3). Perceptual grouping of the sounds is illustrated by the <italic>grey ovals</italic>. Temporal ventriloquism only occurred when the capture sounds were different from the flanker sounds at the &#x223C;100&#xA0;ms interval, as illustrated on the second line. <bold>b</bold> Schematic set-up of Experiment 1, 2 and 3</p></caption><graphic position="anchor" xlink:href="221_2007_881_Fig1_HTML" id="MO1"/></fig></p>
      <sec id="Sec3">
        <title>Method</title>
        <p><bold>Participants</bold> Thirteen students from Tilburg University were given course credits for their participation. All reported normal hearing and normal or corrected-to-normal seeing. They were tested individually and were unaware of the purpose of the experiment. The experimental procedures were approved by the Institute and were in accordance with Declaration of Helsinki.</p>
        <p><bold>Stimuli</bold> Two auditory stimuli, a low (1,500&#xA0;Hz) and a high (3,430&#xA0;Hz) pure tone of 3&#xA0;ms at 72&#xA0;dB(A) were used that clearly differed in pitch. The sounds were presented via a hidden loudspeaker located at eye-level, at central location and at 90&#xA0;cm distance. Visual stimuli were presented by two red LEDs (diameter of 1&#xA0;cm, luminance of 40&#xA0;cd/m<sup>2</sup>), positioned 5&#xB0; below and above the central loudspeaker. A small green LED was placed at the center of the loudspeaker and served as a fixation point (see Fig.&#xA0;<xref rid="Fig1" ref-type="fig">1</xref>b for a schematic set-up). Trials in the &#x223C;0&#xA0;ms AV interval consisted of a sound sequence of 40 sounds in which the interval between the successive tones was equal to the SOA between the two lights. The lights were presented simultaneously with the 25th and 26th sound. Trials in the &#x223C;100&#xA0;ms AV-interval consisted of a tone sequence of 15 sounds with the interval between the tones equal to the SOA of the lights plus 200&#xA0;ms. The two lights were presented in the middle of the temporal gap, &#x223C;100&#xA0;ms after the 10th and &#x223C;100&#xA0;ms before the 11th sound.</p>
        <p><bold>Design</bold> The experiment had three within-subjects factors: Frequency of the flanker sounds (same or different frequency as the capture sounds), the AV-interval between the capture sounds and the lights (&#x223C;0 or &#x223C;100&#xA0;ms), and the SOA between the two lights (&#x2212;75, &#x2212;60, &#x2212;45, &#x2212;30, &#x2212;15, +15, +30, +45, +60, and +75&#xA0;ms; with negative values indicating that the lower light was presented first). These factors yielded 40 equi-probable conditions, each presented 20 times for a total of 800 trials (10 blocks of 80 trials each).</p>
        <p><bold>Procedure</bold> Participants sat at a table in a dimly lit and soundproof booth. The fixation light was illuminated at the beginning of the experiment, and participants were instructed to maintain fixation on this central green LED during testing. The participant&#x2019;s task was to judge whether the lower or the upper LED was presented first. Responses (unspeeded) were made by pressing one of two designated keys with the right thumb (lower light first) or right index (upper light first). Whenever a response was detected, both LEDs were turned off and the next trial started after 2,000&#xA0;ms. A practice block was included consisting of 16 trials in which the four longest SOAs were presented once in each condition. During practice, participants received verbal feedback (&#x201C;Correct&#x201D; or &#x201C;Wrong&#x201D;).</p>
      </sec>
      <sec id="Sec4">
        <title>Results and discussion</title>
        <p>Trials of the practice session were excluded from analyses. The proportion of &#x2018;up-first&#x2019; responses was calculated for each condition and converted into equivalent <italic>Z</italic>-scores assuming a cumulative normal distribution (cf. Finney <xref ref-type="bibr" rid="CR9">1964</xref>). For each of the four conditions, the best-fitting straight line was calculated over the ten SOAs. The lines&#x2019; slopes and intercepts were used to determine the point of subjective simultaneity (PSS) and the just noticeable difference (JND&#xA0;=&#xA0;0.675/slope). The PSS represents the average interval by which the upper stimulus had to lead the lower one in order to be perceived as simultaneous. The JND represents the smallest interval between the onsets of the two lights needed for participants to correctly judge which stimulus had been presented first on 75% of the trials. Temporal ventriloquism was measured by subtracting the JND in the &#x223C;100&#xA0;ms AV interval from the &#x223C;0&#xA0;ms AV interval (see Table&#xA0;<xref rid="Tab1" ref-type="table">1</xref> for the average JNDs).
<table-wrap id="Tab1"><label>Table&#xA0;1</label><caption><p>Mean just noticeable differences (JND) in ms, and standard errors of the mean (in parentheses) of Experiment 1 and 2</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2"/><th align="left" rowspan="2"/><th align="left" colspan="4">Flanker sounds</th></tr><tr><th align="left" colspan="2">Same as capture sounds</th><th align="left" colspan="2">Different from capture sounds</th></tr><tr><th align="left">Experiment </th><th align="left">AV-interval (ms)</th><th align="left">JND</th><th align="left">TVE</th><th align="left">JND</th><th align="left">TVE</th></tr></thead><tbody><tr><td char="." align="char" rowspan="2">Exp 1 (Frequency)</td><td char="." align="char">0</td><td char="." align="char">21.0 (0.8)</td><td char="." align="char">0.5</td><td char="." align="char">22.1 (1.1)</td><td char="." align="char">3.8*</td></tr><tr><td char="." align="char">100</td><td char="." align="char">20.5 (1.1)</td><td char="." align="char"/><td char="." align="char">18.3 (0.7)</td><td char="." align="char"/></tr><tr><td char="." align="char" rowspan="2">Exp 2 (Rhythm)</td><td char="." align="char">0</td><td char="." align="char">29.1 (2.5)</td><td char="." align="char">&#x2212;3.7</td><td char="." align="char">23.9 (1.9)</td><td char="." align="char">3.6*</td></tr><tr><td char="." align="char">100</td><td char="." align="char">32.8 (2.5)</td><td char="." align="char"/><td char="." align="char">20.3 (0.8)</td><td char="." align="char"/></tr></tbody></table><table-wrap-foot><p>Capture Sounds Presented at &#x223C;0 or &#x223C;100&#xA0;ms audio&#x2013;visual intervals; flanker Sounds with the same or different frequency (Exp 1) or rhythm (Exp 2) as capture sounds. The temporal ventriloquist effect (TVE) is the improvement in JND between the &#x223C;0 and &#x223C;100&#xA0;ms audio&#x2013;visual intervals</p><p>*<italic>P</italic>&#xA0;&lt;&#xA0;0.05</p></table-wrap-foot></table-wrap></p>
        <p>A 2&#xA0;&#xD7;&#xA0;2 ANOVA with as within-subjects factors the frequency of the flanker sounds (same or different frequency as the capturer sounds) and the AV-interval (&#x223C;0 and &#x223C;100&#xA0;ms) was conducted on the JNDs and PSSs. In the ANOVA on the PSSs, no effect was significant (all <italic>P</italic>&#x2019;s&#xA0;&gt;&#xA0;0.30), which is in line with our expectations since no shift towards more &#x2018;up&#x2019; or &#x2018;down&#x2019; responses was expected. In the ANOVA on the JNDs, the important interaction between the AV-interval and the frequency of the flanker sounds was significant, <italic>F</italic>(1, 12)&#xA0;=&#xA0;4.90, <italic>P</italic>&#xA0;&lt;&#xA0;0.05. Separate <italic>t </italic>tests comparing the &#x223C;0&#xA0;ms AV interval with the &#x223C;100&#xA0;ms AV interval showed that JNDs improved by 3.8&#xA0;ms when the frequency of the capture and flanker sounds differed, <italic>t</italic>(12)&#xA0;=&#xA0;3.06, <italic>P</italic>&#xA0;&lt;&#xA0;0.01, but no significant difference was obtained (0.5&#xA0;ms) when the capture and flanker sounds were the same, <italic>t</italic>(12)&#xA0;=&#xA0;0.71, <italic>P</italic>&#xA0;=&#xA0;0.49. As predicted, temporal ventriloquism thus only occurred when the capture and flanker sounds differed. It seems therefore likely that segregation of the capture sounds from the flankers was necessary before the capture sounds could interact with the lights. When the capture and flanker sounds were the same, auditory grouping thus took priority over AV pairing.
</p>
      </sec>
    </sec>
    <sec id="Sec5">
      <title>Experiment 2: Capture and flanker sounds with the same or different rhythm</title>
      <p>To further explore the relation between auditory grouping and intersensory pairing, we presented the capture sounds in or out of rhythm with the flankers. Rhythm is, besides frequency, another important auditory segregation cue (Bregman <xref ref-type="bibr" rid="CR6">1990</xref>). It was expected that sounds presented out of rhythm would segregate from the sound sequence, thus enhancing performance on the visual TOJ task. Capture sounds presented in rhythm should not segregate from the auditory stream, and they should thus have no effect on the visual TOJ task.</p>
      <sec id="Sec6">
        <title>Method</title>
        <p><bold>Participants</bold> Twenty new students participated.</p>
        <p><bold>Stimuli and design</bold> Stimuli and design were as in Experiment 1, except that the time interval between the capture and flanker sounds was varied rather than their frequency. The auditory stimuli consisted of 5&#xA0;m&#xA0;s sound bursts presented at 72&#xA0;dB(A). When the capture sounds were presented in rhythm with the flankers, the same interval between consecutive sounds in the sequence was used as in Experiment 1 (i.e., SOA between the two lights&#xA0;+&#xA0;2&#xA0;&#xD7;&#xA0;AV-interval). When the capture sounds were presented out of rhythm, the interval between the capture and flanker sounds was increased, such that there was a short pause before the first and after the second capture sound. In the &#x223C;0&#xA0;ms AV-interval condition, the two longer intervals were 8&#xA0;&#xD7;&#xA0;SOA of the lights, in the &#x223C;100&#xA0;ms AV-interval condition they were 17&#xA0;&#xD7;&#xA0;SOA of the lights +200&#xA0;ms.</p>
      </sec>
      <sec id="Sec7">
        <title>Results and discussion</title>
        <p>In the 2 (Capture sounds in or out of rhythm)&#xA0;&#xD7;&#xA0;2 (AV-interval &#x223C;0 or &#x223C;100&#xA0;ms) ANOVA on the PSSs, no effect was significant (all <italic>P</italic>&#x2019;s&#xA0;&gt;&#xA0;0.30). The same ANOVA on the JNDs showed that the important interaction between AV-interval and rhythm was significant, <italic>F</italic>(1, 19)&#xA0;=&#xA0;15.35, <italic>P</italic>&#xA0;&lt;&#xA0;0.001. Separate <italic>t </italic>tests showed that the 3.6&#xA0;ms temporal ventriloquist effect (lower JNDs in the &#x223C;100&#xA0;ms AV interval rather than &#x223C;0&#xA0;ms) of sounds presented out of rhythm was significant, <italic>t</italic>(19)&#xA0;=&#xA0;2.37, <italic>P</italic>&#xA0;&lt;&#xA0;0.05. Performance got actually worse (&#x2212;3.7&#xA0;ms) when the capture sounds were presented in the same rhythm as the flanker sounds, <italic>t</italic>(19)&#xA0;=&#xA0;&#x2212;2.15, <italic>P</italic>&#xA0;&lt;&#xA0;0.05. Capture sounds thus again only improved performance on the visual TOJ task when they segregated from the flanker sounds.</p>
      </sec>
    </sec>
    <sec id="Sec8">
      <title>Experiment 3: Capture and flanker sounds from the same or different location</title>
      <p>It is known that auditory stream segregation may also occur when there is a difference in the location of consecutive sounds (Bregman <xref ref-type="bibr" rid="CR6">1990</xref>). In Experiment 3, we therefore varied the location of the capture and flanker sounds. The sounds could emanate either from a central loudspeaker near the two lights, or from a lateral loudspeaker on the far left or far right. If intersensory pairing only occurs when the capture sounds segregate from the flankers, then temporal ventriloquism should be obtained when the locations of the capture and flanker sound differ, but not when they are the same.</p>
      <p>This set-up also allowed us to explore whether spatial disparity between the capture sounds and lights affects intersensory pairing. The common notion on intersensory pairing states that commonality in space between the auditory and visual signal matters. However, in contrast with this notion, it has recently been shown that temporal ventriloquism may not be affected by spatial discordance between the sounds and lights. In a study by Vroomen and Keetels (<xref ref-type="bibr" rid="CR23">2006</xref>), it was shown that there were equal amounts of temporal ventriloquism when the two capture sounds came from the same or a different position as the lights, when the sounds were static or moved, or when the sounds and lights came from the same or opposite sides of fixation. Assuming that these results would be replicated in the present set-up as well, we expected sound location to be unimportant for intersensory pairing. Equal amounts of temporal ventriloquism were therefore expected from segregated sounds presented from the central location (near the lights) and the lateral location (far from the lights).</p>
      <p>The notion that sound location matters for auditory grouping, but not for intersensory pairing also lead to a very counter-intuitive prediction. In case flanker sounds were presented near the central lights, there should more temporal ventriloquism by capture sounds presented from a lateral position than from central position, because only the lateral sounds segregate. With central flankers, there should thus be more temporal ventriloquism when the location of the sounds and lights differ, rather then when they are the same.</p>
      <sec id="Sec9">
        <title>Method</title>
        <p>Participants, stimuli and procedures were the same as in Experiment 1, except for the following changes. Eighteen new students from the same subject pool participated. The auditory stimuli consisted of 5&#xA0;ms sound bursts presented at 72&#xA0;dB(A), presented from one of two loudspeakers (see Fig.&#xA0;<xref rid="Fig1" ref-type="fig">1</xref>b). One speaker was located at central location at eye-level and at 90&#xA0;cm distance (as in Experiments 1 and 2), the other was located on either the far left or the far right (at 90&#xB0; azimuth). Four within-subjects factors were used: Location of the two capture sounds (central or lateral), Location of the flanker sounds (same or different position as the capture sounds), the AV-interval between the capture sounds and lights (&#x223C;0 or &#x223C;100&#xA0;ms), and the SOA between the two lights (&#x2212;75 to +75&#xA0;ms). The 80 conditions were each presented 20 times in 10 blocks of 160 trials each. In half of the blocks, the lateral speaker was on the left, in the other half it was on the right.</p>
      </sec>
      <sec id="Sec10">
        <title>Results</title>
        <p>A 2&#xA0;&#xD7;&#xA0;2&#xA0;&#xD7;&#xA0;2 ANOVA with as within-subjects factors Location of the two capture sounds (central or lateral), location of the flanker sounds (same or different position as the capture sounds) and the AV interval (&#x223C;0 and &#x223C;100&#xA0;ms) was conducted on the JNDs and PSSs. In the ANOVA on the PSS, there was an interaction between the location of the capture and flanker sounds, <italic>F</italic>(1, 17)&#xA0;=&#xA0;6.31, <italic>P</italic>&#xA0;&lt;&#xA0;0.025, indicating that there were slightly more &#x2018;up&#x2019; responses in trials in which the capture and flanker sounds were presented centrally (mean PSS&#xA0;=&#xA0;&#x2212;1.84&#xA0;ms) rather than in the other conditions (mean PSS&#xA0;=&#xA0;2.61&#xA0;ms), a finding for which there is no clear explanation.</p>
        <p>In the ANOVA on the JNDs (see Table <xref rid="Tab2" ref-type="table">2</xref>) there was no main effect of the location of the capture sounds, <italic>F</italic>(1, 17)&#xA0;=&#xA0;1.67, <italic>P</italic>&#xA0;=&#xA0;0.21, indicating that JNDs were unaffected by whether the capture sounds were presented centrally (near the two lights) or laterally. Most importantly, there was an interaction between the AV-interval and the location of the flanker sounds, <italic>F</italic>(1, 17)&#xA0;=&#xA0;5.11, <italic>P</italic>&#xA0;&lt;&#xA0;0.05. Separate <italic>t</italic> tests confirmed that the temporal ventriloquist effect (better performance at &#x223C;100&#xA0;ms rather than &#x223C;0&#xA0;ms AV interval) was only significant when the flanker sounds came from a different position than the capture sounds. There was thus no temporal ventriloquism when the capture and flanker sounds came both from central or lateral positions (both <italic>P</italic>&#x2019;s&#xA0;&gt;&#xA0;0.6), while there was a 3.9&#xA0;ms improvement for central capture sounds with lateral flankers, <italic>t</italic>(17)&#xA0;=&#xA0;2.175, <italic>P</italic>&#xA0;&lt;&#xA0;0.05, and a 3.1&#xA0;ms improvement for lateral capture sounds with central flankers, <italic>t</italic>(17)&#xA0;=&#xA0;2.55, <italic>P</italic>&#xA0;&lt;&#xA0;0.025. These two improvements were not significantly different from each other, <italic>t</italic>(17)&#xA0;=&#xA0;0.52, <italic>P</italic>&#xA0;=&#xA0;0.60. Moreover, as predicted, with central flankers, temporal ventriloquism by lateral capture sounds was bigger than that from central ones, <italic>t</italic>(18)&#xA0;=&#xA0;1.798, <italic>P</italic>&#xA0;&lt;&#xA0;0.05.<table-wrap id="Tab2"><label>Table&#xA0;2</label><caption><p>Mean just noticeable differences (JND) in ms, and standard errors of the mean (in parentheses) of Experiment 3</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left"/><th align="left" colspan="4">Location of flanker sounds</th></tr><tr><th align="left"/><th align="left"/><th align="left" colspan="2">Same as capture sounds</th><th align="left" colspan="2">Different from capture sounds</th></tr><tr><th align="left">Location of capture sounds</th><th align="left">AV-interval (ms)</th><th align="left">JND</th><th align="left">TVE</th><th align="left">JND</th><th align="left">TVE</th></tr></thead><tbody><tr><td align="left" rowspan="2">Central</td><td char="." align="char">0</td><td char="." align="char">28.2 (2.1)</td><td char="." align="char">&#x2212;0.9</td><td char="." align="char">27.7 (2.0)</td><td char="." align="char">3.9*</td></tr><tr><td char="." align="char">100</td><td char="." align="char">29.1 (2.3)</td><td char="." align="char"/><td char="." align="char">23.8 (1.4)</td><td char="." align="char"/></tr><tr><td align="left" rowspan="2">Lateral</td><td char="." align="char">0</td><td char="." align="char">30.0 (2.2)</td><td char="." align="char">1.7</td><td char="." align="char">29.0 (1.8)</td><td char="." align="char">3.1*</td></tr><tr><td char="." align="char">100</td><td char="." align="char">28.3 (2.0)</td><td char="." align="char"/><td char="." align="char">25.9 (1.8)</td><td char="." align="char"/></tr></tbody></table><table-wrap-foot><p>Capture Sounds Presented at &#x223C;0 or &#x223C;100&#xA0;ms audio&#x2013;visual intervals from central or lateral location; flanker sounds presented from the same or different location as the capture sounds. The temporal ventriloquist effect (TVE) is the improvement in JND between the &#x223C;0 and &#x223C;100&#xA0;ms audio&#x2013;visual intervals</p><p>*<italic>P</italic>&#xA0;&lt;&#xA0;0.05</p></table-wrap-foot></table-wrap></p>
      </sec>
    </sec>
    <sec id="Sec11">
      <title>General discussion</title>
      <p>This study examined how principles of auditory grouping relate to intersensory pairing. Two capture sounds that normally enhance performance on a visual TOJ task (i.e. temporal ventriloquism) were embedded in a sequence of flanker sounds which could differ in frequency (Exp. 1), rhythm (Exp. 2), or location (Exp. 3). In all experiments, we found that temporal ventriloquism only occurred when the capture sounds differed from the flankers, and there was thus no effect when flanker and capture sounds were the same. Presumably, when the capture sounds differ, they segregate from the auditory stream, and only then they can be paired cross-modally with the lights. When the two capture sounds do not differ from the flankers, they are perceptually grouped in an auditory stream, in which case they lose their saliency and cannot interact cross-modally anymore.</p>
      <p>These results are similar to previous findings, which have shown that intersensory interactions do not occur when sounds that normally enhance performance belong to another auditory group (Vroomen and de Gelder <xref ref-type="bibr" rid="CR21">2000</xref>; Watanabe and Shimojo <xref ref-type="bibr" rid="CR25">2001</xref>; See also Sanabria et&#xA0;al. <xref ref-type="bibr" rid="CR15">2004a</xref>, <xref ref-type="bibr" rid="CR16">b</xref>). The results also imply that a sound can only be assigned to a single event: it either belongs to the auditory stream, or it is paired with the lights, but it cannot be assigned to both simultaneously. In this respect, it is analogous to many of the well-known ambiguous figure-ground displays (e.g., the Face-Vase illusion or the Necker cube), where it is known that only one interpretation of the scene can be maintained.</p>
      <p>Another important finding was that commonality in space between the capture sounds and lights did not affect temporal ventriloquism. The temporal ventriloquist effect was thus equally big for segregated capture sounds that were presented near the lights or far away from the lights. A few other studies have demonstrated before that spatial disparity between sound and vision may not affect intersensory interactions (Welch et&#xA0;al. <xref ref-type="bibr" rid="CR28">1986</xref>; Bertelson et&#xA0;al. <xref ref-type="bibr" rid="CR5">1994</xref>; Stein et&#xA0;al. <xref ref-type="bibr" rid="CR19">1996</xref>; Colin et&#xA0;al. <xref ref-type="bibr" rid="CR7">2001</xref>; Murray et&#xA0;al. <xref ref-type="bibr" rid="CR13">2004</xref>; Vroomen and Keetels <xref ref-type="bibr" rid="CR23">2006</xref>). However, these studies always relied on null-effects, which entails the danger that they simply lacked the power to detect any effect of spatial disparity. Participants in previous studies might, for example, not have been able to perceive spatial disparity, or they might have learned to ignore it in the experimental task. Our findings, though, counter these arguments. By combining principles of auditory grouping with intersensory pairing, we were able to create a situation where the capture sounds were actually more effective when their locations differed from that of the lights rather than when they came from the same position as the lights. Within the same experimental situation, we thus demonstrated that sound location mattered for auditory grouping, but not for intersensory pairing. Such a finding makes it highly unlikely that sound location was not perceived or simply ignored. Rather, it becomes more likely that, at least in the temporal ventriloquist situation, commonality in space between sound and vision is not relevant for AV pairing.</p>
      <p>This may, at first sight, seem unlikely, because after all, most natural multisensory events are spatially an temporally aligned, except for some minor variations in time or space that people are readily able to adjust (e.g. Vroomen et&#xA0;al. <xref ref-type="bibr" rid="CR24">2004</xref>). However, a critical assumption that underlies the idea of spatial correspondence for intersensory pairing is that space has the same function in vision and audition. This notion, though, is arguable as it has been proposed that the role of space in hearing is only to steer vision (Heffner and Heffner <xref ref-type="bibr" rid="CR10">1992</xref>), while in vision it is an indispensable attribute (Kubovy and Van Valkenburg <xref ref-type="bibr" rid="CR11">2001</xref>). If one accepts that auditory spatial perception evolved for steering vision, but not for deciding whether sound and light belong together, there is no reason why intersensory interactions would require spatial co-localization. Our results therefore have also important implications for designing multimodal devices or creating virtual reality environments, as they show that the brain can, at least in some cases, ignore intersensory discordance in space.</p>
    </sec>
  </body>
  <back>
    <ref-list id="Bib1">
      <title>References</title>
      <ref id="CR1">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Aschersleben</surname>
              <given-names>G</given-names>
            </name>
            <name>
              <surname>Bertelson</surname>
              <given-names>P</given-names>
            </name>
          </person-group>
          <article-title>Temporal ventriloquism: crossmodal interaction on the time dimension. 2. Evidence from sensorimotor synchronization</article-title>
          <source>Int J Psychophysiol</source>
          <year>2003</year>
          <volume>50</volume>
          <fpage>157</fpage>
          <lpage>163</lpage>
          <pub-id pub-id-type="doi">10.1016/S0167-8760(03)00131-4</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Aschersleben G, Bertelson P (2003) Temporal ventriloquism: crossmodal interaction on the time dimension. 2. Evidence from sensorimotor synchronization. Int J Psychophysiol 50:157&#x2013;163 <pub-id pub-id-type="pmid">14511843</pub-id></citation>
      </ref>
      <ref id="CR2">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bedford</surname>
              <given-names>FL</given-names>
            </name>
          </person-group>
          <article-title>Constraints on learning new mappings between perceptual dimensions</article-title>
          <source>J Exp Psychol-Hum Percept Perform</source>
          <year>1989</year>
          <volume>15</volume>
          <fpage>232</fpage>
          <lpage>248</lpage>
          <pub-id pub-id-type="doi">10.1037/0096-1523.15.2.232</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Bedford FL (1989) Constraints on learning new mappings between perceptual dimensions. J Exp Psychol-Hum Percept Perform 15:232&#x2013;248 </citation>
      </ref>
      <ref id="CR3">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Bertelson</surname>
              <given-names>P</given-names>
            </name>
          </person-group>
          <person-group person-group-type="editor">
            <name>
              <surname>Aschersleben</surname>
              <given-names>G</given-names>
            </name>
            <name>
              <surname>Bachmann</surname>
              <given-names>T</given-names>
            </name>
            <name>
              <surname>Musseler</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <article-title>Ventriloquism: a case of crossmodal perceptual grouping</article-title>
          <source>Cognitive contributions to the perception of spatial and temporal events</source>
          <year>1999</year>
          <publisher-loc>North-Holland</publisher-loc>
          <publisher-name>Elsevier</publisher-name>
          <fpage>347</fpage>
          <lpage>363</lpage>
        </citation>
        <citation citation-type="display-unstructured">Bertelson P (1999) Ventriloquism: a case of crossmodal perceptual grouping. In: Aschersleben G, Bachmann T, Musseler J (eds) Cognitive contributions to the perception of spatial and temporal events. Elsevier, North-Holland, pp 347&#x2013;363 </citation>
      </ref>
      <ref id="CR4">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Bertelson</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Aschersleben</surname>
              <given-names>G</given-names>
            </name>
          </person-group>
          <article-title>Temporal ventriloquism: crossmodal interaction on the time dimension. 1. Evidence from auditory-visual temporal order judgment</article-title>
          <source>Int J Psychophysiol</source>
          <year>2003</year>
          <volume>50</volume>
          <fpage>147</fpage>
          <lpage>155</lpage>
          <pub-id pub-id-type="doi">10.1016/S0167-8760(03)00130-2</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Bertelson P, Aschersleben G (2003) Temporal ventriloquism: crossmodal interaction on the time dimension. 1. Evidence from auditory-visual temporal order judgment. Int J Psychophysiol 50:147&#x2013;155 <pub-id pub-id-type="pmid">14511842</pub-id></citation>
      </ref>
      <ref id="CR5">
        <citation citation-type="other">Bertelson P, Vroomen J, Wiegeraad G, de Gelder B (1994) Exploring the relation between McGurk interference and ventriloquism. In: International congress on spoken language processing, vol 2, Yokohama, pp 559&#x2013;562</citation>
      </ref>
      <ref id="CR6">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Bregman</surname>
              <given-names>AS</given-names>
            </name>
          </person-group>
          <source>Auditory scene analysis</source>
          <year>1990</year>
          <publisher-loc>Cambridge</publisher-loc>
          <publisher-name>MIT Press</publisher-name>
        </citation>
        <citation citation-type="display-unstructured">Bregman AS (1990) Auditory scene analysis. MIT Press, Cambridge </citation>
      </ref>
      <ref id="CR7">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Colin</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Radeau</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Deltenre</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Morais</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <article-title>Rules of intersensory integration in spatial scene analysis and speechreading</article-title>
          <source>Psychol Belgica</source>
          <year>2001</year>
          <volume>41</volume>
          <fpage>131</fpage>
          <lpage>144</lpage>
        </citation>
        <citation citation-type="display-unstructured">Colin C, Radeau M, Deltenre P, Morais J (2001) Rules of intersensory integration in spatial scene analysis and speechreading. Psychol Belgica 41:131&#x2013;144 </citation>
      </ref>
      <ref id="CR8">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Fendrich</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Corballis</surname>
              <given-names>PM</given-names>
            </name>
          </person-group>
          <article-title>The temporal cross-capture of audition and vision</article-title>
          <source>Percept Psychophys</source>
          <year>2001</year>
          <volume>63</volume>
          <fpage>719</fpage>
          <lpage>725</lpage>
        </citation>
        <citation citation-type="display-unstructured">Fendrich R, Corballis PM (2001) The temporal cross-capture of audition and vision. Percept Psychophys 63:719&#x2013;725 <pub-id pub-id-type="pmid">11436740</pub-id></citation>
      </ref>
      <ref id="CR9">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Finney</surname>
              <given-names>DJ</given-names>
            </name>
          </person-group>
          <source>Probit analysis</source>
          <year>1964</year>
          <publisher-loc>Cambridge</publisher-loc>
          <publisher-name>Cambridge University Press</publisher-name>
        </citation>
        <citation citation-type="display-unstructured">Finney DJ (1964) Probit analysis. Cambridge University Press, Cambridge </citation>
      </ref>
      <ref id="CR10">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Heffner</surname>
              <given-names>RS</given-names>
            </name>
            <name>
              <surname>Heffner</surname>
              <given-names>HE</given-names>
            </name>
          </person-group>
          <article-title>Visual factors in sound localization in mammals</article-title>
          <source>J Comp Neurol</source>
          <year>1992</year>
          <volume>317</volume>
          <fpage>219</fpage>
          <lpage>232</lpage>
          <pub-id pub-id-type="doi">10.1002/cne.903170302</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Heffner RS, Heffner HE (1992) Visual factors in sound localization in mammals. J Comp Neurol 317:219&#x2013;232 <pub-id pub-id-type="pmid">1577997</pub-id></citation>
      </ref>
      <ref id="CR11">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kubovy</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Valkenburg</surname>
              <given-names>D</given-names>
            </name>
          </person-group>
          <article-title>Auditory and visual objects</article-title>
          <source>Cognition</source>
          <year>2001</year>
          <volume>80</volume>
          <fpage>97</fpage>
          <lpage>126</lpage>
          <pub-id pub-id-type="doi">10.1016/S0010-0277(00)00155-4</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Kubovy M, Van Valkenburg D (2001) Auditory and visual objects. Cognition 80:97&#x2013;126 <pub-id pub-id-type="pmid">11245841</pub-id></citation>
      </ref>
      <ref id="CR12">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Morein-Zamir</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Soto-Faraco</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Kingstone</surname>
              <given-names>A</given-names>
            </name>
          </person-group>
          <article-title>Auditory capture of vision: examining temporal ventriloquism</article-title>
          <source>Cogn Brain Res</source>
          <year>2003</year>
          <volume>17</volume>
          <fpage>154</fpage>
          <lpage>163</lpage>
          <pub-id pub-id-type="doi">10.1016/S0926-6410(03)00089-2</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Morein-Zamir S, Soto-Faraco S, Kingstone A (2003) Auditory capture of vision: examining temporal ventriloquism. Cogn Brain Res 17:154&#x2013;163 </citation>
      </ref>
      <ref id="CR13">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Murray</surname>
              <given-names>MM</given-names>
            </name>
            <name>
              <surname>Michel</surname>
              <given-names>CM</given-names>
            </name>
            <name>
              <surname>Grave Peralta</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Ortigue</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Brunet</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Gonzalez Andino</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Schnider</surname>
              <given-names>A</given-names>
            </name>
          </person-group>
          <article-title>Rapid discrimination of visual and multisensory memories revealed by electrical neuroimaging</article-title>
          <source>Neuroimage</source>
          <year>2004</year>
          <volume>21</volume>
          <fpage>125</fpage>
          <lpage>135</lpage>
          <pub-id pub-id-type="doi">10.1016/j.neuroimage.2003.09.035</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Murray MM, Michel CM, Grave de Peralta R, Ortigue S, Brunet D, Gonzalez Andino S, Schnider A (2004) Rapid discrimination of visual and multisensory memories revealed by electrical neuroimaging. Neuroimage 21:125&#x2013;135 <pub-id pub-id-type="pmid">14741649</pub-id></citation>
      </ref>
      <ref id="CR14">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Radeau</surname>
              <given-names>M</given-names>
            </name>
          </person-group>
          <article-title>Auditory&#x2013;visual spatial interaction and modularity</article-title>
          <source>Cah Psychol Cogn-Curr Psychol Cogn</source>
          <year>1994</year>
          <volume>13</volume>
          <fpage>3</fpage>
          <lpage>51</lpage>
        </citation>
        <citation citation-type="display-unstructured">Radeau M (1994) Auditory&#x2013;visual spatial interaction and modularity. Cah Psychol Cogn-Curr Psychol Cogn 13:3&#x2013;51 </citation>
      </ref>
      <ref id="CR15">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sanabria</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Correa</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Lupianez</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Spence</surname>
              <given-names>C</given-names>
            </name>
          </person-group>
          <article-title>Bouncing or streaming? Exploring the influence of auditory cues on the interpretation of ambiguous visual motion</article-title>
          <source>Exp Brain Res</source>
          <year>2004</year>
          <volume>157</volume>
          <fpage>537</fpage>
          <lpage>541</lpage>
          <pub-id pub-id-type="doi">10.1007/s00221-004-1993-z</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Sanabria D, Correa A, Lupianez J, Spence C (2004a) Bouncing or streaming? Exploring the influence of auditory cues on the interpretation of ambiguous visual motion. Exp Brain Res 157:537&#x2013;541 <pub-id pub-id-type="pmid">15241576</pub-id></citation>
      </ref>
      <ref id="CR16">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Sanabria</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Soto-Faraco</surname>
              <given-names>S</given-names>
            </name>
            <name>
              <surname>Spence</surname>
              <given-names>C</given-names>
            </name>
          </person-group>
          <article-title>Exploring the role of visual perceptual grouping on the audiovisual integration of motion</article-title>
          <source>Neuroreport</source>
          <year>2004</year>
          <volume>15</volume>
          <fpage>2745</fpage>
          <lpage>2749</lpage>
        </citation>
        <citation citation-type="display-unstructured">Sanabria D, Soto-Faraco S, Spence C (2004b) Exploring the role of visual perceptual grouping on the audiovisual integration of motion. Neuroreport 15:2745&#x2013;2749 <pub-id pub-id-type="pmid">15597046</pub-id></citation>
      </ref>
      <ref id="CR17">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Scheier</surname>
              <given-names>CR</given-names>
            </name>
            <name>
              <surname>Nijhawan</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Shimojo</surname>
              <given-names>S</given-names>
            </name>
          </person-group>
          <article-title>Sound alters visual temporal resolution</article-title>
          <source>Invest Ophthalmol Vis Sci</source>
          <year>1999</year>
          <volume>40</volume>
          <fpage>4169</fpage>
        </citation>
        <citation citation-type="display-unstructured">Scheier CR, Nijhawan R, Shimojo S (1999) Sound alters visual temporal resolution. Invest Ophthalmol Vis Sci 40:4169 </citation>
      </ref>
      <ref id="CR18">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Stein</surname>
              <given-names>BE</given-names>
            </name>
            <name>
              <surname>Meredith</surname>
              <given-names>MA</given-names>
            </name>
          </person-group>
          <source>The merging of the senses</source>
          <year>1993</year>
          <publisher-loc>Cambridge</publisher-loc>
          <publisher-name>The MIT Press</publisher-name>
        </citation>
        <citation citation-type="display-unstructured">Stein BE, Meredith MA (1993) The merging of the senses. The MIT Press, Cambridge </citation>
      </ref>
      <ref id="CR19">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Stein</surname>
              <given-names>BE</given-names>
            </name>
            <name>
              <surname>London</surname>
              <given-names>N</given-names>
            </name>
            <name>
              <surname>Wilkinson</surname>
              <given-names>LK</given-names>
            </name>
            <name>
              <surname>Price</surname>
              <given-names>DD</given-names>
            </name>
          </person-group>
          <article-title>Enhancement of perceived visual intensity by auditory stimuli: a psychophysical analysis</article-title>
          <source>J Cogn Neurosci</source>
          <year>1996</year>
          <volume>8</volume>
          <fpage>497</fpage>
          <lpage>506</lpage>
        </citation>
        <citation citation-type="display-unstructured">Stein BE, London N, Wilkinson LK, Price DD (1996) Enhancement of perceived visual intensity by auditory stimuli: a psychophysical analysis. J Cogn Neurosci 8:497&#x2013;506 </citation>
      </ref>
      <ref id="CR20">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Stekelenburg</surname>
              <given-names>JJ</given-names>
            </name>
            <name>
              <surname>Vroomen</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <article-title>An event-related potential investigation of the time-course of temporal ventriloquism</article-title>
          <source>Neuroreport</source>
          <year>2005</year>
          <volume>16</volume>
          <fpage>641</fpage>
          <lpage>644</lpage>
          <pub-id pub-id-type="doi">10.1097/00001756-200504250-00025</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Stekelenburg JJ, Vroomen J (2005) An event-related potential investigation of the time-course of temporal ventriloquism. Neuroreport 16:641&#x2013;644 <pub-id pub-id-type="pmid">15812324</pub-id></citation>
      </ref>
      <ref id="CR21">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vroomen</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Gelder</surname>
              <given-names>B</given-names>
            </name>
          </person-group>
          <article-title>Sound enhances visual perception: cross-modal effects of auditory organization on vision</article-title>
          <source>J Exp Psychol Hum Percept Perform</source>
          <year>2000</year>
          <volume>26</volume>
          <fpage>1583</fpage>
          <lpage>1590</lpage>
          <pub-id pub-id-type="doi">10.1037/0096-1523.26.5.1583</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Vroomen J, de Gelder B (2000) Sound enhances visual perception: cross-modal effects of auditory organization on vision. J Exp Psychol Hum Percept Perform 26:1583&#x2013;1590 <pub-id pub-id-type="pmid">11039486</pub-id></citation>
      </ref>
      <ref id="CR22">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vroomen</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Gelder</surname>
              <given-names>B</given-names>
            </name>
          </person-group>
          <article-title>Temporal ventriloquism: sound modulates the flash-lag effect</article-title>
          <source>J Exp Psychol-Hum Percept Perform</source>
          <year>2004</year>
          <volume>30</volume>
          <fpage>513</fpage>
          <lpage>518</lpage>
          <pub-id pub-id-type="doi">10.1037/0096-1523.30.3.513</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Vroomen J, de Gelder B (2004) Temporal ventriloquism: sound modulates the flash-lag effect. J Exp Psychol-Hum Percept Perform 30:513&#x2013;518 <pub-id pub-id-type="pmid">15161383</pub-id></citation>
      </ref>
      <ref id="CR23">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vroomen</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Keetels</surname>
              <given-names>M</given-names>
            </name>
          </person-group>
          <article-title>The spatial constraint in intersensory pairing: no role in temporal ventriloquism</article-title>
          <source>J Exp Psychol Hum Percept Perform</source>
          <year>2006</year>
          <volume>32</volume>
          <issue>4</issue>
          <fpage>1063</fpage>
          <lpage>1071</lpage>
          <pub-id pub-id-type="doi">10.1037/0096-1523.32.4.1063</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Vroomen J, Keetels M (2006) The spatial constraint in intersensory pairing: no role in temporal ventriloquism. J Exp Psychol Hum Percept Perform 32(4):1063&#x2013;1071 <pub-id pub-id-type="pmid">16846297</pub-id></citation>
      </ref>
      <ref id="CR24">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Vroomen</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Keetels</surname>
              <given-names>M</given-names>
            </name>
            <name>
              <surname>Gelder</surname>
              <given-names>B</given-names>
            </name>
            <name>
              <surname>Bertelson</surname>
              <given-names>P</given-names>
            </name>
          </person-group>
          <article-title>Recalibration of temporal order perception by exposure to audio&#x2013;visual asynchrony</article-title>
          <source>Cogn Brain Res</source>
          <year>2004</year>
          <volume>22</volume>
          <fpage>32</fpage>
          <lpage>35</lpage>
          <pub-id pub-id-type="doi">10.1016/j.cogbrainres.2004.07.003</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Vroomen J, Keetels M, de Gelder B, Bertelson P (2004) Recalibration of temporal order perception by exposure to audio&#x2013;visual asynchrony. Cogn Brain Res 22:32&#x2013;35 </citation>
      </ref>
      <ref id="CR25">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Watanabe</surname>
              <given-names>K</given-names>
            </name>
            <name>
              <surname>Shimojo</surname>
              <given-names>S</given-names>
            </name>
          </person-group>
          <article-title>When sound affects vision: effects of auditory grouping on visual motion perception</article-title>
          <source>Psychol Sci</source>
          <year>2001</year>
          <volume>12</volume>
          <fpage>109</fpage>
          <lpage>116</lpage>
          <pub-id pub-id-type="doi">10.1111/1467-9280.00319</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Watanabe K, Shimojo S (2001) When sound affects vision: effects of auditory grouping on visual motion perception. Psychol Sci 12:109&#x2013;116 <pub-id pub-id-type="pmid">11340918</pub-id></citation>
      </ref>
      <ref id="CR26">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Welch</surname>
              <given-names>RB</given-names>
            </name>
          </person-group>
          <person-group person-group-type="editor">
            <name>
              <surname>Aschersleben</surname>
              <given-names>G</given-names>
            </name>
            <name>
              <surname>Bachmann</surname>
              <given-names>T</given-names>
            </name>
            <name>
              <surname>M&#xFC;sseler</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <article-title>Meaning, attention, and the &#x201C;unity assumption&#x201D; in the intersensory bias of spatial and temporal perceptions</article-title>
          <source>Cognitive contributions to the perception of spatial and temporal events</source>
          <year>1999</year>
          <publisher-loc>Amsterdam</publisher-loc>
          <publisher-name>Elsevier</publisher-name>
          <fpage>371</fpage>
          <lpage>387</lpage>
        </citation>
        <citation citation-type="display-unstructured">Welch RB (1999) Meaning, attention, and the &#x201C;unity assumption&#x201D; in the intersensory bias of spatial and temporal perceptions. In: Aschersleben G, Bachmann T, M&#xFC;sseler J (eds) Cognitive contributions to the perception of spatial and temporal events. Elsevier, Amsterdam, pp 371&#x2013;387 </citation>
      </ref>
      <ref id="CR27">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Welch</surname>
              <given-names>RB</given-names>
            </name>
            <name>
              <surname>Warren</surname>
              <given-names>DH</given-names>
            </name>
          </person-group>
          <article-title>Immediate perceptual response to intersensory discrepancy</article-title>
          <source>Psychol Bull</source>
          <year>1980</year>
          <volume>88</volume>
          <fpage>638</fpage>
          <lpage>667</lpage>
          <pub-id pub-id-type="doi">10.1037/0033-2909.88.3.638</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Welch RB, Warren DH (1980) Immediate perceptual response to intersensory discrepancy. Psychol Bull 88:638&#x2013;667 <pub-id pub-id-type="pmid">7003641</pub-id></citation>
      </ref>
      <ref id="CR28">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Welch</surname>
              <given-names>RB</given-names>
            </name>
            <name>
              <surname>DuttonHurt</surname>
              <given-names>LD</given-names>
            </name>
            <name>
              <surname>Warren</surname>
              <given-names>DH</given-names>
            </name>
          </person-group>
          <article-title>Contributions of audition and vision to temporal rate perception</article-title>
          <source>Percept Psychophys</source>
          <year>1986</year>
          <volume>39</volume>
          <fpage>294</fpage>
          <lpage>300</lpage>
        </citation>
        <citation citation-type="display-unstructured">Welch RB, DuttonHurt LD, Warren DH (1986) Contributions of audition and vision to temporal rate perception. Percept Psychophys 39:294&#x2013;300 <pub-id pub-id-type="pmid">3737359</pub-id></citation>
      </ref>
    </ref-list>
  </back>
</article>
</pmc-articleset>