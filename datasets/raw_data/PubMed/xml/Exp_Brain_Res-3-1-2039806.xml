<?xml version="1.0" ?>
<!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd">
<pmc-articleset><article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article">
  <?properties open_access?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Exp Brain Res</journal-id>
      <journal-title>Experimental Brain Research. Experimentelle Hirnforschung. Experimentation Cerebrale</journal-title>
      <issn pub-type="ppub">0014-4819</issn>
      <issn pub-type="epub">1432-1106</issn>
      <publisher>
        <publisher-name>Springer-Verlag</publisher-name>
        <publisher-loc>Berlin/Heidelberg</publisher-loc>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">17632707</article-id>
      <article-id pub-id-type="pmc">2039806</article-id>
      <article-id pub-id-type="publisher-id">1043</article-id>
      <article-id pub-id-type="doi">10.1007/s00221-007-1043-8</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Judging surface slant for placing objects: a role for motion parallax</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" corresp="yes">
          <name name-style="western">
            <surname>Louw</surname>
            <given-names>Stefan</given-names>
          </name>
          <address>
            <phone>+31-20-5982574</phone>
            <fax>+31-20-5988529</fax>
            <email>S.Louw@fbw.vu.nl</email>
          </address>
          <xref ref-type="aff" rid="Aff1"/>
        </contrib>
        <contrib contrib-type="author">
          <name name-style="western">
            <surname>Smeets</surname>
            <given-names>Jeroen B. J.</given-names>
          </name>
          <xref ref-type="aff" rid="Aff1"/>
        </contrib>
        <contrib contrib-type="author">
          <name name-style="western">
            <surname>Brenner</surname>
            <given-names>Eli</given-names>
          </name>
          <xref ref-type="aff" rid="Aff1"/>
        </contrib>
        <aff id="Aff1">Faculty of Human Movement Sciences, Vrije Universiteit, Van der Boechorststraat 9, 1081 BT Amsterdam, The Netherlands </aff>
      </contrib-group>
      <pub-date pub-type="epub">
        <day>14</day>
        <month>7</month>
        <year>2007</year>
      </pub-date>
      <pub-date pub-type="ppub">
        <month>11</month>
        <year>2007</year>
      </pub-date>
      <volume>183</volume>
      <issue>2</issue>
      <fpage>149</fpage>
      <lpage>158</lpage>
      <history>
        <date date-type="received">
          <day>14</day>
          <month>8</month>
          <year>2006</year>
        </date>
        <date date-type="accepted">
          <day>12</day>
          <month>6</month>
          <year>2007</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>&#xA9; Springer-Verlag 2007</copyright-statement>
      </permissions>
      <abstract>
        <p>People have a variety of sources of information (cues) about surface slant at their disposal. We used a simple placing task to evaluate the relative importance of three such cues (motion parallax, binocular disparity and texture) within the space in which people normally manipulate objects. To do so, we projected a stimulus onto a rotatable screen. This allowed us to manipulate texture cues independently of binocular disparity and motion parallax. We asked people to stand in front of the screen and place a cylinder on the screen. We analysed the cylinder&#x2019;s orientation just before contact. Participants mainly relied on binocular cues (weight between 50 and 90%), in accordance with binocular cues being known to be reliable when the stimulus surface is nearby and almost frontal. Texture cues contributed between 2 and 18% to the estimated slant. Motion parallax was given a weight between 1 and 9%, despite the fact that it only provided information when the head began to move, which was just before the arm did. Thus motion parallax is used to judge surface slant, even when one is under the impression of standing still.</p>
      </abstract>
      <kwd-group>
        <title>Keywords</title>
        <kwd>Motion parallax</kwd>
        <kwd>Texture</kwd>
        <kwd>Binocular</kwd>
        <kwd>Cue integration</kwd>
        <kwd>Cue conflict</kwd>
      </kwd-group>
      <custom-meta-wrap>
        <custom-meta>
          <meta-name>issue-copyright-statement</meta-name>
          <meta-value>&#xA9; Springer-Verlag 2007</meta-value>
        </custom-meta>
      </custom-meta-wrap>
    </article-meta>
  </front>
  <body>
    <sec id="Sec1" sec-type="introduction">
      <title>Introduction</title>
      <p>It is often important to accurately judge the slant of surfaces in our nearby environment. Whether placing our foot on the ground when we walk or climb stairs, or our fingers on an object when we grasp it and place it elsewhere, the interaction always involves making contact with surfaces. In order to interact successfully, we need to know the orientation of these surfaces. We have many ways to judge a surface&#x2019;s orientation, including ones based on texture gradients, binocular disparity and motion parallax.</p>
      <p>One important cue that contributes to most people&#x2019;s slant perception is binocular disparity (see Howard and Rogers <xref ref-type="bibr" rid="CR12">1995</xref> for an extensive review of the literature on binocular vision). The small differences between the images in the two eyes suffice to obtain information about the slant in depth. From the literature on grasping it could be inferred that binocular cues normally dominate our actions. For example, Servos and Goodale (<xref ref-type="bibr" rid="CR30">1994</xref>) claim that binocular vision is the principal source of information for reaching and grasping movements. However, binocular information does not guarantee correct grasping (Hibbard and Bradshaw <xref ref-type="bibr" rid="CR8">2003</xref>), so there is reason to expect other cues to also play a role in guiding our actions.</p>
      <p>A second cue that contributes to slant perception is the deformation of any surface texture and of shapes&#x2019; outlines as a result of perspective. We will refer to the combined information from all such sources as the texture cue. This is the cue that allows us to have a powerful and striking impression of surface slant from a flat image, as exemplified in Fig.&#xA0;<xref rid="Fig1" ref-type="fig">1</xref>. It is well known that surface texture provides valuable information on slant perception (Gibson <xref ref-type="bibr" rid="CR6">1950</xref>; Stevens <xref ref-type="bibr" rid="CR31">1981</xref>; Buckley et al. <xref ref-type="bibr" rid="CR2">1996</xref>; Landy and Graham <xref ref-type="bibr" rid="CR17">2004</xref>) and motor control (Knill <xref ref-type="bibr" rid="CR13">1998a</xref>; Watt and Bradshaw <xref ref-type="bibr" rid="CR33">2003</xref>).
<fig id="Fig1"><label>Fig.&#xA0;1</label><caption><p>The deformation of the regular texture of a chess board provides a profound impression that the surface is slanted relative to the plane of the 2D picture</p></caption><graphic position="anchor" xlink:href="221_2007_1043_Fig1_HTML" id="MO1"/></fig></p>
      <p>Retrieving the slant of a surface from texture cues is based on the assumption that the distribution of texture elements over the surface is more or less even and that shapes are more or less symmetrical, see Rosenholtz and Malik (<xref ref-type="bibr" rid="CR28">1997</xref>). This assumption holds for a wide variety of natural and artificial objects.</p>
      <p>The third cue that we will consider is motion parallax (Rogers and Collett <xref ref-type="bibr" rid="CR24">1989</xref>; Rogers and Graham <xref ref-type="bibr" rid="CR25">1979</xref>, <xref ref-type="bibr" rid="CR26">1982</xref>; Ono and Steinbach <xref ref-type="bibr" rid="CR23">1990</xref>; Gillam and Rogers <xref ref-type="bibr" rid="CR7">1991</xref>; Ujike and Ono <xref ref-type="bibr" rid="CR32">2001</xref>). For a review of the widespread use of motion parallax in the animal kingdom, see Kral (<xref ref-type="bibr" rid="CR16">2003</xref>). Movement of the head relative to a surface generates changes in the surface&#x2019;s retinal image over time. These changes depend on the motion of the head relative to the items in the surrounding, and on the items&#x2019; relative distances. The latter dependency can be used to obtain information about depth and slant. Watt and Bradshaw (<xref ref-type="bibr" rid="CR33">2003</xref>) have shown that motion parallax can guide human movements when binocular cues are not available.</p>
      <p>When more than one cue is available the cues are combined. It is generally accepted that the estimated slant is a weighted average of the slants indicated by various cues, and that the weight of a cue is related to its accuracy, although some details of the mechanism are still under debate (Landy et&#xA0;al. <xref ref-type="bibr" rid="CR18">1995</xref>; Hillis et&#xA0;al. <xref ref-type="bibr" rid="CR9">2002</xref>; Hogervorst and Brenner <xref ref-type="bibr" rid="CR11">2004</xref>; Rosas et&#xA0;al. <xref ref-type="bibr" rid="CR27">2005</xref>; Muller et&#xA0;al. <xref ref-type="bibr" rid="CR22">2007</xref>). The relative contribution of binocular cues and texture cues depends on the distance (Hillis et al. <xref ref-type="bibr" rid="CR10">2004</xref>) and surface orientation (Knill <xref ref-type="bibr" rid="CR14">1998b</xref>; Buckley and Frisby <xref ref-type="bibr" rid="CR1">1993</xref>; Ryan and Gillam <xref ref-type="bibr" rid="CR29">1994</xref>), because binocular vision is better nearby and texture gradients change least rapidly with the angle of slant for near-frontal surfaces (for purely geometrical reasons). Knill (<xref ref-type="bibr" rid="CR15">2005</xref>) measured how binocular cues and texture cues to surface orientation are combined to guide motor behaviour. Cue weights were found to be dependent on surface slant and also on the task: more weight was given to binocular cues for controlling hand movements than for making perceptual judgements. Knill used cue-consistent and cue-conflict stimuli in a virtual reality environment.</p>
      <p>We wanted to find out whether motion parallax contributes to judgement of slant in the presence of other cues (such as binocular and texture cues) under more or less natural conditions. To do so, we used a setup in which the physical slant of a surface could be manipulated independently of the slant indicated by a pronounced texture. Thus a conflict between the texture cue and all the other cues was created by violating the assumption that the distribution of texture elements is homogeneous. The judged surface slant was determined by asking participants to swiftly place a flat cylindrical probe on the slanted surface (as in Knill <xref ref-type="bibr" rid="CR15">2005</xref>). Our main interest was in the extent to which head movements and the resulting motion parallax contribute to the perceived surface slant. So, conditions in which the head could move freely were compared with one in which a head restraint was used. We compared conditions with and without binocular vision in order to be able to evaluate the importance of motion parallax in relation to this cue.</p>
    </sec>
    <sec id="Sec2" sec-type="methods">
      <title>Methods</title>
      <sec id="Sec3">
        <title>Participants</title>
        <p>Five people, four of whom were male, participated in the experiment. All participants gave their informed consent prior to their inclusion in the study. The experiment was part of an ongoing research program that was approved by the local ethics committee. All participants were right-handed, had normal or corrected-to-normal vision and good binocular vision (stereo acuity &lt;40&#xA0;arcseconds).</p>
      </sec>
      <sec id="Sec4">
        <title>Experimental setup</title>
        <p>Participants were standing upright in front of a large rotatable screen. A sketch of the setup is given in Fig.&#xA0;<xref rid="Fig2" ref-type="fig">2</xref>. The screen was a plexiglass plate covered with projection foil. Images were projected from below by an Hitachi <sc>cp</sc>-<sc>x325</sc> LCD projector with a resolution of 1024&#xA0;&#xD7;&#xA0;768&#xA0;pixels. The screen and the projector could be rotated as a whole. Participants wore computer-controlled PLATO shutter-glasses, with which we could alternate between monocular and binocular vision, see Milgram (<xref ref-type="bibr" rid="CR21">1987</xref>). A chessboard pattern was projected onto the screen (see Fig.&#xA0;<xref rid="Fig3" ref-type="fig">3</xref>). Slants were defined relative to the gravity-defined horizontal. A grey ring, 104&#xA0;mm in diameter, indicated the target position for the probe. Two positions of the ring, one near the participant (the target&#x2019;s centre 100&#xA0;mm below the stimulus centre) and one further away (100&#xA0;mm above the stimulus centre) were displayed in random order to make sure that participants did not simply repeat the previous movement. Figure&#xA0;<xref rid="Fig3" ref-type="fig">3</xref> shows the stimuli with 0&#xB0; and 10&#xB0; texture slant relative to the surface&#x2019;s physical slant. The geometry of the stimulus was calculated by projecting the texture-defined slant on the physically rotated surface. The projection is calculated from the point of the observer&#x2019;s eyes. The 0&#xB0; stimulus was a 40&#xA0;cm square, with 40&#xA0;cm corresponding to a visual angle of about 27&#xB0;. A dark grey rim was drawn around the stimulus to mask any real edges that could become visible due to reflections within the set-up. To avoid illuminating objects around the set-up, the luminance of the image at the position of the eyes was limited to 0.4&#xA0;Cd&#xA0;m<sup>&#x2212;2</sup>. This was achieved by placing filters in front of the projector.
<fig id="Fig2"><label>Fig.&#xA0;2</label><caption><p>Participants were standing upright, facing the screen. They moved a probe from a starting position 50&#xA0;cm to the <italic>right</italic> of the surface midline to a target position on the surface (indicated by the <italic>grey ring</italic>). Participants wore PLATO glasses with which we could switch between no, monocular and binocular vision. During the experiment, only the slanted surface was visible</p></caption><graphic position="anchor" xlink:href="221_2007_1043_Fig2_HTML" id="MO2"/></fig><fig id="Fig3"><label>Fig.&#xA0;3</label><caption><p>Examples of consistent (<italic>left</italic>) and conflict (<italic>right</italic>) images. The <italic>left panel</italic> shows the 0&#xB0; texture slant on a 0&#xB0; surface slant as seen from above. The <italic>right panel</italic> shows the 10&#xB0; texture slant on the 0&#xB0; surface slant. The deformation of the stimulus is consistent with the actual viewing geometry but for clarity the image is presented as seen from above. The target (<italic>grey ring</italic>) indicates the position at which participants have to place the probe. The targets are shown at the &#x2018;near&#x2019; position. The <italic>dark grey</italic> rim&#x2019;s shape is in accordance with the texture cue</p></caption><graphic position="anchor" xlink:href="221_2007_1043_Fig3_HTML" id="MO3"/></fig></p>
        <p>The probe was a flat cylinder (diameter&#xA0;=&#xA0;104&#xA0;mm, height&#xA0;=&#xA0;22&#xA0;mm, mass&#xA0;=&#xA0;0.2&#xA0;kg). Movements of the probe were registered by an <sc>optotrak&#xA0;3020</sc> system (<sc>northern digital inc.</sc>, Waterloo, ON, Canada). This system tracks the position of active infrared markers with an accuracy better than 0.5&#xA0;mm. The 3D-positions of five markers on the probe were tracked at a rate of 200&#xA0;Hz. The position, orientation and velocity of the probe were calculated from these data.</p>
      </sec>
      <sec id="Sec5">
        <title>Procedure</title>
        <p>Experiments were performed in a completely dark room. The dark environment and the low intensity of the stimuli ensured that there was no visible external reference frame. Participants were instructed to place the probe at the indicated target position on the surface. They were to start moving as soon as the target was visible. Stimuli were shown for 2.5&#xA0;s. All movements were completed well within this interval.</p>
        <p>In order to avoid dark adaptation a bright lamp was turned on for 5&#xA0;s immediately after each trial. During this period participants placed the probe at the starting position, 50&#xA0;cm to the right of the midline of the screen. Then the light was turned off for about 5&#xA0;s, during which time the experimenter adjusted the orientation of the screen in preparation for the next trial.</p>
        <p>Figure&#xA0;<xref rid="Fig4" ref-type="fig">4</xref> shows the six combinations of surface slant and texture slant that were used in the experiment. The different combinations could be viewed monocularly or binocularly. The four consistent combinations (on the diagonal in Fig.&#xA0;<xref rid="Fig4" ref-type="fig">4</xref>) were used as a standard. The physical surface slant (see Fig.&#xA0;<xref rid="Fig2" ref-type="fig">2</xref>) was &#x2212;10&#xB0;, 0&#xB0;, 10&#xB0; or 20&#xB0;, and the image on the surface was as shown on the left in Fig.&#xA0;<xref rid="Fig3" ref-type="fig">3</xref>. The two conflict combinations either involved presenting the image shown on the right in Fig.&#xA0;<xref rid="Fig3" ref-type="fig">3</xref> on a horizontal surface (surface slant 0&#xB0;; texture slant 10&#xB0;) or presenting a similarly transformed image (slanted in the opposite direction) on a surface with 10&#xB0; slant. All six stimuli were presented under various conditions. In total there were four experimental conditions, each consisting of 192&#xA0;trials, divided into 3 blocks of 64 trials. Within every condition 75% of the trials were without conflict and 25% involved a conflict between texture and the other cues present in that condition.
<fig id="Fig4"><label>Fig.&#xA0;4</label><caption><p>The six combinations of physical surface slant (<italic>continuous lines</italic>) and slant suggested by texture (<italic>dashed lines</italic>) that were used in the experiment. In four cases there was no conflict between the cues (<italic>solid disks</italic>). In two cases there was a conflict (<italic>open disks</italic>). The slants have been exaggerated for clarity</p></caption><graphic position="anchor" xlink:href="221_2007_1043_Fig4_HTML" id="MO4"/></fig></p>
        <p>We used four conditions in which different combinations of the available cues were presented. The choice of conditions will become clear when we describe the data analysis. We chose three conditions with which we could calculate the five parameters of our model, and one condition to test one of our assumptions.</p>
        <p>In the &#x2018;binocular&#x2019; condition viewing was binocular and head-free in both conflict and consistent trials. In this condition all cues to slant perception were available. In the &#x2018;monocular&#x2019; condition the conflict and consistent trials were both presented monocularly and head-free. Stimuli were viewed with the left or right eye in random order. No binocular cues were available, but all other cues were present. In the &#x2018;biteboard&#x2019; condition the head was fixed in combination with monocular viewing. The biteboards were made individually with an impression of the participant&#x2019;s teeth. The biteboard severely limits head movements, removing information from motion parallax.</p>
        <p>In the consistent trials of the &#x2018;mixed&#x2019; condition the screen was viewed monocularly (75% of all trials), but in the conflict trials (25%) it was viewed binocularly. This condition was included to evaluate whether participants adapt their strategy at the level of a session rather than per trial. In the &#x2018;binocular&#x2019; condition binocular information was always reliable, so participants could have learnt to use this cue. In the &#x2018;mixed&#x2019; condition, in contrast, binocular cues were absent in the majority of trials, so participants could have learnt to use texture or motion parallax. Note that the 25% binocular, conflict trials in the &#x2018;mixed&#x2019; condition are identical to the conflict trials in the &#x2018;binocular condition&#x2019;, whereas the 75% consistent trials are identical to the consistent trials in the &#x2018;monocular&#x2019; condition. Thus the &#x2018;mixed&#x2019; condition serves as a control condition to test whether the weight given to the cues stays about the same under changing viewing conditions on other trials.</p>
      </sec>
      <sec id="Sec6">
        <title>Analysis</title>
        <p>During some moments of some trials the participant&#x2019;s fingers or hand occluded one or more of the five markers. The position of each marker relative to the centre of the probe is known, so the position and orientation of the probe can be calculated from any set of at least three markers. Frames in which fewer than three marker positions were known were not analysed. Figure&#xA0;<xref rid="Fig5" ref-type="fig">5</xref> shows a schematic side-view of the path followed by the probe. The end of the movement was defined as the first sample at which the centre of the probe was less than 2&#xA0;mm from the screen. The probe orientation was averaged over all samples at which the centre of the probe was between 100 and 20&#xA0;mm from its position at the end of the movement (the grey line segments in Fig.&#xA0;<xref rid="Fig5" ref-type="fig">5</xref>). The last 20&#xA0;mm of the path were excluded to avoid considering moments at which the edge of the probe could be in contact with the real surface of the projection screen.
<fig id="Fig5"><label>Fig.&#xA0;5</label><caption><p>The <italic>upper left panel</italic> gives a schematic side view of the probe&#x2019;s path (<italic>curved thin line</italic>) towards the slanted surface (<italic>straight thick line</italic>). The position and orientation of the probe were measured by the optotrak system. The <italic>upper right panel</italic> shows a side view of a few paths towards the &#x2018;far&#x2019; target position. The average probe orientation is determined during the last 100 to 20&#xA0;mm before the end of the movement (indicated schematically by the <italic>dark-grey</italic> line segments). The <italic>lower panels</italic> show examples of the probe orientation with time intervals of 25&#xA0;ms</p></caption><graphic position="anchor" xlink:href="221_2007_1043_Fig5_HTML" id="MO5"/></fig></p>
        <p>To understand our method for determining the cue weights, consider the two extreme hypothetical outcomes shown in Fig.&#xA0;<xref rid="Fig6" ref-type="fig">6</xref>. At the one extreme, if information from the texture cue is not used at all, probe orientations will always follow the slant of the physical surface (left panel). At the other extreme, if the observer only relies on texture cues the orientation of the probe will follow the texture-defined slant (right panel). In the latter case the line connecting the cue-conflict conditions has approximately the opposite slope of that for consistent conditions. Note that the probe orientations in the consistent trials may differ from the physical surface slant (grey line). Some flattening may arise because the hand may still be rotating towards the surface slant during the last 100&#xA0;mm of its trajectory. Participants may also rely to some extent on previous slopes that they encountered during the experiment. We will model these effects as a prior for a single surface slant for all conditions.
<fig id="Fig6"><label>Fig.&#xA0;6</label><caption><p>A schematic depiction of possible results for two extreme cases: probe orientation is not affected by texture at all (<italic>left panel</italic>) or only depends on the texture slant (<italic>right panel</italic>)</p></caption><graphic position="anchor" xlink:href="221_2007_1043_Fig6_HTML" id="MO6"/></fig></p>
        <p>We assume that the weights that participants give to the different cues are the same in all conditions. This would for instance be so if observers base the weights on the reliability, as in optimal cue combination (Landy et&#xA0;al. <xref ref-type="bibr" rid="CR18">1995</xref>). We can therefore model the estimated slant (S) as a weighted average of the slant estimated from each of the available cues (s<sub>i</sub>), which are all assumed to give veridical estimates except for the prior for a fixed slant (as mentioned in the previous paragraph):<disp-formula id="Equ1"><label>1</label><tex-math id="M1">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ {\text{S }} = {\text{ }}\frac{{{\sum\limits_i {w_{i} {\text{ s}}_{i} {\text{ }}} }}} {{{\sum\limits_i {w_{i} {\text{ }}} }}};\quad w_{i} {\text{ }} \propto \frac{1} {{\sigma ^{2}_{i} }}, $$\end{document}</tex-math></disp-formula>where <italic>w</italic><sub>i</sub> is the weight (in arbitrary units) given to each available cue, with <italic>i</italic>&#xA0;&#x2208;&#xA0;{<sc>b, m, t, r, p</sc>} indicating binocular vision, motion parallax, texture, a rest category containing any other valid cues, and the prior. Note that we predict that the cue weights (<italic>w</italic><sub><italic>i</italic></sub>) of all available cues will be the same in all conditions, although the relative weight given to a cue (<italic>w</italic><sub><italic>i</italic></sub>/&#x2211;<italic>w</italic><sub><italic>i</italic></sub>) will differ between conditions because it depends on the cues that are available in that condition.</p>
        <p>The slant of the prior is a constant. Its value is likely to be near the mean of the slants in all previous conditions, but this is not essential for our analysis: <disp-formula id="Equ2"><label>2</label><tex-math id="M2">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ s_{P} = c $$\end{document}</tex-math></disp-formula></p>
        <p>If s denotes the simulated slant, then the slants indicated by all other available cues are: <disp-formula id="Equ3"><label>3</label><tex-math id="M3">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ s_{i} = s $$\end{document}</tex-math></disp-formula>except for the conflict trials, for which the texture differs 10&#xB0; from all other available cues (see Fig.&#xA0;<xref rid="Fig4" ref-type="fig">4</xref>): <disp-formula id="Equ4"><label>4</label><tex-math id="M4">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ s_{T} = 10^\circ - s $$\end{document}</tex-math></disp-formula> Combining these equations gives: <disp-formula id="Equ5"><label>5</label><tex-math id="M5">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ S_{{{\text{consistent}}}} = \frac{{c\;w_{P} + s\;w_{T} + s{\sum\limits_{i \ne (P,T)} {w_{i} } }}} {{{\sum\limits_i {w_{i} } }}} $$\end{document}</tex-math></disp-formula>and <disp-formula id="Equ6"><label>6</label><tex-math id="M6">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ S_{{{\text{conflict}}}} = \frac{{c\;w_{P} + (10^\circ - s)\;w_{T} + s{\sum\limits_{i \ne (P,T)} {w_{i} } }}} {{{\sum\limits_i {w_{i} } }}} $$\end{document}</tex-math></disp-formula></p>
        <p>The sums in Eqs.&#xA0;<xref rid="Equ5" ref-type="">5</xref> and <xref rid="Equ6" ref-type="">6</xref> are only over cues that were available in each condition. The slopes (&#x3B2;) of the regression lines in Fig.&#xA0;<xref rid="Fig6" ref-type="fig">6</xref> are given by the first derivatives of the estimated slant: <disp-formula id="Equ7"><label>7</label><tex-math id="M7">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ \beta _{{{\text{consistent}}}} = \frac{{\partial S_{{{\text{consistent}}}} }} {{\partial s}} = \frac{{\;w_{T} + {\sum\limits_{i \ne (P,T)} {w_{i} } }}} {{{\sum\limits_i {w_{i} } }}} $$\end{document}</tex-math></disp-formula><disp-formula id="Equ8"><label>8</label><tex-math id="M8">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ \beta _{{{\text{conflict}}}} = \frac{{\partial S_{{{\text{conflict}}}} }} {{\partial s}} = \frac{{\; - w_{T} + {\sum\limits_{i \ne (P,T)} {w_{i} } }}} {{{\sum\limits_i {w_{i} } }}} $$\end{document}</tex-math></disp-formula> Combining Eqs.&#xA0;<xref rid="Equ7" ref-type="">7</xref> and <xref rid="Equ8" ref-type="">8</xref> yields: <disp-formula id="Equ9"><label>9</label><tex-math id="M9">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ \frac{{\; - w_{T} + {\sum\limits_{i \ne (P,T)} {w_{i} } }}} {{w_{T} + {\sum\limits_{i \ne (P,T)} {w_{i} } }}} = \frac{{\beta _{{{\text{conflict}}}} }} {{\beta _{{{\text{consistent}}}} }} $$\end{document}</tex-math></disp-formula>and <disp-formula id="Equ10"><label>10</label><tex-math id="M10">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ \frac{{w_{P} }} {{w_{T} }} = \frac{{2\beta _{{{\text{consistent}}}} - 2}} {{\beta _{{{\text{conflict}}}} - \beta _{{{\text{consistent}}}} }} $$\end{document}</tex-math></disp-formula></p>
        <p>Equations&#xA0;<xref rid="Equ9" ref-type="">9</xref> and <xref rid="Equ10" ref-type="">10</xref> apply to all experimental conditions as modified for cue availability, except for the &#x2018;mixed&#x2019; condition. In the &#x2018;binocular&#x2019; condition all cues yield information about the surface&#x2019;s slant: <disp-formula id="Equ11"><label>11</label><tex-math id="M11">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ {\left( {\frac{{\beta _{{{\text{conflict}}}} }} {{\beta _{{{\text{consistent}}}} }}} \right)}_{{{\text{binocular}}}} = \frac{{\;w_{B} + w_{M} + w_{R} - w_{T} }} {{w_{B} + w_{M} + w_{R} + w_{T} }} $$\end{document}</tex-math></disp-formula></p>
        <p>Similar equations can be written for the other conditions. Binocular information is not available in the &#x2018;monocular&#x2019; condition, so <italic>w</italic><sub><italic>B</italic></sub> does not occur in the equation: <disp-formula id="Equ12"><label>12</label><tex-math id="M12">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ {\left( {\frac{{\beta _{{{\text{conflict}}}} }} {{\beta _{{{\text{consistent}}}} }}} \right)}_{{{\text{monocular}}}} = \frac{{\;w_{M} + w_{R} - w_{T} }} {{w_{M} + w_{R} + w_{T} }} $$\end{document}</tex-math></disp-formula></p>
        <p>Similarly, motion parallax ceases to contribute to the estimated slant in the &#x2018;biteboard&#x2019; condition, giving: <disp-formula id="Equ13"><label>13</label><tex-math id="M13">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ {\left( {\frac{{\beta _{{{\text{conflict}}}} }} {{\beta _{{{\text{consistent}}}} }}} \right)}_{{{\text{biteboard}}}} = \frac{{\;w_{R} - w_{T} }} {{w_{R} + w_{T} }} $$\end{document}</tex-math></disp-formula></p>
        <p>Since the weights are in arbitrary units, we are free to define them in such a way that the sum of all weights is one: <disp-formula id="Equ14"><label>14</label><tex-math id="M14">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ w_{B} + w_{T} + w_{M} + w_{R} + w_{P} = 1 $$\end{document}</tex-math></disp-formula></p>
        <p>First we determine the weight of the prior relative to that of texture (<italic>w</italic><sub><italic>P</italic></sub>/<italic>w</italic><sub><italic>T</italic></sub>) for each condition, using Eq.&#xA0;<xref rid="Equ10" ref-type="">10</xref>. Then, the weighted average of these ratios is calculated for each participant. We found no clear evidence that the assumption that <italic>w</italic><sub><italic>P</italic></sub>/<italic>w</italic><sub><italic>T</italic></sub> is the same across conditions was not justified. Next, determining the ratios between the slopes in the &#x2018;binocular&#x2019;, &#x2018;monocular&#x2019; and &#x2018;biteboard&#x2019; conditions from our data allows us to use Eqs.&#xA0;<xref rid="Equ11" ref-type="">11</xref> to <xref rid="Equ14" ref-type="">14</xref> to determine the values of the weights (<italic>w</italic><sub><italic>B</italic></sub>, <italic>w</italic><sub><italic>T</italic></sub>, <italic>w</italic><sub><italic>M</italic></sub> and <italic>w</italic><sub><italic>R</italic></sub>).</p>
        <p>The data of the &#x2018;mixed&#x2019; condition was analysed by comparing the slopes (&#x3B2;<sub>conflict</sub> and &#x3B2;<sub>consistent</sub>) with the matching slopes in the &#x2018;binocular&#x2019; and the &#x2018;monocular&#x2019; conditions. Data for &#x2018;near&#x2019; and &#x2018;far&#x2019; target positions were pooled before calculating the slopes. The weights of the cues were calculated for individual participants. In addition, we also pooled the data of all participants before calculating the slopes, which yields the weights for &#x2018;All&#x2019; participants.</p>
      </sec>
    </sec>
    <sec id="Sec7" sec-type="results">
      <title>Results</title>
      <p>We determined average probe orientations for each participant and condition. The slopes of probe orientation as a function of surface orientation for conflict and consistent conditions enable us to calculate the cue weights, as explained in the &#x2018;<xref rid="Sec2" ref-type="sec">methods</xref>&#x2019; section.</p>
      <sec id="Sec8">
        <title>Conditions</title>
        <p>The upper panel of Fig.&#xA0;<xref rid="Fig7" ref-type="fig">7</xref> shows the probe orientations in the binocular condition. Conflict (open symbols) and consistent (closed symbols) probe orientations are almost the same. The difference between the slopes is small but significant (<italic>P</italic>&#xA0;&lt;&#xA0;0.05). The second panel of Fig.&#xA0;<xref rid="Fig7" ref-type="fig">7</xref> shows the probe orientations in the monocular condition. The slopes clearly differ between the conflict and the consistent trials (<italic>P</italic>&#xA0;&lt;&#xA0;0.01). In the &#x2018;biteboard&#x2019; condition (third panel of Fig.&#xA0;<xref rid="Fig7" ref-type="fig">7</xref>) the conflict trials have almost the opposite slope than the consistent trials. The difference between the slopes is significant (<italic>P</italic>&#xA0;&lt;&#xA0;0.01). The cue weights were calculated using Eqs.&#xA0;<xref rid="Equ10" ref-type="">10</xref> to <xref rid="Equ14" ref-type="">14</xref> and the values of the regression slopes.
<fig id="Fig7"><label>Fig.&#xA0;7</label><caption><p>Pooled data for all participants. Each panel is for one of the four experimental conditions. Average probe orientations are shown for surfaces with (<italic>open symbols</italic>) and without (<italic>closed symbols</italic>) conflicts between real slant and texture slant. The <italic>error bars</italic> show the overall standard deviation. Correct probe orientations for the consistent trials (<italic>grey lines</italic>), linear regression (<italic>black lines</italic>) and regression slopes, &#x3B2; (numbers in <italic>lower right corner</italic>) are also shown. <italic>Asterisks</italic> indicate whether the difference between the regression slopes is significant (*<italic>P</italic>&#xA0;&lt;&#xA0;0.05; **<italic>P</italic>&#xA0;&lt;&#xA0;0.01)</p></caption><graphic position="anchor" xlink:href="221_2007_1043_Fig7_HTML" id="MO7"/></fig></p>
        <p>The &#x2018;mixed&#x2019; condition was included as a control to ascertain that the cue weights do not depend on the viewing conditions on other trials. We compared the monocular consistent trials with the identical trials in the &#x2018;monocular&#x2019; condition, and the binocular conflict trials with the identical trials in the &#x2018;binocular&#x2019; condition. The regression slope for monocular, consistent trials (&#x3B2;<sub>consistent</sub>&#xA0;=&#xA0;0.72) is not significantly different (<italic>P</italic>&#xA0;&gt;&#xA0;0.05) from the same trials in the &#x2018;monocular&#x2019; condition (&#x3B2;<sub>consistent</sub>&#xA0;=&#xA0;0.76). The slope of the (binocular) conflict trials in the &#x2018;mixed&#x2019; condition (&#x3B2;<sub>conflict</sub>&#xA0;=&#xA0;0.61) is slightly but significantly lower (<italic>P</italic>&#xA0;=&#xA0;0.04) than for conflict trials in the &#x2018;binocular&#x2019; condition (&#x3B2;<sub>conflict</sub>&#xA0;=&#xA0;0.72). Thus the weights may not be completely independent of the conditions. The difference was small enough to accept the calculation of the weights on the basis of the assumption that the condition is irrelevant. Our analysis may however underestimate the weight given to the texture cue.</p>
      </sec>
      <sec id="Sec9">
        <title>Cue weights</title>
        <p>The weight of the binocular cue lies between 50 and 90%, for individual participants (see Fig.&#xA0;<xref rid="Fig8" ref-type="fig">8</xref>). The average standard error is 11%. The errors in the cue weights are calculated by the method of propagation of errors based on the errors in the regression slopes. If we determine the slopes across all participants, the binocular weight is 71&#xA0;&#xB1;&#xA0;6%. The weight of the texture cue lies between 2 and 18% with an average standard error of 3% for individual participants. The weight given to the texture cue is 8&#xA0;&#xB1;&#xA0;1% across all participants. The weight given to motion parallax lies between 1 and 9% for individual participants with an average standard error of 6%. The weight given to motion parallax is 8&#xA0;&#xB1;&#xA0;3% across all participants. The weight attributed to the rest category of cues was only 3&#xA0;&#xB1;&#xA0;2% across all participants. The prior contributed between 6 and 23% for individual participants with an average standard error of 3%. The weight of the prior varies between 7 and 13% across conditions. Across all participants the weight of the prior is 10&#xA0;&#xB1;&#xA0;2%.
<fig id="Fig8"><label>Fig.&#xA0;8</label><caption><p>The weights given to the binocular, texture, motion parallax, other cues and to the prior, for each participant (<italic>horizontal axis</italic>). The weights are obtained by substituting the slopes of conflict data and consistent data in Eqs. <xref rid="Equ10" ref-type="">10</xref>&#xA0;to&#xA0;<xref rid="Equ14" ref-type="">14</xref>. For &#x2018;All&#x2019;, first all participant&#x2019;s data in each condition was pooled and then the weights were determined, which are all significantly different from zero. For individual participants the texture cue was not significantly different from zero in one case, the motion cue in four cases and the rest category in three cases</p></caption><graphic position="anchor" xlink:href="221_2007_1043_Fig8_HTML" id="MO8"/></fig></p>
      </sec>
      <sec id="Sec10">
        <title>Head movements</title>
        <p>Head movements were measured in the monocular viewing condition for three of the participants. Participants move their head considerably when placing the cylinder: EB moved on average 103&#xA0;mm, JG 53&#xA0;mm and DdG 37&#xA0;mm in the lateral direction. Interestingly, the head movement only started just before the arm movement. Shortly before (100&#xA0;ms) the onset of arm movement (when the probe was 10&#xA0;mm from the starting position), the head had only moved 10&#xA0;mm (EB), 4&#xA0;mm (JG) or 6&#xA0;mm (DdG). Thus the information from motion parallax is mainly picked up during the arm movement. None of the participants were aware of having made head movements.</p>
      </sec>
    </sec>
    <sec id="Sec11" sec-type="discussion">
      <title>Discussion</title>
      <p>We used a physically rotatable screen as a surface. The projected stimulus was viewed in a completely dark environment within a space in which objects are normally manipulated. In our analysis systematic deformations that affect a single cue (like depth compression resulting from an erroneous depth estimate) were not considered. Moreover, we assume that the cue weights are the same in all conditions, so that their contributions to the percept only depend on which cues are available. We determined the contributions of binocular disparity, texture cues, motion parallax, a rest category and a prior. Under these conditions and based on these assumptions we conclude that participants mainly relied on binocular information (between 50 and 90%). Texture cues contributed between 2 and 18% to the estimated slant. Motion parallax contributed up to 9%. The prior contributed between 6 and 23%. Residual cues may account for up to 9%.</p>
      <p>Comparing conditions with and without head movement revealed that motion parallax plays a role in slant perception. This is evident from the weights (Fig.&#xA0;<xref rid="Fig8" ref-type="fig">8</xref>) but also from a comparison of performance in the &#x2018;monocular&#x2019; and &#x2018;biteboard&#x2019; conditions (Fig.&#xA0;<xref rid="Fig7" ref-type="fig">7</xref>). It is not unusual to move the whole body, including the head, when making large arm movements. Beside mechanical reasons for doing so we here show that it may also have perceptual advantages.</p>
      <p>We included in our analysis a rest category of cues that might contain information about slant that was not manipulated. The results suggest that this category indeed includes cues that yield some information about slant. Accommodation, or the rate at which the image becomes blurred with distance from fixation, might provide such information (Mather <xref ref-type="bibr" rid="CR20">1997</xref>; Watt et&#xA0;al. <xref ref-type="bibr" rid="CR34">2005</xref>). However, artefacts of our setup such as the possible visible micro texture (fibres in the projection foil or pixels on the screen) and the angular distribution of the light scattered from the surface could play a role too. Taken together in a rest category such cues contribute only a few percent to the estimated slant.</p>
      <p>The probe orientations in the consistent trials in Fig.&#xA0;<xref rid="Fig7" ref-type="fig">7</xref> are not equal to the physical surface slant. We incorporated a prior in our model to take into account behaviour that is not related to the instantaneous information, like visual or haptic information from previous trials. The slant indicated by the prior cue is a constant; i.e. it does not depend on the stimulus. Flatter slopes indicate that the prior plays a relatively large role. The weight of the prior is about as large as the weight of the texture cue. One component of the prior could be that the hand orientation is still changing towards its final value at the moment that we sample, which is slightly before contact (Cuijpers et&#xA0;al. <xref ref-type="bibr" rid="CR3">2004</xref>). Any biases towards a certain orientation of the hand or towards a certain perceived slant will also contribute to the weight of the prior.</p>
      <p>The purpose of having the &#x2018;mixed&#x2019; viewing condition was to check whether the weights change under different conditions. Ernst et al. (<xref ref-type="bibr" rid="CR5">2000</xref>) have shown that haptic feedback can make more weight be given to a visual slant cue that is consistent with the feedback. In our study the haptic feedback was always consistent with the physical slant of the surface, so only the texture cue was sometimes unreliable. So, with a conflict between surface slant and texture the haptic feedback may yield a bias towards other cues than texture. Our results show a small difference between the &#x2018;mixed&#x2019; condition and the comparable trials in the &#x2018;monocular&#x2019; and &#x2018;binocular&#x2019; condition. Thus here too the extent to which cues are used does probably depend to some extent on experience in previous trials. This indicates that the estimated slant does not only depend on the accuracy of the presented cues, as is often assumed in theories of optimal cue combination (Landy et&#xA0;al. <xref ref-type="bibr" rid="CR18">1995</xref>; Hillis et&#xA0;al. <xref ref-type="bibr" rid="CR9">2002</xref>; Muller et&#xA0;al. <xref ref-type="bibr" rid="CR22">2007</xref> ). It is however possible that the difference arises from less use of motion parallax when binocular information was always available, perhaps because participants move less when there is enough information from other sources than motion parallax. We do not know whether this is the case because we did not measure head movements in all conditions. However, these differences are all too small to be taken seriously without further research.</p>
      <p>In our study binocular disparity is given most weight, which is in accordance with binocular cues being known to be reliable when the stimulus surface is nearby and almost frontal. Because experimental conditions were all in favour of binocular disparity, the role of motion parallax and texture cues is probably smaller here than in natural viewing conditions. Motion parallax and texture cues both contribute to a small but significant extent to slant perception, although marked differences between participants were observed. Motion parallax was available only shortly and began relatively late, as the head began to move only just before onset of the arm movement. From animal studies it is known that a range of animals gain depth information by moving from side to side just before the performance of an action, see Kral (<xref ref-type="bibr" rid="CR16">2003</xref>). We have shown that humans are able to use motion parallax during an action. It was known that monocular depth information can be used to guide our actions (Marotta et al. <xref ref-type="bibr" rid="CR19">1998</xref>; Dijkerman et al. <xref ref-type="bibr" rid="CR4">1999</xref>; Watt and Bradshaw <xref ref-type="bibr" rid="CR33">2003</xref>). It was not known, however, that motion parallax plays a role under conditions where other cues are dominantly available and without actively moving one&#x2019;s head before starting the action. We conclude that motion parallax is used as a cue to manipulate objects in our nearby environment, even when one is under the impression of holding one&#x2019;s head still. Motion parallax should therefore not be ignored in a &#x2018;static&#x2019; task unless the head is really fixated.</p>
    </sec>
  </body>
  <back>
    <ack>
      <p>This research was supported by <sc>vidi</sc> grant 452-02-007 of the Netherlands Organization for Scientific Research (NWO). We thank Michael Landy for his suggestions.</p>
    </ack>
    <ref-list id="Bib1">
      <title>References</title>
      <ref id="CR1">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Buckley</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Frisby</surname>
              <given-names>JP</given-names>
            </name>
          </person-group>
          <article-title>Interaction of stereo, texture and outline cues in the shape perception of three-dimensional ridges</article-title>
          <source>Vision Res</source>
          <year>1993</year>
          <volume>33</volume>
          <fpage>919</fpage>
          <lpage>933</lpage>
          <pub-id pub-id-type="doi">10.1016/0042-6989(93)90075-8</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Buckley D, Frisby JP (1993) Interaction of stereo, texture and outline cues in the shape perception of three-dimensional ridges. Vision Res 33:919&#x2013;933. doi:10.1016/0042-6989(93)90075-8 <pub-id pub-id-type="pmid">8506635</pub-id></citation>
      </ref>
      <ref id="CR2">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Buckley</surname>
              <given-names>D</given-names>
            </name>
            <name>
              <surname>Frisby</surname>
              <given-names>JP</given-names>
            </name>
            <name>
              <surname>Blake</surname>
              <given-names>A</given-names>
            </name>
          </person-group>
          <article-title>Does the human visual system implement an ideal observer theory of slant from texture?</article-title>
          <source>Vision Res</source>
          <year>1996</year>
          <volume>36</volume>
          <fpage>1163</fpage>
          <lpage>1176</lpage>
          <pub-id pub-id-type="doi">10.1016/0042-6989(95)00177-8</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Buckley D, Frisby JP, Blake A (1996) Does the human visual system implement an ideal observer theory of slant from texture? Vision Res 36:1163&#x2013;1176. doi:10.1016/0042-6989(95)00177-8 <pub-id pub-id-type="pmid">8762720</pub-id></citation>
      </ref>
      <ref id="CR3">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Cuijpers</surname>
              <given-names>RH</given-names>
            </name>
            <name>
              <surname>Smeets</surname>
              <given-names>JB</given-names>
            </name>
            <name>
              <surname>Brenner</surname>
              <given-names>E</given-names>
            </name>
          </person-group>
          <article-title>On the relation between object shape and grasping kinematics</article-title>
          <source>J Neurophysiol</source>
          <year>2004</year>
          <volume>91</volume>
          <fpage>2598</fpage>
          <lpage>2606</lpage>
          <pub-id pub-id-type="doi">10.1152/jn.00644.2003</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Cuijpers RH, Smeets JB, Brenner E (2004) On the relation between object shape and grasping kinematics. J Neurophysiol 91:2598&#x2013;2606. doi:10.1152/jn.00644.2003 <pub-id pub-id-type="pmid">14749319</pub-id></citation>
      </ref>
      <ref id="CR4">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Dijkerman</surname>
              <given-names>HC</given-names>
            </name>
            <name>
              <surname>Milner</surname>
              <given-names>AD</given-names>
            </name>
            <name>
              <surname>Carey</surname>
              <given-names>DP</given-names>
            </name>
          </person-group>
          <article-title>Motion parallax enables depth processing for action in a visual form agnosic when binocular vision is unavailable</article-title>
          <source>Neuropsychologia</source>
          <year>1999</year>
          <volume>37</volume>
          <fpage>1505</fpage>
          <lpage>1510</lpage>
          <pub-id pub-id-type="doi">10.1016/S0028-3932(99)00063-9</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Dijkerman HC, Milner AD, Carey DP (1999) Motion parallax enables depth processing for action in a visual form agnosic when binocular vision is unavailable. Neuropsychologia 37:1505&#x2013;1510. doi:10.1016/S0028-3932(99)00063-9 <pub-id pub-id-type="pmid">10617271</pub-id></citation>
      </ref>
      <ref id="CR5">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ernst</surname>
              <given-names>MO</given-names>
            </name>
            <name>
              <surname>Banks</surname>
              <given-names>MSW</given-names>
            </name>
            <name>
              <surname>B&#xFC;lthoff</surname>
              <given-names>HH</given-names>
            </name>
          </person-group>
          <article-title>Touch can change visual slant perception</article-title>
          <source>Nat Neurosci</source>
          <year>2000</year>
          <volume>3</volume>
          <fpage>69</fpage>
          <lpage>73</lpage>
          <pub-id pub-id-type="doi">10.1038/71140</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Ernst MO, Banks MSW, B&#xFC;lthoff HH (2000) Touch can change visual slant perception. Nat Neurosci 3:69&#x2013;73. doi:10.1038/71140 <pub-id pub-id-type="pmid">10607397</pub-id></citation>
      </ref>
      <ref id="CR6">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gibson</surname>
              <given-names>JJ</given-names>
            </name>
          </person-group>
          <article-title>The perception of visual surfaces</article-title>
          <source>Am J Psychol</source>
          <year>1950</year>
          <volume>63</volume>
          <fpage>367</fpage>
          <lpage>384</lpage>
          <pub-id pub-id-type="doi">10.2307/1418003</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Gibson JJ (1950) The perception of visual surfaces. Am J Psychol 63:367&#x2013;384 <pub-id pub-id-type="pmid">15432778</pub-id></citation>
      </ref>
      <ref id="CR7">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Gillam</surname>
              <given-names>B</given-names>
            </name>
            <name>
              <surname>Rogers</surname>
              <given-names>B</given-names>
            </name>
          </person-group>
          <article-title>Orientation disparity, deformation and stereoscopic slant perception</article-title>
          <source>Perception</source>
          <year>1991</year>
          <volume>20</volume>
          <fpage>441</fpage>
          <lpage>448</lpage>
          <pub-id pub-id-type="doi">10.1068/p200441</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Gillam B, Rogers B (1991) Orientation disparity, deformation and stereoscopic slant perception. Perception 20:441&#x2013;448. doi:10.1068/p200441 <pub-id pub-id-type="pmid">1771129</pub-id></citation>
      </ref>
      <ref id="CR8">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hibbard</surname>
              <given-names>PB</given-names>
            </name>
            <name>
              <surname>Bradshaw</surname>
              <given-names>MF</given-names>
            </name>
          </person-group>
          <article-title>Reaching for virtual objects: binocular disparity and the control of prehension</article-title>
          <source>Exp Brain Res</source>
          <year>2003</year>
          <volume>148</volume>
          <fpage>196</fpage>
          <lpage>201</lpage>
        </citation>
        <citation citation-type="display-unstructured">Hibbard PB, Bradshaw MF (2003) Reaching for virtual objects: binocular disparity and the control of prehension. Exp Brain Res 148:196&#x2013;201. doi:10.1007/s00221-002-1295-2 <pub-id pub-id-type="pmid">12520407</pub-id></citation>
      </ref>
      <ref id="CR9">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hillis</surname>
              <given-names>JM</given-names>
            </name>
            <name>
              <surname>Ernst</surname>
              <given-names>MO</given-names>
            </name>
            <name>
              <surname>Banks</surname>
              <given-names>MS</given-names>
            </name>
            <name>
              <surname>Landy</surname>
              <given-names>MS</given-names>
            </name>
          </person-group>
          <article-title>Combining sensory information: mandatory fusion within, but not between, senses</article-title>
          <source>Science</source>
          <year>2002</year>
          <volume>298</volume>
          <fpage>1627</fpage>
          <lpage>1630</lpage>
          <pub-id pub-id-type="doi">10.1126/science.1075396</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Hillis JM, Ernst MO, Banks MS, Landy MS (2002) Combining sensory information: mandatory fusion within, but not between, senses. Science 298:1627&#x2013;1630. doi:10.1126/science.1075396 <pub-id pub-id-type="pmid">12446912</pub-id></citation>
      </ref>
      <ref id="CR10">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hillis</surname>
              <given-names>JM</given-names>
            </name>
            <name>
              <surname>Watt</surname>
              <given-names>SJ</given-names>
            </name>
            <name>
              <surname>Landy</surname>
              <given-names>MS</given-names>
            </name>
            <name>
              <surname>Banks</surname>
              <given-names>MS</given-names>
            </name>
          </person-group>
          <article-title>Slant from texture and disparity cues: optimal cue combination</article-title>
          <source>J Vis</source>
          <year>2004</year>
          <volume>4</volume>
          <fpage>967</fpage>
          <lpage>992</lpage>
          <pub-id pub-id-type="doi">10.1167/4.12.1</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Hillis JM, Watt SJ, Landy MS, Banks MS (2004) Slant from texture and disparity cues: optimal cue combination. J Vis 4:967&#x2013;992. doi:10.1167/4.12.1 <pub-id pub-id-type="pmid">15669906</pub-id></citation>
      </ref>
      <ref id="CR11">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hogervorst</surname>
              <given-names>MA</given-names>
            </name>
            <name>
              <surname>Brenner</surname>
              <given-names>E</given-names>
            </name>
          </person-group>
          <article-title>Combining cues while avoiding perceptual conflicts</article-title>
          <source>Perception</source>
          <year>2004</year>
          <volume>33</volume>
          <fpage>1155</fpage>
          <lpage>1172</lpage>
          <pub-id pub-id-type="doi">10.1068/p5253</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Hogervorst MA, Brenner E (2004) Combining cues while avoiding perceptual conflicts. Perception 33:1155&#x2013;1172. doi:10.1068/p5253 <pub-id pub-id-type="pmid">15693662</pub-id></citation>
      </ref>
      <ref id="CR12">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Howard</surname>
              <given-names>IP</given-names>
            </name>
            <name>
              <surname>Rogers</surname>
              <given-names>BJ</given-names>
            </name>
          </person-group>
          <source>Binocular vision and stereopsis</source>
          <year>1995</year>
          <publisher-loc>New York</publisher-loc>
          <publisher-name>Oxford University Press</publisher-name>
        </citation>
        <citation citation-type="display-unstructured">Howard IP, Rogers BJ (1995) Binocular vision and stereopsis. Oxford University Press, New York </citation>
      </ref>
      <ref id="CR13">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Knill</surname>
              <given-names>DC</given-names>
            </name>
          </person-group>
          <article-title>Surface orientation from texture: ideal observers, generic observers and the information content of texture cues</article-title>
          <source>Vision Res</source>
          <year>1998</year>
          <volume>38</volume>
          <fpage>1655</fpage>
          <lpage>1682</lpage>
          <pub-id pub-id-type="doi">10.1016/S0042-6989(97)00324-6</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Knill DC (1998a) Surface orientation from texture: ideal observers, generic observers and the information content of texture cues. Vision Res 38:1655&#x2013;1682. doi:10.1016/S0042-6989(97)00324-6 <pub-id pub-id-type="pmid">9747502</pub-id></citation>
      </ref>
      <ref id="CR14">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Knill</surname>
              <given-names>DC</given-names>
            </name>
          </person-group>
          <article-title>Discrimination of planar surface slant from texture: human and ideal observers compared</article-title>
          <source>Vision Res</source>
          <year>1998</year>
          <volume>38</volume>
          <fpage>1683</fpage>
          <lpage>1711</lpage>
          <pub-id pub-id-type="doi">10.1016/S0042-6989(97)00325-8</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Knill DC (1998b) Discrimination of planar surface slant from texture: human and ideal observers compared. Vision Res 38:1683&#x2013;1711. doi:10.1016/S0042-6989(97)00325-8 <pub-id pub-id-type="pmid">9747503</pub-id></citation>
      </ref>
      <ref id="CR15">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Knill</surname>
              <given-names>DC</given-names>
            </name>
          </person-group>
          <article-title>Reaching for visual cues to depth: the brain combines depth cues differently for motor control and perception</article-title>
          <source>J Vis</source>
          <year>2005</year>
          <volume>5</volume>
          <fpage>103</fpage>
          <lpage>315</lpage>
          <pub-id pub-id-type="doi">10.1167/5.2.2</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Knill DC (2005) Reaching for visual cues to depth: the brain combines depth cues differently for motor control and perception. J Vis 5:103&#x2013;315. doi:10.1167/5.2.2 <pub-id pub-id-type="pmid">15831071</pub-id></citation>
      </ref>
      <ref id="CR16">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Kral</surname>
              <given-names>K</given-names>
            </name>
          </person-group>
          <article-title>Behavioural-analytical studies of the role of head movements in depth perception in insects, birds and mammals</article-title>
          <source>Behav Processes</source>
          <year>2003</year>
          <volume>64</volume>
          <fpage>1</fpage>
          <lpage>12</lpage>
          <pub-id pub-id-type="doi">10.1016/S0376-6357(03)00054-8</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Kral K (2003) Behavioural-analytical studies of the role of head movements in depth perception in insects, birds and mammals. Behav Processes 64:1&#x2013;12. doi:10.1016/S0376-6357(03)00054-8 <pub-id pub-id-type="pmid">12914988</pub-id></citation>
      </ref>
      <ref id="CR17">
        <citation citation-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Landy</surname>
              <given-names>MS</given-names>
            </name>
            <name>
              <surname>Graham</surname>
              <given-names>N</given-names>
            </name>
          </person-group>
          <person-group person-group-type="editor">
            <name>
              <surname>Chalupa</surname>
              <given-names>LM</given-names>
            </name>
            <name>
              <surname>Werner</surname>
              <given-names>JS</given-names>
            </name>
          </person-group>
          <article-title>Visual perception of texture</article-title>
          <source>The visual neurosciences</source>
          <year>2004</year>
          <publisher-loc>Cambridge</publisher-loc>
          <publisher-name>MIT Press</publisher-name>
          <fpage>1106</fpage>
          <lpage>1118</lpage>
        </citation>
        <citation citation-type="display-unstructured">Landy MS, Graham N (2004) Visual perception of texture. In: Chalupa LM, Werner JS (eds) The visual neurosciences. MIT Press, Cambridge, pp 1106&#x2013;1118 </citation>
      </ref>
      <ref id="CR18">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Landy</surname>
              <given-names>MS</given-names>
            </name>
            <name>
              <surname>Maloney</surname>
              <given-names>LT</given-names>
            </name>
            <name>
              <surname>Johnston</surname>
              <given-names>EB</given-names>
            </name>
            <name>
              <surname>Young</surname>
              <given-names>M</given-names>
            </name>
          </person-group>
          <article-title>Measurement and modeling of depth cue combination: in defense of weak fusion</article-title>
          <source>Vision Res</source>
          <year>1995</year>
          <volume>35</volume>
          <fpage>389</fpage>
          <lpage>412</lpage>
          <pub-id pub-id-type="doi">10.1016/0042-6989(94)00176-M</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Landy MS, Maloney LT, Johnston EB, Young M (1995) Measurement and modeling of depth cue combination: in defense of weak fusion. Vision Res 35:389&#x2013;412. doi:10.1016/0042-6989(94)00176-M <pub-id pub-id-type="pmid">7892735</pub-id></citation>
      </ref>
      <ref id="CR19">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Marotta</surname>
              <given-names>JJ</given-names>
            </name>
            <name>
              <surname>Kruyer</surname>
              <given-names>A</given-names>
            </name>
            <name>
              <surname>Goodale</surname>
              <given-names>MA</given-names>
            </name>
          </person-group>
          <article-title>The role of head movements in the control of manual prehension</article-title>
          <source>Exp Brain Res</source>
          <year>1998</year>
          <volume>120</volume>
          <fpage>134</fpage>
          <lpage>138</lpage>
          <pub-id pub-id-type="doi">10.1007/s002210050386</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Marotta JJ, Kruyer A, Goodale MA (1998) The role of head movements in the control of manual prehension. Exp Brain Res 120:134&#x2013;138. doi:10.1007/s002210050386 <pub-id pub-id-type="pmid">9628412</pub-id></citation>
      </ref>
      <ref id="CR20">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Mather</surname>
              <given-names>G</given-names>
            </name>
          </person-group>
          <article-title>The use of image blur as a depth cue</article-title>
          <source>Perception</source>
          <year>1997</year>
          <volume>26</volume>
          <fpage>1147</fpage>
          <lpage>1158</lpage>
          <pub-id pub-id-type="doi">10.1068/p261147</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Mather G (1997) The use of image blur as a depth cue. Perception 26:1147&#x2013;1158. doi:10.1068/p261147 <pub-id pub-id-type="pmid">9509149</pub-id></citation>
      </ref>
      <ref id="CR21">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Milgram</surname>
              <given-names>P</given-names>
            </name>
          </person-group>
          <article-title>A spectacle-mounted liquid-crystal tachistoscope</article-title>
          <source>Behav Res Methods Instrum Comput</source>
          <year>1987</year>
          <volume>19</volume>
          <fpage>449</fpage>
          <lpage>456</lpage>
        </citation>
        <citation citation-type="display-unstructured">Milgram P (1987) A spectacle-mounted liquid-crystal tachistoscope. Behav Res Methods Instrum Comput 19:449&#x2013;456. doi:10.1068/p080125 </citation>
      </ref>
      <ref id="CR22">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Muller</surname>
              <given-names>CPM</given-names>
            </name>
            <name>
              <surname>Brenner</surname>
              <given-names>E</given-names>
            </name>
            <name>
              <surname>Smeets</surname>
              <given-names>JBJ</given-names>
            </name>
          </person-group>
          <article-title>Living up to optimal expectations</article-title>
          <source>J Vis</source>
          <year>2007</year>
          <volume>7</volume>
          <fpage>1</fpage>
          <lpage>10</lpage>
          <pub-id pub-id-type="doi">10.1167/7.3.2</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Muller CPM, Brenner E, Smeets JBJ (2007) Living up to optimal expectations. J Vis 7:1&#x2013;10. doi:10.1167/7.3.2 </citation>
      </ref>
      <ref id="CR23">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ono</surname>
              <given-names>H</given-names>
            </name>
            <name>
              <surname>Steinbach</surname>
              <given-names>MJ</given-names>
            </name>
          </person-group>
          <article-title>Monocular stereopsis with and without head movement</article-title>
          <source>Percept Psychophys</source>
          <year>1990</year>
          <volume>48</volume>
          <fpage>179</fpage>
          <lpage>187</lpage>
        </citation>
        <citation citation-type="display-unstructured">Ono H, Steinbach MJ (1990) Monocular stereopsis with and without head movement. Percept Psychophys 48:179&#x2013;187 <pub-id pub-id-type="pmid">2385492</pub-id></citation>
      </ref>
      <ref id="CR24">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rogers</surname>
              <given-names>BJ</given-names>
            </name>
            <name>
              <surname>Collett</surname>
              <given-names>TS</given-names>
            </name>
          </person-group>
          <article-title>The appearance of surfaces specified by motion parallax and binocular disparity</article-title>
          <source>Q J Exp Psychol A</source>
          <year>1989</year>
          <volume>41</volume>
          <fpage>697</fpage>
          <lpage>717</lpage>
        </citation>
        <citation citation-type="display-unstructured">Rogers BJ, Collett TS (1989) The appearance of surfaces specified by motion parallax and binocular disparity. Q J Exp Psychol A 41:697&#x2013;717. doi:10.1080/14640748908402390 <pub-id pub-id-type="pmid">2587795</pub-id></citation>
      </ref>
      <ref id="CR25">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rogers</surname>
              <given-names>BJ</given-names>
            </name>
            <name>
              <surname>Graham</surname>
              <given-names>ME</given-names>
            </name>
          </person-group>
          <article-title>Motion parallax as an independent cue for depth perception</article-title>
          <source>Perception</source>
          <year>1979</year>
          <volume>8</volume>
          <fpage>125</fpage>
          <lpage>134</lpage>
          <pub-id pub-id-type="doi">10.1068/p080125</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Rogers BJ, Graham ME (1979) Motion parallax as an independent cue for depth perception. Perception 8:125&#x2013;134. doi:10.1068/p080125 <pub-id pub-id-type="pmid">471676</pub-id></citation>
      </ref>
      <ref id="CR26">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rogers</surname>
              <given-names>BJ</given-names>
            </name>
            <name>
              <surname>Graham</surname>
              <given-names>ME</given-names>
            </name>
          </person-group>
          <article-title>Similarities between motion parallax and stereopsis in human depth perception</article-title>
          <source>Vision Res</source>
          <year>1982</year>
          <volume>22</volume>
          <fpage>261</fpage>
          <lpage>270</lpage>
          <pub-id pub-id-type="doi">10.1016/0042-6989(82)90126-2</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Rogers BJ, Graham ME (1982) Similarities between motion parallax and stereopsis in human depth perception. Vision Res 22:261&#x2013;270 <pub-id pub-id-type="pmid">7101762</pub-id></citation>
      </ref>
      <ref id="CR27">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rosas</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Wagemans</surname>
              <given-names>J</given-names>
            </name>
            <name>
              <surname>Ernst</surname>
              <given-names>MO</given-names>
            </name>
            <name>
              <surname>Wichmann</surname>
              <given-names>FA</given-names>
            </name>
          </person-group>
          <article-title>Texture and haptic cues in slant discrimination: reliability-based cue weighting without statistically optimal cue combination</article-title>
          <source>J Opt Soc Am A Opt Image Sci Vis</source>
          <year>2005</year>
          <volume>22</volume>
          <fpage>801</fpage>
          <lpage>809</lpage>
          <pub-id pub-id-type="doi">10.1364/JOSAA.22.000801</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Rosas P, Wagemans J, Ernst MO, Wichmann FA (2005) Texture and haptic cues in slant discrimination: reliability-based cue weighting without statistically optimal cue combination. J Opt Soc Am A Opt Image Sci Vis 22:801&#x2013;809 <pub-id pub-id-type="pmid">15898539</pub-id></citation>
      </ref>
      <ref id="CR28">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Rosenholtz</surname>
              <given-names>R</given-names>
            </name>
            <name>
              <surname>Malik</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <article-title>Surface orientation from texture: isotropy or homogeneity (or both)?</article-title>
          <source>Vision Res</source>
          <year>1997</year>
          <volume>37</volume>
          <fpage>2283</fpage>
          <lpage>2293</lpage>
          <pub-id pub-id-type="doi">10.1016/S0042-6989(96)00121-6</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Rosenholtz R, Malik J (1997) Surface orientation from texture: isotropy or homogeneity (or both)? Vision Res 37:2283&#x2013;2293. doi:10.1016/S0042-6989(96)00121-6 <pub-id pub-id-type="pmid">9578909</pub-id></citation>
      </ref>
      <ref id="CR29">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ryan</surname>
              <given-names>C</given-names>
            </name>
            <name>
              <surname>Gillam</surname>
              <given-names>B</given-names>
            </name>
          </person-group>
          <article-title>Cue conflict and stereoscopic surface slant about horizontal and vertical axes</article-title>
          <source>Perception</source>
          <year>1994</year>
          <volume>23</volume>
          <fpage>645</fpage>
          <lpage>658</lpage>
          <pub-id pub-id-type="doi">10.1068/p230645</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Ryan C, Gillam B (1994) Cue conflict and stereoscopic surface slant about horizontal and vertical axes. Perception 23:645&#x2013;658. doi:10.1068/p230645 <pub-id pub-id-type="pmid">7845758</pub-id></citation>
      </ref>
      <ref id="CR30">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Servos</surname>
              <given-names>P</given-names>
            </name>
            <name>
              <surname>Goodale</surname>
              <given-names>MA</given-names>
            </name>
          </person-group>
          <article-title>Binocular vision and the on-line control of human prehension</article-title>
          <source>Exp Brain Res</source>
          <year>1994</year>
          <volume>98</volume>
          <fpage>119</fpage>
          <lpage>127</lpage>
          <pub-id pub-id-type="doi">10.1007/BF00229116</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Servos P, Goodale MA (1994) Binocular vision and the on-line control of human prehension. Exp Brain Res 98:119&#x2013;127. doi:10.1007/BF00229116 <pub-id pub-id-type="pmid">8013579</pub-id></citation>
      </ref>
      <ref id="CR31">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Stevens</surname>
              <given-names>KA</given-names>
            </name>
          </person-group>
          <article-title>The information content of texture gradients</article-title>
          <source>Biol Cybern</source>
          <year>1981</year>
          <volume>42</volume>
          <fpage>95</fpage>
          <lpage>105</lpage>
          <pub-id pub-id-type="doi">10.1007/BF00336727</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Stevens KA (1981) The information content of texture gradients. Biol Cybern 42:95&#x2013;105 <pub-id pub-id-type="pmid">7326290</pub-id></citation>
      </ref>
      <ref id="CR32">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ujike</surname>
              <given-names>H</given-names>
            </name>
            <name>
              <surname>Ono</surname>
              <given-names>H</given-names>
            </name>
          </person-group>
          <article-title>Depth thresholds of motion parallax as a function of head movement velocity</article-title>
          <source>Vision Res</source>
          <year>2001</year>
          <volume>41</volume>
          <fpage>2835</fpage>
          <lpage>2843</lpage>
          <pub-id pub-id-type="doi">10.1016/S0042-6989(01)00164-X</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Ujike H, Ono H (2001) Depth thresholds of motion parallax as a function of head movement velocity. Vision Res 41:2835&#x2013;2843. doi:10.1016/S0042-6989(01)00164-X <pub-id pub-id-type="pmid">11701179</pub-id></citation>
      </ref>
      <ref id="CR33">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Watt</surname>
              <given-names>SJ</given-names>
            </name>
            <name>
              <surname>Bradshaw</surname>
              <given-names>MF</given-names>
            </name>
          </person-group>
          <article-title>The visual control of reaching and grasping: binocular disparity and motion parallax</article-title>
          <source>J Exp Psychol Hum Percept Perform</source>
          <year>2003</year>
          <volume>29</volume>
          <fpage>404</fpage>
          <lpage>415</lpage>
          <pub-id pub-id-type="doi">10.1037/0096-1523.29.2.404</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Watt SJ, Bradshaw MF (2003) The visual control of reaching and grasping: binocular disparity and motion parallax. J Exp Psychol Hum Percept Perform 29:404&#x2013;415. doi:10.1037/0096-1523.29.2.404 <pub-id pub-id-type="pmid">12760624</pub-id></citation>
      </ref>
      <ref id="CR34">
        <citation citation-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Watt</surname>
              <given-names>SJ</given-names>
            </name>
            <name>
              <surname>Akeley</surname>
              <given-names>K</given-names>
            </name>
            <name>
              <surname>Ernst</surname>
              <given-names>MO</given-names>
            </name>
            <name>
              <surname>Banks</surname>
              <given-names>MS</given-names>
            </name>
          </person-group>
          <article-title>Focus cues affect perceived depth</article-title>
          <source>J Vis</source>
          <year>2005</year>
          <volume>5</volume>
          <fpage>834</fpage>
          <lpage>862</lpage>
          <pub-id pub-id-type="doi">10.1167/5.10.7</pub-id>
        </citation>
        <citation citation-type="display-unstructured">Watt SJ, Akeley K, Ernst MO, Banks MS (2005) Focus cues affect perceived depth. J Vis 5:834&#x2013;862. doi:10.1167/5.10.7 <pub-id pub-id-type="pmid">16441189</pub-id></citation>
      </ref>
    </ref-list>
  </back>
</article>
</pmc-articleset>