Extensión de los sistemas argumentativos basados en reglas con elementos de argumentación clásica
﻿
Esta línea de investigación se llevará a cabo dentro del ámbito del Laboratorio de Investigación
y Desarrollo en Inteligencia Artificial (LIDIA), y está asociada a los siguientes proyectos de investigación:
“Formalismos Argumentativos aplicados a Sistemas Inteligentes para Toma de Decisiones”. Código: PGI 24/ZN18. Director: Alejandro Javier García. Co-director: Marcelo Alejandro Falappa. Acreditado con evaluación externa para el período 1/1/2009 - 31/12/2011. Financiamiento: Universidad Nacional del Sur.
“Sistemas De Apoyo a la Decisión Basados en Argumentación: formalización y aplicaciones”.
PIP-CONICET (PIP-112-200801-02798). Director: Carlos Iván Chesñevar. Período 01/2009 - 12/2011.
Financiamiento: CONICET.
Resumen
El objetivo general de esta investigación es mejorar los Sistemas Argumentativos Basados en Reglas (SABR) con elementos presentes en formalismos de argumentación clásica, los cuales aún no
han sido considerados en los SABR desarrollados hasta el momento. Una crítica usualmente realizada sobre los SABR es que determinados patrones de razonamiento argumentativo estudiados en
otras áreas, y que constituyen importantes aportes a la argumentación, no son considerados por los
SABR. Esta investigación tiene como objetivo incorporar dichos aportes a los SABR, lo cual permitirá mejorar tanto los SABR como sus correspondientes implementaciones, representando un avance
significativo para los sistemas argumentativos dentro del área de Inteligencia Artificial y Ciencias de
la Computación.
Palabras clave: Argumentación, Razonamiento Rebatible, Inteligencia Artificial
                      67WICC 2010 - XII Workshop de Investigadores en Ciencias de la Computación
1. Introducción
Argumentación es una forma de razonamiento en la cual, para una afirmación determinada, se
presta atención explícita a las justificaciones presentadas y a la resolución de los posibles conflictos
entre ellas. En este tipo de razonamiento, una afirmación es aceptada o rechazada según el análisis
de los argumentos a su favor y en su contra. La forma en que los argumentos y las justificaciones
para una afirmación son considerados, permite definir un tipo de razonamiento automático, en el cual
puede haber información contradictoria, incompleta e incierta. En la última década, argumentación
ha evolucionado como un atractivo paradigma para conceptualizar el razonamiento de sentido común
(ver surveys [5, 17]). Esto produjo como resultado la formalización de diferentes frameworks de
argumentación abstracta como [3, 7, 15], y de Sistemas Argumentativos Basados en Reglas (SABR)
como [2, 8, 11, 16].
Los SABR son formalismos de argumentación en que el conocimiento de un agente incluye un
conjunto de reglas de inferencia a partir de las cuales se pueden construir argumentos a favor o en
contra de una afirmación. Estos sistemas son de particular interés en el área de Inteligencia Artificial
(IA) dado que este tipo de reglas de inferencia permiten representar conocimiento de sentido común,
y la construcción de argumentos puede realizarse de manera automática. Los SABR poseen características que los hacen especialmente aptos para su implementación computacional. En la actualidad,
algunos de los SABR propuestos en la literatura cuentan con una implementación [8, 11], permitiendo
así su aplicación concreta a otras áreas de las Ciencias de la Computación.
Por otra parte, en la definición y formalización de los SABR dentro de IA, se han realizado
ciertas abstracciones y simplificaciones con respecto a modelos de argumentación producidos en
otras áreas, entre las cuales se encuentran el razonamiento legal, la teoría de la comunicación y la
filosofía [20, 21, 23, 24, 25, 26]. En consecuencia, una crítica usualmente efectuada sobre los SABR
es que determinados patrones de razonamiento argumentativo estudiados en las áreas mencionadas, y
que constituyen importantes aportes a la argumentación, no se encuentran actualmente considerados
por los SABR.
Una de las simplificaciones realizadas en los SABR, por ejemplo, consiste en considerar que la
noción de desacuerdo y ataque entre argumentos esté basada en reglas de inferencia que concluyen
información contradictoria. Por lo tanto, en los SABR un argumento únicamente puede atacar a la
conclusión de una regla que es utilizada en la formulación de otro argumento. A pesar de que este
tipo de ataque captura la mayoría de las situaciones, en otras áreas se han estudiado diversas formas de ataque que podrían considerarse dentro de los SABR. Esto constituye uno de los objetivos
particulares de esta propuesta. Es decir, el estudio de diferentes formas de ataque a un argumento
y su formalización dentro de los SABR. De este modo, se obtendrán mejoras para los SABR y los
nuevos aportes representarán un avance significativo para los sistemas argumentativos dentro del área
de Inteligencia Artificial y Ciencias de la Computación.
2. Líneas de Investigación y Desarrollo
Esta línea de investigación se enfocará sobre la problemática involucrada en la utilización de
SABR para la representación de bases de conocimiento con información que un agente puede utilizar
a fin de tomar decisiones dentro de su entorno. Se buscará incorporar a los SABR elementos presentes
en los modelos argumentativos producidos en áreas tales como el razonamiento legal, la teoría de la
comunicación y la filosofía, con el fin de obtener una mejora en los formalismos de representación de
conocimiento para agentes.
                      68WICC 2010 - XII Workshop de Investigadores en Ciencias de la Computación
2.1. Agentes y Argumentación
Un agente es una entidad computacional autónoma que obtiene percepciones de su entorno a
través de sensores y actúa en dicho entorno utilizando efectores. El decir que se trata de una entidad
autónoma implica que ésta cuenta con algún tipo de control sobre su propio comportamiento, y que
puede actuar sin la intervención de otros agentes o humanos. Actualmente los agentes tienen un campo
de aplicación muy amplio, y existe una gran variedad de tipos de agentes con distintos dominios de
aplicación. En particular, los agentes inteligentes están reconocidos en la literatura por su importancia
en la resolución de problemas complejos [27].
Desde los orígenes en la investigación sobre agentes inteligentes, es reconocida la relevancia de
utilizar argumentación como mecanismo de razonamiento para la toma de decisiones de los agentes.
En la actualidad diversos trabajos [1, 12, 14, 18, 19] presentan significativas contribuciones en este
área, en particular, vinculando el uso de SABR con los mecanismos de representación para arquitecturas de agentes. Sin embargo, los formalismos argumentativos utilizados en estos trabajos sufren las
críticas antes mencionadas para los SABR. En consecuencia, estos formalismos podrían incorporar
elementos de argumentación clásica, con el objetivo de beneficiar y mejorar el razonamiento de los
agentes que los emplean.
2.2. Sistemas Argumentativos
Dentro de la teoría de representación de conocimiento, los formalismos argumentativos son reconocidos por la construcción y comparación de argumentos para razonar con información inconsistente [7]. En este tipo de formalismos, una afirmación es aceptada o rechazada según el análisis de
los argumentos a su favor y en su contra. Diversos trabajos en la literatura reconocen la importancia
del uso de argumentación como un mecanismo de razonamiento en sistemas inteligentes [4, 6]. En
particular, esta línea de investigación está vinculada con un sistema argumentativo concreto, llamado
Defeasible Logic Programming (DeLP) [11]. DeLP es un formalismo que combina los resultados de
programación en lógica y argumentación rebatible. Utilizando DeLP es posible representar información tentativa de forma declarativa, mediante el uso de reglas “débiles”. Dado que es posible utilizar
negación estricta en la cabeza de este tipo de reglas, será posible representar información contradictoria. En este formalismo se identifican aquellos elementos en contradicción, y posteriormente se lleva
a cabo un proceso argumentativo de dialéctica para determinar cuál de estos elementos prevalecerá.
3. Resultados Obtenidos/Esperados
En los últimos años, dentro del LIDIA se han llevado a cabo diferentes proyectos de investigación sobre SABR y su aplicación en áreas tales como Toma de Decisiones, Robótica Cognitiva y Web Semántica (entre otras). Dentro de estos proyectos se desarrolló una implementación
de un SABR (DELP), que en la actualidad cuenta con diferentes versiones disponibles. Además
de la versión original de DeLP [11], que provee un lenguaje de programación en lógica rebatible, se encuentra disponible una versión que permite el uso del sistema a través de la web (ver
http://lidia.cs.uns.edu.ar/delp). Adicionalmente se desarrolló una versión llamada DeLP-Server [10],
la cual provee un servicio de razonamiento para sistemas multi-agente, donde diferentes agentes en
host remotos pueden hacer uso de este servicio de razonamiento argumentativo. Estas implementaciones se han utilizado en aplicaciones concretas como toma de decisiones en un entorno de robots
Kephera [9], sistemas de recomendación [6, 22], e implementación de agentes [13].
Esta línea de investigación tiene por objetivo mejorar los Sistemas Argumentativos Basados en
Reglas (SABR) con elementos presentes en formalismos de argumentación clásica. Es decir, añadir
                      69WICC 2010 - XII Workshop de Investigadores en Ciencias de la Computación
elementos que aún no han sido considerados en los SABR desarrollados hasta el momento, los cuales
corresponden a patrones de razonamiento argumentativo estudiados en otras áreas, y que constituyen importantes aportes a la argumentación. El propósito de esta investigación es incorporar dichos
aportes a los SABR, permitiendo mejorar tanto los SABR como sus correspondientes implementaciones. De este modo, se podría lograr un avance significativo para los sistemas argumentativos dentro
del área de Inteligencia Artificial y Ciencias de la Computación.
