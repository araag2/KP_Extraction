Interpolación polinomial
﻿
El procesamiento inteligente de imágenes ha
crecido de manera continua y vertiginosa debido
en parte a la creciente sofisticación y accesibilidad
a los dispositivos que las generan y también como
consecuencia del incremento generalizado de la capacidad de procesamiento. Existe una abundante
cantidad de datos en formato de imagen digital, y
una relativa escasez de sistemas de procesamiento
inteligente que permitan aprovechar y determinar
sistemáticamente la información relevante en ellas.
Por otra parte, las aplicaciones de inteligencia
artificial y reconocimiento de patrones en imágenes que se desarrollan en distintos campos, se encuentran frente al desafío cada vez más frecuente
de vincular conocimiento y experiencia provenientes de áreas dispares y tradicionalmente no relacionadas, de una manera creativa y útil.
El principal objetivo de este proyecto consiste en desarrollar métodos avanzados de procesamiento de imágenes digitales empleando diferentes descriptores, y clasificando por medio de metodologías de la inteligencia artificial y el reconocimiento de patrones. Se pretende encarar el estudio
de situaciones específicas de aplicación en las que
se requiere el procesamiento inteligente de imágenes, basadas en situaciones específicas y donde los
resultados son de aplicación directa en otros ámbitos.
La realización de este proyecto requiere,
además, la fusión de datos con otro tipo de sensores para poder cotejar y validar los resultados de
la clasificación automática en imágenes.
Palabras clave: Descriptores, Procesamiento
Digital de Imágenes, Reconocimiento de Patrones,
Superresolución.
Contexto
Este trabajo se desarrolló dentro del marco del
proyecto de investigación 29/A269 denominado
Procesamiento Digital de Imágenes a Través de
Herramientas de Inteligencia Artificial, perteneciente y financiado por la Universidad Nacional
de la Patagonia Austral en la Unidad Académica
Río Gallegos.
En este proyecto de investigación se pretende
desarrollar metodologías propias de la inteligencia
artificial y el reconocimiento de patrones a fin de
aplicarlas en el procesamiento digital de imágenes,
para la segmentación, búsqueda de descriptores e
identificación de características en imágenes digitales provenientes de distintos campos de aplicación. Se pretende que, dependiendo del contexto
de aplicación, pueda lograrse el reconocimiento de
características a fin de contrastarlas con aquellos
elementos que constituyan zonas de interés que
además son caracterizables a través de modelos
físico-matemáticos, cuyas características los hacen
mensurables.
En una primera etapa se busca estudiar la segmentación y medición de característicos lineales
en imágenes de sensado remoto, especialmente
imágenes satelitales, dado que la resolución de las
mismas es en general siempre de menor calidad
WICC 2012 368
2012 XIV Workshop de Investigadores en Ciencias de la Computación
que lo necesario para realizar estudios geográficos
de alta precisión [6]. Al mismo tiempo, los algoritmos usuales de segmentación de característicos
lineales (bordes, fronteras, etc.) incurren en errores sistemáticos independientes de la resolución,
que pueden llegar a sobreestimar la medición en
un 40 %.
Introducción
Las imágenes satelitales se pueden definir como
la representación visual de la información capturada por un sensor montado en un satélite artificial
[2]. Estos sensores recogen información reflejada
por la superficie de la tierra que luego es enviada
y procesada convenientemente, entregando valiosa
información sobre las características de la zona representada. La extracción y detección de bordes es
una herramienta fundamental en el procesamiento de imágenes y visualización. Particularmente
en la detección y extracción de características en
las cuales su objetivo es identificar zonas en una
imagen que muestren discontinuidades [3].
En este trabajo buscamos estudiar el impacto de
incorporar interpolación de alto orden, y comparar
la mejora obtenida respecto de trabajos anteriores
donde se utiliza interpolación lineal [1] e interpolación a través de polinomios de Hermite, mediante
la utilización del algoritmo de “Marching Squares”.
En análisis numérico, la interpolación polinómica es una técnica de representación de un conjunto de datos o de una función matemática a través
de una expresión polinómica. Es decir, dado cierto número de puntos obtenidos por muestreo o a
partir de un experimento, se pretende encontrar
un polinomio que pase por todos los puntos. También es utilizado para conocer, de un modo aproximado, los valores que toma cierta función de la
cual sólo se conoce su imagen en un número finito
de abscisas. A menudo, ni siquiera se conocerá la
expresión de la función y sólo se dispondrá de los
valores que toma para dichas abscisas.
El objetivo del método será hallar un polinomio
que cumpla lo antes mencionado y que permita hallar aproximaciones de otros valores desconocidos
para la función con una precisión deseable fijada.
Por ello, para cada polinomio interpolador se dispondrá de una fórmula del error de interpolación
que permitirá ajustar la precisión del polinomio,
de acuerdo a la cantidad de puntos y del grado del
polinomio.
Se dispone de varios métodos generales de interpolación polinómica que permiten aproximar una
función por un polinomio de grado m. El primero de éstos es el método de la interpolación lineal,
que luego se observa como un caso particular de la
Interpolación general de Newton [7]. Otro de los
métodos es la interpolación de Lagrange, equivalente a Newton pero más tedioso en su cálculo, y
por último, la interpolación de Hermite [7].
Con el polinomio de interpolación de Newton se
logra aproximar un valor de la función f(x) en un
valor desconocido de x. El caso particular, para
que una interpolación sea lineal es en el que se
utiliza un polinomio de interpolación de grado 1,
y se denota de la siguiente manera:
f(x|x1;x2) = f(x1) +
f(x2)− f(x1)
x2 − x1
(x− x1)
El Polinomio Interpolador de Hermite de grado
2m+1 de la función f es un polinomio de la forma:
P2m+1(x) = Σ
m
i=0fiΦi(x) + Σ
m
i=0f
′
iΨi(x),
con:
Φi(x) = (1− 2l
′
i(xi)(x− xi))l
2
i (x)
Ψi(x) = (x− xi)l
2(x), i = 0, . . . ,m.
La principal ventaja del polinomio de Hermite es
su sencillez de cálculo, mientras que su gran desventaja es que es una interpolación local, teniendo
sólo en cuenta los dos puntos adyacentes (derecho
e izquierdo) a los extremos de la curva interpolada.
Si se intenta determinar el borde de una imagen,
se deben identificar los puntos del contorno. Para
ello se debe determinar qué píxel es foreground y
qué pixel es background. Con este fin se utiliza el
algoritmo de Marching Squares.
Una imagen para ser utilizable en el procesamiento por medio de computadora debe ser digitalizada. A esta digitalización la llamamos muestreo de la imagen. El muestreo digital es una de las
partes del proceso de digitalización de las señales.
Consiste en tomar muestras de una señal analógica
a una frecuencia o tasa de muestreo constante, para cuantificarlas posteriormente. Según el teorema
WICC 2012 369
2012 XIV Workshop de Investigadores en Ciencias de la Computación
de muestreo de Nyquist-Shannon, para poder replicar con exactitud (es decir, siendo matemáticamente reversible en su totalidad) la forma de una
onda es necesario que la frecuencia de muestreo
sea superior al doble de la máxima frecuencia a
muestrear. El proceso de muestreo sobre una señal
continua que varía en el tiempo (o en el espacio como en una imagen u otra variable independiente
en cualquier otra aplicación) es realizado midiendo
simplemente los valores de la señal continua cada
T unidades de tiempo (o espacio), llamado intervalo de muestreo. El resultado de este proceso es
una secuencia de números, llamadas muestras, y
son una representación de la imagen original. La
frecuencia de muestreo f es el recíproco del intervalo de muestreo f = 1/T y se expresa en Hz (si
es tiempo), o en oscilaciones por píxel, si se trata
de una imagen digital. El muestreo debe cumplir
con dos condiciones:
Limitar en banda a través de un filtro pasobajas la señal a muestrear.
Siguiendo el criterio de Nyquist, si conocemos el ancho de banda de la señal, entonces
la frecuencia de muestreo f para lograr una
reconstrucción casi perfecta de la señal original deberá ser: fN ≤ 2WB donde WB es el
ancho de banda de la señal original y la frecuencia de muestreo que sigue esta condición
se le llama frecuencia de Nyquist.
Si las condiciones de muestro no se satisfacen, entonces las frecuencias se pueden llegar a traslapar;
es decir, las frecuencias superiores a la mitad de la
frecuencia de muestreo serán reconstruidas y aparentarán ser frecuencias por debajo de la frecuencia de muestreo. El resultado sería una distorsión
llamada aliasing [5].
Líneas de Investigación y Desarrollo
El plan de actividades previsto para la primera
etapa se centra fundamentalmente en la formación
intensiva en los aspectos teóricos necesarios. Para
la segunda etapa, se espera estar en condiciones de
abordar problemáticas de aplicación, fundamentalmente seleccionadas de entre los objetos de esFigura 1: Imagen binaria sintética
tudio de otros grupos de investigación, principalmente se espera trabajar con imágenes satélites.
Finalmente, la tercera etapa constituye el período
de integración y selección de temas que puedan
constituir una definición sobre el crecimiento del
grupo.
Dentro de las actividades propuestas, se incluye la formación de recursos humanos atravesada
por el cursado de los programas de posgrado de
los integrantes, fuertemente relacionados con este
proyecto.
Resultados y Objetivos
Como ejemplo de aplicación de lo antes mencionado, se trabajó con imágenes binarias sintéticas.
El principal resultado se obtuvo de una imagen
de 3300x2100px en la que se observan cinco círculos, de diámetros 1600px, 800px, 400px, 200px y
100px (Figura 1). A cada círculo se lo dividió por
su diámetro horizontal y ambas partes fueron separadas entre sí por una franja de 3100x100px para que la imagen resultante tuviera sectores verticales en ambos extremos y se pudiera analizar la
convergencia del algoritmo a pesar de los cambios
de curvatura. En el lado izquierdo de la imagen es
casi imperceptible este efecto, pero en el derecho
es claramente visible.
Además, la figura presentada posee gran riqueza
geométrica, y fue seleccionada con el fin de verificar la robustez del algoritmo de detección, ya que
sus cambios de orientación de la curvatura así como el radio de curvatura varían a lo largo de toda
la imagen. Otra característica distintiva es que se
WICC 2012 370
2012 XIV Workshop de Investigadores en Ciencias de la Computación
puede calcular el valor exacto del perímetro aplicando matemática básica, en este caso de 9939px.
La imagen fue remuestreada a un tamaño de píxel
mucho mayor (simulando el efecto del sensor satelital), con lo que se obtuvieron imágenes de mucho menor resolución. La idea del método consiste
en mostrar que pese a este deterioro, es posible
recuperar la información del perímetro original a
través de una reconstrucción de alto orden.
Para la reconstrucción del perímetro, se utilizó el método de marching squares con interpolación lineal presentado en [1]. También se utilizaron los puntos encontrados por dicho método
como puntos de control para generar una curva
de Hermite. En la figura 2 es posible observar el
resultado de reducir la resolución de la figura 1 a
1/50 (es decir, la cantidad final de píxels es 2500
veces menor), los puntos de control encontrados,
y la curva de Hermite computada.
Figura 2: Reconstrucción del perímetro por medio
de polinomios de Hermite
En el Cuadro 1 se puede observar el resultado
de ambos métodos para diferentes disminuciones
de la resolución.
El gráfico asociado al Cuadro 1 es el que se presenta como Figura 4, donde se aprecia claramente
que el error sigue la misma tendencia independientemente del método de interpolación, aunque con
los polinomios de Hermite se consiguen resultados
más precisos. Las líneas continuas representan el
ajuste de los datos de error a un polinomio de grado 2. Es posible observar que la interpolación de
Hermite disminuye el error, de una manera más
Figura 3: Detalle (ampliación) de la reconstrucción por Hermite
apreciable a medida que la calidad del submuestreo es mayor. Una forma de interpretar estos resultados es que, por ejemplo, para una imagen con
una resolución 20 veces menor (400 veces menos
píxels) es aún posible medir los perímetros de los
objetos con un error menor al 5 %. Como se mostrara en trabajos anteriores, los métodos tradicionales de mediciones de perímetro cometen errores
de un orden de magnitud mayor, aún en mejores
circunstancias.
Figura 4: Tamaño de MP vs Error
Es posible mencionar que, con los resultados
observados, se puede establecer una regresión del
perímetro medido en función del tamaño del píxel,
y computar una dimensión fractal [4] que permiWICC 2012 371
2012 XIV Workshop de Investigadores en Ciencias de la Computación
MP L Error ( %) H Error ( %)
15 9373 5.70 9557 3.84
20 9304 6.39 9469 4.73
25 9229 7.14 9360 5.83
30 9076 8.68 9139 8.05
35 9046 8.98 9132 8.12
40 8867 10.78 8928 10.18
45 8953 9.92 9018 9.27
50 8831 11.15 8903 10.42
55 8760 11.86 8814 11.32
60 8723 12.23 8767 11.80
65 8707 12.39 8767 11.79
70 8660 12.87 8733 12.13
80 8539 14.09 8602 13.46
90 8501 14.46 8561 13.86
100 8329 16.20 8381 15.67
Cuadro 1: Tabla con el perímetro obtenido y el error
relativo en la interpolación lineal (L) y la interpolacion polinomial de Hermite (H), para diferentes submuestreos (MP).
tiría extrapolar estos resultados con aún mayor
precisión. Estos resultados preliminares permiten
concluir que la interpolación de Hermite es más
estable para este objetivo que la interpolación lineal.
Formación de Recursos Humanos
El equipo de este proyecto se encuentra formado por un Dr. en Ciencias de la Computación, una
Lic. en Sistemas y un Prof. en Matemática. Los
dos últimos integrantes son alumnos regulares de
la Maestría en Informática y Sistemas de la UNPA, además de docentes ordinarios de la UARG.
