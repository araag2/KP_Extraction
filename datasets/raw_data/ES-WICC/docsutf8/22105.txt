Entrenamiento de redes neuronales
﻿. 
En particular se consideran dos sublíneas de trabajo: 
Evolución de redes neuronales para la obtención de arquitecturas adecuadas para problemas difíciles. 
Paralelización de redes neuronales. 
2. Evolución de redes neuronales 
Los algoritmos evolucionarios son meta-heurísticas de optimización que han ganado una gran reputación 
en los últimos años debido a sus éxitos en distintas áreas de aplicación [10]. Los algoritmos evolucionarios 
constituyen, en pocas palabras, una simulación muy rudimentaria del proceso Darwiniano de selección del 
individuo más adecuado. Los algoritmos evolucionarios han resuelto con éxito problemas difíciles de 
optimización, desde problemas de optimización paramétricos no continuos hasta instancias muy difíciles 
de problema de optimización combinatorial, tanto académicos como del mundo real. 
La gran flexibilidad de los algoritmos evolucionarios les permite manejar adecuadamente representaciones 
de espacios de búsqueda no comunes, incluso espacios con información espacial desconocida, como los 
que se presentan en el campo de la mecánica estructural [11 ][12]. 
Los mecanismos de aprendizaje de redes neuronales trabajan en general realizando una búsqueda de los 
pesos adecuados para una estructura dada, es decir, el número de unidades y el patrón de conexiones en la 
red son fijos [9]. Existen métodos que permiten la búsqueda de los pesos y la selección de la estructura, 
pero en general son métodos que trabajan entrenando redes de arquitectura fija, y luego realizando 
agregado de nuevas unidades o eliminación de unidades superfluas. 
El proceso de realizar la búsqueda de una estructura adecuada y además el conjunto de pesos al mismu 
tiempo, se plantea como un problema extremadamente más difícil dado que el espacio de búsqueda es no 
estándar. Los algoritmos evolucionarios se plantean entonces como una muy buena posibilidad de 
Wicc 2000 - 46 
solución en este contexto, dadas sus características. 
La propuesta sobre la que se está trabajando consiste en evolucionar poblaciones de componentes de redes 
neuronales, que son combinadas para su evaluación. De esta forma, ninguna red por si sola es considerada 
una solución completa, sino que depende de otras redes. De esta forma, se estimula la especialización de 
redes en áreas particulares del problema, y al mismo tiempo, se fuerza un sentido de cooperación entre las 
redes, dado que cada red necesita de otras para poder lograr una solución completa al problema. Este 
enfoque, propuesto por Miikulainen y Moriarty [1][2][3], Y conocido como aproximación simbiótica, ha 
sido ya utilizado con éxito en trabajos anteriores en esta línea de investigación para la evolución de 
controladores difusos [14 J[ 15]. 
Se está siguiendo además una aproximación similar a la utilizada en otros dominios de aplicación de 
algoritmos evolucionarios conocida como la aproximación Michigan [7][ 10], que se aplica con éxito en 
Machine Learning, donde los individuos son las reglas y la solución es una base de reglas, y también en el 
problema inverso de IFS (Iteraled Function Systems) en el dominio de procesamiento de imágenes, donde 
los individuos elementales son mapeos constructivos, y la solución global consiste en un conjunto de esos 
mapeos. En estas aproximaciones, el mayor problema consiste en el cálculo de la recompensa (fitness) que 
corresponde a cada individuo. 
La gran ventaja de esta aproximación es que en lugar de trabajar con una red de arquitectura fija, se están 
evolucionando redes de arquitecturas distintas al mismo tiempo, lo que permite encontrar no sólo el 
conjunto de pesos adecuado, sino además, una arquitectura adecuada para la red. 
Los problemas sobre los que se está aplicando esta aproximación son problemas de ajuste de datos (data 
fitting), donde intencionalmente se proveen áreas del espacio que están muestreadas en forma pobre. 
También se están analizando problemas de control de robots móviles que deben realizar una serie de 
tareas en secuencia [5][6][8]. En este caso se plantea la posibilidad de realizar el aprendizaje en forma 
incremental, partiendo de un problema de una única tarea y agregando gradualmente nuevas tareas. 
3. Paralelización de redes neuronales 
Una de las desventajas de las redes neuronales consiste en la gran cantidad de tiempo que se necesita para 
el entrenamiento. Una forma directa de lograr reducir este tiempo, consiste en la paralelización de los 
algoritmos de aprendizaje [16J. Sin embargo, no siempre los algoritmos se pueden paralelizar en forma 
simple, y además, la cantidad de comunicación entre las CPUs, hace que la mayoría de las versiones 
paralelas de estos algoritmos sólo se puedan ejecutar adecuadamente en computadoras paralelas. 
En la línea de investigación, se está trabajando en la paralelización de algoritmos de redes neuronales, ell 
particular, a través de un algoritmo que limita la cantidad de información que transita entre los distintas 
CPUs. De esta forma, los procesadores utilizan a veces información que está desactualizada, pero nunca 
más allá de un porcentaje, que se define como parámetro del algoritmo. 
De esta forma, se trata de permitir la aplicación en clusters de computadoras de algoritmos estándar de 
paralelización para computadoras paralelas. Uno de los problemas elegidos para probar esta aproximación 
es el reconocimiento de imágenes. También se considera evaluar la posibilidad de implementar redes 
modulares. Se están desarrollando aplicaciones usando MPI [17] para su ejecución en una computadora 
paralela de 32 CPUs y en una red de computadoras Linux. 
4.
