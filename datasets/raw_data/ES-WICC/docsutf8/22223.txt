Planificación difusa auto adaptativa para hebras
﻿Rau! TrelllsaL PL'drll ¡:UiiiiJil \ (-1Ir1\l'.  ~I\ ka 
L-mail: l:ku\ku' (/'unsI.I:Ju_ar 
DI..'parlaIlIL'rtll l lk Illr(lrllllüiLa 
llni"L'rsiJau 1\\ll"i()Ill¡\ de San I,uis 
l".JL'ILiLO JL' ¡v:; AIllIL'S 'i:\(¡ -- jIUU"  "';Ull LUIS 
El modelo de programación con hebras es muy utilizado hoy en día. Las hebras se pueden 
ejecutar en forma concurrente dentro del mismo programa, ejecutando tareas claramente 
divididas, y compartiendo datos. Las bibliotecas estándar de hebras proveen control sobre­
la planificación, pero no le pernlitcn al usuario definir nuevos algoritmos de planificación. 
En este trabajo se propone dar al programador de aplicaciones que utilizan hebras la 
posibilidad de definir nuevos algoritmos de planificación utilizando reglas difusas. Se 
ii1ff~~~~~~~W.;·_I __ ,,;Iii.fijÁ8a..~~~~!!i. 
1. Introducción 
A través de la utilización de hebras se puede dividir un programa en subtareas cuya 
ejecución puede ser llevada a cabo en forma concurrente. Un algoritmo de planificación 
selecciona una hebra paid su ejecución a partir de un conjunto de hebras que están 
esperando su turno. Esta decisión está determinada por un algoritmo de planificación y se 
basa en la prioridad de las hebras. El programador puede definir las prioridades y 
seleccionar una política particular, pero no puede definir un nuevo algoritmo de 
planificación. 
En este trabajo, se propone mejorar la biblioteca estándar de hebras con la inclusión de un 
mecanismo para la definición de nuevos algoritmos de planificación en base a reglas 
difusas. Los algoritmos obtenidos son mucho más fáciles de entender y son más robustos. 
Un problema que surge, sin embargo, es que el proceso de 'sintonía fina' o adecuación, a 
veces, se transforma en un proceso de corrección por intento y error. Se propone la 
utilización de una técnica de aprendizaje por refuerzo combinada con redes neuronales para 
mejorar el desempeño del planificador. En este trabajo se muestra como ejemplo, la definición de un planificador de tiempo real 
para hebras, y los resultados al aplicar el proceso de mejora. 
2. Planificaciún difusa 
I.os algoritmos de planificación para hehras involucran usualmente dos atrihutos por cada 
hhbra: 
• prioridad: dl.!t\!rmina 4UI.! h\!bra pued\! accl;!dl;!r al procesador. 
• política: es una forma de especificar de que forma dos hebras de la misma prioridad se 
ejecutan y comparten la CPU.' . ... 
Las dos políticas principales son 
• FlFO: permite a las hebras que se ejecuten hasta que terminen o se bloqueen. Cuando 
una hebra se bloquea, es colocada al final de su cola de prioridades. 
• Round-Robin: permite que las hebras se ejecuten sólo por una cantidad limitada de 
tiempo. Cuando su tiempo se acaba, el procesador se asigna a otra hebra. 
Sc;;agre·g&-a',lwbibliotearo:estándm·o:de"hebI8'S?"1HI·,'·UIJeY(F-atgoritmC1"denominado'·:f'tJ'ElH:< 
Trabaja como el Round-Robin, pero las prioridades de las hebras se definen por reglas 
difusas, basadas en atributos definidos por el usuario. Los atributos pueden estar basados en 
el tiempo, como el tiempo de comienzo o fin (deadline) esperado, o ser independientes del 
tiempo, como por ejemplo la importancia de una hebra, su costo, etc. 
De esta forma, la definición de un algoritmo de planificación involucra: 
• La definición de un conjunto de atributos y sus correspondientes valores lingüísticos. 
• La definición de un conjunto de reglas utilizadas para calcular la prioridad de una hebra 
teniendo en cuenta sus valores de atributos. 
Por ejemplo, se puede definir un planificador de tiempo real considerando tres atributos: 
• tiempo de comienzo: las hebras se planifican únicamente sólo después de su tiempo de 
mlClO. 
• criticalidad: las hebras se planifican sólo si no hay hebras más importantes esperando 
para ejecución. 
• tiempo de finalización: las hebras deben finalizar antes de este tiempo. 
Se asume que los tiempos de llegada y de finalización de las hebras no se conocen hasta 
que el programa es puesto en ejecución. De esta forma, no es posible utilizar un algoritmo 
I 
de planificación estático. El algoritmo propuesto es dinámico y la planificación se realiza 
en línea. Cada vez que llega una hebra o cada vez que alguna finaliza su' ejecución, las 
prioridades se recalculan. 
Los valores lingüísticos para cada atrihuto son: 
• tiempo de comienzo: temprano. medio y tardío. 
• criticalidad: importantc. promedio y no-importante. 
• ticmpo de tinalizaciún: temprano. medio y tardío . 
. LL~valorr~ __  ~ los__tributos parr cc hebra  ~n transfOlIlladooen-yalorr difusos, x}uego,é¿',';; 
se utiliza un conjunto de reglas para calcular los valores de prioridad. Un conjunto de reglas 
difusas para este planificador de tiempo real se muestra a continuación: 
mlclo finalización criticalidad prioridad 
temprano importante diez 
temprano temprano promedio nueve 
medio temprano promedio ocho 
tardío temprano no importante siete 
temprano temprano no importante ocho 
",mediQ;¡Qil!íi@M, _,,;;.í.._) íí d- Lp ..  s ..  ~~~ño-im:pw::j--¡;i¡i(t;dr¡jitaa.o.. y;aA _.i!;,;¡W.q;; 
tardío temprano 
temprano medio 
medio medio 
tardío medio 
medio 
medio 
tardío 
tardío 
tardío 
no importante 
importante 
importante 
importante 
promedio 
no importante 
importante 
promedio 
no importante 
Por ejemplo, la segunda fila de la tabla representa la regla difusa: 
Si 
Entonces 
el tiempo de comienzo es temprano y 
el tiempo de finalización es temprano y 
la criticalidad es promedio 
la prioridad es nueve. 
seis 
seis 
CInCO 
cuatro 
CInCO 
cuatro 
tres 
dos 
uno 
Los valores del centro corresponden al centro de las funciones triangulares, y los otros dos 
valores a la amplitud izquierda y derecha respectivamente. La palabra abierto quiere decir 
que en esa dirección, el valor de pertenencia es 1 desde la posición central. 
De esta forma, cada hebra recibe un valor de prioridad calculado en base a los atributos. 
Las hebras se planifican en base a estas prioridades calculadas. en forma dinámica. . ',,''f,>-.. ',-, 
Los valores de prioridad también se definen como conjuntos difusos. Algunos valores para 
poder definir ejemplos se muestran a continuación: 
\ariabk conj L1I1lo di/LIso 
temprano 
medio 
tardío 
temprano 
tiempu dc tillLlli/.L1ciún medio 
tardío 
:' .. ;.·...:.:c'no importantecriticalidad promedio 
prioridad 
importante 
uno 
dos 
tres 
cuatro 
CInCO 
'. sels 
centro 
100 
300 
500 
100 
300 
500 
2 .:':0 .. : 
5 
10 
1 
2 
3 
4 
5 
6 
amplitud iZYLllerd<.t alllplilLld derecha 
ahierto 1 :'0 
150 150 
150 
ahierto 
150 
150 
abierto 
3 
3 
abierto 
1 
1 
1 
1 
1 
ahierto 
150 
lSU 
150 
3 
3 
abierto 
1 
1 
1 
1 
1 
1 
.,.;,.. --o .. fC .. 'M!Jt,."" r.;.i:,:;;··:_:·""~ ."..:;:Z:': -"'\..=··;",·t¡¡!",·::-··!·-'f""--:-·;:';: 
nueve 9 1 abierto 
Este algoritmo de planificación de tiempo real es sólo un ejemplo. Un algoritmo 
completamente diferente se puede definir involucrando atributos tales como costo, 
beneficio, etc. Las reglas correspondientes se usarán para calcular los valores de 
prioridades, y las hebras entonces se planifican de acuerdo a esos valores obtenidos. 
3. Auto adaptación 
El objetivo de esta propuesta es mejorar la calidad del planificador difuso. El planificador 
se evalúa bajo condiciones controladas. Sólo se hacen cambios cuando su desempeño no es 
adecuado. 
Condiciones controladas quiere decir casos de entrenamiento, o en otras palabras, un 
. conjunto de hebras que incluye casos límite orientados a generar dificultades en la 
planificación. Para el ejemplo de tiempo real, un caso de entrenamiento estará constituido 
por hebras que permitan planificaciones exitosas y planificaciones no exitosas también. 
Para la etapa de entrenamiento, proponemos representar al planificador difuso como una 
red neuronal. Se ha seleccionado la componente ASN (Action Selection Network) del 
modelo GARIC (Generalized Approximate Reasoning-based lntelligent Control) propuesto 
por Berenji y Khedkar. Si se conoce la salida esperada del sistema, es decir, la prioridad 
correcta para cada hebra, es muy fácil corregir los conjuntos difusos representados en la 
red. 
Este es. sin embargo, el principal problema, dado que este valor no se puede conocer. Se 
propone utilizar un tutor para la etapa de entrenamiento, basado en una clase de estrategia 
,._ ;11'11'ii,¡I/;!::' ¡),\r r,,'!ÚLT/1l lkn\lll1inadu ()-kar:::n;..:. 1; ;¡¡:':(lj·itllHl. usad\! (11I1,iuntal1l(1l1( 
(On el planilicador difuso. genera información Sffbn: la calidad dc las posibles acciones del 
planificador. l isando esta inlcJrmación. la red neuronal puede ser mcjorada, lJn diagrama se 
muestra cn la ligura 1: 
planificador 
difuso 
casos dl' entrenamiento 
tutor 
Figura 1: diagrama del proceso de auto-adaptativo 
3.1 La red neuronal 

,·"··,*;PPO;¡;¿¿"_;;ijR¡;i¡@.,*".  ., h' iI!i1Zki$! . J!iiF.JJ" . ,;7-" "!,,";:-,,!,,,: ;;::;.)JiS .,.f·JL.,¿,[l@ih •.. ,s¡rfll1.A.;.,,+_: .. Ürr@1 
La figura 2 muestra la red neuronal eqUIvalente al sIstema dIfuso defimdo antenonnente. 
Esta red es alimentada con los valores de cada uno de los atributos definidos por el usuario 
y obtiene la prioridad a la salida. Para mas detalles sobre su construcción consultar las 
referencias. Una vez conocida la salida esperada, el error es fácilmente corregido a través 
de la actualización de las funciones de pertenencia. 
tiempo de inicio 
criticalidad 
criticalidad 
tiempo de fin 
Figura 2: red neuronal equivalente al sistema difuso 
3.2 El tutur 
ss pUl!dd considerar al problema de plani1icación como un prohlema dc aprendizaje por 
refuerzo. donde el planificador es el agentt que toma decisiones en cada  stado. En cada 
paso. el agente recihe una representación del amhiente (valores de los atrihutos) y 
:-,-.:kk¡;iona una acción dl! un wnjulllo de m:cion..:s posibks telige una prioridad). Ln l!tapas 
posteriores recibe una recompensa. Su objetivo es tomar las decisiones que le permiten 
''ñiaximizar la recoiripenss óen'otraS palabraS, lográr las'mejciresplariificaciones":"-" " " .... ,..;,i . . 
Un algoritmo de Q-Iearning se aplica para maximizar la recompensa acumulada a largo 
plazo. Para evitar el análisis de un espacio muy grande de estados, se agrega al algoritmo de 
Q-Iearning el planificador difuso. El planificador es usado para obtener una salida 
(prioridad) y con una perturbación se le permite explorar estados vecinos. 
4. Un ejemplo 
identificador 
A 
B 
mIcIo 
o 
10 
criticalidad 
10 
5 
finalización 
90 
105 
El planificador encuentra una planificación que permite cumplir con los tiempos de 
finalización, tal como se muestra en la figura 3, dado que asigna a A una prioridad de 9, y a 
B una prioridad menor de 8. 
A 
B 
10ms 70 ms tiempo 
Figura 3: planificación exitosa 
Con el objeto de evaluar el funcionamiento del algoritmo auto-adaptativo propuesto, se 
modifica intencionalmente un conjunto difuso para forzar al planificador a tomar decisiones 
erróneas. Se selecciona el conjunto de salida 'ocho' y se modifica sus parámetros para 
hacerlo más parecido a nueve, lo que producirá un error en la asignación de prioridades. 
Los valores elegidos son 8.7 para el centro y 1 Y 0.5 para las amplitudes izquierda y 
derecha respectivamente. 
En este caso, las dos hebras reciben el valor nueve como prioridad. Teniendo ambas el 
mismo valor. ambas hebras permanecen en la misma cola de prioridad recibiendo cada una 
Ull qllalllllm dI.: l·.ii:(u.:¡. 1::. '." :: .. :':.; .. .., ,: .. ,:,::lldi";¡,!;¡ i,l :;lliiLii:Ilh: (ullllO P;¡l';¡ pL'llkr Sil 
deadlinc. como se muestra en la figura 4 . 
.. 
A 

~.::,a...'i;t!C ...  ''' . ,;:I__~~~~~~~----i;; ... ' .................. .....-;... ·..~::f§:::::~~~~~~~~~~~~:::...~~~~~~iá-::·jj~~~_ lOOs·· '.';:"". .. 70 ms tIempo 
Figura 4: planificación no exitosa. 
El diagrama de estados con los valores obtenidos por el algoritmo de Q-leaming se 
muestran en la figura 5. El camino adecuado seleccionado por el tutor se encuentra 
remarcado. 
Figura 5: Grafo de estados 
El siguiente paso consiste en la utilización de la red neuronal para correggr el. ep:or en los 
conjuntos difusos. Luego del entrenamiento basado en el camino obtenido como adecuado, 
el error que se introdujo en el conjunto difuso 'ocho' queda corregido. Sus nuevos valores 
son 8.2 para el centro, 1.3 para la amplitud izquierda y 0.15 para la amplitud derecha. La 
figura 7 muestra el efecto del aprendizaje. El conjunto dibujado con línea de puntos es el 
()httñido luego del entrenamiento. 
5. Conclusiones 
Se ha propuesto un nuevo mecanismo a través del cual se pueden definir algoritmos de 
planificación para hebras, a través de reglas difusas, considerando atributos definidos por el 
usuarIo. 

~~~~_ .. P'r.QRUUsl9:.::.4S;iiriie...~~~ad::tpttción.  ,,,~Alej.Q¡a¡;".eL..seepeño:: .. lQs.;,.","," 
planificadores: .. Combina .. una aproximación de redes neuronales con un algoritmo de 
aprendizaje por refuerzo. El espacio de estados se reduce usando la salida del planificador 
difuso como guía en el proceso de aprendizaje. 
Los algoritmos se encuentran implementados en una biblioteca de hebras Posix para Linux. 
