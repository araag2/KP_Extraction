Refinamiento de reglas rebatibles para el aprendizaje de conceptos
﻿Refinamiento de Reglas Rebatibles
para el Aprendizaje de Conceptos
Telma Delladio∗
td@cs.uns.edu.ar
Laboratorio de Investigación y Desarrollo en Inteligencia Artificial (LIDIA) †
Departamento de Ciencias e Ingeniería de Computación (DCIC)
Universidad Nacional del Sur (UNS)
Avda. Alem 1253 - Bahía Blanca - Bs. As.
Tel (0291) 459-5135 - Fax (0291) 459-5136
Introducción
El aprendizaje de conceptos a partir de ejemplos puede desarrollarse en el marco de la Programación en Lógica Rebatible (plr) [GS03, Del03]. En ese caso las definiciones aprendidas son
conjuntos de reglas rebatibles que modelan el concepto que es objeto de aprendizaje. Estos conjuntos de reglas rebatibles deben respetar las observaciones provistas al proceso de aprendizaje.
En una propuesta top down, las definiciones se obtienen a través de un proceso continuo de refinamiento. A partir de una definición general, se analizan los conflictos que ésta presenta frente a
las observaciones consideradas, y se realiza un paso de refinamiento que resuelva estos conflictos,
obteniendo así una nueva definición. Los refinamientos pueden realizarse de distintas formas. Se
propone analizar entonces cómo estos pasos de refinamiento pueden realizarse a través de un análsis
de las propiedades que cumplen los individuos que intervienen en las observaciones consideradas.
El objetivo es identificar las propiedades que permitan aislar las observaciones que están siendo
cubiertas en forma errónea por la definición actual, y utilizar esta propiedad en el refinamiento de
esta definición.
∗ Parcialmente financiada por el Concejo Nacional de Investigaciones Científicas y Técnicas (CONICET) y
Agencia Nacional de Promoción Científica y Tecnológica (PICT 13096)
† Miembro del IICyT, Institulo de Investigación en Ciencias y Tecnología Informática
Refinamiento a través de propiedades
En la propuesta de aprendizaje a partir de ejemplos en el marco de la plr [Del03] una instancia
del problema del aprendizaje considera, un programa lógico rebatible BC = (Π, ∆), un conjunto de
observaciones O, y un espacio de hipótesis H, a partir de los cuales se debe encontrar un conjunto
de reglas rebatibles S ∈ H, tal que ∀o ∈ O se verifique que el programa (Π, ∆ ∪ S) cubra o.
El conocimiento base, representado por un programa lógico rebatible está formado por un
conjunto de reglas estrictas y un conjunto de reglas rebatibles. Decimos que el conjunto de reglas
cuyas cabezas se forman por el mismo símbolo de predicado definen un concepto. Cada concepto
puede considerarse una propiedad, y si un individuo pertenece a este concepto, decimos que verifica
la propiedad. Se usa el término genérico propiedad para hacer referencia tanto a un atributo de un
individuo (propiedad simple) o a una relación (propiedad derivada) definida en términos de otras
propiedades.
El proceso de aprendizaje procede en dirección top-down. Entonces, dada una instancia particular del problema de aprendizaje, 〈Π,∆,H,O〉, se va generando, a través de sucesivos refinamientos,
una definición del concepto que se desea aprender. En cada momento, la definición actual, se confronta con las observaciones consideradas O y se determinan las observaciones cubiertas en forma
errónea. Esto es, Oc = {o ∈ O: (Π, ∆∪C) garantiza o }, donde o es el complemento del literal o.
La propuesta es analizar las propiedades disponibles y seleccionar una propiedad para realizar
un paso de refinamiento. Este paso de refinamiento tendrá como objetivo separar las observaciones
mal cubiertas de aquellas que son cubiertas en forma correcta por la definición actual. Por ejemplo,
dado la instancia 〈Π, ∆,H,O〉, con:
Π = { p(e)., p(f).,q(a).,q(e).,q(f).,r(e).,t(f).}
∆ = { s(X) —≺ r(X)., s(X) —≺ t(X).}
O= { b(a).,∼ b(e)., ∼ b(f)}
si la definición actual es {b(X) —≺ .}, las observaciones cubiertas correctamente son Ook={b(a)},
mientras que las observaciones cubiertas en forma errónea son Oc={∼ b(e), ∼ b(f)}.
Analizando las propiedades, se observa que las propiedade “p” y “s” se verifican para las
observaciones en Oc, y no se verifican para las observaciones en Ook. Por lo tanto, cualquiera
de estas propiedades puede utilizarse para refinar la definición actual. Se puede obtener la nueva
definición { b(X) —≺ ., b(X) —≺ p(X).} utilizando la propiedad “p”, o la definición { b(X) —≺ .,
b(X) —≺ s(X).} si se utiliza la propiedad “s”. Decimos que “p” es una propiedad simple y que “s” es
una propiedad derivada. Inicialmente se prefieren, para realizar los refinamientos, las propiedades
simples antes que las propiedades derivadas. Obviamente no siempre será posible, pero en caso
de serlo, preferimos las propiedades simples porque estas brindan información más específica de
los individuos involucrados. Si una propiedad simple permite aislar las observaciones cubiertas en
forma errónea de aquellas que están siendo cubiertas correctamente, es de esperar que ésta sea
una propiedad relevante en la definición del concepto que se desea aprender.
Es necesario valorar el aporte que puede hacer cada propiedad al momento de realizar un paso
de refinamiento. El objetivo principal en la búsqueda de la definición del concepto en cuestión, es
cubrir correctamente todo el conjunto de observaciones por medio de refinamientos sucesivos y a
través del análisis y la utilización de propiedades.
En este contexto, existen diferentes situaciones que pueden surgir. Es posible que sólo una
propiedad sea la que permita aislar completamente las observaciones cubiertas erróneamente, de
aquellas que están correctamente cubiertas. En este caso, dicha propiedad puede utilizarse sin
problemas en el paso de refinamiento. Por otro lado, existen situaciones, como en el ejemplo anterior, en las cuales más de una propiedad permite alcanzar el aislamiento buscado. En estos casos,
es necesario definir un criterio de selección para determinar cuál es la propiedad más adecuada.
Se considera que dicho criterio debiera explotar la noción de especificidad pues, como ya se dijo,
es de esperar que una propiedad más específica permita modelar mejor el concepto que es objeto
de aprendizaje. Otros casos a analizar, son aquellos en los cuales no existe ninguna propiedad, ni
simple ni derivada, que permita aislar existosamente todas las observaciones mal cubiertas. En
estos casos, es necesario definir un criterio que valore para cada propiedad considerada, en qué
medida esta resuelve los conflitos presentados. Una primera aproximación podría valorar cada
refinamiento obtenido (por cada una de las propiedades consideradas) considerando qué proporción de los conflictos existentes se resuelven. En cada instante, la definición actual determina el
conjunto de observaciones mal cubiertas, Oc. En el mejor de los casos un paso de refinamiento
obtiene una nueva definición para la cual el conjunto Oc es vacío. Si esto no puede lograrse, es de
esperarse que, al menos, el nuevo conjunto de observaciones mal cubiertas sea más pequeño que
el anterior.
Lo expuesto anteriormente sola hace mención a la interacción de refinamientos y observaciones
mal cubiertas. No obstante, hay que mencionar que un refinamiento arbitrario puede afectar
las observaciones que ya son cubiertas en forma correcta. Por esa razón, se habla de aislar las
observaciones cubiertas correctamente de aquellas cubiertas en forma errónea. Esto es, cada
refinamiento debiera realizarse teniendo en cuenta no solo el conjunto Oc sino también el conjunto
Ook.
Conclusiones y trabajo en curso
El desarrollo de aprendizaje en el marco de la plr brinda las ventajas de flexibilidad de representación, propias de los formalismos de razonamiento no-monótono. La no monotonía permite
considerar el aprendizaje de conceptos como un proceso incremental de refinamientos sucesivos.
El proceso de aprendizaje puede ser retomado ante la disponibilidad de nuevas observaciones,
como una continuación de los procesos de aprendizaje anteriores. En este sentido, como cada
definición está formada por un conjunto de reglas rebatibles, todas estas reglas interactúan entre sí y al momento de realizar un paso de refinamiento se necesita analizar cuidadosamente las
consecuencias que este acarrea. En caso de ser posible, sería conveniente que los refinamientos
aplicados sean seleccionados de forma tal que sus consecuencias sean limitadas solo a a efectos
deseados. Por ejemplo, un refinamiento que elimina todos los conflictos presentes. Por esa razón
se está estudiando qué criterios pueden utilizarse para obtener refinamientos adecuados en cada
paso. Existe una gran variedad de propuestas, dentro de la Programación en Lógica Inductiva
[NCd97, LD94, Bra90], que abordan el problema del aprendizaje incremental de conceptos en un
esquema top-down y que podrían adaptarse al problema del aprendizaje de conceptos en el marco
de la plr.
