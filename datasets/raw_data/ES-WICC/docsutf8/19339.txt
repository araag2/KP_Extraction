Métodos de evaluación de usabilidad una propuesta de aplicación en Objetos de Aprendizaje
﻿
En este trabajo se presenta un modelo
de evaluación de Objetos de Aprendizaje (OA) desde la perspectiva de la Interacción Persona - Ordenador (IPO).
En ocasiones un OA puede cumplir con
estándares para el e-learning y posibilitar así su interoperabilidad, pero su diseño no atiende a objetivos educativos
específicos inmersos en un contexto de
aprendizaje. Con esta perspectiva, la
calidad toma un sentido que va más allá
de lo tecnológico y abarca otros aspectos como los pedagógicos. Es necesario
pues, generar un proceso para evaluar
los OAs en diversos momentos del
desarrollo a través de diferentes criterios, instrumentos y estrategias de evaluación, indicando además quiénes deben participar en esta tarea.
En cada uno de las etapas de desarrollo
se seleccionó una combinación de diferentes métodos de evaluación de usabilidad  adaptados a este tipo de producto
de software.
Las conclusiones y mejoras implementadas en el diseño del OA podrán orientar a los docentes en la selección de estos recursos de acuerdo a los objetivos
de aprendizaje y el contexto de aplicación.
Palabras clave: Objeto de aprendizaje,
evaluación, usabilidad.
Contexto
La investigación descripta en este trabajo es un avance de una tesis doctoral en
Informática de la UNLP y se desarrolla
en el marco del proyecto de investigación “Ambientes virtuales de aprendizaje para la enseñanza de la Ingeniería”
perteneciente al Departamento de Matemática de la Facultad de Ingeniería de
la Universidad Nacional de Mar del Plata (UNMDP).
Introducción
Existen numerosas definiciones de los
Objetos de Aprendizaje (OA) que han
generado diversas controversias en el
campo. En este trabajo, la siguiente:
“la mínima estructura independiente
que contiene un objetivo, una actividad de aprendizaje, un metadato y
un mecanismo de evaluación, el cual
puede ser desarrollado con tecnologías de infocomunicación (TIC) de
manera de posibilitar su reutilización, interoperabilidad, accesibilidad
y duración en el tiempo” [1]
Dicha definición aporta el marco conceptual para el desarrollo y evolución de
los OAs.
La discusión acerca de la calidad de los
OAs también ha tenido diversos enfoques a lo largo del tiempo. Encontramos
que la mayoría de la investigaciones
hasta 2005 se focaliza principalmente
en discusiones acerca de la “calidad del
metadato” relacionado a la concepción
y definición técnica inicial de los OA.
Coincidimos con [2] en que el proceso
de aseguramiento de la calidad debería
estar compuesto por tres niveles y concepciones: en el proceso mismo del
desarrollo (software), mediante la valoración por comunidades profesionales
WICC 2012 922
2012 XIV Workshop de Investigadores en Ciencias de la Computación
(multidisciplinar) y finalmente, la valoración de los usuarios finales (pertinencia y posibilidades reales de uso).
En síntesis y de acuerdo con [3], los
OA deberían diseñarse también considerando los conceptos y metodologías
propios de la Interacción PersonaOrdenador (IPO),  a partir de un mayor
grado de  implicación de todos los actores de los procesos de enseñanza y
aprendizaje.  Se basa en un Proceso de
Diseño Centrado en el Usuario (DCU).
Si pensamos en los OAs como recursos
digitales que se diseñan mediante editores de páginas Web, se podrían rescatar
criterios de evaluación de calidad de
sitios Web en donde el concepto de
usabilidad juega un papel importante. Si
pensamos en los OAs como recursos
pedagógicos, los criterios de evaluación
de calidad deben referirse al destinatario, al contenido y los objetivos específicos entre otros aspectos.
Conciliando ambos criterios y extendiendo el concepto introducido por [4],
denominamos “usabilidad  pedagógica” a la facilidad de aprendizaje, eficiencia de uso pedagógico y la satisfacción con las que las personas son capaces de realizar sus tareas gracias al uso
del producto con el que está  interactuando. Entendemos eficiencia de uso
pedagógico como la capacidad de propiciar aprendizajes significativos mediante interacciones generadas en la
Zona de Desarrollo Próximo (ZDP).
Desde esa perspectiva, tomamos la expresión acuñada por [5], “amplificadores de la mente” para hacer referencia al
software  diseñado bajo los parámetros
de usabilidad ya que en palabras de [6]:
“La fuerza del potencial cognitivo radica en que la usabilidad exige que los
sistemas se adapten a los usuarios y no
a la inversa” y en el caso de los OA estos usuarios son estudiantes y consecuentemente tienen un objetivo principal y concreto: aprender.
Existen una amplia variedad de métodos
de evaluación de usabilidad que utilizan
diferentes medios y técnicas e intentan
medir diferentes aspectos. Básicamente
pueden agruparse en tres categorías:
inspección, indagación y test :  Veremos
en este apartado los métodos más destacados de cada una de ellas:
a) Métodos de inspección: los expertos
evaluadores  examinan aspectos de la
interfaz del sistema relacionados con la
usabilidad y la accesibilidad que la
misma ofrece a sus usuarios.
 Evaluación Heurística: El método fue
desarrollado por Nielsen ([7]), y Molich ([8]) y consiste en analizar la conformidad de la interfaz con unos principios reconocidos de usabilidad (heurísticos).
 Recorrido Cognitivo: Los evaluadores
construyen los escenarios de tarea y
después asumen el rol del usuario trabajando con esa interfaz ([9],[10])
 Inspección de características: el objetivo averiguar si las características de
un producto satisfacen las necesidades
y exigencias del usuario ([11]).
 Inspección de estándares: inspección
exhaustiva de la interfaz para comprobar que cumple con el estándar establecido ([12]).
b) Indagación: permiten descubrir y
aprender para generar ideas de diseño,
especialmente para obtener información
de usabilidad sobre un producto que se
desea producir. ([11]).
 Indagación contextual: su objetivo es
comprender cómo los usuarios de los
sistemas interactivos realizan sus tareas y las acciones que efectúan ([4]).
 Focus Group: en una reunión de 6 a 9
implicados se discuten aspectos relacionados con el sistema. Un  experto
en usabilidad realiza la función de
moderador.
 Entrevistas. : pueden ser efectivas para una evaluación profunda, para descubrir, motivaciones, valores y experiencias de los usuarios ([13]).
 Cuestionarios: lista de cuestiones
planteadas con el objetivo de rescatar
WICC 2012 923
2012 XIV Workshop de Investigadores en Ciencias de la Computación
la información relativa a la interacción
de los usuarios con el sistema y la
percepción subjetiva de estos sobre la
experiencia de su manejo ([11]).
 Grabación del uso: Se basa en "grabar" o "recoger" (por sistema) todas
las actividades realizadas por el usuario con el sistema para su posterior
análisis ([14]).
c) Test: usuarios representativos trabajan en tareas concretas utilizando el sistema (o el prototipo) y los evaluadores
toman los resultados para analizar cómo
la interfaz de usuario da soporte a los
usuarios con sus tareas.
Medida de las prestaciones: está basado en la toma de medidas objetivas
(rendimiento) u otro tipo de aspecto
subjetivo que afecte a la usabilidad del
sistema.([15]).
 Pensando en voz alta : se solicita al
usuario que exprese verbalmente  qué
está pensando, qué no entiende, por
qué lleva a cabo una acción o duda
mientras que interacciona con el sistema ([4]).
 Eye-tracking: permite documentar los
puntos del sistema que ha estado mirando el usuario en cada momento
([16]).
El OA, como recurso digital, establece
metas pedagógicas y en este sentido
consideramos  su evaluación desde ambos aspectos.
Si ampliamos el concepto de usabilidad
al campo de la valoración de los OAs
podríamos utilizar métodos de evaluación de usabilidad de productos de
software considerando criterios que involucren dimensiones pedagógicas. Autores como [17], [3], [18], entre otros,
recomiendan aplicar estos métodos.
En cuanto al momento de la evaluación
de la usabilidad, [19] y [20], sostienen
que la usabilidad debería ser considerada desde el mismo comienzo hasta las
últimas acciones antes de librar el sistema a sus destinatarios.
En este sentido, apuntamos a realizar
una evaluación formativa del OA, que
consiste,  “en la realización de pruebas
con usuarios con el objetivo de aprender sobre el diseño para mejorar la
nueva iteración” ([21]).
En relación a los métodos de evaluación, [11], [22], [23], [24] y [16], destacan que los  métodos cuantitativos pueden enriquecerse con las expresiones de
los usuarios durante la interacción con
el sistema registrando y resumiendo
cualitativamente conceptos como satisfacción o los problemas generales de
usabilidad.  Es decir, desde una visión
ecléctica de la evaluación, concluimos
en utilizar una confluencia de métodos
para realizar la evaluación del OA.
Líneas de Investigación
 Objetos de aprendizaje. Parámetros
de Calidad de los OA a partir de la
elaboración de criterios de valoración
de acuerdo a las funcionalidades, los
estándares y el contexto educativo de
implementación.
 Análisis de diferentes repositorios de
OA a fin de identificar los puntos críticos de implementación de propuestas
educativas que incorporen  OA.
 Evaluación comparativa de OA de
Matemática y Algorítmica enfocado al
diseño pedagógico, funcional, gráfico,
tecnológico y operacional.
 Metodologías de desarrollo de OA
transferibles a un EVEA (Entorno virtual de enseñanza aprendizaje).
Resultados Obtenidos
En base a lo expresado en la Introducción se propone el  plan de evaluación
de un OA considerando que el proceso
consiste en iterar hasta que los objetivos
se cumplan. Ejemplos de la ejecución
de este plan se encuentran en [25] y
[26].
Fase 1: Elicitación y Especificación de
requerimientos
 Indagación contextual: especificar y
entender los objetivos del proceso de
WICC 2012 924
2012 XIV Workshop de Investigadores en Ciencias de la Computación
enseñanza y aprendizaje  a través de la
observación de las tareas actuales de
los estudiantes y profesores.
 Focus Group con implicados: rescatar e interpretar reacciones subjetivas
acerca de las suposiciones que ayudarán a entender su entorno y cómo tratan de resolver sus problemas.
 Cuestionarios administrados a estudiantes con el objeto de conocer sus
hábitos de interacción y acceso a Internet y su  percepción en cuanto al
propio aprendizaje.
Fase 2: Diseño
Sesiones de evaluación con un prototipo
en papel, luego con una maqueta digital
y finalizando con un prototipo de software con las funcionalidades básicas del
OA.
 Recorrido Cognitivo: a fin de evaluar
en el diseño su facilidad de aprendizaje (usabilidad pedagógica)
 Pensamiento en voz alta: para capturar aspectos relacionados con las actividades cognitivas de los usuarios potenciales (los estudiantes) del sistema
evaluado.
Fase 3: Implementación
 Evaluación de los atributos del OA.
Inspección de características y de estándares. Determinar si un  elemento
digital puede ser considerado un OA
realizando una inspección para comprobar compatibilidad con los estándares y otros requisitos. Se utilizan los
principios de diseño de un OA de
[27], como guía y orientación para la
inspección.
 Evaluación heurística, observación
del experto y Recorrido Cognitivo.
A los evaluadores se le presentan varios escenarios de tareas con el objeto
de facilitarle la inspección y que pueda completar el informe de la evaluación a partir de una planilla denominada GEHOA (Guía de Evaluación
Heurística para Objetos de Aprendizaje) que contiene una colección de heurísticos con criterios pedagógicos y
tecnológicos [25]. Los expertos son
observados durante la ejecución de
cada tarea para ver cómo utilizaban la
interfaz durante su realización.
Fase 4: Lanzamiento
 Cuestionarios : Medición del grado
de satisfacción de los estudiantes al
interactuar con el OA([26])
 Grabación de uso: registro de la interfaz y  estadísticas sobre la frecuencia con la que cada usuario ha utilizado el OA y frecuencia de los diversos
eventos de interés.
 Entrevistas en profundidad a estudiantes seleccionados  a los efectos de
contrastar, comprender y describir información recopilada mediante un
análisis retrospectivo de la acción.
Formación de recursos humanos
Se  encuentran  en  desarrollo tres tesis
de posgrado de la UNLP  en el marco
del proyecto de investigación: dos de la
Maestría en Tecnología Informática
Aplicada y una del Doctorado en Ciencias Informáticas.
Se  realizaron  numerosas  actividades
de  transferencia: gestión y asesoramiento en el uso de la Plataforma Educativa Moodle de la Fac. De Ingeniería
de la UNMDP.
