Normalización de imágenes satelitales en el análisis multi temporal
﻿– En los últimos años la teledetección ha crecido de manera exponencial tanto así como las áreas en 
que pueden utilizarse. Existen numerosas aplicaciones basadas en el análisis de imágenes satelitales que abarcan 
campos científicos muy variados como cartografía, agricultura y forestación, entre los más comunes.  
Una alternativa interesante de aplicación que ha surgido, es la posibilidad de estudiar la evolución a lo largo del 
tiempo de diferentes fenómenos utilizando una secuencia de imágenes. Debido a que la disponibilidad de imágenes 
no es amplia surge la necesidad de utilizar imágenes obtenidas por diferentes sensores. Ya que cada sistema sensor 
posee características diferentes, las imágenes resultantes tienen también diferentes características. Es por esto que 
surge la necesidad de normalizar la secuencia de imágenes de manera que éstas puedan ser comparables.  
Este trabajo presenta una alternativa de normalización de imágenes satelitales que analiza todos los parámetros que 
definen a cada una de las imágenes utilizadas en el estudio. Esta tarea de normalización es imprescindible a la hora de 
intentar estudiar cualquier tipo de fenómeno utilizando imágenes obtenidas por diferentes sensores.  
 
Palabras clave - Teledetección, Resolución, Análisis Multi-Temporal, Normalización 
 
1.- Introducción 
Se denomina resolución de un sistema de captación de imágenes a la capacidad de éste 
para discriminar información de detalle de los objetos contenidos en la misma [1]. El 
concepto de resolución aplicado a los instrumentos ópticos tradicionales se refiere 
fundamentalmente al poder de separación espacial del sistema. Cuando se utilizan 
sensores remotos a bordo de satélites, el estudio de una cubierta introduce nuevas 
dimensiones, además de las planimétricas. La variable altimétrica en determinados 
casos puede considerarse despreciable, pero sin embargo aparecen, por un lado, la 
variable espectral, al poder ser adquirida la imagen en varias bandas del espectro 
electromagnético, y por otro, la variable temporal, al ser posible el estudio 
multitemporal de una escena, en virtud de la periodicidad del paso del satélite por el 
lugar de estudio. En teledetección se emplea el mismo término resolución, pero como 
una extensión del concepto anterior. Así pues se habla de resolución espacial, espectral, 
radiométrica y temporal [2], [3]. 
En la actualidad muchas  aplicaciones visuales requieren imágenes con altos valores en 
su resolución de manera de facilitar una adecuada interpretación de los datos 
almacenados en las mismas. 
Si se desea realizar algún análisis de la evolución de cierto fenómeno a lo largo del 
tiempo es necesario utilizar una secuencia de imágenes que abarquen el período 
deseado. Generalmente, debido a la escasa disponibilidad, es necesario recopilar 
imágenes provenientes de diferentes sensores. Como es sabido cada sensor posee 
características y dispositivos diferentes que definen la resolución de éste en todas sus 
dimensiones, de manera que las imágenes resultantes también tienen resoluciones 
diferentes de las otras.  
Esto hace necesario realizar algunas operaciones previas al análisis, ya que se deben 
compatibilizar todas las imágenes de la secuencia de manera que éstas puedan ser 
comparables entre si.  
Este trabajo presenta alternativas para el estudio y la normalización de los valores de las 
diferentes resoluciones con el fin específico de permitir un facilitar el análisis 
comparativo de diferentes imágenes satelitales, obtenidas por los mismos o diferentes 
sensores, a lo largo del tiempo. Esta normalización implica un análisis minucioso de 
cada variable, intentando en toda circunstancia lograr una mejora en los valores de cada 
uno de estos parámetros. 
 
2.- Resolución de un sistema sensor 
La definición de los valores de cada una de las resoluciones  depende fundamentalmente 
del objetivo para el cual el sensor fue construido, la capacidad de transmisión y 
almacenamiento de información a estaciones receptoras. A continuación se  definen 
cada una de estas resoluciones. 
 
2.1.- Resolución Espacial 
Se llama resolución espacial a la capacidad del sistema para distinguir el objeto más 
pequeño posible en una imagen. Esta acepción del término coincide con su formulación 
tradicional, tal como se aplica a sistemas analógicos. La resolución espacial de los 
satélites óptico-electrónicos depende de la altura orbital, de la velocidad de exploración 
y del número y la miniaturización de los detectores entre otras características. La 
resolución espacial de los sensores actualmente en explotación varía de acuerdo al 
objetivo específico de cada uno; existen sensores con resoluciones por debajo del metro 
mientras que hay otros que oscilan alrededor de los 11000m. 
 
2.2.- Resolución Espectral 
Se denomina resolución espectral a la capacidad del sensor para discriminar la radiancia 
detectada en distintas longitudes de onda del espectro electromagnético. La resolución 
espectral está determinada por el número de bandas que el sensor puede captar y por la 
anchura espectral de éstas. 
En términos generales, el sensor será de mayor utilidad cuanto mayor sea el número de 
bandas que proporcione, ya que algunas cubiertas requieren estudios multiespectrales. 
Por otro lado, conviene que el ancho de cada banda sea lo más reducida posible, con el 
objeto de no obtener valores medios de regiones espectrales de diferentes significación 
física. Algunos sensores discriminan el espectro en 3 bandas mientras que los hiperespectrales oscilan alrededor del centenar. 
 
2.3.- Resolución Radiométrica 
La resolución radiométrica es la capacidad del sensor para discriminar niveles o 
intensidades de radiancia espectral. En los sistemas analógicos como la fotografía, la 
resolución radiométrica viene determinada por el número de niveles de gris que pueden 
obtenerse. En los sistemas óptico-electrónicos, la radiancia incidente en el sensor es 
registrada matricialmente por un arreglo de celdas, cada una de las cuales reporta un 
nivel digital (ND) proporcional a la cantidad de energía electromagnética recibida. Este 
dato es obtenido por un convertidor analógico-digital incorporado en la plataforma. 
Existen sensores que diferencian 128 niveles mientras que otros alcanzan los 1024 
niveles diferentes. 
 
2.4.- Resolución Temporal 
Se denomina resolución temporal a la capacidad del sistema para discriminar los 
cambios temporales sufridos por la superficie en estudio. Este concepto hace referencia 
a la periodicidad con que el sensor puede adquirir una nueva imagen del mismo punto 
de la superficie terrestre. En la mayoría de los satélites, la periodicidad de paso por un 
lugar depende solamente de dos factores: la altura de la órbita, de la que depende la 
velocidad del satélite, y el ángulo de abertura de la observación.  
 
3.- Métodos Propuestos  
Habitualmente para poder estudiar la evolución o analizar los cambios de las superficies 
a lo largo del tiempo utilizando imágenes satelitales diferentes o adquiridas por 
diferentes sensores, es necesario en la mayoría de los casos, realizar correcciones o 
adaptaciones respecto de algún tipo de resolución de forma de adecuar las imágenes a 
una forma normal y común.  
Las imágenes una vez recibidas por las estaciones terrenas sufren una serie de 
correcciones, por un lado correcciones de carácter geométrico y por otro de carácter 
radiométrico debido fundamentalmente a la presencia de la atmósfera. Una vez 
realizadas estas correcciones, las imágenes resultantes quedan disponibles para los 
usuarios finales. 
A continuación se presentan las alternativas propuestas para la normalización de las 
imágenes, analizando y describiendo éstas desde los tres puntos de vista mencionados.  
 
3.1.- Desde el punto de vista  TEMPORAL 
Cuanto mayor sea la resolución temporal de un sensor, se podrá realizar un análisis mas 
detallado en virtud de que existirán muchas imágenes disponibles. En casos que la 
resolución temporal no se suficiente para cubrir las necesidades existe la posibilidad de 
completar el periodo de estudio con imágenes provenientes de otros sensores cubriendo 
aquellos momentos en que un sensor no este disponible. 
Una imagen satelital mayormente esta separada de la próxima en por lo menos varios 
días. El transcurso del tiempo trae aparejado algunos inconvenientes, principalmente el 
cambio en las condiciones de iluminación.  
La iluminación promedio de una imagen satelital integrante de una secuencia temporal 
de imágenes de un lugar específico de la Tierra, difiere notoriamente de las 
correspondientes iluminaciones promedio de otras imágenes de la misma secuencia; 
esto es debido a numerosos factores. Indudablemente el más importante es la variación 
del ángulo solar y luego le sigue la variación de la distancia entre la Tierra y el Sol. La 
variación del ángulo solar depende de la época del año, en verano el ángulo de 
elevación solar es mucho mayor que en invierno mientras que en el hemisferio sur la 
distancia Tierra Sol es menor en el verano y mayor en el invierno.  
Para comparar imágenes capturadas en diferentes estaciones del año, ya sean obtenidas 
por el mismo sensor o por sensores diferentes, es necesario entonces independizarse de 
la época del año en la cual fue adquirida cada imagen. Esta normalización  implica una 
corrección de cada valor de energía recibido por el sensor respecto del día del año en la 
que la imagen fue capturada. Estas correcciones son conocidas y se aplican 
normalmente. 
Existen también otros problemas no menores como las condiciones meteorológicas y la 
diafanidad del aire en el momento de la captura. En estos casos se esta estudiando la 
posibilidad de introducir información adicional como datos meteorológicos o de trabajo 
de campo de manera de poder eliminar estos efectos. 
 
3.2.- Desde el punto de vista ESPACIAL 
En las últimas décadas, con el avance de la tecnología, las características de los sensores 
han avanzado permitiendo de esta manera una mejora en la resolución espacial. Desde 
el punto de vista del análisis Multi-Temporal puede ser necesario comparar imágenes de 
varios años y hasta décadas de diferencia, con evidentes diferencias en su resolución 
espacial. En este caso es deseable poder discriminar y detectar objetos más pequeños 
que los que el sensor puede capturar, o al menos lograr aproximar la resolución de las 
imágenes con menor resolución espacial a las imágenes de mayor resolución, de forma 
de facilitar el estudio de diversos fenómenos como humedad en el suelo, enfermedades 
de cultivos, estimación de cosechas, superficie inundada, etc.  
Existe una técnica de mejoramiento de imágenes conocida como Súper-Resolución y se 
basa en aprovechar la información no redundante presente en una secuencia de 
imágenes. Idealmente cada imagen debe diferir respecto de las otras en un simple vector 
desplazamiento. El vector desplazamiento no puede ser cualquiera, pues si hay 
correspondencia entre la secuencia de baja resolución en unidades enteras de píxeles, 
entonces ambas imágenes contendrán casi la misma información, solamente que 
desplazada, con lo cual no existe nueva información que permita construir una imagen 
de mayor resolución con este método. Pero, si las imágenes tienen desplazamientos a 
nivel sub-píxel entre ellas, entonces existe información adicional y se puede mejorar la 
resolución espacial [4]-[9].  
Esta técnica ya ha sido extendida y aplicada con éxito a imágenes satelitales [9],[10] 
permitiendo de manera relativamente sencilla mejorar la resolución espacial en una 
secuencia de imágenes satelitales.  
Este trabajo ya esta hecho y probado, en algunos casos se podrá mejorar la resolución de 
todas las imágenes mientras que en otros sólo se podrán mejorar algunas dependiendo 
de la disponibilidad de éstas.   
 
3.3.- Desde el punto de vista RADIOMETRICO 
Entre el sol y la superficie terrestre; y entre la superficie terrestre y el sensor se 
interpone la atmósfera, que interfiere de formas diversas con el flujo radiante captado 
por los sensores. Los principales fenómenos físicos que se producen por la interposición 
son la absorción y la dispersión. Esto lleva consigo una necesidad de realizar 
correcciones a los valores de energía recibidos. Se entiende por esta corrección a 
cualquier proceso que conduce a la restauración de los valores de radiancias obtenidas 
para una imagen de manera de acercarlos a los valores que hubieran tenido en 
condiciones de recepción ideales y ausencia del efecto atmosférico. Ante esta situación 
surge la necesidad de normalizar la energía, es decir llevar todos los valores de energía a 
una escala “normal y común” a la secuencia de imágenes a utilizar.  
Una de las formas de expresar esta normalización es utilizar en vez de valores de 
energía reflejada los valores de reflectividad de superficies. 
La reflectividad es la relación entre el flujo incidente y el reflejado por una superficie 
terrestre, precisamente es el porcentaje de radiación incidente que es reflejada por la 
superficie [2]. La reflectividad es una característica del objeto observado, aunque puede 
variar con el ángulo de observación, pero no depende del sistema de observación, por lo 
tanto, es la magnitud ideal para comparar imágenes Multi-Temporales o multi-sistema.  
Una vez estimados los valores de reflectividad se puede utilizar información adicional 
como valores de reflectividad obtenidos en trabajo de campo o teóricos conocidos de 
manera de corregir los valores calculados.  
  
3.4.- Desde el punto de vista ESPECTRAL 
Cada banda esta defina en una porción del espectro electromagnético, dicha porción 
depende directamente de las características de los detectores a bordo del sensor.  
Si se desea comparar imágenes adquiridas por sensores diferentes será necesario, 
siempre que sea posible, compatibilizar las bandas. 
Hacer compatible una banda de una imagen proveniente de un sensor con otra banda de 
una imagen proveniente de otro no es tarea sencilla. El valor captado por cada detector 
corresponde a la cantidad total de energía recibida para el intervalo de longitud de onda 
que lo define, con lo cual será necesario diferenciar que porción de la energía total 
recibida corresponde a un subintervalo de longitud de onda de la banda.  
Esta tarea no es nada sencilla y se están realizando pruebas para diferenciar por 
ejemplo: la banda pancromática de imágenes Landsat 7 con la proporción  
correspondiente a las bandas  infrarroja, roja y verde. Siempre que se hagan estas 
estimaciones deberá indicarse el porcentaje de error con el que se esta trabajando. 
 
4. Conclusiones y trabajos futuros 
La teledetección conforma actualmente una herramienta muy útil para estudiar la 
evolución de muchos fenómenos, tanto naturales como elaborados por el hombre. 
Realizar un análisis Multi-Temporal no es una tarea sencilla, para poder tener resultados 
certeros es fundamental normalizar cada una de las imágenes utilizando un patrón 
común.  
La normalización de imágenes respecto de la resolución temporal esta relativamente 
bien resuelta utilizando una compensación de la iluminación respecto de la fecha de 
adquisición. 
Para normalizar imágenes respecto de la resolución espacial, se ha desarrollado 
satisfactoriamente un algoritmo que extiende las técnicas de Súper-Resolución de 
manera de incrementar la resolución de una imagen satelital y así poder compararla 
directamente con otra.  
Respecto de la resolución radiométrica, es fundamental utilizar valores de reflectividad 
y no energía  detectada. Por otro lado es fundamental completar estos valores de 
reflectividad con valores de campo reales de manera lograr una correcta interpretación 
independizándose totalmente de los efectos atmosféricos.  
Por último, la normalización desde el punto de vista espectral implica un estudio 
minucioso y un conocimiento detallado de las características de los elementos sensibles 
y analizar de qué manera podría lograrse una normalización de bandas compensando 
entre ellas. Esta tarea todavía no se ha resuelto pero se esperan obtener resultados 
prontamente. 
 
5.-
