Un sistema de visión global para fútbol de robots
﻿
El propósito de este trabajo es describir una de las líneas de investigación del Grupo de
Investigación en Robótica Inteligente, de la Universidad Nacional del Comahue, que tiene
como objetivo el diseño e implementación de un sistema de visión global para fútbol de
robots. El sistema de visión global propuesto implementa mejoras sobre los ya existentes.
1. Introducción
El CAFR[7] es un ambiente pleno de oportunidades para aplicaciones de visión por computadora. Se juega un partido de fútbol con robots y una pelota sobre una cancha. La cancha
consiste de una alfombra de color verde, con líneas blancas que demarcan los límites, áreas y
círculo central.
Es necesario un seguimiento (tracking) de cada objeto en la cancha que requiere precisamente
de un sistema de visión de alto rendimiento.
La pelota es una pelota estándar de golf color naranja, mientras que los robots se ajustan a
las dimensiones especificas de cada categoría. Cualquiera sea la categoría, cada robot se identifica con un sombrero (hat) ubicado en su parte superior. Existen en la actualidad sistemas
de visión global para esta actividad como lo son Doraemon[5] y Ergo[6] En este trabajo presentamos el diseño e implementación de un nuevo sistema de visión con facilidad de uso y de
extender el sistema que lo diferencian de las aplicaciones existentes.
El sistema es abierto lo que lo habilita como plataforma de experimentación y para extenderlo a otras aplicaciones. Fue implementado utilizando la biblioteca OpenCV[3]. Un sistema
de visión a través de una o dos cámaras captura la realidad sobre el campo de juego. En tiempo
real procesa cada imagen para identificar cada objeto, su orientación, y velocidad. Luego envía
esta información por un paquete UDP – broadcast por la red para que cada equipo pueda
procesarla. En base a estos datos cada equipo[4] decide su próximo movimiento, que es enviado
al servidor de comando, quien se encarga de enviar estos comandos a los jugadores en el campo
de juego. De esta manera, cada jugador de cada equipo es controlado.
El sistema de visión cuenta con la posibilidad de realizar ajustes de color, brillo y contraste sobre las imágenes obtenidas desde las cámaras. Como así también corregir propiedades
indeseables de distorsión en las mismas.
La identificación de cada objeto permite el estudio de diferentes técnicas de identificación
y sus combinaciones para lograr dicho cometido.
Este ambiente es útil tanto para profesores como para estudiantes que cursen o estén próximos a iniciarse en la visión por computadoras. Permite estudiar los aspectos teóricos y su
utilidad aplicada en una práctica particular. Este trabajo esta organizado como sigue. En la
siguiente sección se describe la arquitectura de nuestro sistema. En la sección 3 se define cómo
el sistema identifica los elementos y por último en la sección 4 se dan las conclusiones y trabajos
futuros.
2. Arquitectura de un sistema de visión global
Nuestro sistema de visión tiene un estado de configuración, y uno de servidor. El estado
configuración se utiliza para ajustes y parametrización general. Mientras que el estado servidor
se utiliza únicamente para entregar los datos (objetos identificados, su orientación y velocidad)
obtenidos conforme a la configuración establecida en el estado configuración.
El sistema de visión captura imágenes (frames) desde una o dos cámaras ubicadas físicamente sobre la cancha. En caso de requerirse, puede modificarse la calidad de la imagen, tal
como brillo, contraste, gamma, etc.
A fin de corregir la distorsión producida por algunos lentes de cámaras, calculamos los
parámetros internos y externos de la cámara usando el método Tsai[8].
Para la identificación de robots, por cada uno se ajustan filtros de colores con umbrales
mínimos y máximos para aislar cada color y se ajusta la cantidad mínima y máxima del color
requerido. Por lo que deben configurarse tantos filtros de colores con sus respectivas cantidades
como colores posea el modelo del sombrero elegido para representar cada robot. Estos rangos
son necesarios debido a los cambios de luminosidad sensibles a los lentes de las cámaras.
Para la identificación de la pelota, se ajusta un filtro con umbrales mínimos y máximos
para aislar el color naranja de la pelota sobre la imagen capturada. Se toma la región de color
naranja, se ajusta un rango de radio de círculo mínimo y máximo, y también se ajusta un rango
de área mínima y máxima. Si el objeto detectado esta dentro estos rangos, entonces marcamos
la pelota como identificada. Estos rangos de círculos y área son necesarios debido a la velocidad
de desplazamiento a la que puede llegar la pelota en la que pierde su forma original circular
por una más alargada. Lo que esta dado por las limitaciones de frames por segundos que posea
la cámara. Ver figura 1
El sistema dibuja los robots y pelota hallados en cada imagen capturada. Y los robots
también son etiquetados cada uno con un breve nombre.
Una vez analizados e identificados cada objeto en la imagen capturada se conforma un
paquete UDP que es enviado por broadcast por la red para su procesamiento por cada equipo.
3. Identificación, Orientación y Velocidad de Robots
El sistema de visión implementado determina las identidades, orientación, y posiciones de
los objetos en la imagen capturada. Para ello, en cada imagen capturada, primero se aplica
un algoritmo de detección de bordes Canny, ver figura 2 y sobre ésta se aplica un algoritmo
de detección de círculos (transformada circular de Hough). De esta manera obtenemos las
potenciales posiciones de cada robot.
A posterior, es necesario verificar que cada círculo detectado sea realmente un robot válido.
Figura 1: Pelota en movimiento
Figura 2: Detección de bordes
Figura 3: Detección Orientación del Robot
Por cada círculo detectado, en su área se clasifica cada píxel según un rango preestablecido
para cada robot al momento de parametrización y calibración. Este rango se fija con valores
mínimos y máximos en el espacio de colores de tres dimensiones HSV.
Luego de aplicarse un filtro para determinar si un color esta presente, se calcula su histograma a fin de establecer la cantidad de color presente. Si el valor del histograma obtenido
está entre los valores de histograma predefinidos para el color, entonces se continúa con el siguiente filtro. Finalmente, si todos los filtros preestablecidos a un robot se verifican es que se
determina su identidad.
Cuando un robot es identificado se marca para no ser incluido en búsquedas posteriores
sobre la misma imagen capturada.
Una vez que un robot ha sido identificado, se procede a determinar su orientación. Para
ello, se repite el proceso de detección de bordes y luego de círculo pero en esta ocasión sobre el
área del robot identificado. Con la posición central del círculo inicial (robot identificado) y la
posición central del círculo menor (ubicado en el sombrero) es que se determina la orientación
en radianes respecto a la dirección x e y.
Entre las distintas imágenes capturadas (frames), para cada robot identificado con las respectivas posiciones calculamos su velocidad.
4. Conclusiones y Trabajos Futuros
En este trabajo se ha presentado una de las líneas de investigación del Grupo de Investigación
en Robótica Inteligente que tiene como objetivo el diseño, desarrollo e implementación de un
sistema de visión global aplicado a fútbol de robots.
Es importante señalar que nuestro sistema de visión reconoce robots sin un modelo de
sombrero preestablecido, siempre que no se interfiera con la modalidad de como se precisa la
orientación. Solo basta que el modelo seleccionado contenga una codificación lo suficientemente
variada en colores y que sus cantidades identifiquen unívocamente a cada robot.
Como trabajos futuros será necesario determinar un sombrero que se adapte a las reglas
de la liga CAFR como así también de la liga F180. Analizar otras formas de segmentación,
particularmente las propuestas en [2] y en [1].
También será implementado una forma de seguimiento (tracking) que pueda predecir la
siguiente posición de cada objeto. Disminuyendo el área de análisis para identificar cada objeto.
Por otra parte, para el caso de utilizarse dos cámaras se analizará la alternativa de primero
realizar la identificación de robots y pelota individualmente en cada imagen capturada por
cámara. Permitiendo aprovechar procesamiento en paralelo, para luego reunir luego los datos.
Sin embargo se incorpora un problema que son los objetos a identificarse ubicados parcialmente
en cada imagen capturada.
Las líneas de estudios a realizarse pretenden hacer uso mínimo de los recursos computacionales, por lo que se mantendrá un procesamiento acotado por la naturaleza de tiempo real del
dominio de la aplicación.
