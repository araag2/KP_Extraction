Aplicación de interfaces lectoras de bioseñales en un contexto de control remoto de un robot
﻿de control
remoto de un robot.
Jorge Ierache1,, Gustavo Pereira1,.Iris Sattolo1, Alejandro Guerrero1, Juan D’Altto1, Juan Iribarren1
Instituto de Sistemas Inteligentes y Enseñanza Experimental de la Robótica (ISIER)1
ISIER, Facultad de Informática Ciencias de la Comunicación y Técnicas Especiales
Universidad de Morón, Cabildo 134, (B1708JPD) Morón, Buenos Aires, Argentina
54 11 5627 200 int 189
jierache@unimoron.edu.ar
Resumen: Se presenta en este trabajo
la investigación que en la actualidad
se está desarrollando dentro del área
de la comunicación remota de
humanos a robots, sobre la base de
bioseñales cerebrales. Para esta
investigación se aplican tecnologías
e interfases disponibles que facilitan
la lectura de las señales del cerebro
del usuario y su asociación a
comandos explícitos. Nuestro trabajo
explora una solución de ingeniería,
aplicando las bases tecnológicas y, el
desarrollo de un framework de
comunicación y control del robot.
Key words: Robots, Brain Machine Interface,
Bio-Electrical Signal, Human Machine
Interfaces.
1. Contexto de la Investigación
En la actualidad se trabaja en el control
remoto de robots a través de la adaptación de
Brain-Machine Interfase (BMI). Nuestras
líneas de trabajo se enfocan en la
experimentación de soluciones de integración
para el control de robots por bioseñales.
Este proyecto se encuentra financiado por la
Facultad de Informática, Ciencias de la
Comunicación y Técnicas Especiales de la
Universidad de Morón. A su vez propicia la
formación de recursos, con la participación de
estudiantes de grado y posgrado para la
continuación de las líneas de investigación
relacionadas.
La aplicación de bioseñales para el control de
sistemas, robots, aplicaciones, juegos y otros
dispositivos, presenta un enfoque novedoso al
abrir las puertas para la interacción entre
humanos y computadoras en una nueva
dimensión, donde se explotan específicamente
biopotenciales eléctricos registrados en el
usuario, a través de: el electro-miograma, el
electro-encefalograma y el electrooculograma, que son bioseñales eléctricas
generadas por los patrones de actividad de los
músculos, el celebro y los ojos del usuario.
2. Introducción.
La idea de mover robots o facilitar la
aplicación de dispositivos para discapacitados
sin aplicar controles manuales y alcanzar el
control sólo a través de la actividad mental,
fascinó a los investigadores. En este orden, se
presentaron diversos trabajos: los primeros,
recurrieron a implantar electrodos
intracraneales en la corteza motora de
primates [1], [2]. Los trabajos no invasivos
para humanos recurrieron a señales de
WICC 2012 812
2012 XIV Workshop de Investigadores en Ciencias de la Computación
Electroencefalogramas (EEG), aplicados a
ejercicios de comandos mentales, como
mover el cursor de una computadora [3], [4]
basados en el empleo de Brain-Machine
Interface (BMI). Millan et. al. [5] demuestra
como dos personas pueden mover un robot
usando un simple electroencefalograma, sobre
la base de reconocer tres estados mentales, los
que se asocian a comandos del robot. Los
trabajos de Saulnier et. al. [6] se enfocaron en
controlar la velocidad de un robot y extender
su aplicación para inferir el nivel de stress del
usuario, y a partir de éste influir en el
comportamiento social de robots domésticos,
en este caso una aspiradora robot.
El trabajo seminal de Millan et. al. [5],
emplea como única bioseñal el electroencefalograma, sobre la base del trabajo de
dos personas para apoyar la navegación de un
robot, a diferencia de éste, nuestro trabajo
presenta el resultado preliminar empleando un
BMI de bajo costo, utilizado en trabajos
secundarios como el de Saulnier et. al. [6],
que incluye las bioseñales correspondientes al
electro-encefalograma, electro-oculograma y
electromiograma.
A diferencia del trabajo de Saulnier et. al. [6],
que implementa un control de velocidad sobre
la base del electromiograma e infiere el estado
de stress del usuario a través del
electroencefalograma, nuestro trabajo se
enfoca en la ejecución de un patrón de
navegación por parte de un robot. Confronta
los tiempos de ejecución del control manual y
del control mental durante el inicio de la
curva de aprendizaje de un usuario, con
resultados que demuestran que el control
mental requiere, en términos generales, el
doble de tiempo que el control manual para la
ejecución de un mismo patrón de navegación.
Podemos afirmar que nuestro trabajo presenta
según el contexto descrito, una mejora en los
tiempos de control mental, superando
ligeramente al manual, en las pruebas de
ejecución del mismo patrón de navegación, la
que denominamos control mental con auto
foco [7], [8], [9], [10].
Se empleo un simple robot móvil sobre la
base de un Lego NXT [11] y el BMI  NIA
[12].
3 Líneas de Investigación y
Desarrollo
Las líneas de trabajo se orientan al control
remoto de robots a través de la adaptación de
Brain-Machine Interfase (BMI), se enfocan en
la experimentación de soluciones de
integración para el control de robots por
bioseñales.
Actualmente nos encontramos trabajando
en:
[a] En la comunicación de alto nivel con el
BMI de EMOTIV [15], (Figura Nº 1)
Figura Nº 1 “BMI Emotiv”
[b] integración del control  de un  usuario
remoto con un BMI a través de Internet con la
incorporación de video en el framework de
control .
En el marco de futuras líneas de
investigación se experimentara la aplicación
de un nuevo BMI: EMOTIV con el que se
implementaran mayores prestaciones de
control extendidas tanto a robots como
dispositivos remotos de control infrarrojo
(Aire Acondicionado, TV, entre otros
dispositivos., que se integraran al framework
de control facilitando a personas
discapacitadas el control, al igual que la
interacción y control  de estos usuarios con
dispositivos ubicados en sitio remotos.
WICC 2012 813
2012 XIV Workshop de Investigadores en Ciencias de la Computación
4. Objetivos  y Resultados
Nuestro objetivo inicial fue explorar una
solución de ingeniería que nos permitiera
alcanzar una integración remota vía Internet
entre un Brain-Machine Interface (BMI) y un
ubicado en una localización remota robot.
.
Para mantener la premisa de que el control
mental pueda ser usado por un usuario sin
experiencia en controles BMI se plantearon
dos comandos: uno que permitiese controlar
la selección de comportamientos y otro, la
ejecución de los mismos sobre la base de sus
propios controladores (por ejemplo moverse
hacia adelante o girar a la derecha).
Se estableció una arquitectura experimental
que contempla dos vías de comunicación, la
primera vía la denominamos vía de
comunicación de alto nivel ó “usuariocomputadora”. Esta vía, al igual que en las
investigaciones previas se instrumentó con un
BMI de bajo costo OCZ NIA, de empleo
experimental en video juegos (Figura 2), que
permitió la asociación de patrones de señales
mentales con el teclado de la computadora.
Figura Nº  2  BMI-Banda NIA
Sobre estas facilidades determinamos un
perfil simple para el manejo del robot, que
asocia y caracteriza en primer lugar, el control
para la ejecución del comando mental sobre la
base de la detección de señales musculares, en
nuestro caso a través de un leve movimiento
de los párpados. En segundo lugar la
selección de los comandos de alto nivel del
robot, en este caso se trabajó sobre la base de
las ondas cerebrales Alfa. Este tipo de
bioseñales no aseguraron un adecuado control
al usuario en los desplazamientos, a través de
un panel ú de selección de comandos del
framework de control del robot. Frente a esta
razón se implementó en el framework la
opción de aplicación de auto foco [7], [8], [9],
para el modo control mental, a fin de mejorar
el gobierno del usuario en el proceso de
selección de comandos.
La segunda vía de comunicación,
denominada vía de comunicación de bajo
nivel “computadora–robot”. Se efectuó a
través de comunicación en Bluetooth la cual
es nativa en el kit del robot Lego NXT y para
la cual hay una gran cantidad de librerías
disponibles para su comunicación con una
computadora.
Por último, ambas vías de comunicación
fueron implementadas mediante un servicio
web el cual recibe los comandos del cliente
remoto y los transfiere vía HTTP, utilizando
el protocolo de comunicación SOAP,
conectando a  una capa que controla la
conexión bluetooth del Lego NXT [13], y sus
primitivas de movimiento. Esta capa fue
implementada por medio de las librerías
AForce [14], que facilitan el dominio de un
robot NXT con el Framework .NET de
Microsoft. Se presentan muestra en la Figura
Nº 3 la arquitectura conceptual implementada
para  alcanzar la integración entre el BMI del
usuario que efectúan el control de un  robot
ubicado en un sitio remoto
Fig.3. Integración de BMI-NIA y Robot ubicado en un sitio
remoto
El siguiente paso de la investigación fue
desarrollar un sistema de control remoto de la
interfase que permita manejar un robot en un
WICC 2012 814
2012 XIV Workshop de Investigadores en Ciencias de la Computación
sitio distante por medio de una conexión a
internet.
Para llegar a este cometido se desarrolló una
arquitectura por medio de un web service el
cual recibe los comandos de las primitivas de
conexión y de movimiento y los envía a un
robot NXT por medio de una interface
bluetooth que corre desde una computadora
remota con bluetooth. Tomando como base
para el desarrollo del framework de control, la
interface diseñada anteriormente [7] [8], [9]
para las pruebas con BMI-NIA.
En el servidor remoto se encuentra el web
service, el cual recibe los comandos del
cliente y los traduce a las instrucciones para el
NXT. Se eligió implementar un web service
para tener una conexión segura, con un
protocolo conocido de comunicaciones y
porque permite que se desarrolle el cliente en
varios lenguajes de programación y para
múltiples plataformas. Para la prueba del web
service se incorporó un frontend que permite
ver las tramas recibidas, ejecutadas por el
NXT  y los datos de conexión.
La visualización de los movimientos del
robot en el sitio remoto se efectuaron
inicialmente mediante un cliente de video
llamadas estándar.
La razón por la que no se implementó la
transmisión de video en el framework de
comunicación, es debido a que de esta manera
se pueden utilizar diversos dispositivos para
transmitir el video, como por ejemplo:
webcams, teléfonos inteligentes, tablets, etc.
5. Formación de Recursos Humanos
Este PID lo integran cuatro investigadores y
dos estudiantes de tesis de grado, orientadas
al control remoto de robots/dispositivos por
Bioseñales con la aplicación de BrainMachine Interface (BMI vía Internet.
6.
