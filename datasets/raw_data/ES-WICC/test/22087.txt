Métricas y escalabilidad de algoritmos paralelos
﻿Introducción 
Métricas y escalabilidad de algoritmos paralelos 
Marcelo Naiouf1, Armando De Giust¡Z, Diego Tarrío3, Laura De Giuste 
(mna iou/, degiusti, dtarrio, ldgiusti}@lidi.info.unlp.edu.ar 
LIDI. Laboratorio de Investigación y Desarrollo en Informática 
Facultad de Informática. UNLP 
50 y 115. 1 er Piso. La Plata 
Resulta innegable la importancia del procesamiento paralelo en el espectro de la Ciencia de la 
Computación. Existen diversas razones para esta realidad: 
- la capacidad de reducir el tiempo de procesamiento en problemas de cómputo intensivo o de grandes 
volúmenes de datos 
- el límite físico alcanzado por las computadoras secuenciales en algunos casos torna inaceptable el tiempo 
para resolver determinados problemas, y hace que la solución paralela sea la única factible. 
- la existencia de sistemas en los que no interesa tanto la velocidad de cómputo sino la necesidad dI! estar 
en más de un lugar a la vez, capacidad que puede mapearse a una configuración paralela 
- las posibilidades que el paradigma paralelo ofrece en términos de investigación de técnicas para el 
análisis, diseño y evaluación de algoritmos. 
En una de las líneas de investigación aplicada dentro del proyecto Procesamiento Concurrente)' Paralelo 
del LIDI se trabaja en temas de especificación y evaluación de algoritmos paralelos. Esto incluye d 
desarrollo de procesos paralelos, la transformación de algoritmos secuenciales en paralelos y las métricas 
de evaluación de performance sobre diferentes plataformas de soporte (tanto de hardware como dd 
software). Más allá de la arquitectura de hardware y el software de soporte, en esta línea la mayor 
importancia está dada en los algoritmos paralelos, y en los métodos utilizados para su construcción y 
análisis de performance. 
Un punto importante es que no es adecuado referirse a un algoritmo paralelo sin ml!ucionar el modelo de 
computación paralela para el que se lo diseñó. En este marco, debe destacarse que no hay un modelu 
teórico unificador, a diferencia del cómputo secuencial donde el modelo RAM es aceptado como tal. Esto 
se debe a que los diferentes modelos paralelos (PRAM para memoria compartida, BSP para memoria 
distribuida, LogP para redes de procesadores asincrónicos, etc), enfatizan determinados aspectos a costa 
de otros. Una razón más sutil es que no es probable una máquina paralela universal; para cada aplicación 
existe una máquina óptima. 
Por esto, nos refl!rirnos a sistemas paralelos como la combinación de algoritmo y arquitectura. La 
diversidad hace complicado el análisis de pl!rformance del sistema paralelo. En otras palabras: qué es lo 
que interesa medir? Qué indica que un sistema paralelo es mejor que otro? Qué sucede si se utiliza un 
algoritmo COIl una mayor cantidad de procesadores? Se sigue comportando adecuadamente? En el 
mundo serial podl!mos realizar la evaluación a través de los requerimientos de tiempo y espacio del 
programa. En el paralelismo, hay otra cantidad de medidas que pueden ser de interés, esas métricas I!stán 
ligadas tanto al algoritmo como a la arquitl!ctura paralela de destino. 
1 Profesor Adjunto Dedicación Exclusiva. 

 Inwstigador PrilKipat CONICET. Profesor Titular Dedicación Exclusiva. 
-' Ayudante Diplomado Dedicación Semi Exclusiva. Becario LID!. 
LIDl - Facultad de Informática. UNLP - Call!: 50 y 115 ler Piso, (1900) La Plata, Argentina. 
TE/Fax +(54)(221 )422-7707. hltp:i/lidi.info.unlp.edu.ar 
Temas de Investigación y Desarrollo 
Existen una gran cantidad de métricas para evaluar sistemas paralelos. Las más conocidas son el tiempo de 
ejecución paralelo, el speedup y la eficiencia de utilización del sistema. Pero existen otras medidas que 
pueden ser útiles en algunas circunstancias: costo, overhead paralelo, grado de concurrencia. 
escalabilidad, isoeficiencia, isospeed, etc. En particular, en el caso del speedup se han propuesto distintos 
modelos de performance, entre los que se pueden citar a la Ley de Amdahl (tamaño de problema fijo), la 
Ley de Gustafson (problemas escalados, donde el tamaño del problema crece con el incremento en el 
tamaño de la máquina), y el modelo de speedup de Sun y Ni (problemas escalados acotados en la 
capacidad de memoria). La escalabilidad de un sistema paralelo es una medida de su capacidad de 
incrementar speedup en proporción al número de procesadores. Refleja la capacidad de un sistema 
paralelo de incrementar los recursos de procesamiento efectivamente. 
El tema de la escalabilidad, y su relación con la función de isoeficiencia, es de importancia dado que 
permiten capturar las características de un algoritmo paralelo así como de la arquitectura en la que se lo 
implementa. Se puede testear la performance de un programa paralelo sobre unos pocos procesadores y 
predecir su performance sobre un número mayor de procesadores. También permite caracterizar la 
cantidad de paralelismu inherente en un algoritmo paralelo, y puede usarse para estudiar el 
comportamiento de un sistema paralelo con respecto a cambios en parámetros de hardware tales como la 
velocidad de los procesadores y canales de comunicación. 
En este marco, interesa evaluar la performance de distintas clases de aplicaciones sobre diferentes 
arquitecturas reales para obtener resultados concretos. El énfasis está en adecuar los resultados teóricos 
ideales en las métricas a la realidad de la implementación de determinada clase de problema sobre 
distintas plataformas. Este interés se basa en que muchos sistemas paralelos no alcanzan su capacidad 
teórica, y las causas de esta degradación son muchas y variadas. En parte puede deberse a la poca 
correspondencia entre aplicaciones, software y hardware, pero existen otros factores que pueden influir y 
no siempre son tenidos en cuenta al formular una métrica. Entre ellos están: desbalance en la carga de 
trabajo de procesos y procesadores, demoras debidas a la sincronización, overhead por scheduling. 
topología, efecto de la granularidad, grado de escalabilidad del sistema, mapeo de procesos y datos a 
procesadores que puede acarrear mayor o menor comunicación, distintos niveles de memoria 
involucrados, etc. 
El análisis sobre plataformas disponibles permite estudiar el impacto que tienen algunos de estos factores 
sobre las implementaciones, y adecuar las métricas clásicas a las mismas. En particular se estudia la 
influencia de las estrategias de distribución de procesos y datos, y la carga (estática o dinámica) asignada a 
cada procesador sobre el speedup, la eficiencia y la escalabilidad. Se realiza experimentación para el caso 
de procesadores homogéneos y heterogéneos, en algoritmos numéricos y no numéricos. 
Equipamiento de experimentación 
La línea de investigación en procesamiento paralelo existe en el LIDI desde el año 1994, utilizando en es\.! 
entonces redes de PC con Netbios, kits de 4 transputers y simuladores de DSPs. Actualmente la Facultad 
de Infurmática de la UNLP cuenta con un Laboratoriu de Procesamiento Paralelo, en el cual se dispone de 
una serie de equipos que permiten realizar experiencias en el área. Se ha trabajado con: 
- Multiprocesador homogéneo con 32 transputers TT05 4Mb de memoria local. La importancia está dada 
en la posibilidad de re<:onfiguración, lo que permite la evaluación de performance sobre diferentes 
topologías de conexión. 
- Red heterogénea con PCs y workstations. Permite la emulación de una arquitectura paralela utilizando 
software de soporte como PVM o MPI. 
- MultiDSP, en especial para aplicaciones en procesamiento de señales (DSPs Motorola 56000 y MS340). 
Wicc 2000 - 5 
Respecto del soporte de software, básicamente se utilizó C (en sus distintas versiones paralelas para cada 
arquitectura), OCCAM y Ada. 
Actualmente se está gestionando ante la SeTCIP la posibilidad de utilización de la supercomputadora 
Clementina II (SGI Origin 2000, multiprocesador con característica NUMA) incorporada al sistema 
científico. 
Algunos resultados obtenidos y temas actuales 
Los resultados obtenidos y temas actuales incluyen publicaciones, tesinas de grado y tesis de postgrado. 
En los mismos se pone enfasis en las métricas de evaluación y el impacto de los factores mencionados 
anteriormente. En este sentido pueden mencionarse: 
- efecto del des balance de carga en el procesamiento, por ejemplo en operaciones sobre imágenes con 
carga no homogénea sobre arquitecturas homogéneas. Esto involucra distribución de tareas, estudio del 
número óptimo de particiones para el mejor speedup con buena eficiencia, distribución de datos, etc. 
- análisis de performance en problemas de reconocimiento y clasificación de objetos, con restricciones de 
tiempo real 
- problemas clásicos de sorting y manejo de matrices sobre diferentes arquitecturas 
- trabajos sobre escalabilidad en algoritmos de búsqueda de caminos mínimo en grafos, sobre distintas 
arquitecturas y variación de topologías. 
- paralelización de algoritmos de reconocimiento basado en texturas, con procesamiento intensivo. 
- evaluación de performance en algoritmos de seguimiento de trayectorias de objetos en una secuencia de 
imágenes 
- modelización de memoria cache distribuida 
- análisis de similitud en imágenes 
