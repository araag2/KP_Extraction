Especificación e implementación de agentes inteligentes para el soporte a la toma de decisiones
﻿ 
El objetivo general de esta línea de 
investigación es estudiar en el contexto de un 
sistema multi-agente (MAS), la problemática 
asociada con la especificación e implementación 
de un agente inteligente deliberativo con la 
capacidad de brindar apoyo a la toma de 
decisiones. Uno de los objetivos particulares es 
el diseño y la realización computacional de una 
arquitectura para un agente autónomo con la 
capacidad de contribuir a la toma de decisiones 
en un entorno MAS colaborativo.  
Palabras claves: Sistema Multi-agente, 
Agente Inteligente Deliberativo, Toma de 
Decisiones 
Contexto 
El presente plan de trabajo está estrechamente 
relacionado con los siguientes proyectos de 
investigación que se desarrollan dentro del 
ámbito del Laboratorio de Investigación y 
Desarrollo en Inteligencia Artificial (LIDIA): 
 
“Sistemas De Apoyo a la Decisión Basados en 
Argumentación: formalización y aplicaciones”. PIPCONICET (PIP-112-200801-02798). Director: Carlos 
Iván Chesñevar. Período  01/2009 - 12/2011. 
CONICET.  
“Formalismos Argumentativos aplicados a 
Sistemas Inteligentes para Toma de Decisiones”. 
Código: PGI 24/ZN18. Director: A. J.García. Codirector: M.A. Falappa. Acreditado con evaluación 
externa para el período 01/2009 - 12/2011. 
Universidad Nacional del Sur.  
“Representación de conocimiento, 
argumentación y apoyo a la toma de decisiones”. 
Secretaria de Ciencia y Tecnología - Universidad 
Nacional del Sur. 
1. Introducción   
Dentro de las Ciencias de la Computación, 
el problema de toma de decisiones ha sido 
abordado mayormente desde el campo de 
investigación de la Inteligencia Artificial (IA) 
estudiando el problema de razonamiento práctico 
que enfrenta un agente inteligente, i.e., decidir 
qué hacer.  
De acuerdo con Doyle y Thomason en 
[DT99], los distintos mecanismos formales de 
toma de decisiones no deben ser considerados 
aisladamente, sino que deben ser integrados de 
manera coherente en los modelos de agentes 
desarrollados en otras áreas de estudio dentro de 
la IA. Notablemente, en [BT96] se realiza un 
estudio a nivel teórico, donde se presenta un 
enfoque axiomático para caracterizar las 
propiedades deseables de esta integración. 
Asimismo, en [Wel96], se postulan ciertos 
fundamentos prácticos para alcanzar esta 
integración, aprovechando la experiencia 
obtenida por el autor en el área de programación 
orientada a mercados. 
A partir de estos trabajos diversos enfoques 
sobre la decisión se han integrado dentro de 
arquitecturas de agentes, entre ellos se pueden 
mencionar resumidamente: especificaciones 
cualitativas de modelos cuantitativos [BK97], 
representaciones gráficas de distribuciones de 
probabilidades [D'A99] y planeamiento bajo 
incertidumbre [Bly99]. Recientemente, Amgoud 
y Prade en [AP09] han distinguido dos 
tendencias principales que están influenciando 
actualmente la investigación sobre este tema en 
Inteligencia Artificial. Estas son los sistemas 
basados en teoría de decisión clásica y los 
enfoques para la toma de decisiones sobre la base 
de la arquitectura BDI (Beliefs-DesiresIntentions) que permite diseñar e implementar un 
esquema de razonamiento práctico. El modelo de 
arquitectura BDI [RG95, RG91, Rao96] es uno 
de los más utilizados como base para el 
desarrollo de agentes inteligentes, convirtiéndose 
en uno de los modelos más difundido y estudiado 
de la literatura. 
En la actualidad, el uso de sistemas 
informáticos basados en conocimiento para 
ayudar a sus usuarios (agentes humanos o 
agentes de software) a resolver sobre qué hacer 
está creciendo rápidamente. Este crecimiento es 
alentado por desarrollos teórico-prácticos en los 
sistemas multi-agente y por la conectividad que 
brinda la capacidad de acceso a grandes 
repositorios de conocimiento, la creciente 
capacidad de procesamiento para aprovechar 
esos repositorios, y la portabilidad del equipo 
computacional que los hace ubicuos, i.e., su 
disponibilidad en todo lugar. Estos sistemas son 
conocidos como sistemas de apoyo a la decisión. 
Al enfrentar decisiones complejas acerca de 
qué hacer, la perfomance de un agente 
responsable de actuar puede ser mejorada 
utilizando un sistema de soporte que aconseje 
sobre las mejores opciones posibles. Usualmente 
este apoyo resulta más confiable y útil cuando es 
brindado por un agente que posee conocimiento 
especializado del problema en cuestión. Por otra 
parte, dado que el contexto de la decisión es 
usualmente único y particular al agente, el apoyo 
ofrecido debería satisfacer las siguientes 
características:  
a. Claridad: la recomendación debe ser 
presentada en forma inteligible para el agente, 
de manera que este pueda comprenderla en su 
totalidad,  
b. Fundamentación: debe brindarse la 
información básica para la recomendación y la 
forma como a partir de ella se llega a obtener la 
recomendación, e  
c. Interactividad: bajo demanda del agente, 
debe ser posible realizar consultas sobre los 
detalles referidos tanto a la recomendación 
como al proceso de elaboración de dicha 
recomendación.  
Se opta como hipótesis que los Sistemas 
Argumentativos por sus características únicas 
pueden aportar de manera significativa al avance 
en la solución para este problema. La ventaja 
estratégica de los formalismos argumentativos es 
que por su propia definición y construcción 
satisfacen en gran medida las tres características 
recomendables señaladas con anterioridad: 
Claridad, Fundamentación e Interactividad. Un 
argumento aceptado representa una explicación 
clara de porqué la conclusión que soporta es 
propuesta, y el proceso por el cual el argumento 
es aceptado, brinda los componentes necesarios 
para que el agente que recibe la recomendación 
comprenda las razones que avalan la 
recomendación. En ese mismo proceso se 
introduce también la posibilidad de análisis 
interactivo en el estudio de los argumentos y 
contra-argumentos tenidos en cuenta. 
Como se mencionó anteriormente esta línea 
de investigación tiene por objetivo el diseño y la 
realización computacional de una arquitectura 
para un agente autónomo con la capacidad de 
contribuir a la toma de decisiones en un entorno 
colaborativo donde el componente cognitivo de 
razonamiento epistémico y el componente de 
razonamiento práctico que estén basados en un 
formalismo argumentativo. Partiendo de la 
arquitectura básica BDI, en el desarrollo de los 
sistemas de apoyo a la decisión, se puede 
concebir una arquitectura para un agente 
autónomo que satisfaga estas premisas, i.e., los 
diferentes componentes que la integran utilicen 
razonamiento basado en formalismos 
argumentativos.  
 
2. Líneas de Investigación y 
Desarrollo 
La presente línea de investigación estudiará 
en el contexto de un sistema multi-agente 
(MAS), la problemática asociada con la 
especificación e implementación de un agente 
inteligente deliberativo con la capacidad de 
brindar apoyo a la toma de decisiones. En 
particular se diseñará e implementará  una 
arquitectura para un agente autónomo con la 
capacidad de contribuir a la toma de decisiones 
en un entorno MAS colaborativo. El componente 
cognitivo del agente, compuesto de un razonador 
epistémico (para establecer lo que el agente 
conoce) y de un razonador práctico (para decidir 
lo que el agente debe hacer), estará basado en 
formalismos argumentativos apropiados. 
 
2.1. Arquitectura BDI 
Un agente con arquitectura BDI (Figura 1) 
posee un conjunto B de creencias acerca de su 
entorno, un conjunto D de deseos y un conjunto I 
de intenciones. La arquitectura BDI tiene sus 
raíces en el estudio del denominado 
Razonamiento Práctico.  
 
Dado un entorno particular que el agente 
tiene la capacidad de percibir (flecha superior 
izquierda en la Figura 1), este tipo de 
razonamiento puede describirse como el proceso 
de decidir qué acción realizar para alcanzar las 
metas (flecha inferior izquierda en la Figura 1). 
Involucra dos importantes procesos:  
(i) Deliberación, i.e., decidir qué metas se 
quieren alcanzar, y  
(ii) Razonamiento de medios-fines (meansends), i.e, decidir cómo se alcanzarán las 
metas. La primera parte involucra el 
razonamiento epistémico. 
Las intenciones de un agente son un 
subconjunto de las alternativas que éste posee 
para alcanzar sus metas. Una de las 
características más importantes de las intenciones 
es su rol motivador, i.e., provocan acciones. Una 
vez adoptada una intención, ésta afectará el 
razonamiento práctico que considere el futuro. 
Las intenciones tienen la propiedad de 
persistencia. Esto es, para que resulten útiles el 
agente no deberá abandonar una intención, sino 
que la mantendrá hasta que la cumpla, o bien sea 
evidente que no podrá hacerlo, o bien las razones 
que tuvo para adoptarla dejaron de ser válidas. 
Sus intenciones están relacionadas con sus 
creencias acerca del futuro. 
 La arquitectura BDI básica comprende el 
siguiente esquema de comportamiento para los 
agentes: 
1. Percibir los cambios del entorno en el 
que se desenvuelve. 
2. Revisar sus creencias acerca del mundo 
en base a su percepción (knowledge base 
update). 
3. Razonar acerca de sus intenciones a fin 
de reconsiderarlas en caso que sea 
necesario. 
4. Seleccionar una acción a seguir 
(decisión), razonando sobre sus creencias 
y sus intenciones. 
5. Ejecutar la acción seleccionada, la cual 
producirá cambios en el entorno, y 
volver al paso 1 a fin de percibir los 
cambios que se han producido. 
 
2.2. Sistemas Argumentativos 
En argumentación es una proposición es 
aceptada o no de acuerdo a un análisis de las 
razones de las que se dispone para creer o no en 
la misma, donde estas razones o justificaciones 
toman la forma de argumentos [CMR00]. 
Además, la manera en que estos argumentos son 
considerados permite la automatización de este 
tipo de razonamiento.  
En los sistemas argumentativos basados en 
reglas (SABR), existe un conjunto de reglas de 
inferencia con las cuales, a partir de cierta 
información (antecedente o conjunto de 
premisas) se puede inferir de manera tentativa 
nueva información (consecuente). En este tipo de 
sistemas, las reglas son almacenadas en una base 
de conocimiento, junto a otra información en 
forma de hechos o presuposiciones, que 
representan la evidencia que el agente obtiene de 
su entorno. A partir de esta evidencia, el agente 
puede usar las reglas de inferencia para construir 
argumentos a favor o en contra de una 
afirmación. Una vez hecho esto se evalúan todos 
los argumentos construidos, y se determina 
cuáles de ellos son aceptados, buscando concluir 
si, a partir de la base de conocimiento del agente, 
está afirmación puede aceptarse o no. Estos 
formalismos son no-monótonos dado que la 
introducción de nueva información al sistema 
puede generar nuevos argumentos que resultan 
contradictorios con algunos de los ya existentes. 
En general, en la mayoría de estos formalismos, 
argumentos y contra-argumentos son 
comparados utilizando un criterio de preferencia 
pre-determinado permitiendo decidir si un ataque 
tiene éxito. En esta situación es posible que 
ciertas conclusiones que antes estaban aceptadas 
Módulo de Percepción 
Función de Revisión de Creencias 
B D I 
Módulo de Razonamiento 
Ejecutar 
Reconsideración 
de Intenciones 
Selección de 
Acciones 
Figura 1. Esquema de la arquitectura BDI básica 
e
n
t
o
r
n
o 
dejen de estarlo demostrando que la relación de 
inferencia así definida exhibe un comportamiento 
no-monótono. 
En el últimos años, el campo de aplicación 
de la argumentación se ha expandido 
velozmente, en gran parte debido a los avances 
teóricos, pero también gracias a la demostración 
exitosa de su uso práctico en un gran número de 
dominios de aplicación, tales como el 
razonamiento legal [PS02], la ingeniería del 
conocimiento [CRL00], los sistemas multiagentes [PSJ98, AMP02], y el e-government 
[ABM05], entre muchos otros [RS09]. 
 
2.3. Agentes  y Argumentación 
La argumentación constituye un área de 
estudio de especial interés en el ámbito de la 
Inteligencia Artificial (ver por ejemplo [RS09]), 
principalmente, porque permite razonar en 
entornos sobre los que un agente puede solo 
acceder a la información de manera parcial o 
cuando su capacidad de adquirirla es imprecisa. 
Estas características, junto con la capacidad de 
tolerar la existencia de información 
contradictoria en la base de conocimiento 
disponible para el agente, los hacen 
particularmente apropiados para su utilización en 
la implementación del componente cognitivo 
superior de un agente autónomo [GGTS00]. Este 
tipo de razonamiento resulta así particularmente 
atractivo para ser utilizado en la toma de 
decisiones. 
 
3. Resultados Obtenidos y  
Esperados  
En el LIDIA a través de los años se han 
llevado a cabo diferentes proyectos sobre 
Sistemas de Argumentación, en particular 
investigaciones dedicadas a desarrollar sistemas 
de argumentación masiva. Varias publicaciones 
proponiendo la creación de mecanismos que 
pudieran mejorar la complejidad computacional 
de los sistemas de argumentación basados en 
Defeasible Logic Programing (DeLP) [GS04] 
fueron propuestas y publicadas en conferencias y 
revistas internacionales. Además dentro de estos 
proyectos se desarrolló una implementación de 
un SABR (llamado DeLP o Defeasible Logic 
Programming) y hoy cuenta con diferentes 
versiones disponibles. Estas implementaciones se 
han utilizado en aplicaciones concretas como 
toma de decisiones en un entorno de Robots 
Kephera [FEGG08], sistemas de recomendación 
[CMS07, TGS09], e implementación de agentes 
[GGS09].   
El objetivo de esta línea de investigación 
consiste en el diseño y la realización 
computacional de una arquitectura para un 
agente autónomo con la capacidad de contribuir a 
la toma de decisiones en un entorno colaborativo. 
El componente cognitivo de razonamiento 
epistémico y el componente de razonamiento 
práctico del agente estarán basados en un 
formalismo argumentativo. Finalmente, 
utilizando la arquitectura básica BDI en el 
desarrollo de los sistemas de apoyo a la decisión, 
se puede concebir una arquitectura para un 
agente autónomo que satisfaga estas premisas. 
De este modo, es posible que los diferentes 
componentes que integran la arquitectura del 
agente utilicen razonamiento basado en 
formalismos argumentativos.  
 
