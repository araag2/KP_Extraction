Modelos formales del razonamiento científico
﻿Modelos Formales del Razonamiento Cient¶³¯co
Claudio Delrieux
Universidad Nacional del Sur, Bahia Blanca - ARGENTINA
claudio@acm.org
1 Introducci¶on
El objetivo de esta l¶³nea de trabajo consiste en formalizar el razonamiento cient¶³¯co utilizando un lenguaje l¶ogico. Dentro del m¶etodo cient¶³¯co, especialmente dentro de las ciencias
experimentales, se estableci¶o un conjunto de procedimientos que permiten llevar adelante la
explicaci¶on y predicci¶on de fen¶omenos y la generaci¶on, corroboraci¶on y refutaci¶on de teor¶³as.
La formalizaci¶on de estos procedimientos constituye uno de los principales objetos de estudio
de la teor¶³a de la ciencia. El conocimiento cient¶³¯co se ordena y con¯gura en estructuras complejas. Las unidades de organizaci¶on m¶as destacadas dentro de esta estructura son las teor¶³as.
Las teor¶³as cient¶³¯cas tienen la funci¶on de establecer conexiones sistem¶aticas dentro de un aspecto de la realidad. De ese modo es posible la inferencia de determinados hechos a partir
de otros. Si el tipo de conocimiento que constituye una teor¶³a cient¶³¯ca fuese conocimiento
verdadero justi¯cado y el m¶etodo cient¶³¯co fuese deductivamente v¶alido, entonces no habr¶³a
diferencia entre las teor¶³as cient¶³¯cas y las l¶ogicas. Sin embargo, las teor¶³as cient¶³¯cas involucran tipos de conocimiento cuya justi¯caci¶on es problem¶atica, y mecanismos de inferencia
ampliativos. Por lo tanto estas teor¶³as no tienen el status de ser deductivamente v¶alidas.
Hempel [3] propone que la l¶ogica de la predicci¶on y de la explicaci¶on proceden seg¶un un
mismo esquema T  e, donde T , el explanans es un conjunto de leyes, y e, el explanandum es
el fen¶omeno o hecho a explicar. La sistematizaci¶on por medio de este esquema se denomin¶o
paradigma hipot¶etico-deductivo o deductivo-nomol¶ogico, dado que el explanans constituye una
pieza de conocimiento hipot¶etico, del cual se debe deducir la evidencia. El procedimiento
de inferir el explanans no puede ser deductivo, es decir, T nunca puede ser verdadera. Una
conclusi¶on, seeñalada por Popper, es que las teor¶³as cient¶³¯cas no se veri¯can sino que se
refutan. Dicho de otra forma, no existe evidencia posible que garantice la verdad l¶ogica de
una teor¶³a, pero una sola predicci¶on o explicaci¶on incorrecta -aunque sea frente a una cantidad
enorme de casos correctos- sirve para mostrar que una teor¶³a es falsa.
Una propuesta pragm¶aticamente m¶as adecuada que el paradigma H-D fue realizada por
Lakatos en sus programas de investigaci¶on [4]. Lakatos observa que una teor¶³a no puede ser
absolutamente verdadera. Es m¶as, una teor¶³a puede ser falsa pero tener consecuencias verdaderas y operacionales. Por esta raz¶on los programas de investigaci¶on reales permanecen
abiertos y sujetos al cambio y la evoluci¶on. Esto determina que un programa pueda sobrevivir sin que por ello sea verdadero. Los programas de investigaci¶on son estructuras que
incluyen a las teor¶³as cient¶³¯cas, integr¶andolas con un conjunto de procedimientos de inferencia y que poseen un conjunto perif¶erico de hip¶otesis auxiliares. El n¶ucleo de un programa es
un conjunto de conocimiento que se considera central, y que de¯ne la teor¶³a como tal. Este
n¶ucleo es el conjunto de conocimientos (leyes, generalizaciones o postulados) que determina
la identidad de la teor¶³a y por consiguiente del programa mismo. El n¶ucleo, por lo tanto, se
considera de¯nitivo, y el resto de la estructura del programa opera de modo tal de protegerlo
Workshop de Investigadores en Ciencias de la Computación WICC 2002
Página 29
de la refutaci¶on. Esta protecci¶on consiste b¶asicamente en implementar un cintur¶on protector
de hip¶otesis auxiliares, que impiden que el n¶ucleo sea refutado. De esa forma, existen dos
procedimientos heur¶³sticos para confrontar a la teor¶³a con la evidencia de un resultado experimental e. Mientras no ocurran refutaciones, entonces se aplica la heur¶³stica positiva, en la
cual se busca una sistematizaci¶on del cintur¶on protector (como consecuencia del n¶ucleo duro
o por medio de nuevas leyes). Si el resultado e no es correctamente predicho o explicado por
la teor¶³a, entonces se aplica la heur¶³stica negativa, que consiste en encontrar una hip¶otesis c
particular al caso e tal que de la teor¶³a aumentada con c se siga e. Si dicha hip¶otesis no es
compatible con el resto de la teor¶³a, entonces algo en la misma deber¶a corregirse.
2 Formalizando los programas de Lakatos
En esta Secci¶on propondremos una formalizaci¶on de los Programas, en t¶erminos de los sistemas de razonamiento no monot¶onicos. Tambi¶en esbozaremos algunas ideas tendientes a
comparar entre s¶³ diferentes programas en funci¶on de algunas caracter¶³sticas ventajosas, como
ser el progreso emp¶³rico y el ¶exito relativo, dejando planteadas otras posibilidades como por
ejemplo el poder sistematizador, o la menor cantidad de hip¶otesis ad hoc. Esta formalizaci¶on
presupone que el conocimiento v¶alido K es conocido y universalmente aceptado por todos los
programas, al igual que la evidencia E. Utilizaremos como mecanismo de inferencia subyacente a un sistema abstracto de razonamiento argumentativo [5, 6]. Es decir, las predicciones
o explicaciones en los programas se obtienen construyendo argumentos.
Definici¶on 1 Dado un conjunto K de conocimiento v¶alido y un conjunto E de evidencia (literales de base), un programa de investigaci¶on P = hT ; Ci consta de una teor¶³a no
monot¶onica T y un cintur¶on protector C. La teor¶³a T est¶a representada por medio de un
conjunto de condicionales derrotables a(X) >¡¡ b(X), y C por medio de literales de base
que representan las hip¶otesis ad hoc. Un programa de investigaci¶on P = hT ; Ci predice (o
explica) a un literal de base e cuando existe un argumento para e a partir de K; T ; C y E.
Es importante recordar que la existencia de un argumento para un literal no es condici¶on
su¯ciente para asumir que la teor¶³a argumentativa acepta a dicho literal como conclusi¶on, dado
que pueden existir argumentos en contra que lo derroten. Esto es an¶alogo a lo que ocurre
en un programa de investigaci¶on, donde el programa puede realizar predicciones para un
observable, pero tambi¶en predicci¶ones contradictorias con el mismo observable. Por lo tanto
deber¶³amos repasar cu¶ales son las \actitudes proposicionales" que la teor¶³a argumentativa nos
permite asumir respecto del literal e.
Definici¶on 2 Dado un programa P y un literal de base e, se pueden dar los casos:
De¯nitiva Revisable
Argumentos solamente Argumentos tanto para e como para :e
Aceptar e para e pero existe un argumento no derrotado para e
Argumentos solamente Argumentos tanto para e como para :e
Aceptar :e para :e pero existe un argumento no derrotado para :e
No hay argumentos Argumentos tanto para e como para :e
Indeciso ni para e ni para :e pero no existen argumentos no derrotados
Dado un programa P y un literal de base e el cual se con¯rma en la experiencia, se
puede dar solamente uno de entre los siguientes casos:
Workshop de Investigadores en Ciencias de la Computación WICC 2002
Página 30
Predicci¶on de P Status de P luego de la con¯rmaci¶on de e
Aceptaci¶on de¯nitiva de e P se con¯rma
Aceptaci¶on revisable de e P se con¯rma parcialmente
Aceptaci¶on de¯nitiva de :e Anomal¶³a grave
Aceptaci¶on revisable de :e Anomal¶³a parcial
Indecisi¶on de¯nitiva Hecho sorprendente
Indecisi¶on revisable \Laguna"
Ejemplo 1 Supongamos que nuestro conocimiento, evidencia, y suposiciones acerca de
las propiedades de algunos animales es el siguiente:
K = fpingÄuino(X) ) ave(X)g.
T 1 = fave(X) >¡¡ vuela(X); pingÄuino(X) >¡¡ :vuela(X); en-avi¶on(X) >¡¡ vuela(X)g:
E = fpingÄuino(Opus); ave(Pint¶³n); ave(Tweety); pingÄuino(Schmuck); en-avi¶on(Schmuck)g:
Por el momento, nuestro programa no requiere hip¶otesis auxiliares C1 = fg. En estas
condiciones, las predicciones que hace nuestro programa P1 = hT 1 ; C1i con el conocimiento
subyacente K y la evidencia E se basan en lo siguiente:
1. Existe un argumento para vuela(Opus) (por ser ave), pero hay otro argumento para
:vuela(Opus) (por ser pingÄuino) que es m¶as espec¶³¯co y que lo derrota. Por lo tanto
P1 predice :vuela(Opus).
2. Existe un argumento para vuela(Tweety), por lo tanto P1 predice dicho literal.
3. Existe un argumento para vuela(Pint¶³n), por lo tanto P1 predice dicho literal.
4. Existe un argumento para vuela(Schmuck) (por estar en avi¶on) y otro argumento para
:vuela(Schmuck) (por ser pingÄuino). Ambos argumentos se derrotan mutuamente, por
lo que P1 no hace predicciones al respecto.
Supongamos ahora que realizamos observaciones acerca de los individuos voladores, encontrando la siguiente evidencia:
Er = f:vuela(Opus);:vuela(Tweety); vuela(Gringa); vuela(Pint¶³n); vuela(Schmuck)g:
En dicho caso, podemos ver que nuestro programa P1 tiene el siguiente status frente a las nuevas observaciones: con :vuela(Opus) tiene una con¯rmaci¶on parcial, con
:vuela(Tweety) tiene una anomal¶³a grave, con vuela(Gringa) tiene una observaci¶on
sorprendente, con vuela(Pint¶³n) tiene una con¯rmaci¶on, y con vuela(Schmuck) tiene una
laguna.
Por el momento, no estableceremos diferencias entre con¯rmaciones y con¯rmaciones parciales, lagunas y hechos sorprendentes, y anomal¶³as parciales o graves. La distinci¶on ser¶a
importante m¶as adelante, cuando tratemos en la pr¶oxima Secci¶on de formalizar algunos aspectos de la din¶amica de los programas, es decir, cu¶ando y c¶omo el programa debe modi¯carse
para adaptarse a las nuevas observaciones. De esa forma, denominaremos V al conjunto de
casos donde la evidencia con¯rma total o parcialmente al programa P , I las indeterminaciones
o casos sorprendentes o lagunas para P , y F los casos refutatorios o anomal¶³as parciales o
graves. En el ejemplo anterior, podemos ver que V1 = f:vuela(Opus); vuela(Pint¶³n)g; I1 =
fvuela(Gringa); vuela(Schmuck)g; F1 = f:vuela(Tweety)g:
Workshop de Investigadores en Ciencias de la Computación WICC 2002
Página 31
Definici¶on 3 Un programa P1 es emp¶³ricamente m¶as progresivo que otro P2 siempre que
tenga estrictamente mayor cantidad de casos con¯rmatorios. Es decir,
P1ÁprogP2, V2 ½ V1:
P1 es m¶as exitoso que P2 si cada caso con¯rmatorio de P2 es tambi¶en con¯rmatorio de P1 ,
cada caso refutatorio de P1 es tambi¶en refutatorio de P2, pero hay por lo menos un caso
con¯rmatorio de P1 que no es con¯rmatorio de P2 o por lo menos un caso refutatorio de P2
que no es refutatorio de P1. Es decir,
P1ÁexP2, V2 µ V1 ; F1 µ F2; 9v 2 V1 ¡ V2 _ 9f 2 F2 ¡ F1
Ejemplo 2 Supongamos estar en una situaci¶on similar a la del Ejemplo 1. A partir de la
evidencia previa Ed del ejemplo, un programa P2 edi¯cado a partir una segunda teor¶³a T 2
realizar¶a las siguientes predicciones:
T 2 = fave(X) >¡¡ vuela(X); pingÄuino(X) >¡¡ :vuela(X)g:
1. Existe un argumento para vuela(Opus) (por ser ave), pero hay otro argumento para
:vuela(Opus) (por ser pingÄuino) que es m¶as espec¶³¯co y que lo derrota. Por lo tanto
P2 predice :vuela(Opus).
2. Existe un argumento para vuela(Tweety), por lo tanto P2 predice dicho literal.
3. Existe un argumento para vuela(Pint¶³n), por lo tanto P2 predice dicho literal.
4. Existe un argumento para :vuela(Schmuck) (por ser pingÄuino), por lo que P2 predice
dicho literal.
Si luego nos confrontamos a las mismas observaciones
Er = f:vuela(Opus);:vuela(Tweety); vuela(Gringa); vuela(Pint¶³n); vuela(Schmuck)g;
podemos ver que el nuevo programa P2 tiene con :vuela(Opus) una con¯rmaci¶on parcial, con :vuela(Tweety) tiene una anomal¶³a grave, con vuela(Gringa) tiene una observaci¶on
sorprendente, con vuela(Pint¶³n) tiene una con¯rmaci¶on, y con vuela(Schmuck) tiene otra
anomal¶³a grave. Entonces V2 = f:vuela(Opus); vuela(Pint¶³n)g; I2 = fvuela(Gringa)g; F2 =
f:vuela(Tweety); vuela(Schmuck)g:
En estas condiciones, si bien P1 y P2 son igualmente progresivos, dado que coinciden
sus casos con¯rmatorios, P2 es menos exitoso que P1 porque existe por lo menos una
observaci¶on (vuela(Schmuck)) que es an¶omala para P2 pero no para P1 .
3 La din¶amica de los programas
En la Secci¶on anterior identi¯camos seis posibles resultados de un programa P confrontado
a un resultado experimental er. En esta Secci¶on trataremos de dilucidar cu¶al deber¶³a ser la
estrategia de un programa en funci¶on del status que asume frente a nuevos resultados experimentales. Si el programa se confronta con un hecho sorprendente, entonces deber¶³a recurrir
a alg¶un mecanismo de inferencia ampliativa para poder explicarlo (en este punto es donde se
Workshop de Investigadores en Ciencias de la Computación WICC 2002
Página 32
requiere de un contexto de descubrimiento). En cambio, cuando los resultados son an¶omalos,
entonces es necesario aplicar la heur¶³stica negativa, es decir, tratar de modi¯car las hip¶otesis
perif¶ericas del mismo para defender el n¶ucleo de la refutaci¶on o para mantener progresivo al
programa. Cuando existe con¯rmaci¶on total o parcial deber¶³a aplicarse la heur¶³stica positiva, es decir, tratar de aplicar el n¶ucleo del programa para sistematizar tambi¶en el cintur¶on
protector, y de esa manera reducir la cantidad de hip¶otesis ad hoc. Finalmente, cuando el
programa est¶a indeterminado por tener una laguna, es decir, si el programa gener¶o teor¶³as
o argumentos no de¯nitivos tanto a favor como en contra de la nueve evidencia, entonces es
discutible si alguna de las dos heur¶³sticas deber¶³a ser aplicada. Una manera de asimilar la
importancia de los mecanismos de inferencia que presentamos en los anteriores Cap¶³tulos consiste en verlos como posibles formalizaciones de estas estrategias heur¶³sticas de un programa
cuando se confronta con una alguno de los casos mencionados.
Ejemplo 3 Supongamos estar en la misma situaci¶on que en el Ejemplo 1 y deseamos desde
el programa P1 encontrar explicaci¶on al hecho sorprendente vuela(Gringa). Una estrategia
para explicar un hecho sorprendente e consiste en encontrar por abducci¶on [1, 2] alg¶un hecho
particular h el cual, junto con la teor¶³a, permita inferir e. En este caso tenemos dos posibles
explicaciones m¶as espec¶³¯cas1 encontradas por abducci¶on: ave(Gringa) y en-avi¶on(Gringa),
hip¶otesis que luego habr¶a que corroborar por la experiencia. Mientras que estas hip¶otesis no
est¶en corroboradas, cualquiera de las dos (o ambas) pueden pasar a formar parte del cintur¶on
protector C.
Ejemplo 4 Siguiendo nuevamente con el Ejemplo 1 desde el programa P1 . Tenemos en
:vuela(Tweety) una anomal¶³a grave. Sin embargo, podemos encontrar una explicaci¶on abductiva que corrija la anomal¶³a. En efecto, si agregamos la hip¶otesis pingÄuino(Tweety) al
programa, entonces el programa tendr¶a ahora la posibilidad de construir un argumento para :vuela(Tweety) que derrota al argumento para vuela(Tweety), es decir, el programa se
protege de la observaci¶on an¶omala.
Ejemplo 5 Siguiendo nuevamente con el Ejemplo 1 desde el programa P1 . Tenemos en
vuela(Schmuck) una laguna. En esta situaci¶on es necesario o bien establecer un ranking entre
los condicionales derrotables utilizados para generar los argumentos para vuela(Schmuck) y
para :vuela(Schmuck), o bien es necesario modi¯car alguno de los condicionales (por ejemplo,
pingÄuino(X) ^ en-avi¶on(X) >¡¡ vuela(X)).
