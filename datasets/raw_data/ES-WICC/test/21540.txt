Optimización de algoritmos sobre arquitecturas paralelas de memoria distribuida Aplicación al reconocimiento de patrones
﻿
   El objetivo general es investigar la transformación y optimización de algoritmos para su ejecución
sobre arquitecturas paralelas de memoria distribuida, con énfasis en la aplicación al reconocimiento
de patrones.
   Interesan las clases de problemas relacionadas con el tratamiento masivo de datos (potencialmente
distribuidos) tales como los patrones de secuencias en reconocimiento de ADN o los patrones
clásicos de identificación humana (huellas digitales, rostros).
   En todos los casos los resultados esperados son la optimización de algoritmos, el estudio de
complejidad y de escalabilidad de los mismos.
PALABRAS CLAVES
Paralelización y optimización de algoritmos – Memoria distribuida – Tiempo real -Reconocimiento
de patrones
INTRODUCCIÓN
   La evolución del procesamiento hacia el paralelismo ha sido evidente, prácticamente desde el
inicio mismo de las computadoras digitales. Los ejes que han impulsado los temas de concurrencia
en software y multiprocesamiento en hardware son múltiples, pero podemos mencionar dos:
! La necesidad de reducir los tiempos de procesamiento de grandes volúmenes de datos
(problemas matemáticos, modelos, grandes bases de datos, imágenes, sistemas expertos,
biotecnología, etc.).
! El procesamiento de información (datos, señales) en tiempo real para la toma de decisiones
tanto en ambientes administrativos como industriales (robótica, industria militar, sistemas
multimediales en tiempo real, georeferenciación, reconocimiento de patrones).
1Investigador Principal CONICET. Profesor Titular Ded. Exclusiva. degiusti@lidi.info.unlp.edu.ar.
2Profesor Titular.  mnaiouf@lidi.info.unlp.edu.ar.
3Licenciado en Informática. Becario UNLP. Ayudante Diplomado.  francoch@lidi.info.unlp.edu.ar.
4LIDI – Facultad de Informática. UNLP – Calle 50 y 115 1er Piso, (1900) La Plata, Argentina.
 TEL/Fax +(54) (0221) 422-7707. http:/lidi.info.unlp.edu.ar.
   Esta evolución conduce a un gran esfuerzo por transformar el procesamiento secuencial en
paralelo, buscando reducir los tiempos de ejecución de procesos y de respuesta a eventos del mundo
real. También en este aspecto podemos encontrar dos ejes en la respuesta tecnológica:
! El crecimiento de la potencia de cómputo, dado en la evolución de la tecnología de los
componentes y en las arquitecturas de procesamiento (supercomputadoras, hipercubos de
procesadores homogéneos, grandes redes de procesadores no homogéneos, procesadores
especializados de imágenes, procesadores para el tratamiento de señales).
! La transformación y creación de algoritmos que exploten al máximo la concurrencia implícita en
el problema a resolver, de modo de distribuir el procesamiento minimizando el tiempo total de
respuesta. Naturalmente esta transformación, también debe adaptarse a la arquitectura física de
soporte.
   Una de las áreas de mayor interés y crecimiento en los últimos años dentro de las aplicaciones del
procesamiento paralelo es la de tratamiento de grandes volúmenes de datos, tales como los que
caracterizan la identificación de patrones como secuencias de ADN, huellas digitales e imágenes.
Esta tarea abarca distintas etapas que van desde la transformación de los algoritmos secuenciales al
análisis de complejidad de las soluciones paralelas sobre diferentes modelos de arquitectura. El
parámetro final de optimización es naturalmente la eficiencia y escalabilidad de la solución paralela.
TEMAS DE INVESTIGACIÓN Y DESARROLLO
! Sistemas Paralelos. Arquitecturas multiprocesador para procesamiento paralelo. Arquitecturas
de memoria distribuida. Casos de memoria total y parcialmente  compartida. Clusters de PCs.
! Paradigmas de Programación paralela. Especificación de algoritmos paralelos.
! Modelos de predicción de perfomance clásicos: PRAM, LOGP, BSP, CCM, OBSP, BSPRAM.
Análisis del ajuste de los modelos a “clases” de sistemas paralelos. Desarrollos experimentales.
! Métricas de eficiencia en algoritmos paralelos. Análisis de complejidad en algoritmos paralelos.
! Dependencia de los modelos respecto del balance de carga en los procesadores.
! Aplicaciones paralelas de reconocimiento de patrones, sobre memoria distribuida.
! Lenguajes de soporte para programación paralela en clusters de workstations: PVM y MPI.
ADA  y C Paralelo.
! Transformación e implementación de algoritmos paralelos sobre clusters de PCs con memoria
distribuida. Optimización.
! Fundamentos del tratamiento de secuencias. Reconocimiento de Patrones de secuencias.
Análisis de similitud en grandes secuencias. Optimización de algoritmos paralelos.
! Otras clases de problemas de reconocimiento sobre grandes volúmenes de datos distribuidos:
huellas digitales, imágenes de rostros.
Desarrollos a realizar
! Implementación de algoritmos paralelos de análisis y reconocimiento de patrones en secuencias
sobre cluster de PCs.
! Análisis de complejidad y optimización de los algoritmos. Análisis de escalabilidad.
! Extensión de los resultados a otras clases de problemas sobre grandes volúmenes de datos
distribuidos.
EQUIPAMIENTO DE EXPERIMENTACIÓN
   En el LIDI se dispone de un cluster de PCs con 32 equipos homogéneos. Por otra parte, se tiene
acceso a la computadora Clementina (SGI Origin 2000) que tiene 40 procesadores con memoria
compartida distribuida.
   Naturalmente también se puede experimentar con arquitecturas seudo-paralelas tal como redes
heterogéneas con un soporte de comunicaciones tipo PVM o MPI.
BIBLIOGRAFÍA RELACIONADA
[Akl89] Akl S, “The Design and Analysis of Parallel Algorithms”, Prentice-Hall, Inc., 1989.
[Akl97] Akl S, “Parallel Computation. Models and Methods”, Prentice-Hall, Inc., 1997.
[Andr91] Andrews, "Concurrent Programming", Benjamin/Cummings, 1991.
[Bri95] Brinch Hansen, P., “Studies in computational science: Parallel Programming Paradigms”,
Prentice-Hall, Inc., 1995.
[Bub97] Bubak, Funika, Moscinski, “Performance Analysis of Parallel Applications under Message
Passing Environments”, www.icsr.agh.edu.pl/publications/html/perf_full/, 1997
[Bust88] Bustard, Elder, Welsh, "Concurrent Program Structures", Prentice Hall, 1988.
[Cof92] M. Coffin, "Parallel programming- A new approach", Prentice Hall, Englewood Cliffs,
1992.
[CSA90] “Transputer Architecture”, Computer System Architects, 1990.
[Cha88] Chandi K.M., Misra J., “Parallel Program Design. A Foundation”, Addisson Wesley, 1988.
[Dasg87] S. Dasgupta, "Computer Architecture: A modern synthesis", Wiley, 1987.
[Day94] Day K., Tripathi A., “A Comparative Study of Topological Properties of Hypercubes and
Star Graphs” IEEE Trans. Parallel and Distributed Systems, vol. 5, no. 1, pp. 31-38, Jan. 1994
[Debl90] Mario de Blasi, "Computer Architecture", Addison-Wesley, 1990.
[Don94] Dongarra J., et al, “PVM: Parallel Virtual Machine, A Users Guide and Tutorial for
Neworked Parallel Computing”, MIT Press, 1994.
[Fly72] Flynn M. J., “Some Computer Organizations and Their Effectiveness”, IEEE Transactions
on Computers, C-21, No 9, September, 1972.
[Fort85] P. Fortier, "Design and analysis of distributed real-time systems", McGraw-Hill, 1985.
[FUK90] Keinosuke Fukunaga "Statistical Pattern Recognition". Academic Press. 1990
[Gon92] Rafael C. Gonzáles, Richard E. Woods, "Digital Image Processing", Addison-Wesley
Publishing Comp., 1992.
[Gup93] Gupta A., Kumar V., “Performance properties of large scale parallel systems”, Journal of
Parallel and Distributed Computing, November 1993.
[Gus88] Gustafson J., “Reevaluating Amdahls Law”, Comm. Of the ACM, Volume 31 (1988), pp.
532-533.
[Heer91] D. W. Heermann, A. N. Burkitt, "Parallel Algorithms in Computational Science",
Springer-Verlag, 1991.
[Hoar85] C. A. R. Hoare, "Communicating Sequential Processes", Pentice-Hall, 1985.
[Hwan84] Hwang, Briggs, "Computer architecture and parallel processing", McGraw Hill, 1984.
[Hwan93] K. Hwang, "Advanced Computer Architecture. Parallelism, Scalability,
Programmability", McGraw Hill, 1993.
[IEEE] Colección de "IEEE Transactions on Parallel and Distributed Systems", IEEE.
[JAI89] Anil K Jain " Fundamentals of Digital Image Processing" Prentice Hall. 1989.
[Kar92] Karonis N, “Timing Parallel Programs That Use Message Passing”, Journal of Parallel and
Distributed Computing, 14, 1992.
[Kum94] Kumar V., Grama A., Gupta A., Karypis G., “Introduction to Parallel Computing. Desing
and Analysis of Algorithms”, Benjamin/Cummings, 1994.
[Kun91] Kung H.T., Sansom R., Schlick S., Steenkiste P., Arnould M., Bitz F.J., Christianson F.,
Cooper E.C., Menzilcioglu O., Ombres D., and Zill B., “Network-Based Multicomputers: An
Emerging Parallel Architecture” Proc. Supercomp.'91, pp. 664-673. IEEE, Albuquerque, Nov. 1991.
[Leig92] F. T. Leighton, “Introduction to Parallel Algorithms and Architectures: Arrays, Trees,
Hypercubes”, Morgan Kaufmann Publishers, 1992.
[Levi90] S. Levi, A. Agrawala, "Real Time System Design", McGraw-Hill Inc, 1990.
[LIM90] Jane S Lim "Two – Dimensional Signal and Image Processing" PTR Prentice Hall. 1990
[Log94] “Transputer Toolset”, Logical System, 1994.
[Luq93] Luque E, Senar M, Hernandez P, Franco D, Heymann E, Moure J, “Distributed Kernel for
a Transputer Based Computer”, Transputers Applications and Systems'93. Vol 2, IOS Press, 1993.
[Luq95] Luque E, Ripoll A, Cortès A, Margalef T, “A Distributed Diffusion Method for Dynamic
Load Balancing on Parallel Computers”, Proceedings of the EUROMICRO Workshop on Parallel
and Distributed Processing, IEEE Computer Society, Jan. 1995.
[Mil98] Miller R., Stout Q. F., “Algorithmic Techniques for Networks of Processors”, CRC
Handbook of Algorithms and Theory of Computation, M. J. Atallah, ed, 1998.
[Mor94] Morse F., “Practical Parallel Computing”, AP Professional, 1994.
[RUS95] John C Russ "The Image Processing Handbook"  2nd Edition CRC Press-1995
[Sim97] Sima D, Fountain T, Kacsuk P, “Advanced Computer Architectures. A Design Space
Approach”, Addison Wesley Longman Limited, 1997.
[Ste96] Steenkiste P., “Network-Based Multicomputers: A Practical Supercomputer Architecture”,
IEEE Transactions on Parallel and Distributed Systems, Vol. 7, No. 8, August 1996, pp. 861-875
[Sun95] Sun X., Zhu J.,“Performance Considerations of Shared Virtual Memory Machines”,
Transactions on Parallel and Distribued Systems, Vol 6, No. 11: November 1995, pp. 1185-1194.
[Tin98] Tinetti F., De Giusti A., "Procesamiento Paralelo. Conceptos de Arquitectura y
Algoritmos", Editorial Exacta, 1998.
[Zom96] Zomaya A. (ed), “Parallel Computing. Paradigms and Applications”, International
Thomson Computer Press, 1996.
Sitios de consulta en Internet
WWW.EMBoss.org. Sitio WEB del desarrollo de software libre para Biocomputación.
WWW.EMNet.org. Sitio WEB del European Expertise in Biocomputing.
WWW.SDSC.edu.
http://cmgm.stanford.edu/biochem210. Computational Molecular Biology.
