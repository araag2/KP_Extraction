Métricas para la evaluación de performance en procesamiento paralelo
﻿Métricas para la evaluación de performance en 
procesamiento paralelo 
Descripción 
Lic. Marcelo Naiouf, Ing. A. De Giusti 
Laboratorio de Investigación y Desarrollo en Informática1 
Departamento de Informática - Facultad de Ciencias Exactas 
Universidad Nacional de La Plata 
Es común encontrar en la literatura un par de razones por las cuales hacer computación paralela. 
Una de ellas es el límite físico alcanzado por las computadoras secuenciales que hacen 
inaceptable el tiempo necesario para resolver algunos problemas. La otra es que las máquinas 
paralelas a veces permiten resolver problemas que de otra forma no es posible atacar, no tanto por 
la velocidad de cómputo sino por la capacidad de estar "en más de un lugar a la vez". Pero existe 
una tercera razón dada porque este paradigma ofrece la posibilidad de investigación de técnicas 
novedosas para el análisis y diseno de algoritmos. Más allá de la arquitectura de hardware y el 
software de soporte, la mayor importancia está dada en los algoritmos paralelos, y en los métodos 
utilizados para su construcción. 
No es posible hablar de un algoritmo paralelo sin hacer mención al modelo de computación 
paralela para el cual fue diseñado. Esto se debe a que se han propuesto y utilizado una gran 
variedad de modelos teóricos. Los modelos difieren de acuerdo a si los procesadores se 
comunican por memoria compartida o red, si la interconexión es en la forma de un arreglo, un árbol 
o un hipercubo, si los procesadores ejecutan el mismo o distintos algoritmos, si los procesadores 
operan sincrónica o asincrónicamente, etc. La razón obvia para esta diversidad es que ningún 
modelo se ha establecido como standard unificador. Una razón más sutil es que no es probable (ni 
deseable) una máquina paralela universal. Para cada aplicación, hay una computadora paralela 
"óptima". Como resultado, se ha desarrollado un gran campo de investigación y conocimiento en 
esta área. 
Si bien toda computadora paralela tiene más de un procesador, esta diversidad de modelos trae 
aparejada la necesidad de referirse al sistema paralelo, esto es, una combinación de algoritmo y 
arquitectura. Esta diversidad también complica la tarea de medir la performance del sistema 
paralelo. En el "mundo serial", la performance con frecuencia se obtiene mediante los 
requerimientos de tiempo y espacio de un programa. En el mundo paralelo, además de tiempo y 
espacio, hay otra cantidad de medidas. Como resultado, las métricas de performance para 
algoritmos paralelos están ligadas a la arquitectura paralela de destino, y debe hablarse de la 
performance del sistema paralelo. 
Se han propuesto una cantidad de métricas para la evaluación de sistemas paralelos. De todas 
ellas la más conocida es el speedup, dado por el cociente entre el tiempo de ejecución serial y el 
paralelo. De todas maneras, hay variantes en las definiciones de tiempos de ejecución serial y 
paralela, lo que da lugar a al menos 5 definiciones distintas del speedup (relativo, real, absoluto, 
real asintótico y relativo asintótico). Pero además del speedup existen otras medidas, tales como la 
eficiencia de utilización del sistema, el costo, la isoeficiencia, el isospeed, etc. 
En particular, en el caso del speedup se han propuesto distintos modelos de performance, entre los 
que se pueden citar a la "pesimista" Ley de Amdahl (basada en un tamano de problema fijo), la Ley 
de Gustafson (aplicada a problemas escalados, donde el tamano del problema crece con el 
incremento en el tamano de la máquina), y el modelo de speedup de Sun y Ni (para problemas 
escalados acotados en la capacidad de memoria). 
1 Calle 50 y 1151er Piso, (1900) La Plata, Argentina, TE/Fax +(54}(221}422-7707. http:lnidUnfo.unlp.edu.ar 
.... 
En este marco, interesa el tema de evaluar la performance de distintas clases de aplicaciones 
sobre diferentes arquitecturas reales, para obtener resultados concretos, por ejemplo, respecto del 
speedup alcanzable en cada uno de los casos. Esta línea de investigación está incluida en el 
proyecto "Procesamiento Concurrente y Paralelo" del LlDI. 
Objetivos de la línea de investigación 
En este proyecto se realiza investigación sobre la especificación de procesos concurrentes y 
paralelos, la transformación de algoritmos secuenciales en paralelos  sí como su optimización, la 
implementación de los algoritmos paralelizados sobre arquitecturas multiprocesador, y la 
evaluación de performance. Por otra parte, es de interés la aplicación de las investigaciones al 
procesamiento de señales (voz e imágenes). 
En el Laboratorio de Procesamiento Paralelo se cuenta con tres modelos de arquitectura bien 
diferenciados que se utilizan en la investigación experimental: 
Multiprocesador homogéneo con 32 transputers, con la posibilidad de reconfiguración de la 
topología de conexión. 
Red de procesadores heterogéneos, incluyendo PCs y Workstations, y con soporte de 
comunicaciones PVM y MPI para el desarrollo de aplicaciones. 
Arquitectura multiprocesador dedicada basada en procesadores especializados para señales 
(DSPs Motorola 56000 y TMS 340) 
En particular, dentro de la línea descripta en esta presentación, se investiga la paralelización de 
algoritmos sobre los modelos de arquitectura mencionados y fundamentalmente las métricas para 
la evaluación de performance de los sistemas paralelos. El énfasis está puesto en ir de los 
resultados teóricos "ideales" en las métricas a la realidad de la implementación de determinada 
clase de problema sobre una arquitectura particular. 
Muchos de los sistemas paralelos no alcanzan su capacidad teórica para diferentes aplicaciones. 
Las causas de la degradación son muchas y muy variadas. En algunos casos se deben en gran 
medida a la falta de correspondencia entre aplicaciones, software y hardware. Pero también existe 
una variedad de factores que llevan a que no siempre puedan alcanzarse los valores teóricos, y 
que no siempre son tenidos en cuenta en la formulación de una métrica. 
Dentro de estos factores que afectan la performance de un sistema paralelo se encuentran, entre 
otros: 
el desbalance en la carga de trabajo que debe realizar cada proceso/procesador 
el efecto de demora que pueden provocar los puntos de sincronización de procesos 
el overhead de scheduling de procesos en el que incurre el sistema de soporte 
la topología del sistema paralelo 
el efecto que provoca la elección de una granularidad determinada 
la escalabilidad o no del sistema paralelo 
el mapeo de los procesos en los procesadores 
las diferentes maneras de mapear los datos que pueden llevar a más o menos comunicaciones 
los distintos niveles/velocidad de las memorias involucradas en el procesamiento 
Con estos factores en mente, se trata de adecuar las métricas clásicas de evaluación de 
performance a arquitecturas de soporte disponibles. En particular, interesa estudiar el problema del 
efecto que produce el desbalance de carga en el procesamiento de una secuencia de trabajos de 
un tipo de problema (como puede ser distintas operaciones sobre imágenes). En este sentido, se 
trata de determinar la mejor forma de distribuir las tareas, el número óptimo de particiones, la 
conveniencia de variar dinámicamente este número, de manera tal de obtener el mayor speedup 
con buena eficiencia. Este problema incluye varios de los factores que afectan la performance 
mencionados anteriormente. 
Resultados obtenidos 
Dentro de esta linea de investigación en el LlDI se han realizado experiencias desde el afio 1994. 
En esa época se utilizaban redes de PC y Netbios como soporte de comunicaciones, un primer kit 
de 4 transputers, y un simulador de DSP. Estos trabajos apuntaban principalmente a familiarizarse 
con el procesamiento paralelo a través de la resolución de problemas simples como filtrado de 
imágenes, operaciones matriciales, etc. 
Luego se migró de redes de PC y Netbios a la utilización de las máquinas heterogéneas y PVM o 
MPI. Los tipos de problema también fueron creciendo en complejidad y se trabajó por ejemplo 
sobre reconocimiento de patrones. En particular, se obtuvo un buen resultado en la paralelización 
del reconocimiento de objetos tales como frutas en una imagen para su clasificación. En este 
problema se tenia una restricción de "tiempo real", ya que los objetos debían ser reconocidos 
dentro de un limite debido a que se los suponía dentro de una cinta transportadora 
La incorporación del multiprocesador con 32 transputers y de placas multi-DSP abrió nuevas 
posibilidades de investigación en este ámbito. Los problemas incluyeron la paralelización y 
evaluación de algoritmos tales como sort by merge sobre los transputers y la red heterogénea con 
PVM. 
Actualmente los temas abarcan: 
paralelización de algoritmos de seguimiento de. trayectorias de objetos en una secuencia de 
imágenes 
algoritmos clásicos como la búsqueda de camino mínimo en un grafo, paralelizado sobre 
distintas arquitecturas, e incluso con distintas topologías dentro de una misma arquitectura 
paralelización de algoritmos de reconocimiento basado en texturas, los cuales implican un 
procesamiento muy intensivo, del orden de varias horas en máquinas "secuenciales" 
problemas con carga balanceada y desbalanceada, y distribución estática y dinámica de 
procesos 
evaluación de la performance de los sistemas mencionados, estudiando el impacto sobre las 
métricas tradicionales 
Bibliografía 
[AkI89] Akl S, "The Design and Analysis of Parallel Algorithms", Prentice-Hall, Inc., 1989. 
[AkI97] Akl S, "Parallel Computation. Models and Methods", Prentice-Hall, Inc., 1997. 
[Amd67] Amdahl G., "On the Validty of the Single-Processor Approach to Achieving Large-SCALE 
Computing Capabilities", Proc. Of the AFIPS Conference, 1967, pp. 483-485 
[Bri95] Brinch Hansen, P., "Studies in computational science: Parallel Programming Paradigms", 
Prentice-Hall, Inc., 1995. 
[Bub97] Bubak M., Funika W., Moscinski J., "Performance Analysis of Parallel Applications under 
Message Passing Environments", www.icsr.agh.edu.pl/publications/html/perf_full/perf_full.html. 
1997 
[Cha88] Chandi K. M., Misra J., "Parallel Program Design. A Foundation", Addisson Wesley, 1988. 
[Cof92] M. Coffin, "Parallel programming- A new approach", Prentice Hall, Englewood Cliffs, 1992. 
[CoI96] Colbrook A., Brewer E., Dellarocas C., Weihl W., "Algorithms tor Search Trees on Message­
Passing Architectures", IEEE Transactions on Parallel and Distributed Systems, Vol. 7, No. 2: 
February 1996, pp. 97-108 
[CSA90] "Transputer Architecture", Computer System Architects, 1990. 
[Day94] Day K., Tripathi A., "A Comparative Study of Topological Properties of Hypercubes and 
Star Graphs" IEEE Trans. Parallel and Distributed Systems, vol. 5, no. 1, pp. 31-38, Jan. 1994 
[Don94] Dongarra J., et al, "PVM: Parallel Virtual Machine, A User's Guide and Tutorial for 
Neworked Parallel Computing", MIT Press, 1994. 
[Fly72] Flynn M. J., "Sorne Computer Organizations and Their Effectiveness", IEEE Transactions on 
Computen;, C-21, No 9, September, 1972. ' 
[Gup93] Gupta A, Kumar V., "Performance properties of large scale parallel systems", Journal of 
Parallel and Distributed Computing, November 1993. 
[Gus88] Gustafson J., "Reevaluating Amdahl's Law" , Comm. Of the ACM, Volume 31 (1988), pp. 
532-533. 
[Gus92] Gustafson J. L., "The consequences of fixed time performance measurement", 
Proceedings of the 25th Hawaii International Conference on System Sciences, Volume 111, pp 113124, 1992. 
[Hoa85] Hoare C, "Communicating Sequential Pror;esses", Englewood Cliffs, Prentice-Hall, 1985. 
[Hwa93] Hwang K., "Advanced Computer Architecture: Paralelism, Scalability, Programability", 
McGraw-Hill, 1993. 
[Kar92] Karonis N, "Timing Parallel Programs That Use Message Passing", Journal of Parallel and 
Distributed Computing, 14, 1992. 
[Kum94] Kumar V., Grama A, Gupta A, Karypis G., "Introduction to Parallel Computing. Desing 
and Analysis of Algorithms", Benjamin/Cummings, 1994. 
[Kun91] Kung H. T., Sansom R., Schlick S., Steenkiste P., Arnould M., Bitz F. J., Christianson F., 
Cooper E. C., Menzilcioglu O., Ombres D., and Zill B., "Network-Based Multicomputers: An 
Emerging Parallel Architecture" Proc. Supercomputing '91, pp. 664-673. IEEE, Albuquerque, Nov. 
1991. ' 
[Law92] H. Law50n, "Parallel processing in industrial real time applications", Prentice Hall 1992. 
[Lei92] Leighton F.' T., "Introduction to Parallel Algorithms and Architectures: Arrays, Trees, 
Hypercubes", Morgan Kaufmann Publishers, 1992. 
[Log94] "Transputer Toolset", Logical System, 1994. 
[Luq93] Luque E, Senar M, Hernandez P, Franco D, Heymann E, Moure J, "Distributed Kernel for a 
Transputer Based Computer", Transputers Applications and Systems'93. Vol 2, lOS Press, 1993. 
[Luq95] Luque E, Ripoll A, Cortés A, Margalef T, "A Distributed Diffusion Method for Dynamic Load 
Balancing on Parallel Computers", Proceedings of the EUROMICRO Workshop on Parallel and 
Distributed Processing, IEEE Computer Society, Jan. 1995. 
[Mi198] Miller R., Stout a. F., "Algorithmic Techniques for Networks of Processors", CRC Handbook 
of Algorithms and Theory of Computation, M. J. Atallah, ed, 1998. 
[Mor94] Morse F., "Practical Parallel Computing", AP Pl'ofessional, 1994. 
[Nig95] Nigam M., Sahni S., "Sorting n2 Numbers on n x n Meshes", IEEE Transactions on Parallel 
and Distributed Systems, Vol. 6, No. 12: December 1995, pp. 1221-1225 
[Sim97] Sima D, Fountain T, Kacsuk P, "Advanced Computer Arch itectu res. A Design Space 
Approach", Addison Wesley Longman Limited, 1997. 
[Ste96] Steenkiste P., "Network-Based Multicomputers: A Practical Supercomputer Architecture", 
IEEE Transactions on Parallel and Distributed Systems, Vol. 7, No. 8, August 1996, pp. 861-875 
[Sun90] Sun X., Ni,L. M., "Another view of parallel speedup", Supercomputing "90 Proceedings, pp 
324-333, 1990. 
[Sun95] Sun X., Zhu J.,"Performance Considerations of Shared Virtual Memory Machines", 
Transactions on Parallel and Distribued Systems, Vol 6, No. 11: November 1995, pp. 1185-1194. 
[Tin98] Tinetti F., De Giusti A, "Procesamiento Paralelo. Conceptos de Arquitectura y Algoritmos", 
Editorial Exacta, 1998. 
[Zom96] Zomaya A (ed), "Parallel Computing. Paradigms and Applications", International Thomson 
Computer Press, 1996. 
.,/ 
1, 
.tI 
