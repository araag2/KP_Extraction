Investigación en sistemas paralelos
﻿
 
El objetivo de esta línea es investigar en Sistemas Paralelos, esto es, la combinación de problemas de software 
asociados con la utilización de arquitecturas de procesamiento paralelo, especialmente sistemas multiprocesador 
distribuidos (como clusters y multiclusters). 
Los temas fundamentales abarcan la especificación, transformación, optimización y verificación de algoritmos 
ejecutables en sistemas paralelos/distribuidos, la optimización de clases de soluciones en función de modelos de 
arquitectura multiprocesador, las métricas de complejidad y eficiencia relacionadas con el procesamiento paralelo, la 
influencia del balance de carga y la asignación de tareas a procesadores, la escalabilidad de los sistemas paralelos, los 
modelos de predicción de performance en sistemas paralelos, así como aspectos de simulación y diseño de arquitecturas 
VLSI orientadas a multiprocesamiento. 
Interesa la aplicación de las investigaciones en áreas con procesamiento masivo de datos tales como cómputo científico,  
procesamiento de imágenes digitales, bases de datos distribuidas, reconocimiento de patrones en secuencias y 
algoritmos no numéricos complejos. Para esto, se trabaja experimentalmente con distintos modelos de arquitectura 
disponibles o accesibles desde el III-LIDI y arquitecturas disponibles en distintas Universidades del país y el exterior 
con las cuales se tienen convenios de cooperación. 
El proyecto está financiado por la Universidad Nacional de La Plata, la Comisión de Investigaciones Científicas de la 
Provincia de Buenos Aires y la Agencia Nacional de Promoción Científica y Técnica. 
 
Introducción 
 
Actualmente es innegable la importancia y el creciente interés en el procesamiento paralelo y 
distribuido dentro de la Ciencia de la Computación por un gran número de razones (crecimiento de 
la potencia de cálculo dada por la evolución tecnológica, transformación y creación de algoritmos 
que explotan la concurrencia para obtener mejores tiempos de respuesta, la necesidad de tratar 
sistemas de tiempo real distribuidos, el límite físico de las máquinas secuenciales que convierte a la 
solución paralela en la única factible, etc).  
 
En términos generales las máquinas paralelas permiten resolver problemas de complejidad creciente 
y obtener resultados con mayor velocidad. Las mismas ofrecen soluciones más rápidas, permitiendo 
pueden resolver problemas más grandes y complejos cuyos datos de entrada o resultados 
intermedios exceden la capacidad de memoria de un procesador, las simulaciones pueden ser 
ejecutarse con mayor resolución, los fenómenos físicos pueden ser modelados de manera más 
                                                          
1 Investigador Principal CONICET. Profesor Titular. 
2 Profesor Titular. 
3 Becaria de Formación Superior UNLP. Jefe de Trabajos Prácticos. 
4 Becario de Perfeccionamiento UNLP. Jefe de Trabajos Prácticos. 
5 Profesor Adjunto. 
6 Becario de Iniciación UNLP. Ayudante Diplomado. 
7 Ayudante Diplomado. 
8 Profesor Asociado. 
9 Jefe de Trabajos Prácticos. 
10 III-LIDI - Facultad de Informática. UNLP - Calle 50 y 115 1er Piso, (1900) La Plata, Argentina.  
  TE/Fax +(54)(221)422-7707. http://www.lidi.info.unlp.edu.ar 
 
realista. En algunos casos el costo del paralelismo puede ser alto en términos del esfuerzo de 
programación requerido, en muchos casos debe pensarse en la aplicación de técnicas novedosas 
reescribiendo completamente el código serial, y las técnicas de debugging y tuning de performance 
“secuenciales” no se extienden fácilmente al mundo paralelo.  
 
Se debe hacer referencia a sistemas paralelos como la combinación de algoritmo y arquitectura, ya 
que a diferencia del cómputo secuencial donde el modelo RAM es aceptado prácticamente como 
standard, en el paralelismo no se encuentra un modelo unificador ya que cada uno enfatiza 
determinados aspectos en desmedro de otros. Las diferentes arquitecturas (memoria compartida o 
distribuida, procesadores homogéneos o heterogéneos, topologías de conexión, etc.) hacen que en el 
desarrollo de las soluciones paralelas sea indispensable considerar la combinación de ambos 
factores. 
 
La última etapa en el desarrollo de algoritmos paralelos es el mapeo de procesos en procesadores; 
los objetivos son mejorar la utilización de los procesadores y obtener el mejor tiempo de respuesta 
de la aplicación realizando la distribución de manera que la carga computacional tienda a ser 
equitativa (balanceada) en el tiempo. Este es uno de los aspectos centrales del procesamiento 
paralelo, pues producen un impacto directo en el uso eficiente de los recursos (que implican costo) 
y las mejoras de performance alcanzables. 
 
La performance obtenida en el sistema paralelo está dada por una compleja relación en la que 
intervienen una gran cantidad de factores: el tamaño del problema, la arquitectura de soporte, la 
distribución de procesos en procesadores, la existencia o no de un algoritmo de balanceo de carga, 
etc. Existen numerosas métricas para evaluar sistemas paralelos; entre ellas se encuentran tiempo 
efectivo, speedup, eficiencia, producto procesador-tiempo (costo), overhead paralelo, grado de 
concurrencia, escalabilidad, isoeficiencia, isospeed, etc.  
 
En esta línea de investigación es de interés la evaluación de performance de distintas clases de 
aplicaciones sobre las arquitecturas disponibles, de modo de verificar los resultados teóricos 
predichos. Esto se basa en que muchos sistemas paralelos no alcanzan su capacidad teórica, y las 
causas de esta degradación son muchas y no siempre fáciles de determinar. El análisis permite 
estudiar el impacto que tienen estos factores sobre las implementaciones, y adecuar las métricas 
clásicas a las mismas. En particular, se estudia la influencia de las estrategias de distribución de 
procesos y datos, y la carga (estática o dinámica) asignada a cada procesador sobre el speedup, la 
eficiencia y la escalabilidad. Más allá de las características algorítmicas de las aplicaciones, el 
rendimiento real y por lo tanto el tiempo necesario para resolver los problemas dependerá de la 
arquitectura de procesamiento elegida para la implementación.  
 
En la actualidad, la utilización de arquitecturas de clusters de PCs o workstations tienen un gran 
auge debido a la relación costo-performance alcanzada. El poder conectar diferentes máquinas a 
través de redes locales (LAN) o extendidas (WAN) genera la creación continua de nuevas 
arquitecturas (homogéneas o heterogéneas, cluster único o multicluster, locales o extendidos, y sus 
combinaciones). Los problemas clásicos mencionados (performance, escalabilidad, overhead de 
comunicaciones, etc) se ven potenciados por las dificultades propias de la red de comunicación 
utilizada. 
 
Los temas presentados se enmarcan en el Proyecto “Procesamiento Concurrente y Paralelo” del 
Instituto de Investigación en Informática LIDI, y existen convenios de cooperación en estos temas 
de interés común con varias Universidades del país y del exterior. 
 
Líneas de Investigación y desarrollo 
 
• Algoritmos paralelos. Paralelización de aplicaciones, incluyendo su adecuación a diferentes 
modelos de arquitectura. Optimización de algoritmos. 
• Paradigmas de programación paralela orientados a la arquitectura de soporte. 
• Estudio de las diferentes métricas de evaluación de performance de sistemas paralelos. Abarca 
el análisis de la complejidad de los algoritmos, el rendimiento de las soluciones paralelas y la 
caracterización de los modelos de performance asociados.  
• Modelos de predicción de performance en sistemas paralelos. Análisis de la respuesta de los 
modelos para clases de arquitecturas reconocidas. 
• Análisis de los problemas de migración y asignación óptima de procesos y datos a procesadores. 
Migración dinámica. Balance de carga estático y dinámico. 
• Caracterización de la performance de las comunicaciones sobre diferentes plataformas (clusters, 
multiclusters). 
• Desarrollo de aplicaciones en clusters dedicados y no dedicados. Análisis de la eficiencia de las 
soluciones. 
• Investigación aplicada en temas de procesamiento paralelo sobre arquitecturas multicluster. 
Migración de soluciones paralelas a este tipo de arquitecturas y estudio de la performance. 
• Grid computing. Impacto de este paradigma en la resolución de aplicaciones paralelas. 
• Modelos de Memoria en arquitecturas paralelas (compartida, parcialmente compartida, 
totalmente distribuida). 
• Simulación de arquitecturas VLSI para multiprocesamiento a nivel circuito integrado, tendientes 
a migrar a hardware procesos de administración de recursos compartidos propios de las capas 
bajas de los sistemas operativos. Lenguajes de simulación/especificación.  
• Aplicación de las investigaciones en áreas como el procesamiento de datos numéricos en 
cómputo científico, el procesamiento de imágenes digitales, las bases de datos distribuidas, 
reconocimiento de patrones en bases de datos de secuencias (por ejemplo en los casos de 
investigación sobre genoma, ADN), reconocimiento de patrones de identificación (rostros, 
huellas digitales). 
 
Resultados obtenidos/esperados 
 
• Desarrollo de soluciones a los problemas mencionados sobre diferentes modelos de arquitectura 
(cluster y multiclusters homogéneos y heterogéneos, multiprocesadores con memoria 
compartida distribuida tipo SGI Origin 2000). Evaluar la eficiencia, rendimiento y speedup 
obtenido. 
• Resolver problemas concretos que requieren procesamiento paralelo en el área médica, en el 
área de tratamiento de señales en tiempo real, en cómputo numérico y en procesamiento de 
bases de datos distribuidas. Realizar transferencia de los resultados. 
• Potenciar las investigaciones sobre procesamiento en cluster desarrolladas en el III-LIDI 
abriendo una línea en arquitecturas multicluster conectadas vía Internet e Internet 2. 
• Investigar la migración de aplicaciones paralelas conocidas a esquemas multicluster. Estudiar la 
necesidad de transformar los algoritmos, su escalabilidad, balance de carga y el efecto de la 
heterogeneidad del hardware.  
• Esutdiar los modelos de predicción de performance con diferentes paradigmas de interacción 
entre procesos, en esquemas de cluster y multicluster.  
• Extender soluciones de balance dinámico de carga a esquemas multicluster 
• Caracterizar el modelo y rendimiento en el subsistema de comunicaciones y su impacto en la 
performance y potencia de cómputos del esquema multicluster. 
• Plantear modelos de arquitectura VLSI orientados a multiprocesamiento “on-chip” y estudiar su 
comportamiento teórico mediante simulación. Analizar la migración de algoritmos de software 
para tratamiento de señales en tiempo real a hardware dedicado. 
• Desarrollar herramientas de soporte y conexiones concretas multicluster con grupos de I/D en 
Universidades del país y del exterior. 
• Formar recursos humanos en los temas de Procesamiento Concurrente y Paralelo, incluyendo 
Tesis de Postgrado. 
 
Formación de Recursos Humanos 
 
En el marco de esta línea de investigación se han concluido dos Tesis Doctorales, se espera concluir 
otras dos en 2006, y se están iniciando un par durante el corriente año. En todos los casos se cuenta 
con Directores o Codirectores del exterior.  
 
Por otra parte, se desarrollan permanentemente Tesinas de Grado de Licenciatura en Informática 
(unas 5 por año) vinculadas con los temas de investigación y desarrollo presentados. 
 
Bibliografía Básica  
[AKL97] Akl S, “Parallel Computation. Models and Methods”, Prentice-Hall, Inc., 1997. 
[ALP95] Alpern B., L. Carter, J. Ferrante, “Space-limited procedures: A methodology for portable high-performance”, 
International Working Conference on Massively Parallel Programming Models, 1995. 
[AND95] Anderson T., Culler D., Patterson D., NOW Team, “A Case for NOW (Networks of Workstations)”, IEEE 
Micro, 15(1), 1995, pp. 54-64. 
[AND00] Andrews.“Foundations of Multithreaded, Parallel and Distributed Programming”, Addison Wesley, 2000 
[AUG02] P. Augerat, C. Martin, B. Stein. “Scalable monitoring and configuration tools for grids and clusters”. 10th 
Euromicro Workshop on Parallel,Distributed and Network-Based Processing, 2002. 
[BAK99] Baker M., G. Fox, “Metacomputing: Harnessing Informal Supercomputers”, in R. Buyya Ed., High 
Performance Cluster Computing: Architectures and Systems, Vol. 1, Prentice-Hall, Upper Saddle River, NJ, USA, pp. 
154-185, 1999. 
[BAN98] Banikazemi M., V. Moorthy, D. Panda, “Efficient Collective Communication on Heterogeneous Networks of 
Workstations”, Proc. International Conference on Parallel Processing, pp. 460-467, 1998. 
[BAR99] Barak A., La’adan O., Shiloh A., “Scalable Cluster Computing with MOSIX for LINUX”. 1999. 
[BUB97] Bubak, Funika, Moscinski, “Performance Analysis of Parallel Applications under Message Passing 
Environments”, www.icsr.agh.edu.pl/publications/html/perf_full/, 1997 
[CAM99] Campos L.M., Scherson I., "Rate of Change Load Balancing in Distributed and Parallel Systems", 
Proceedings of the 13th International Parallel Processing Symposium and 10th Symposium on Parallel and Distributed 
Processing, San Juan, Puerto Rico, 1999, 701-707 
[CAS96] Castleman, K, “Digital Image Processing.” Prentice Hall.1996 
[CHA88] Chandy, Misra, “Parallel Program Design. A Foundation”, Addison Wesley, 1988. 
[CHI99] Chiola G., G. Ciaccio, “Lightweigth Messaging Systems”, in R. Buyya Ed., High Performance Cluster 
Computing: Architectures and Systems, Vol. 1, Prentice-Hall, Upper Saddle River, NJ, USA, pp. 246-269, 1999. 
[COAXX] Communications of the ACM (colección de revistas) 
[COMXX] IEEE Computer (colección de revistas) 
[COSSXX] IEEE Communications society (colección de revistas) 
[COCXX] IEEE Concurrency (colección de revistas) 
[COR99] Corradi A., Leonardi L., Zambonelli F., "Diffusive Load-Balancing Policies for Dynamic Applications", IEEE 
Concurrency, 7(1), Jan-Mar 1999, 22-31. 
[CUL93] Culler D., Karp R., Patterson D. Sahay A., Schauser K., Santos E. Subramonian R., von Eicken T., “LogP: 
Towards a Realistic Model of Parallel Computation”, SIGPLAN Notices (USA), 28(7), 1993, pp. 1-12. 
[GEI94] Geist Al, Beguelin A., Dongarra J., Jiang W., Manchek R., Sunderam V., “PVM: Parallel Virtual Machine. A 
Users' Guide and Tutorial for Networked Parallel Computing “, The MIT Press, Cambridge, Massachusetts. 1994.  
[GOL02] Goldman. “Scalable Algorithms for Complete Exchange on Multi-Cluster Networks”. In: CCGRID'02, 
IEEE/ACM, Berlin, p. 286 - 287, 2002. 
[GRA03] Grama A., Gupta A., Karypis G., Kumar V., "An Introduction to Parallel Computing. Design and Analysis of 
Algorithms", Pearson Addison Wesley, 2nd Edition, 2003  
[HOA85] Hoare C., “Communicating Sequential Processes”, Englewood Cliffs, Prentice Hall, 1985 
[HWA93] K. Hwang, "Advanced Computer Architecture. Parallelism, Scalability, Programmability", McGraw Hill, 
1993. 
[HWA98] Hwang K., Xu Z., “Scalable Parallel Computing”, McGraw-Hill, 1998. 
[JAI00] Jain A.K., Duin R.P.W., Jianchang M., "Statistical pattern recognition: a review,"  IEEE Trans. Pattern Anal. 
Mach. Intell. 22 (1) (2000) 4-37. 
[JIA97] Jiang and D. Yeung,  “Scalable Inter-Cluster Communication System for Clustered Multiprocessors”. 1997. 
[JOR02] Jordan H.F., Alaghband G., Jordan H.E., "Fundamentals of Parallel Computing", Prentice Hall, 2002 
[KAF98] Kafil M., Ahmad I., "Optimal Task Assignment in Heterogeneous Distributed Computing Systems", IEEE 
Concurrency, 6(3), Jul-Sep 1998, 42-51 
[KAR02] N. Karonis, B. Toonen, and I. Foster .”MPICH-G2: A Grid-Enabled Implementation of the Message Passing 
Interface”, Journal of Parallel and Distributed Computing (JPDC), Vol. 63, No. 5, pp. 551-563, May 2003. 
[KUN91] Kung H. T., Sansom R., Schlick S., Steenkiste P., Arnould M., Bitz F. J., Christianson F., Cooper E. C., 
Menzilcioglu O., Ombres D., and Zill B., “Network-Based Multicomputers: An Emerging Parallel Architecture” 
[KUR03] Kurmann C., Rauch F. Stricker M., "Cost/Performance Tradeoffs in Network Interconnects for Clusters of 
Commodity PCs", Technical Report No. 391, Swiss Federal Institute of Technology Zurich, Institute for Computer 
Systems, January 2003  
[LEE97] Lee C-H., Shin K.,"Optimal Task Assignment in Homogeneous Networks", IEEE Transactions on Parallel and 
Distributed Systems, 8(2), February 1997, 119-129 
[LEI92] Leighton F. T., “Introduction to Parallel Algorithms and Architectures: Arrays, Trees, Hypercubes”, Morgan 
Kaufmann Publishers, 1992. 
[LEO01] Leopold C., "Parallel and Distributed Computing. A survey of Models, Paradigms, and Approaches", Wiley 
Series on Parallel and Distributed Computing. Albert Zomaya Series Editor, 2001 
[LIA00] Lian D-R., Tripathi S., "On Performance Prediction of Parallel Computations with Precedent Constraints", 
IEEE Transactions on Parallel and Distributed Systems, 11(5), May 2000, 491-508 
[MPI97] MPI Forum, “MPI-2: Extension to the MPI”, University of Tennesse Knoxville, 1997. 
[OLI02] Olivier Aumage, “Heterogeneous Multi-Cluster Networking with the Madeleine III Communication Library”. 
IPDPS 2002. 
[PFI98] Pfister G., “In Search of Clusters”, Prentice Hall, 2nd Edition, 1998. 
[SGIXX] SGI, “SGI Origin 2000”, www.sgi.com. 
[SHO03] Shoji Ogura, Hidemoto Nakada, Satoshi Matsuoka,  “Evaluation of the inter-cluster data transfer on Grid 
environment”, Proceedings of CCGrid 2003 , pp. 374-381, May 2003. 
[SIM97] Sima D, Fountain T, Kacsuk P, “Advanced Computer Architectures. A Design Space Approach”, Addison 
Wesley Longman Limited, 1997.  
[SKI96] Skillicorn, D.B., Hill, J., McColl, W.F. Questions and Answers about BSP.  Oxford University Computing 
Laboratory. Report PRG-TR-15-96. 96.  
[SNI96] Snir M., Otto S., Huss-Lederman S., Walker D., Dongarra J., “MPI: The Complete Reference”, The MIT Press, 
Cambridge, Massachusetts ,1996. 
[SUN99] Sun X-H., Pantano M., Fahringer T., Zhan Z., "SCALA: A Framework for Performance Evaluation of 
Scalable Computing", Proceedings of the 4th Workshop on High Level Parallel Programming Models and Supportive 
Environments (HIPS 99), Lecture Notes in Computer Science No. 1586, Springer Verlag, 1999, 49-62" 
[TIN98] Tinetti F., De Giusti A., "Procesamiento Paralelo. Conceptos de Arquitectura y Algoritmos", Editorial Exacta, 
1998. 
[TFC04]  IEEE Task Force on Cluster Computing (www.ieeetfcc.org) 
[TPDXX] IEEE Transactions on Parallel and Distributed Processing (colección de revistas) 
[VAL90] Valiant L, “A Bridging Model for Parallel Computation”, Commnications of the ACM, 33(8), 1990, pp. 103111. 
[WAT98] Watts J., Taylor S., "A Practical Approach to Dynamic Load Balancing", IEEE Transactions on Parallel and 
Distributed Systems, 9(3), March 1998, 235-248 
[WIL99] Wilkinson B., Allen M., Parallel Programming: Techniques and Applications Using Networking 
Workstations, Prentice-Hall, Inc., 1999. 
[ZOM96] Zomaya A., “Parallel Computing. Paradigms and Applications”, Int. Thomson Computer Press, 1996. 
