Combinando revisión de creencias y argumentación para mejorar las capacidades de razonamiento de agentes en sistemas multi agente
﻿
Esta línea de investigación se enfoca en
mejorar las capacidades de razonamiento de
agentes que participan en Sistemas MultiAgente (SMA). Su objetivo general es desarrollar técnicas de razonamiento avanzadas, combinando revisión de creencias y argumentación
para su aplicación en SMA. En particular, se
espera poder integrar y combinar los avances
producidos en las áreas de revisión de creencias
y teoría de argumentación. Dicha integración
permitirá realizar un avance en ambas áreas
de investigación, y además, proveerá de técnicas avanzadas aplicables a los modelos de razonamiento de agentes inteligentes y sistemas
multi-agente para entornos dinámicos.
Palabras Clave: Argumentación, Revisión de
Creencias, Sistemas Multi-Agente.
2. Contexto
Esta línea de investigación se desarrolla dentro del marco del proyecto de investigación
bilateral titulado “Combinando Revisión de
Creencias y Argumentación para mejorar las
capacidades de razonamiento de agentes en
Sistemas Multi-Agente”, en la cual participan todos los autores del presente trabajo, y
está coordinado por el Laboratorio de Investigación y Desarrollo en Inteligencia Artificial
(LIDIA), del Depto. de Ciencias e Ingeniería
de la Computación de la Universidad Nacional
del Sur (Argentina) y Facultät für Informatik,
Techniscshe Universität (Dortmund, Alemania). Este proyecto es dirigido por Dr. Alejandro Javier García y Dr. Gabrielle Kern Isberner y es financiado por el Ministerio de Ciencia, Tecnología e Innovación productiva (MinCyT, Argentina) conjuntamente con Deutzcher Akademischer Austausch Dienst (DAAD,
Alemania).
3. Introducción
Los SMA han cobrado una creciente relevancia como un paradigma general para resolu1
ción de problemas distribuidos y para la coordinación de unidades autónomas e inteligentes
(agentes) [19]. Los SMA que modelan escenarios del mundo real, son dinámicos y generalmente trabajan con información incierta o
incompleta. Por lo tanto, actuar en tales escenarios demanda una capacidad de razonar
rebatiblemente, i.e., los agentes deben ser capaces de revisar sus creencias o las conclusiones
obtenidas previamente. De esta manera, podrán mantener un modelo adecuado y consistente del entorno en el que están insertos. Más
aún, para que los agentes puedan llevar a cabo
sus metas, deben poder decidir entre las posibles opciones que se les presentan a fin de elegir
la más promisoria.
Como los sistemas de argumentación resultan particularmente útiles para toma de decisiones, tales deliberaciones pueden modelarse
de una forma dialéctica usando argumentos a
favor y en contra de cada opción [10, 12, 5,
6, 18, 16, 3, 4]. Dado que el razonamiento y
la toma de decisiones son componentes centrales dentro de una arquitectura de un agente,
nuestra línea de investigación pretende establecer vínculos estrechos entre estos dos componentes para poder mejorar la coherencia dentro de un modelo de agentes. Desde el punto
de vista teórico, elaborar tales conexiones entre argumentación y revisión de creencias, y
poder aplicarlas a los SMA, permitirá un progreso científico substancial en el campo de la
representación de conocimiento [17, 2, 14].
Tanto revisión de creencias como argumentación son áreas de investigación muy activas en Inteligencia Artificial. El estudio de
los vínculos y relaciones entre ambas áreas ha
comenzado hace muy poco. Aunque ya existen en la literatura comentarios [8, 11] de que
ambas áreas podrían combinarse con buenos
resultados, el tema carece de resultados importantes. Por lo tanto, con la línea de investigación propuesta se esperan obtener resultados
relevantes en el área de razonamiento y representación de conocimiento, los cuales ayuden a
mostrar la importancia de combinar e integrar
ambos temas.
Por ejemplo, las técnicas de revisión de
creencias proveen a los agentes la capacidad
de corregir sus creencias cuando existe una discrepancia con la información nueva que pueden
obtener de su entorno [1, 7, 9, 15]. Uno de los
resultados esperados es mejorar los sistemas de
revisión de creencias utilizando argumentación
para evaluar si es importante que la nueva información obtenida sea incorporada o no a las
creencias del agente. Otro de los resultados esperados, es poder utilizar argumentos en el
proceso de revisión para poder decidir cuales
creencias deben ser eliminadas ante la presencia de una contradicción.
Los formalismos de argumentación ofrecen
una metodología natural para razonar evaluando diferentes puntos de vista, y proveen herramientas para tomar decisiones y resolver conflictos. Sin embargo, en la actualidad los sistemas multi-agente carecen de técnicas avanzadas para reaccionar ante cambios en un entorno dinámico y poder evaluar argumentos
para la toma de decisiones. Por lo tanto, se espera que las áreas de revisión de creencias y argumentación puedan complementarse, y también puedan ser usadas en forma combinada
para resolver problemas en escenarios complejos de sistemas multi-agente que exceden el alcance de cada área en forma individual.
4. Líneas de Investigación
y Desarrollo
La línea principal de investigación presentada en este trabajo, busca mejorar las capacidades de razonamiento de agentes que participan en Sistemas Multi-Agente (SMA) a
través de la integración de mecanismos argumentativos y de revisión de creencias. Su objetivo es desarrollar formalismos avanzados de
representación de conocimiento y razonamiento basados en una combinación entre argumentación y revisión de creencias. En particular, de esta línea principal se desprenden cuatro
sub-líneas de investigación:
L1) Desarrollar métodos para equipar a los sistemas de argumentación con la posibilidad
de tener en cuenta cambios dinámicos; integrando, de esta manera, técnicas de revisión de creencias a la argumentación rebatible. Esto permitirá obtener un formalismo que puede ser utilizado para aplicaciones prácticas y permitirá realizar argumentación en entornos dinámicos.
L2) Desarrollar un sistema formal que permita describir postulados y propiedades
deseables. Este formalismo permitirá establecer una forma de catalogar y evaluar propuestas de argumentación para entornos dinámicos. En particular nos permitirá evaluar la propuesta de la línea L1
y compararla con otras propuestas diferentes.
L3) Mejorar los sistemas de revisión de creencias utilizando argumentación para evaluar información nueva que es obtenida,
y utilizar argumentos en el proceso de
revisión. Esto incluye el estudio de la
relación de entre “em epistemic entrechment” y “defeat” como los conceptos que
guien los procesos de revisión y argumentación.
L4) La revisión de creencias en un entorno
distribuido y con múltiples agentes heterogéneos podría mejorarse usando argumentación. En este caso, la revisión y argumentación no es llevada a cabo por un
agente, sino por un grupo de agentes. Por
lo tanto esta línea estudiará como varios agentes pueden cambiar de opinión si
hay un intercambio de argumentos. En
particular, la revisión de creencias en sistemas multi-agente puede ser extendida
con técnicas de argumentación tanto a
nivel teórico como práctico.
5. Resultados y Objetivos
Los resultados alcanzados hasta el momento
involucran principalmente a la línea de investigación L1, aunque parte del objetivo L2 ya
se ha desarrollado y está actualmente en proceso, al igual que la línea L3. Todos los resultados obtenidos hasta el momento relativos a
las líneas L1 y L2 han sido publicados en [13].
Los resultados de línea L3 han sido plasmados en un artículo enviado a un workshop de
la especialidad y se encuentra en proceso de
evaluación.
Entre los resultados específicos referentes
a las líneas L1 y L2 se encuentra la definición de operadores de contracción para modelar la dinámica de los programas lógicos rebatibles (DeLP) [12]. DeLP es un formalismo
que combina argumentación rebatible y programación en lógica; y este operador de contracción está definido siguiendo trabajos de operadores de contracción para claúsulas Horn.
En particular, se estudio el problema de contraer literales en un programa DeLP. Se desarrollaron diferentes nociones de contracción en
base a las diferentes formas de deducción implícitas en un proceso argumentativo y la influencia que pueden exhibir los literales en el proceso de razonamiento. Para estos operadores de
contracción se han presentado postulados de
racionalidad basados en los ampliamente aceptados en el área de revisión de creencias [1].
En relación a los resultados obtenidos para
la línea de investigación L3, se estudio un operador de revisión no priorizada que utiliza argumentación para decidir que parte de la nueva información será utilizada para revisar. En
este contexto, conocido como revisión selectiva, hay dos pasos: primero aplicar una función
de transformación para decidir que parte de
la entrada utilizar y luego incorporar el resultado de la primera utilizando un operador de
revisión priorizada. Por lo tanto se implemento
una transformación que emplea argumentación
deductiva para evaluar el peso de la nueva información. Hemos probado que el operador implementado satisface propiedades deseables en
revisión selectiva.
Además, se trabajó en la confección de otros
dos artículos que vinculan argumentación y revisión de creencias, proponen nuevas líneas de
investigación y realizan un análisis del estado
del arte de estas dos áreas de trabajo. Estos
dos artículos están en proceso de evaluación
en The Knowledge Engineering Review Journal (KER) y Journal of Philosophical Logic
(JPL).
Respecto a los objetivos en curso de esta
investigación, se dará una caracterización formal completa de los mecanismos creados en las
líneas L1, L2 y L3. Además, se comenzará con
el estudio y desarrollo de un modelo de revisión
de creencias distribuido para sistemas multiagente combinado con argumentación. Para esto se utilizarán y consolidarán los desarrollos
previos en las líneas L1, L2 y L3. Este objetivo está relacionado con la revisión de creencias
en un entorno distribuido, donde el procesos
de revisión con múltiples agentes heterogéneos
podrían mejorarse usando argumentación. En
este caso, la revisión y argumentación no son llevadas a cabo por un agente, sino por un grupo
de agentes. Estudiaremos como varios agentes
pueden cambiar de opinión si hay un intercambio de argumentos y así revisar dinámicamente
su conocimiento.
