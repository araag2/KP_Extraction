Búsquedas indexadas en texto
﻿
Uno de los principales problemas al que nos
enfretamos al indexar una base de datos de texto es que el índice ocupa más espacio que el
texto a indexar, pudiendo alcanzar de 4 a 20
veces el tamaño del mismo. Una alternativa
para reducir el espacio ocupado por el índice es buscar una representación compacta del
mismo. Pero en grandes colecciones de texto,
el índice aún comprimido suele ser demasiado
grande como para residir en memoria principal. En estos casos, la cantidad de accesos a
discos realizados durante el procesamiento de
una consulta resulta crítica para la performance del índice. Nuestro ámbito de investigación
es el estudio de índices comprimidos y en memoria secundaria para búsquedas en texto.
Palabras claves: Bases de Datos de Texto,
Índices, Compresión, Memoria Secundaria.
1. Contexto
El presente trabajo se desarrolla en el ámbito de la línea Técnicas de Indexación para Datos no Estructurados del Proyecto Tecnologías
Avanzadas de Bases de Datos, cuyo objetivo principal es realizar investigación básica en
problemas relacionados al manejo y recuperación eficiente de información no tradicional.
2. Introducción
Una base de datos de texto es un sistema
que mantiene una colección grande de texto,
y provee acceso rápido y seguro al mismo.
Las búsquedas en la que el usuario ingresa un
patrón de búsqueda y el sistema retorna todas
las posiciones del texto donde el patrón ocurre,
es una de las búsquedas más comunes en este
tipo de bases de datos. Las tecnologías tradicionales de bases de datos no ofrecen una solución viable en este contexto, dado que no es
posible organizar una colección de texto en registros y campos. Sin pérdida de generalidad,
asumiremos que la base de datos de texto es
un único texto T posiblemente almacenado en
varios archivos.
Dado un texto T = t1, . . . , tn sobre un alfabeto Σ de tamaño σ, donde tn = $ /∈ Σ
es un símbolo menor en orden lexicográfico que cualquier otro símbolo de Σ, denotaa    b    c    c    a    b    c    a    $ Texto=
Arreglo de Sufijos:
5
9
8
1
2
3
4
6
a   $
a   b   c   a   $
a   b   c   c   a   b   c   a   $
b   c   a   $
b   c   c   a   b   c   a   $
c   a   $
c   a   b   c   a   $
c   c   a   b   c   a   $
$
7
 
 6
(5)
(2)
(3)
(5) 2
 7  4
3
Arbol de Sufijos:
(1)
(2)
(3)
 9
 8
 5
(7)
 1
1     2    3   4    5    6    7   8    9
Figura 1: Un ejemplo de un arreglo de sufijos y un árbol de sufijos.
remos con Ti,j a la secuencia ti, . . . , tj , con
1 ≤ i ≤ j ≤ n. Un sufijo de T es cualquier string de la forma Ti,n = ti, . . . , tn y
un prefijo de T es cualquier string de la forma T1,i = t1, . . . , ti con i = 1..n. Un patrón
de búsqueda P = p1 . . . pm es cualquier string
sobre el alfabeto Σ.
Si el texto es pequeño, la búsqueda de patrones puede resolverse eficientemente sin indexar el texto. Si el texto es demasiado grande se debe preprocesar el texto para construir
un índice. Entre los índices más populares para
resolver búsqueda de patrones encontramos el
arreglo de sufijos, el trie de sufijos y el árbol de
sufijos. Estos índices se construyen basándose
en la observación de que un patrón P ocurre en
el texto si es prefijo de algún sufijo del texto.
Arreglo de sufijos: un arreglo de sufijos
A[1, n] es una permutación de los números
1, 2, . . . , n tal que TA[i],n ≺ TA[i+1],n , donde
≺ es la relación de orden lexicográfico [11].
Buscar un patrón P en T equivale a buscar todos los sufijos de los cuales P es prefijo, los
cuales estarán en posiciones consecutivas de
A. El proceso de búsqueda consiste entonces
en dos búsquedas binarias. La figura 1 muestra
un ejemplo de un arreglo de sufijos.
Trie de Sufijos: un trie de sufijos es un Trie
[4] construido sobre el conjunto de todos los
sufijos del texto, en el cual cada hoja mantiene el índice del sufijo que esa hoja representa
[15]. El trie de sufijos resuelve eficientemente búsquedas de patrones en un texto basándose en la observación anterior y utilizando la
eficiencia del Trie para resolver búsquedas de
prefijos en un conjunto de string.
Árbol de sufijos: un árbol de sufijos es un
Pat-Tree [4] construido sobre el conjunto de
todos los sufijos de T codificados sobre alfabeto binario. Cada nodo interno mantiene el
número de bit del patrón que corresponde usar
en ese punto para direccionar la búsqueda y
las hojas contienen una posición del texto que
representa al sufijo que se inicia en dicha posición [15]. La figura 1 muestra un ejemplo,
suponiendo que la codificación binaria de los
símbolos es $ = 00, a = 01, b = 10, c = 11.
Contrariamente a lo que sucede en las bases
de datos tradicionales, los índices en las bases
de datos de texto generalmente ocupan más espacio que el texto a indexar, pudiendo alcanzar
de 4 a 20 veces el tamaño del mismo.
Una alternativa para reducir el espacio ocupado por el índice es buscar una representación
compacta del mismo, manteniendo las facilidades de navegación sobre la estructura [5, 6]
Pero en grandes colecciones de texto, el índiC1,1 C1,2 2,1C 3,3C3,2C3,1C 4,1C C4,2
C1,1 2,1C 3,1C 4,1C 5,1C
C1,2 3,2C C4,2
3,3C
A 1
B 1
A 2
B 2
A 3
B 3
01 0 1 1
0 01
0
C 5,1C
Figura 2: Representación de una secuencia de códigos
de longitud variable usando DAC.
ce aún comprimido suele ser demasiado grande como para residir en memoria principal. Por
esta razón, el estudio de índices comprimidos y
en memoria secundaria para búsquedas en texto es un tema de creciente interés en la comunidad de bases de datos.
3. Líneas de Investigación
El objetivo principal de esta línea de investigación es el diseño de índices comprimidos
en memoria secundaria, que resulten eficientes
para la búsqueda de patrones. Damos a continuación una reseña de las líneas de estudio que
estamos desarrollando en este momento.
3.1. Códigos DAC
Dentro de la temática de compresión de datos, un problema central es la asignación de
códigos de longitud variable a los símbolos de
alfabeto del texto que se está comprimiendo.
Los métodos de compresión estadísticos, como
por ejemplo Huffman, asignan códigos más
corto a los símbolos más frecuentes y códigos
más largos a los menos frecuentes. El principal
problema de estos métodos es que no permiten acceder eficientemente al i-ésimo símbolo
en la secuencia codificada. La solución típica a
este problema implica un overhead en tiempo y
espacio que ocasiona perder parte del espacio
ganado al comprimir.
El Directly Addressable Variable-Length
Code (DAC), presentado en [1], es una técnica que permite acceso aleatorio y eficiente a
cada código en una secuencia de códigos de
longitud variable.
Dada una secuencia de códigos de longitud
variable C = C1, C2, . . . , Ck, se divide cada código Ci en bloques de b bits. Luego se
crea un arreglo A1 conteniendo la concatenación de los primeros bloques de cada símbolo, y un mapa de bits (bitmap) B1 de k bits,
donde el i-ésimo bit está en 1 si el código Ci
está formado por más de un bloque. Se continua con la creación de un arreglo A2 conteniendo la concatenación de los segundos bloques de cada símbolo y un bitmap B2 con 1
en aquellos bits correspondientes a los códigos
con más de dos bloques. Se continua así hasta
alcanzar la máxima cantidad de bloques. La figura 2 muestra un ejemplo para una secuencia
C formada por 5 códigos de longitud variable,
Ci,j representa el j-ésimo bloque del i-ésimo
código de la secuencia.
Para acceder al código Ci de la secuencia
original primero buscamos su primer bloque
en A1[i]. Si el i-ésimo bit de B1 está en 0,
se finaliza retornando Ci = A1[i]. Caso contrario, continuamos buscando el segundo bloque del código Ci en A2[rank1(B1, i)], donde
rank1(B1, i) es la cantidad de unos en B1[1..i].
Este proceso continúa hasta llegar al último
nivel de arreglos o hasta encontrar el bit del
correspondiente bitmap en cero.
3.1.1. Aplicación de Códigos DAC
Entre los índices para texto en memoria secundaria más relevantes encontramos el String
B-Tree [3] y el Compact Pat Tree [2].
El String B-Tree es un índice dinámico para búsquedas de patrones en memoria secundaria. Básicamente consiste en una combinación de dos estructuras: el B-Tree y el Pat-Tree
[4]. No es un índice comprimido y su versión
estática requiere en espacio de 5 a 6 veces el tamaño del texto. Estamos trabajando en la implementación de una variante comprimida de
este índice que consiste en comprimir la representación de los Pat-Tree involucrados. Para ello se utiliza la representación de paréntesis
[12] para mantener la topología del árbol y los
códigos DAC para la representación de los valores de salto del Pat-Tree.
El Compact Pat Tree (CPT) consiste en representar un árbol de sufijos en memoria secundaria y en forma compacta. Si bien no existen desarrollos teóricos que garanticen el espacio ocupado por este índice y el tiempo insumido en la búsqueda, en la práctica tiene un muy
buen desempeño. Los autores proponen una representación comprimida de los valores de salto que implica la creación de hojas adicionales
especiales llamadas dummy. Hemos diseñado
una implementación del CPT en la que se incorporan los códigos DAC para la representación de los valores de salto de este árbol, lo que
evita la creación de hojas dummy. Los primeros experimentos realizados son alentadores en
cuanto al espacio ocupado por el índice.
3.2. Locally Compressed SA
Un arreglo de sufijos A construido sobre un
texto T de longitud n es compresible si T lo es.
La entropía de orden k de T (Hk) se refleja en
A formando secuencias largas A[i, i + l], denominadas pseudo-repeticiones que aparecen
en otro lugar A[j, j + l] con todos los valores
incrementados en uno, es decir: A[j + s] =
A[i+ s] + 1 con 0 ≤ s ≤ l.
Si particionamos A en pseudo-repeticiones
de tamaño maximal, el número de partes que
obtendríamos sería a lo más nHk + σk, para
algún k [13]. Esta propiedad ha sido usada por
varios autores para comprimir un arreglo de
sufijos A [9, 10]. El Locally Compressed Suffix Array (LCSA) [6] es un técnica para compresión de arreglos de sufijos que consiste en
convertir las pseudo-repeticiones en repeticiones reales, que luego son factorizadas usando
Re-Pair [8].
3.2.1. Aplicación de LCSA
En [7] hemos presentado un modificación
en el diseño del CPT que permite mantener
la representación del arreglo de sufijos subyacente en el CPT separada de la representación
del árbol propiamente dicho. Esto nos permite como próximo paso reducir el espacio total requerido por el índice comprimiendo dicho
arreglo de sufijos. Para ellos estamos trabajando en la incorporación de la técnica LCSA en
el CPT.
3.3. Trie de Sufijos
El trabajo sobre este índice apunta a lograr
una representación en memoria secundaria de
un trie de sufijos, de manera tal que el mismo
resulte competitivo en cantidad de accesos a
disco. Hemos diseñado una técnica de paginación del mismo la que surge como una extensión para arboles r-arios del paginado utilizado en el CPT. Esta técnica fue presentada en
[14], encontrándonos actualmente en la etapa
de evaluación experimental de la misma.
4. Resultados Esperados
Se espera obtener índices con las mismas
funcionalidades que los originales pero reduciendo el espacio necesario para su representación. En el caso particular del trie, el aporte además será contar con una versión eficiente del mismo en memoria secundaria. El desempeño de los índices obtenidos será medido tanto analíticamente como en forma empírica. Para esto último se cuenta con un conjunto
de textos de prueba usados y aceptados por la
comunidad científica del área de estudio.
5. Recursos Humanos
El trabajo desarrollado en esta línea de investigación forma parte del desarrollo de dos
Trabajos Finales de la Licenciatura en Ciencias de la Computación, dos Tesis de Maestría
en Ciencias de la Computación y una Tesis de
Doctorado en Ciencias de la Computación, todos realizados en el ámbito de la Universidad
Nacional de San Luis, con el asesoramiento del
Dr. Gonzalo Navarro de la Universidad de Chile y de la Dra. Nieves Brisaboa de la Universidad da Coruña, España.
