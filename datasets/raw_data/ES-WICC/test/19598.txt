Control de robots basado en bioseñales
﻿
En la actualidad se trabaja en el control de 
robots a través de la adaptación de de BrainMachine Interfase (BMI), nuestra líneas de 
trabajo se enfocan a la experimentación de 
soluciones de integración para el control de 
robots por bioseñales. Este proyecto se 
encuentra financiado por la Facultad de 
Informática, Ciencias de la Comunicación y 
Técnicas Especiales de la Universidad de 
Morón. Se trabaja en futuras pruebas de 
integración de control de Bioseñales para el 
control remoto de robots, como así también la 
participación de estudiantes de grado y 
posgrado para la continuación de las líneas de 
investigación relacionadas  
 
RESUMEN 
En este artículo se describe el trabajo de 
investigación que en la actualidad se está 
desarrollando dentro del área de las 
comunicación de humanos a robots, sobre la 
base de bioseñales cerebrales, con la 
aplicación de tecnologías e interfases 
disponibles que facilitaron las lecturas de 
señales del cerebro del usuario y su 
asociación a comandos explícitos que 
permitieron a través de la adecuación de 
dispositivos de comunicación, el control de 
robots bípedos y móviles. Nuestro trabajo 
explora una solución de ingeniería, aplicando 
las bases tecnológicas, el desarrollo de un 
framework de comunicación de alto y bajo  
 
Palabras clave: Robots, Maquina de interface 
con el Cerebro, Señales bio-electricas, 
Interfaces humano-maquina.  
 
1. INTRODUCCIÓN 
La aplicación de bioseñales para el control de 
sistemas, robots, aplicaciones, juegos y 
dispositivos en general presenta un enfoque 
novedoso al abrir las puertas para la 
interacción entre humanos y computadoras en 
una nueva dimensión, donde se explotan 
específicamente biopotenciales eléctricos 
registrados en el usuario, estos biopotenciales 
incluyen el electro-miograma, el electroencefalograma y el electro-oculograma, que 
son bioseñales eléctricas generadas por los 
patrones de actividad de los músculos, el 
celebro y los ojos del usuario. La idea de 
mover robots o facilitar la aplicación de 
dispositivos para discapacitados sin aplicar 
controles manuales y alcanzar el control sólo 
a través de la actividad mental, fascinó a los 
investigadores. En este orden diversos 
trabajos se presentaron, los primeros trabajos 
recurrieron a implantar electrodos 
intracraneales en la corteza motora de 
primates [1], [2]. Los trabajos no invasivos 
para humanos recurrieron a señales de 
Electroencefalogramas (EEG), aplicados a 
ejercicios de comandos mentales, como 
mover el cursor de una computadora [3], [4] 
basados en el empleo de Brain-Machine 
Interface (BMI) Millan et. al [5] demuestra 
cómo dos personas pueden mover un robot 
usando un simple electroencefalograma, sobre 
                      641WICC 2010 - XII Workshop de Investigadores en Ciencias de la Computación
la base de reconocer tres estados mentales, los 
que se asocian a comandos del robot. Los 
trabajos de Saulnier et. al. [6] se enfocaron en 
controlar la velocidad de un robot y extender 
su aplicación para inferir el nivel de stress del 
usuario, y a partir de éste influir en el 
comportamiento social de robots domésticos, 
en este caso una aspiradora robot. El trabajo 
seminal de Millan et al [5], emplea como 
única bioseñal el electro-encefalograma, sobre 
la base del trabajo de dos personas para 
apoyar la navegación de un robot, a diferencia 
de éste, nuestro trabajo presenta el resultado 
preliminar empleando un BMI de bajo costo, 
utilizado en trabajos secundarios como el de 
Saulier et al [6], que incluye las bioseñales 
correspondiente al electro-encefalograma, la 
de electro-oculograma y el electromiograma. 
A diferencia del trabajo de Saulier et al [6], 
que implementa un control de velocidad sobre 
la base del electromiograma e infiere el estado 
de stress del usuario sobre la base del 
electroencefalograma, nuestro trabajo se 
enfoca en la ejecución de un patrón de 
navegación por parte de un robot, 
confrontando los tiempos de ejecución del 
control manual y del control mental, durante 
el inicio de la curva de aprendizaje de un 
usuario, con resultados que demuestran que el 
control mental requiere en términos generales 
el doble de tiempo que el control manual para 
la ejecución de un mismo patrón de 
navegación. Sin embargo nuestro trabajo 
presenta en el contexto descrito una mejora en 
los tiempos de control mental, que supera 
ligeramente al control manual, en las pruebas 
de ejecución del mismo patrón de navegación, 
la que denominamos control mental con auto 
foco. En nuestra investigación se empleo el 
Bípedo Robosapiens V1. [7] de la familia 
Wow Wee Robotics [8], para los ensayos 
preliminares y como robot principal se armó 
un simple robot móvil sobre la base de un 
Lego NXT [9], actualmente se trabaja en el 
control de un robot e-puck desarrollado por 
EPFL, el Instituto Federal Suizo de 
Tecnología en Lausanne y el BMI Emotiv. 
 
 
 
2. LÍNEAS DE INVESTIGACIÓN Y 
DESARROLLO 
Integración de una solución de ingeniería para 
el control de sistemas de robots a través de 
bio-señales de humanos, en el contexto de 
aprendizaje por refuerzo por la observación de 
un tutor humano. 
 
3. DISCUSIÓN DE LOS RESULTADOS 
Nuestro objetivo inicial fue explorar una 
solución de ingeniería que nos permita 
alcanzar una integración primaria de un BMI 
y un robot, para ser utilizada por un usuario 
que no requiera tener experiencia previa con 
técnicas de meditación o entrenamiento 
específico de concentración mental. 
Para el control mental de un robot, se 
plantearon dos comandos: uno que permite 
controlar la selección de comportamientos y 
otro que permite la ejecución, de los 
comportamientos de los robots, sobre la base 
de sus propios controladores (por ejemplo 
caminar hacia adelante para el robot bípedo o 
girar a la derecha para el robot móvil), esto no 
presentó mayores dificultades al ser asociada 
la ejecución a un estímulo de una bioseñal 
muscular. Sin embargo la selección de un 
comportamiento (en nuestro contexto, los 
correspondientes al menú de la familia de 
comportamientos del robot) a través de 
control mental, sobre la base de bioseñales 
provenientes del electro-encefalograma, no 
resultó práctico para el usuario, en razón a la 
dificultad que se le presentó para controlar en 
forma estable el menú de selección de 
comportamientos. 
Se estableció una arquitectura experimental 
que contempla dos vías de comunicación, la 
primera vía y principal objeto de estudio la 
denominamos vía de comunicación de alto 
nivel: “usuario-computadora”, esta vía se 
instrumentó con un BMI de bajo costo OCZ 
NIA [10], de empleo experimental en video 
juegos, que permite la asociación de patrones 
de señales mentales con el teclado y controles 
del mouse de la computadora. Sobre estas 
facilidades se determinó un profile simple 
para el manejo de los robots, que asocian y 
caracterizan en primer lugar, el control para la 
ejecución del comando mental sobre la base 
                      642WICC 2010 - XII Workshop de Investigadores en Ciencias de la Computación
de la detección de señales musculares, en 
nuestro caso a través de un leve movimiento 
de los párpados. En segundo lugar la 
selección de los comandos de alto nivel del 
robot, en este caso se trabajó sobre la base de 
las ondas cerebrales Alfa. Este tipo de 
bioseñales no aseguraron un adecuado control 
al usuario en los desplazamientos, a través del 
menú de selección de comandos del 
framework de control del robot. Frente a esta 
razón se implementó en el framework la 
opción de aplicación de auto foco para el 
modo control mental, a fin de mejorar el 
gobierno del usuario en el proceso de 
selección. La segunda vía de comunicación la 
denominamos vía de comunicación de bajo 
nivel: “computadora –robot”, se efectuó para 
el caso del Robosapiens V1 a través del 
empleo de una torre IR [11] y para el robot 
móvil NXT se explotaron sus capacidades de 
comunicación en Bluetooth. La comunicación 
con robots vía IR, se basó sobre los resultados 
obtenidos en la captura y reproducción de 
comandos controlados desde una 
computadora [12]. Se utilizó como interface 
cerebro-máquina (brain-machine interface/ 
BMI) el Neural impulse actuator (NIA) [10].  
La comunicación de los comportamientos de 
robots se implementan en dos vías de 
comunicación (Fig 1), una de alto nivel entre 
el BMI-NIA y el framework y otra de bajo 
nivel entre este último a través del dispositivo 
de transmisión de comunicación con el robot. 
  
 
Fig.1. Integración BMI-NIA y Robots 
La configuración del framework para el 
desarrollo de las pruebas en la modalidad 
control mental con auto foco, adoptó la 
siguiente ruta de comandos: left-stop, 
forward-stop, right-stop. La ejecución del 
comando forward se configuró con un tiempo 
de 2 segundos y los giros con un tiempo de 50 
segundos. Para las pruebas de control mental 
(sin auto foco) se desactivó dicha función y se 
empleó el mismo framework al igual que en 
el control manual, con los mismo parámetros 
temporales para la ejecución de forward y 
giros. 
A la fecha no se han dominado todas las 
características del BMI de NIA, podemos 
comentar: que cada vez que se utiliza debe ser 
calibrado, si bien se encontró que la 
calibración no ha sido siempre necesaria, lo 
mejor es calibrar antes de cada período de 
sesiones de pruebas. En diversas 
oportunidades no se arribó a los resultados 
deseados: especialmente en los primeros 
intentos, esto se debe en parte a la 
sensibilidad del equipo a campos 
electromagnéticos, como así también se 
encontró que el usuario también podía 
influenciar al BMI de NIA al tocarlo. Los 
usuarios en los entrenamientos iniciales al 
cabo de aproximadamente 30 minutos se 
cansaban y requerían un breve reposo. Al 
comenzar, el usuario realiza movimientos 
musculares exagerados, pero con la práctica y 
las mejoras en la calibración del profile, los 
movimientos musculares se minimizan. Las 
pruebas realizadas con el robot bípedo se 
orientaron a la ejecución libre de comandos 
mentales y sirvieron como base para la 
preparación de las pruebas de mayor 
complejidad con el robot móvil. Se 
documentó, una de las pruebas funcionales de 
ejecución libre de comportamientos del 
bípedo con un video [13]. Las pruebas del 
robot móvil se realizaron sobre una área de 
experimentación (2,00 mts x 1,50 mts) sobre 
las cual se marcaron cuatro check–points 
(Cp). El primer caso de prueba fue el de 
control manual (MC) del robot controlado por 
el usuario, para este caso se realizaron tres 
sesiones de entrenamiento y tres sesiones de 
prueba. El segundo caso de prueba fue el de 
control mental (BC), se realizaron nueve 
sesiones de entrenamiento previo y tres 
sesiones de prueba. El tercer caso de prueba 
se realizó para verificar la propuesta de este 
trabajo, en relación al empleo de control 
mental con auto-foco (BC-AF) en el comando 
                      643WICC 2010 - XII Workshop de Investigadores en Ciencias de la Computación
a ejecutar, en función del patrón de 
navegación. 
Se realizaron seis sesiones de entrenamiento y 
tres sesiones de prueba para esta modalidad. 
Para cada sesión de pruebas se tomaron los 
tiempos parciales de cada tramo definido 
entre cada check-point (Cp), “Resultados de 
experimentación robot móvil”. Se obtuvo 
como resultado preliminar que la 
combinación de control mental con auto foco 
(BC-AF) resultó más rápida que la solución 
de control manual, sin embargo la solución de 
control mental (BC) resultó más lenta en 
términos generales que una solución de 
control manual (MC). Los resultados 
promedios comparativos obtenidos de las tres 
sesiones de pruebas para cada caso de control 
(manual, mental, mental con auto foco 
respectivamente): (a) el tiempo por tramo 
entre cada check point, (b) el tiempo total 
para realizar el patrón, (c) la diferencia de 
tiempo entre control manual y control mental, 
(d) la diferencia de tiempo entre control 
manual y control mental con auto foco, (e) 
porcentajes finales entre control manual y 
control mental, porcentajes finales entre 
control manual y control mental con auto 
foco.  
Finalmente como síntesis podemos decir que 
el control mental con auto foco resultó en un 
11,32 % mejor que el control manual, sin 
embargo el control manual resultó un 111 % 
mejor que el control mental (sin auto foco). 
Se muestra en la Fig 2 la distribución 
comparativa de los tiempos promedios de las 
sesiones de pruebas para cada tramo: con 
control manual, control mental, y control 
mental con auto-foco respectivamente. 
Finalmente se muestra en la Fig 3 el tiempo 
total para cada tramo, por cada prueba en 
función del tipo de control (control manual, 
control mental, y control mental con autofoco respectivamente). Para completar el 
patrón de navegación, la segunda prueba de 
control mental (test 2 BC) fue la que demandó 
el mayor tiempo (45,47 seg) y la tercer prueba 
de control mental con auto foco (test 3 BCAF) resultó ser la que menos tiempo demandó 
(13,93 seg) para completar el mismo patrón 
de navegación. Se documentó con videos 
parte de las pruebas detalladas: control mental 
[14], control mental con auto foco [15]. 
  
 
 
 
 
 
 
 
Fig. 2. Tiempo promedio entre path 
 
 
 
 
 
 
Fig. 3. Tiempo total para cada prueba 
Finalmente los trabajos futuros se centrarán 
en el control de un robot e-puck desarrollado 
por EPFL, el Instituto Federal Suizo de 
Tecnología en Lausanne y el BMI de Emotiv. 
 
4. FORMACIÓN DE RECURSOS 
HUMANOS 
En la actualidad esta línea de investigación 
vincula al PID de FICCTE–UM, lo integra un 
estudiante de Doctorado que trabaja en el área 
de sistemas autónomos de robots y dos 
estudiantes de tesis de grado orientadas al 
control remoto de robots por Bioseñales vía 
Internet y su futura continuación a través de 
las líneas de investigación de aprendizaje por 
refuerzo de robots a través de bioseñales. 
 
5.
