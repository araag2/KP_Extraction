Control de robots con la aplicación de interfase cerebro máquina
﻿ En este artículo se 
describe el trabajo de investigación 
que en la actualidad se está 
desarrollando dentro del área de la 
comunicación de humanos a robots, 
sobre la base de bioseñales 
cerebrales. Para esta investigación 
se aplican tecnologías e interfases 
disponibles que facilitan la lectura de 
las señales del cerebro del usuario y 
su asociación a comandos explícitos. 
Además  permiten a través de la 
adecuación de dispositivos de 
comunicación, el control de robots 
bípedos y móviles. Nuestro trabajo 
explora una solución de ingeniería, 
aplicando las bases tecnológicas y, el 
desarrollo de un framework de 
comunicación de alto y bajo.  
Key words: Robots, Brain Machine Interface, 
Bio-Electrical Signal, Human Machine 
Interfaces. 
1. Contexto de la Investigación 
En la actualidad se trabaja en el control de 
robots a través de la adaptación  de BrainMachine Interfase (BMI). Nuestras líneas de 
trabajo se enfocan en la experimentación de 
soluciones de integración para el control de 
robots por bioseñales, y futuras pruebas de 
integración del control de bioseñales para el 
control remoto de robots. 
 
 Este proyecto se encuentra financiado por la 
Facultad de Informática, Ciencias de la 
Comunicación y Técnicas Especiales de la 
Universidad de Morón. A su vez propicia la 
formación de recursos, con la participación de 
estudiantes de grado y posgrado para la 
continuación de las líneas de investigación 
relacionadas.  
 
La aplicación de bioseñales para el control de 
sistemas, robots, aplicaciones, juegos y otros 
dispositivos, presenta un enfoque novedoso al 
abrir las puertas para la interacción entre 
humanos y computadoras en una nueva 
dimensión, donde se explotan específicamente 
biopotenciales eléctricos registrados en el 
usuario, a través de: el electro-miograma, el 
electro-encefalograma y el electrooculograma, que son bioseñales eléctricas 
generadas por los patrones de actividad de los 
músculos, el celebro y los ojos del usuario. 
 
 La idea de mover robots o facilitar la 
aplicación de dispositivos para discapacitados 
sin aplicar controles manuales y alcanzar el 
control sólo a través de la actividad mental, 
fascinó a los investigadores. En este orden, se 
presentaron diversos trabajos: los primeros, 
recurrieron a implantar electrodos 
intracraneales en la corteza motora de 
primates [1], [2]. Los trabajos no invasivos 
para humanos recurrieron a señales de 
Electroencefalogramas (EEG), aplicados a 
ejercicios de comandos mentales, como 
mover el cursor de una computadora [3], [4] 
basados en el empleo de Brain-Machine 
Interface (BMI). Millan et. al. [5] demuestra 
como dos personas pueden mover un robot 
usando un simple electroencefalograma, sobre 
la base de reconocer tres estados mentales, los 
que se asocian a comandos del robot. Los 
trabajos de Saulnier et. al. [6] se enfocaron en 
controlar la velocidad de un robot y extender 
su aplicación para inferir el nivel de stress del 
usuario, y a partir de éste influir en el 
comportamiento social de robots domésticos, 
en este caso una aspiradora robot. 
 
 El trabajo seminal de Millan et. al. [5], 
emplea como única bioseñal el electroencefalograma, sobre la base del trabajo de 
dos personas para apoyar la navegación de un 
robot, a diferencia de éste, nuestro trabajo 
presenta el resultado preliminar empleando un 
BMI de bajo costo, utilizado en trabajos 
secundarios como el de Saulnier et. al. [6], 
que incluye las bioseñales correspondientes al 
electro-encefalograma, electro-oculograma y 
electromiograma. 
 
 A diferencia del trabajo de Saulnier et. al. [6], 
que implementa un control de velocidad sobre 
la base del electromiograma e infiere el estado 
de stress del usuario a través del 
electroencefalograma, nuestro trabajo se 
enfoca en la ejecución de un patrón de 
navegación por parte de un robot. Confronta 
los tiempos de ejecución del control manual y 
del control mental durante el inicio de la 
curva de aprendizaje de un usuario, con 
resultados que demuestran que el control 
mental requiere, en términos generales, el 
doble de tiempo que el control manual para la 
ejecución de un mismo patrón de navegación.  
 
Podemos afirmar que nuestro trabajo presenta 
según el  contexto descrito, una mejora en los 
tiempos de control mental, superando 
ligeramente al manual, en las pruebas de 
ejecución del mismo patrón de navegación, la 
que denominamos control mental con auto 
foco.  
 
Se empleó el Bípedo Robosapiens V1. [7] de 
la familia Wow Wee Robotics [8], para los 
ensayos preliminares y como robot principal 
se armó un simple robot móvil sobre la base 
de un Lego NXT [9]. 
2. Objetivos Teóricos  y 
Experimentales 
Nuestro objetivo inicial fue explorar una 
solución de ingeniería que nos permitiera 
alcanzar una integración primaria de un BMI 
y un robot, para ser utilizada por un usuario 
que no requiera tener experiencia previa con 
técnicas de meditación o entrenamiento 
específico de concentración mental. 
Para el control mental de un robot, se 
plantearon dos comandos: uno que permitiese 
controlar la selección de comportamientos y 
otro, la ejecución de los mismos sobre la base 
de sus propios controladores (por ejemplo 
caminar hacia adelante para el robot bípedo o 
girar a la derecha para el robot móvil).Esto no 
presentó mayores dificultades al ser asociada 
la ejecución a un estímulo de una bioseñal 
muscular. Sin embargo la selección de un 
comportamiento (en nuestro contexto, los 
correspondientes al menú de la familia de 
comportamientos del robot) a través del 
control mental, sobre la base de bioseñales 
provenientes del electro-encefalograma, no 
resultó práctico para el usuario, por la 
dificultad que se le presentó para controlar en 
forma estable el menú de selección de 
comportamientos. 
 
Se estableció una arquitectura experimental 
que contempla dos vías de comunicación, la 
primera vía y principal objeto de estudio, la 
denominamos vía de comunicación de alto 
nivel “usuario-computadora”. Esta vía se 
instrumentó con un BMI de bajo costo OCZ 
NIA [10], de empleo experimental en video 
juegos, que permitió la asociación de patrones 
de señales mentales con el teclado y controles 
del mouse de la computadora. Sobre estas 
facilidades determinamos un profile simple 
para el manejo de los robots, que asocian y 
caracterizan en primer lugar, el control para la 
ejecución del comando mental sobre la base 
de la detección de señales musculares, en 
nuestro caso a través de un leve movimiento 
de los párpados. En segundo lugar la 
selección de los comandos de alto nivel del 
robot, en este caso se trabajó sobre la base de 
las ondas cerebrales Alfa. Este tipo de 
bioseñales no aseguraron un adecuado control 
al usuario en los desplazamientos, a través del 
menú de selección de comandos del 
framework de control del robot. Frente a esta 
razón se implementó en el framework la 
opción de aplicación de auto foco para el 
modo control mental, a fin de mejorar el 
gobierno del usuario en el proceso de 
selección. La segunda vía de comunicación la 
denominamos vía de comunicación de bajo 
nivel “computadora –robot”.Se efectuó para el 
caso del Robosapiens V1 a través del empleo 
de una torre IR [11]; para el robot móvil NXT 
se explotaron sus capacidades de 
comunicación en Bluetooth. La comunicación 
con robots vía IR, se basó sobre los resultados 
obtenidos en la captura y reproducción de 
comandos controlados desde una 
computadora [12], [13]. Se utilizó como 
interfase cerebro-máquina (brain-machine 
interfase/ BMI) el Neural impulse actuator 
(NIA) [10].  La comunicación de los 
comportamientos de robots se implementan 
en dos vías de comunicación (Fig 1), una de 
alto nivel entre el BMI-NIA y el framework y 
otra de bajo nivel entre este último a través 
del dispositivo de transmisión de 
comunicación con el robot. 
  
 
Fig.1. Integración BMI-NIA y Robots 
La configuración del framework para el 
desarrollo de las pruebas en la modalidad 
control mental con auto foco, adoptó la 
siguiente ruta de comandos: left-stop, 
forward-stop, right-stop. La ejecución del 
comando forward se configuró con un tiempo 
de 2 segundos y los giros con un tiempo de 50 
segundos. Para las pruebas de control mental 
(sin auto foco) se desactivó dicha función y se 
empleó el mismo framework al igual que en 
el control manual, con los mismo parámetros 
temporales para la ejecución de forward y 
giros. 
 
A la fecha no se han dominado todas las 
características del BMI de NIA: cada vez que 
se utiliza debe ser calibrado, si bien se 
encontró que la calibración no ha sido 
siempre necesaria, lo mejor es hacerlo antes 
de cada período de sesiones de pruebas. En 
diversas oportunidades no se arribó a los 
resultados deseados, especialmente en los 
primeros intentos, esto se debe en parte a la 
sensibilidad del equipo a campos 
electromagnéticos, como así también se 
encontró que el usuario también podía 
influenciar al BMI de NIA al tocarlo. Los 
usuarios en los entrenamientos iniciales al 
cabo de aproximadamente 30 minutos se 
cansaban y requerían un breve reposo. Al 
comenzar, el usuario realiza movimientos 
musculares exagerados, pero con la práctica y 
las mejoras en la calibración del profile, los 
movimientos musculares se minimizan. Las 
pruebas realizadas con el robot bípedo se 
orientaron a la ejecución libre de comandos 
mentales y sirvieron como base para la 
preparación de las pruebas de mayor 
complejidad con el robot móvil. Se 
documentó una de las pruebas funcionales de 
ejecución libre de comportamientos del 
bípedo con un video [14]. Las pruebas del 
robot móvil se realizaron sobre un área de 
experimentación (2,00 mts x 1,50 mts) sobre 
la cual se marcaron cuatro check–points (Cp). 
El primer caso de prueba fue el de control 
manual (MC) del robot controlado por el 
usuario, para este caso se realizaron tres 
sesiones de entrenamiento y tres sesiones de 
prueba. El segundo caso, fue el de control 
mental (BC), se realizaron nueve sesiones de 
entrenamiento previo y tres sesiones de 
prueba. Con el tercer caso de prueba 
verificamos la propuesta de este trabajo: el  
empleo de control mental con auto-foco (BCAF) en el comando a ejecutar, en función del 
patrón de navegación. 
 
Se realizaron seis sesiones de entrenamiento y 
tres sesiones de prueba para esta modalidad. 
Para cada sesión de pruebas se tomaron los 
tiempos parciales de los tramos definidos 
entre cada check-point (Cp), “Resultados de 
experimentación robot móvil”. Se obtuvo 
como resultado preliminar que la 
combinación de control mental con auto foco 
(BC-AF) resultó más rápida que la solución 
de control manual, sin embargo la solución de 
control mental (BC) resultó más lenta en 
términos generales que una solución de 
control manual (MC). Los resultados 
promedios comparativos  que se obtuvieron  
de las tres sesiones de pruebas para cada caso 
de control (manual, mental, mental con auto 
foco respectivamente) fueron: (a) el tiempo 
por tramo entre cada check point, (b) el 
tiempo total para realizar el patrón, (c) la 
diferencia de tiempo entre control manual y 
control mental, (d) la diferencia de tiempo 
entre control manual y control mental con 
auto foco, (e) porcentajes finales entre control 
manual y control mental, porcentajes finales 
entre control manual y control mental con 
auto foco.  
 
Finalmente como síntesis podemos decir que 
el control mental con auto foco resultó en un 
11,32 % mejor que el control manual, 
mientras que  el control manual resultó un 
111 % mejor que el control mental (sin auto 
foco). Se muestra en la Fig 2 la distribución 
comparativa de los tiempos promedios de las 
sesiones de pruebas para cada tramo: con 
control manual, control mental, y control 
mental con auto-foco respectivamente. Se 
muestra en la Fig 3 el tiempo total para cada 
tramo, por cada prueba en función del tipo de 
control (control manual, control mental, y 
control mental con auto-foco 
respectivamente). Podemos observar que, la 
segunda prueba de control mental (test 2 BC) 
fue la que demandó el mayor tiempo (45,47 
seg) y la tercer prueba de control mental con 
auto foco (test 3 BC-AF) resultó ser la que 
menos tiempo demandó (13,93 seg) para 
completar el mismo patrón de navegación. Se 
documentó con videos parte de las pruebas 
detalladas: control mental [15], control mental 
con auto foco [16]. 
  
 
 
 
 
 
 
 
 
Fig. 2. Tiempo promedio entre path   
 
 
 
 
 
 
Fig. 3. Tiempo total para cada prueba 
Actualmente nos encontramos trabajando 
en: 
 [a] comandos de control para un robot 
volador Fig 4 FlyTech Bladestar [17], 
aplicando interfases USB-UIRT [11],para 
reconocer sus comandos e integrarlos al frame 
work de control, aplicando la mencionada 
interface para la comunicación de bajo nivel 
con el robot volador. La comunicación de alto 
nivel con el framework se realizará con el 
BMI de NIA y en segundo lugar con el BMI 
de EMOTIV [18] según se muestra en la Fig 
5. 
 [b] control de un robot e-puck desarrollado 
por EPFL, el Instituto Federal Suizo[19]  de 
Tecnología en Lausanne y el BMI Emotiv. 
 [c] integración del control  de un  usuario 
remoto con un BMI a través de Internet con la 
incorporación de video en el framework de 
control . 
00:00,00
00:08,64
00:17,28
00:25,92
00:34,56
00:43,20
00:51,84
Path 1 Path 2 Path 3 Path 4
Test 1 MC
Test 1 BC 
Test 1 BC- AF
Test 2 MC
Test 2 BC 
Test 2 BC-AF 
Test 3 MC
Test 3 BC 
Test 3 BC-AF 
00:00,00
00:04,32
00:08,64
00:12,96
00:17,28
Path 1 Path 2 Path 3 Path 4
Manual Control
Brain  Control
 Brain Control with
Auto focus
               
Fig 4. FlyTech Bladestar        Fig 5. BMI Emotiv 
 
3 Líneas de Investigación y 
Desarrollo  
 
Integración de una solución de ingeniería para 
el control de sistemas de robots a través de 
bioseñales de humanos, en el contexto de 
aprendizaje por refuerzo, por la observación 
de un tutor humano. 
4. Formación de Recursos Humanos 
 
En la actualidad esta investigación está 
financiada por el PID 01-006-10 de FICCTE–
UM, la integran cuatro investigadores y dos 
estudiantes de tesis de grado, orientadas al 
control remoto de robots por Bioseñales vía 
Internet, agregando futuras continuación a 
través de las líneas de investigación de 
aprendizaje por refuerzo de robots a través de 
bioseñales.  
 
5.
