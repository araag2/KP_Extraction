Computación de altas prestaciones
﻿
El proyecto de investigación que presentamos se ocupa
de varios aspectos relativos a Computación de Altas Prestaciones (High Performance Computing, HPC). Se propone brindar un marco para la formación de postgrado de sus
integrantes, insertar temáticas asociadas a HPC en el curriculum de las carreras de grado de la FAI, y contribuir a
formar profesionales en HPC para atender un área vacante
en el medio regional. La temática principal abordada por
el proyecto son los clusters híbridos, donde los diferentes
nodos están conectados por una red pero a su vez cada
nodo dispone de múltiples recursos de cómputo.
1. Contexto
El proyecto Computación de Altas Prestaciones se forma en Enero de 2010, como iniciativa del Departamento
de Ingeniería de Computadoras de la Facultad de Informática (FAI), Universidad Nacional del Comahue. El objetivo general del proyecto es adquirir conocimientos para el
diseño, desarrollo, gestión y mejora de las tecnologías de
hardware y software involucradas en la Computación de
Altas Prestaciones (High Performance Computing, HPC)
y sus aplicaciones en Ciencia e Ingeniería Computacional.
2. Introducción
Un gran problema transversal de las Ciencias e Ingenierías Computacionales es la aplicación eficiente de modernas herramientas de cómputo paralelo y distribuido. La
respuesta a este problema transversal está condensada en
el concepto de Computación de Altas Prestaciones, que
abarca todos aquellos principios, métodos y técnicas que
permiten abordar problemas con estructuras de cómputo
complejas y de altos requerimientos. La resolución de estos problemas involucra conjuntos masivos de datos, una
gran cantidad de variables y complejos procesos de cálculo.
Estos métodos y técnicas exigen la utilización de recursos de computación que hasta hoy eran excepcionales.
Ejemplos de estos recursos son, por un lado, las supercomputadoras, y por otro, la colaboración de una gran
cantidad de computadoras a través de las redes, en diferentes niveles de agregación como clusters, multiclusters y grid. En la actualidad, sin embargo, la industria de
la tecnología incluye dispositivos de cómputo paralelo y
distribuido en muchos de sus productos. Este proceso de
cambio tecnológico implica la llegada de las arquitecturas distribuidas al dominio de los segmentos inferiores de
mercado, ubicando los computadores paralelos en el rango de commodities, recursos fáciles de adquirir y mantener, y por lo tanto de uso masivo.
Tanto las arquitecturas de recursos más recientes, multicores y manycores, como las ya existentes de los supercomputadores, clusters y grid, pueden ser comprendidas
y operadas bajo los principios de la computación paralela y distribuida, desarrollados hace tiempo, y que ahora
cobran una nueva significación. No obstante, las mejores
soluciones que van haciéndose factibles, no se logran únicamente con el recurso físico, entendido como el conjunto de dispositivos de cómputo y de comunicaciones, sino
que son necesarios nuevos modelos y diseños de software
para utilizar eficientemente dichos recursos. No existe al
presente, y no parece factible, un mecanismo automático
1
para esta adaptación. La migración de las soluciones existentes a las nuevas plataformas requiere nuevos esfuerzos
de programación, rediseño y reevaluación de metodologías. A veces será necesario adaptar un algoritmo, que resuelve un problema en forma de cómputo secuencial, para
ser distribuido en varios procesadores; a veces, el algoritmo necesitará ser desarrollado desde el principio en forma
paralela, o la solución completa ser reelaborada bajo otro
esquema de pensamiento que contemple desde el inicio el
dominio de los recursos.
2.1. Objetivos del proyecto
El proyecto contempla tanto aspectos de hardware como de programación de aplicaciones paralelas, con énfasis en la utilización de nuevas tecnologías, y se propone
lograr una comprensión integral de las problemáticas involucradas en las soluciones de HPC. Para esto define los
objetivos siguientes.
De formación de recursos humanos
Formar recursos humanos en el tema de HPC prosiguiendo con los postgrados de los integrantes que
están desarrollándose.
Elaborar propuestas de tesis de postgrado de los integrantes en el tema de HPC.
Insertar el conocimiento preliminar de la temática
de HPC en líneas generales, en nuestras carreras de
Ciencias de la Computación, aportando a la modificación de los contenidos de las materias regulares, y
dictando instancias ocasionales como cursos y seminarios.
De producción científica
Contribuir a abonar el desarrollo de las propuestas de
tesis de postgrado mediante la producción de publicaciones con referato.
De transferencia
Relevar los requerimientos de HPC de otros investigadores en Ciencias e Ingeniería Computacional y
cooperar en su diagnóstico y/o resolución.
Detectar necesidades relacionadas con HPC en otras
entidades del ámbito regional y plantear correspondientes actividades de transferencia.
Otros
Acercarse a la realidad del sistema científico nacional en términos de requerimientos y disponibilidades
de HPC.
Conocer las prestaciones, casos de aplicación y mejores prácticas de los productos de hardware y software para HPC que vayan haciéndose disponibles.
Colaborar con proyectos del universo del Software
Libre para el desarrollo o mejoramiento de sistemas
relacionados con HPC.
3. Líneas de investigación
Entre los intereses del grupo pueden distinguirse tres
ramas temáticas principales: memoria distribuida, memoria compartida, y manycores. Estas tres ramas convergen
en una estrategia emergente que son los clusters híbridos,
donde los diferentes nodos están conectados por una red
pero a su vez cada nodo dispone de múltiples recursos de
cómputo.
Los problemas que se presentan en estas arquitecturas
son diversos y modifican la forma de programación y optimización de aplicaciones. Estas arquitecturas de cómputo híbridas son visualizadas como el escenario futuro más
probable para los potenciales usuarios con quienes nos relacionamos.
3.1. Predicción de performance
Como parte de su relación con dichos usuarios, el grupo colabora con investigadores de la UNC que ejecutan
sus aplicaciones científicas en clusters de computadoras.
Estos usuarios buscan asesoramiento sobre cómo obtener
performance para sus aplicaciones, y sobre cómo mantenerla al ampliar o renovar su equipamiento. A veces, las
aplicaciones de estos usuarios provienen de terceros, y su
código fuente es cerrado, por lo cual es difícil conocer la
2
naturaleza de estas aplicaciones para poder emitir una recomendación. Un subgrupo del proyecto se aboca entonces a obtener datos sobre el comportamiento de aplicaciones cerradas, con técnicas de instrumentación de caja
negra. El objetivo de esta línea de investigación es definir
una metodología simple y efectiva de predicción automática de performance de aplicaciones.
3.2. Manycores
Otra línea de investigación del proyecto aborda la programación sobre arquitecturas manycore, especialmente
GPUs. El objetivo de esta línea es reunir conocimiento
sobre las mejores prácticas de programación, localización
de datos y distribución de procesos de cómputo en clusters
híbridos, con nodos provistos de uno o más dispositivos
manycore.
4. Resultados y Objetivos
4.1. Predicción de Performance
La actividad de esta línea está centrada en el objetivo de
proveer apoyo a grupos de investigadores de la UNC que
utilizan aplicaciones paralelas proporcionadas por terceros. Para contestar las principales preguntas sobre las mejores plataformas donde correr esas aplicaciones, en primer lugar se han realizado comparaciones de ejecución de
un benchmark bien conocido[1] sobre diferentes escenarios, lo que ha permitido ofrecer algunas recomendaciones a priori sobre la elección de densidad de núcleos en
un cluster híbrido[3].
Posteriormente se ha desarrollado una herramienta de
software que interviene transparentemente la ejecución y
permite obtener trazas o perfiles con prescindencia de los
fuentes o módulos objeto de las aplicaciones. El usuario
puede escribir las funciones de callback que serán llamadas antes y después de cada invocación a las rutinas de
la biblioteca de paso de mensajes, obteniendo las estadísticas que se deseen[4]. La intención final es utilizar esta herramienta para obtener un perfil de ejecución de las
aplicaciones que pueda extrapolarse para predecir su rendimiento en diferentes arquitecturas.
4.2. Manycores
Esta línea del proyecto considera la utilización, para
propósitos generales, de los dispositivos de cómputo gráfico masivamente paralelos (GPUs). Estos dispositivos,
derivados de la industria de la generación de gráficos 3D,
como los que suelen verse en los juegos de acción, presentan gran cantidad de núcleos y una arquitectura de memoria sumamente compleja y particular. Para cierta gama
de aplicaciones, las GPUs ofrecen posibilidades de performance realmente notables frente a su costo de adquisición.
El grupo tiene en preparación un laboratorio constituido por 16 nodos de doble núcleo equipados con una GPU
por nodo. Las GPUs seleccionadas pertenecen, en iguales proporciones, a las dos principales casas fabricantes,
NVIDIA y ATI. El objetivo de esta línea es conocer y
comparar las diferentes arquitecturas y lenguajes de programación para estos dispositivos, con especial énfasis en
OpenCL por su carácter de estándar abierto.
El laboratorio es compartido con cursos regulares de la
Facultad, lo que por un lado limita el espacio de tiempo
disponible para ensayos, y por otro lado implica que el
software y ambiente de los equipos debe mantenerse sin
modificación para las clases. Por estos motivos el grupo
ha creado un dispositivo de software para asistir al arranque en frío o reset del hardware, selección de la imagen de
arranque y provisión de la misma a través de la red. Todas
estas operaciones pueden realizarse en forma remota gracias a dicho dispositivo. La meta para esta etapa es contar con un panel de control del cluster híbrido para poder
arrancar o reiniciar los equipos desde cualquier lugar de
la red, en horarios sin otra actividad, y poder restablecer
la personalidad habitual de los equipos al momento de las
clases.
5. Formación de Recursos Humanos
El proyecto contempla diversos aspectos de formación
de recursos humanos. Por un lado, pretende conformar un
marco propicio para la formación de postgrado de algunos de sus integrantes. Por otro lado, se propone insertar
temáticas asociadas a HPC en el curriculum de las carreras de grado de la FAI. Finalmente, intenta lograr la ca3
pacidad de formar profesionales en HPC para solventar
las necesidades de los potenciales usuarios en la región
de influencia de la UNC. Estos potenciales usuarios comprenden tanto entidades gubernamentales, industriales o
comerciales, como el conjunto de los propios investigadores de la UNC.
Uno de los objetivos del grupo es el acercamiento a la
realidad nacional en materia de HPC. El aprovechamiento
racional de las nuevas capacidades instaladas es clave para las Ciencias e Ingenierías Computacionales en la era de
las e-Ciencias. Aunque las actuales políticas educativas y
científicas de Estado buscan absorber parte de este impacto creando estructuras de recursos compartidas e integradas para todo el sistema científico nacional, el proceso de
unión a este sistema no será trivial, y deberá recibir apoyo de personal especializado, que en nuestra Universidad
es un área de vacancia. Por esto, aunque no se considera
una línea de investigación, el proyecto promueve en general la capacitación de sus integrantes en administración
y operación de recursos de cómputo compartidos, destinando tiempos a conocer mecanismos y herramientas de
clustering y de integración de recursos.
Uno de los integrantes del proyecto se encuentra actualmente en vías de formular su tesis de Magister en
Cómputo de Altas Prestaciones de la UNLP sobre la línea de investigación de Predicción de Performance, con
los antecedentes y objetivos mencionados en este trabajo. En el sitio de acceso público [2] se mantiene el estado
de avance del proyecto, información de contacto, publicaciones del equipo, noticias y otros datos. Se agradecerán
contactos y sugerencias de la comunidad interesada.
