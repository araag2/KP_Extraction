Especificación e implementación de agentes inteligentes para el soporte a la toma de decisiones
﻿
El objetivo general de esta línea de investigación es estudiar en el contexto de un sistema multi-agente (MAS), la problemática asociada con la especificación e implementación de
un agente inteligente deliberativo con la capacidad de brindar apoyo a la toma de decisiones. Es importante tener en cuenta que las bases de conocimientos que manejaran los agentes podrían variar en el tiempo y ser influenciadas o afectadas por distintas fuerzas que gobiernan el mundo real, e.g. la confiabilidad de
una determinada fuente de información. Uno
de los objetivos particulares es el diseño y la
realización computacional de una arquitectura
para un agente autónomo con la capacidad de
contribuir a la toma de decisiones en un entorno MAS colaborativo y dinámico.
Palabras clave: Sistema Multi-agente, Agente Inteligente Deliberativo, Toma de Decisiones
Contexto
El presente plan de trabajo está estrechamente relacionado con los siguientes proyectos de investigación que se desarrollan dentro
del ámbito del Laboratorio de Investigación y
Desarrollo en Inteligencia Artificial (LIDIA):
“Sistemas De Apoyo a la Decisión Basados en Argumentación: formalización
y aplicaciones”. PIP-CONICET (PIP112-200801-02798). Director: Carlos Iván
Chesñevar. Período 01/2009 - 12/2011.
CONICET.
“Formalismos Argumentativos aplicados a
Sistemas Inteligentes para Toma de Decisiones”. Código: PGI 24/ZN18. Director:
A. J.García. Co-director: M.A. Falappa.
Acreditado con evaluación externa para
el período 01/2009 - 12/2011. Universidad
Nacional del Sur.
“Representación de Conocimiento y Razonamiento Argumentativo: Herramientas
Inteligentes para la Web y las Bases de
Datos Federadas”. 24/N030, 01/01/11 –
31/12/2014..
Introducción
Dentro de las Ciencias de la Computación, el
problema de toma de decisiones ha sido abordado mayormente desde el campo de investigación de la Inteligencia Artificial (IA) estuWICC 2012 108
2012 XIV Workshop de Investigadores en Ciencias de la Computación
diando el problema de razonamiento práctico
que enfrenta un agente inteligente, i.e., decidir qué hacer. Recientemente, Amgoud y Prade
en [2] han distinguido dos tendencias principales que están influenciando actualmente la investigación sobre este tema en Inteligencia Artificial. Estas son los sistemas basados en teoría
de decisión clásica y los enfoques para la toma
de decisiones sobre la base de la arquitectura BDI (Beliefs-Desires-Intentions) que permite diseñar e implementar un esquema de razonamiento práctico.
Figura 1: Esquema de la Arquitectura BDI
básica
El modelo de arquitectura BDI [8, 7, 9]
es uno de los más utilizados como base para el desarrollo de agentes inteligentes, convirtiéndose en uno de
los modelos más difundido y estudiado de la literatura. En la actualidad,
el uso de sistemas informáticos basados en
conocimiento para ayudar a sus usuarios
(agentes humanos o agentes de software)
a resolver sobre qué hacer está creciendo
rápidamente. Este crecimiento es alentado
por desarrollos teórico-prácticos en los sistemas multi-agente y por la conectividad
que brinda la capacidad de acceso a grandes
repositorios de conocimiento, la creciente
capacidad de procesamiento para aprovechar
esos repositorios, y la portabilidad del equipo
computacional que los hace ubicuos, i.e., su
disponibilidad en todo lugar. Estos sistemas
son conocidos como sistemas de apoyo a la
decisión. Al enfrentar decisiones complejas
acerca de qué hacer, la perfomance de un
agente responsable de actuar puede ser mejorada utilizando un sistema de soporte que
aconseje sobre las mejores opciones posibles.
Usualmente este apoyo resulta más confiable
y útil cuando es brindado por un agente que
posee conocimiento especializado del problema
en cuestión. Por otra parte, dado que el
contexto de la decisión es usualmente único y
particular al agente, el apoyo ofrecido debería
satisfacer las siguientes características:
Claridad: la recomendación debe ser presentada en forma inteligible para el agente,
de manera que este pueda comprenderla
en su totalidad,
Fundamentación: debe brindarse la información básica para la recomendación y la
forma como a partir de ella se llega a obtener la recomendación, e
Interactividad: bajo demanda del agente,
debe ser posible realizar consultas sobre
los detalles referidos tanto a la recomendación como al proceso de elaboración de
dicha recomendación.
Se opta como hipótesis que los Sistemas
Argumentativos por sus características únicas
pueden aportar de manera significativa al avance en la solución para este problema. La ventaja estratégica de los formalismos argumentativos es que por su propia definición y construcción satisfacen en gran medida las tres características recomendables señaladas con anterioridad: Claridad, Fundamentación e Interactividad. Un argumento aceptado representa
una explicación clara de porqué la conclusión
WICC 2012 109
2012 XIV Workshop de Investigadores en Ciencias de la Computación
que soporta es propuesta, y el proceso por el
cual el argumento es aceptado, brinda los componentes necesarios para que el agente que recibe la recomendación comprenda las razones
que avalan la recomendación. En ese mismo
proceso se introduce también la posibilidad de
análisis interactivo en el estudio de los argumentos y contra-argumentos tenidos en cuenta.
Por otro lado, dentro de esta investigación se
incorporo dos grandes variaciones: 1) el efecto
del tiempo en el momento del estudio de los argumentos, i.e., el modelado de la variación de
la disponibilidad de argumentos en el tiempo y
2) el efecto de fuerzas que gobiernan el mundo
real, e.g. el grado de confiabilidad de los argumentos que conforman un determinado razonamientos. Estos dos aspectos aumentan de
una forma considerable la capacidad de representación del mundo real a la hora de modelar
los estados del mismo.
Líneas de Investigación y
Desarrollo
La presente línea de investigación estudiará en el contexto de un sistema multi-agente
(MAS), la problemática asociada con la especificación e implementación de un agente inteligente deliberativo con la capacidad de brindar
apoyo a la toma de decisiones. En particular
se diseñará e implementará una arquitectura
para un agente autónomo con la capacidad de
contribuir a la toma de decisiones en un entorno MAS colaborativo. El componente cognitivo del agente, compuesto de un razonador
epistémico (para establecer lo que el agente conoce) y de un razonador práctico (para decidir
lo que el agente debe hacer), estará basado en
formalismos argumentativos apropiados.
Arquitectura BDI
Un agente con arquitectura BDI (Figura 1)
posee un conjunto B de creencias acerca de su
entorno, un conjunto D de deseos y un conjunto I de intenciones. La arquitectura BDI tiene
sus raíces en el estudio del denominado Razonamiento Práctico.
Dado un entorno particular que el agente tiene la capacidad de percibir (flecha superior izquierda en la Figura 1), este tipo de razonamiento puede describirse como el proceso de
decidir qué acción realizar para alcanzar las
metas (flecha inferior izquierda en la Figura
1). Involucra dos importantes procesos:
Deliberación, i.e., decidir qué metas se
quieren alcanzar, y
Razonamiento de medios-fines (meansends), i.e, decidir cómo se alcanzarán las
metas. La primera parte involucra el razonamiento epistémico.
Las intenciones de un agente son un subconjunto de las alternativas que éste posee para
alcanzar sus metas. Una de las características más importantes de las intenciones es su
rol motivador, i.e., provocan acciones. Una vez
adoptada una intención, ésta afectará el razonamiento práctico que considere el futuro. Las
intenciones tienen la propiedad de persistencia. Esto es, para que resulten útiles el agente
no deberá abandonar una intención, sino que
la mantendrá hasta que la cumpla, o bien sea
evidente que no podrá hacerlo, o bien las razones que tuvo para adoptarla dejaron de ser
válidas. Sus intenciones están relacionadas con
sus creencias acerca del futuro.
Sistemas Argumentativos
En argumentación es una proposición es
aceptada o no de acuerdo a un análisis de las
razones de las que se dispone para creer o no en
WICC 2012 110
2012 XIV Workshop de Investigadores en Ciencias de la Computación
la misma, donde estas razones o justificaciones
toman la forma de argumentos [3]. Además, la
manera en que estos argumentos son considerados permite la automatización de este tipo de
razonamiento. En los sistemas argumentativos
basados en reglas (SABR), existe un conjunto
de reglas de inferencia con las cuales, a partir de cierta información (antecedente o conjunto de premisas) se puede inferir de manera tentativa nueva información (consecuente).
En este tipo de sistemas, las reglas son almacenadas en una base de conocimiento, junto a
otra información en forma de hechos o presuposiciones, que representan la evidencia que el
agente obtiene desu entorno. A partir de esta
evidencia, el agente puede usar las reglas de
inferencia para construir argumentos a favor o
en contra de una afirmación. Una vez hecho
esto se evalúan todos los argumentos construidos, y se determina cuáles de ellos son aceptados, buscando concluir si, a partir de la base de
conocimiento del agente, está afirmación puede aceptarse o no. Estos formalismos son nomonótonos dado que la introducción de nueva información al sistema puede generar nuevos argumentos que resultan contradictorios
con algunos de los ya existentes. Como resultados de esta investigación se incorporo a los
SABR el tratamiento de reglas que están activas en determinados intervalos de tiempo que
brinda la posibilidad de modelar conocimientos que esta disponible solo en determinado
intervalos de tiempo aumentando así la capacidad de representación del mundo real y modelos mas simples de analizar. En general, en
la mayoría de estos formalismos, argumentos y
contra-argumentos son comparados utilizando
un criterio de preferencia pre-determinado permitiendo decidir si un ataque tiene éxito. En el
últimos años, el campo de aplicación de la argumentación se ha expandido velozmente, en
gran parte debido a los avances teóricos, pero
también gracias a la demostración exitosa de
su uso práctico en un gran número de dominios de aplicación, tales como el razonamiento
legal [5], los sistemas multi-agentes [10],entre
muchos otros.
Agentes y Argumentación
La argumentación constituye un área de estudio de especial interés en el ámbito de la Inteligencia Artificial (ver por ejemplo [6]), principalmente, porque permite razonar en entornos sobre los que un agente puede solo acceder a la información de manera parcial o cuando su capacidad de adquirirla es imprecisa.
Estas características, junto con la capacidad
de tolerar la existencia de información contradictoria en la base de conocimiento disponible para el agente, los hacen particularmente apropiados para su utilización en la implementación del componente cognitivo superior
de un agente autónomo [1]. Este tipo de razonamiento resulta así particularmente atractivo para ser utilizado en la toma de decisiones, además como resultados de la línea de
investigación es posible realizar modelos en
los cuales la fuerza de un determinado razonamiento puede variar con el tiempo, e.g. la
confiabilidad de un determinado razonamiento asociado a la confiabilidad de las fuentes de
conocimiento que contiene el mismo.
Objetivos y Resultados
Esperados
En el LIDIA a través de los años se han llevado a cabo diferentes proyectos sobre Sistemas
de Argumentación, en particular investigaciones dedicadas a desarrollar sistemas de argumentación masiva. Varias publicaciones proponiendo la creación de mecanismos que pudieran mejorar la complejidad computacional de
los sistemas de argumentación basados en Defeasible Logic Programing (DeLP) [4] fueron
WICC 2012 111
2012 XIV Workshop de Investigadores en Ciencias de la Computación
propuestas y publicadas en conferencias y revistas internacionales. El objetivo de esta línea
de investigación consiste en el diseño y la realización computacional de una arquitectura para
un agente autónomo con la capacidad de contribuir a la toma de decisiones en un entorno
colaborativo y dinámico. El componente cognitivo de razonamiento epistémico y el componente de razonamiento práctico del agente
estarán basados en un formalismo argumentativo. Finalmente, utilizando la arquitectura
básica BDI en el desarrollo de los sistemas de
apoyo a la decisión, se puede concebir una arquitectura para un agente autónomo que satisfaga estas premisas. De este modo, es posible
que los diferentes componentes que integran la
arquitectura del agente utilicen razonamiento
basado en formalismos argumentativos.
Formación de Recursos
Humanos
Actualmente el equipo de trabajo de esta
línea de investigación se encuentra compuesto por un becario de posgrado que accedió a
una beca interna del CONICET y su director.
Por otra parte se vincula con un grupo de trabajo sobre argumentación y agentes inteligentes compuesto por doctorandos e investigadores formados.
