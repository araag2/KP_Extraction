VIGITAN Modelo de un sistema de vigilancia y monitoreo utilizando una interfaz tangible
﻿
 
Existe una gran variedad de sistemas de vigilancia en el mercado, tanto hogareños como industriales. Todos emplean 
algún tipo de videocámara, mostrando las imágenes capturadas sobre una o más pantallas. En el caso de disponer de 
varias cámaras, el control de las imágenes mostradas se realiza por selección del usuario.  Este tipo de selección se 
puede llevar a cabo con distinto grado de automatización y siempre manipulado algún tipo de control. 
En este trabajo se presenta un modelo de un sistema de vigilancia moderno, basado en una interfaz tangible, que permite 
seleccionar y manipular las cámaras directamente sobre un plano de la locación en la que se encuentran. Estas 
características impactan positivamente en la usabilidad de este tipo de sistemas, fundamentalmente en lo que hace a la 
sobrecarga visual, mostrando sólo la información necesaria, y en el lugar que corresponde. 
 
Palabras clave: Sistemas de Vigilancia, Interacción Humano-Computadora, Interfaces Tangibles. 
 
CONTEXTO 
 
Este trabajo se lleva a cabo en el Laboratorio de Investigación y Desarrollo en Visualización y Computación Gráfica 
(VyGLab) del Departamento de Ciencias e Ingeniería de la Computación de la Universidad Nacional del Sur.  
El trabajo de Investigación presentado está inserto en el proyecto “Interfaces No Convencionales. Su Impacto En Las 
Interacciones” (24/Zn19), dirigido por el Lic. Sergio Martig; financiado por la Secretaría General de Ciencia y 
Tecnología de la Universidad Nacional del Sur; y acreditado por la Universidad Nacional del Sur, Bahía Blanca. 
 
 
1. INTRODUCCION 
 
Existe una gran variedad de sistemas de 
vigilancia en el mercado, tanto hogareños 
como industriales. Todos estos emplean algún 
tipo de videocámara, mostrando las imágenes 
capturadas sobre una o más pantallas. En el 
caso de disponer de varias cámaras, la manera 
de controlar la agrupación de imágenes 
mostradas se realiza por una selección del 
usuario. La misma puede efectuarse mediante 
una secuencia automática o manualmente, 
accionando algún tipo de botón de selección. 
En la actualidad se está investigando una 
nueva clase de interfaces, principalmente 
impulsada por el MIT Media Laboratory de la 
mano de Hiroshi Ishii, llamadas interfaces 
tangibles. Este tipo de interfaces permite que 
una persona interactúe con la información 
digital de un sistema a través de la 
manipulación de objetos físicos (phicons). 
En este trabajo se presentará una alternativa a 
los sistemas de vigilancia convencionales, 
aprovechando las bondades de una interfaz 
tangible para controlar las operaciones 
sobre las cámaras de seguridad.  
Además se expondrán una serie de mejoras, 
que algunos de los sistemas existentes 
incluyen, las cuales aportan información 
adicional al usuario, como por ejemplo 
alarmas visuales. 
 
2. TRABAJO PREVIO 
 
2.1. Sistemas de vigilancia 
 
Actualmente, se puede encontrar una gran 
variedad de sistemas de vigilancia hogareños, 
básicamente montados sobre una PC con un 
conjunto de cámaras a monitorear.  
Las cámaras pueden estar asociadas a la 
computadora mediante conexiones wireless o 
cableadas. En este tipo de sistemas, la 
selección de cámaras la realiza el usuario 
                      321WICC 2010 - XII Workshop de Investigadores en Ciencias de la Computación
sobre la PC, accionando algún control sobre 
la interfaz gráfica del software asociado. Por 
ejemplo: Los kits de cámaras CCTV basados 
en la placa Pico 2000 permiten conectar hasta 
cuatro cámaras por placa. Dicho kit viene 
equipado con un software servidor y de 
monitoreo, que permite seleccionar y 
visualizar las cámaras a mostrar, acción que 
queda a cargo del usuario. 
Además, existe otro tipo de sistemas de 
vigilancia, que utilizan hardware dedicado, en 
lugar de una PC. Los mismos pueden ser 
utilizados tanto para vigilancia hogareña o de 
pequeños comercios como para grandes 
empresas, ya que pueden manejar una mayor 
cantidad de cámaras. 
En estos sistemas, la selección de cámaras se 
realiza pulsando algún tipo de botón, ya sea 
físico o también como componente de alguna 
interfaz gráfica de usuario. Este tipo de 
interacción podría no asociar la disposición de 
estos controles con la ubicación física de las 
cámaras. Generalmente esto se resuelve 
visualizando todas las cámaras al mismo 
tiempo o mostrando secuencias predefinidas 
en un orden establecido por el usuario. 
Además se necesita visualizar en pantalla 
información que identifique el origen de las 
imágenes. En el caso de disponer de 
información adicional asociada a la imagen 
mostrada, deberá presentarse también en 
pantalla. Todo esto lleva a una sobrecarga 
visual que puede provocar que el usuario 
pierda de vista algún evento importante, 
además del estrés introducido por la cantidad 
de información visualizada. 
 
2.2. Interfaces tangibles 
 
Tangible Bits de Hiroshi Ishii es una de las 
publicaciones más relevantes en el área de 
interfaces tangibles, donde se define una 
particular visión de la forma con la que se 
manipulan objetos físicos para interactuar con 
un sistema digital. En dicho trabajo, se 
presentan tres prototipos de interfaces 
tangibles. El más interesante, denominado 
metaDESK, consiste en una superficie 
horizontal interactiva, donde se proyectan 
gráficos, y diferentes elementos físicos para 
interactuar con la misma. TransBOARD y 
ambientROOM son los otros prototipos 
presentados en esta publicación. 
Un ejemplo de la utilización de metaDESK es 
Tangible Geospace, construido también en el 
MIT. Esta aplicación proyecta un mapa 2D 
del campus del MIT. Al ubicar un phicon que 
representa el edificio central, permite rotar o 
desplazar el mapa. A su vez, al colocar otro 
phicon sobre la superficie, asociado a otro 
edificio del campus, se puede ampliar o 
reducir la visualización del mapa, 
acercándolos o alejándolos entre sí. 
Numerosos proyectos modernos utilizan 
algún tipo de interfaz  tangible. Por ejemplo, 
Reactable, de construcción similar al 
prototipo metaDESK, es un sistema que le 
permite a un músico experimentar con el 
sonido, modificando sus parámetros mediante 
una interfaz tangible. En este sistema, cada 
objeto físico representa un sintetizador o sus 
parámetros. Cuando los phicons son apoyados 
sobre la superficie, éstos comienzan a 
interactuar con el sistema, pudiendo 
combinarse con otros phicons para modificar 
los parámetros del sonido, como por ejemplo 
frecuencia y resonancia. 
 
2.3. Software de seguimiento de objetos 
 
Las interfaces tangibles requieren del uso de 
algún tipo de componente que permita 
obtener la posición y orientación de los 
phicons. Una solución comúnmente usada 
consiste en cámaras que constantemente 
capturan imágenes de la superficie interactiva. 
Un software procesa dichas imágenes y 
provee la información de ubicación de los 
phicons necesaria.  
Existen varios frameworks que se encargan de 
esta tarea, de los cuales se pueden destacar 
Trackmate y reacTIVision. Ambos paquetes 
de software están disponibles bajo la licencia 
de código abierto GPLv2. La funcionalidad 
de los mismos consiste en el reconocimiento 
de fiduciales o tags sobre las caras de los 
phicons. A partir de estas marcas, el software 
informa la cantidad y ubicación de los 
phicons en la zona monitoreada. Esta 
información es propagada, mediante algún 
protocolo, hacia un software cliente. Tal 
cliente formará parte de la aplicación que 
                      322WICC 2010 - XII Workshop de Investigadores en Ciencias de la Computación
utiliza la interfaz tangible. Tanto Trackmate 
como reacTIVision implementan su propio 
protocolo, llamados LusidOSC y TUIO 
respectivamente, ambos basados en OSC 
(Open Sound Control). OSC es un protocolo 
de código abierto basado en mensajes 
desarrollado para la comunicación entre 
computadoras, sintetizadores de sonido, y 
otros dispositivos multimedia. 
 
3. NUESTRA PROPUESTA 
 
Se presenta un modelo de un sistema de 
vigilancia moderno, cuya solución estará 
apoyada sobre los resultados anteriormente 
mencionados. Se utilizará una interfaz 
tangible que permitirá seleccionar y 
manipular las cámaras directamente sobre un 
plano de la locación en la que se encuentran. 
Esto minimizará el problema de la sobrecarga 
visual, mostrando sólo la información 
necesaria, y en el lugar que corresponde. 
El modelo propuesto consta principalmente de 
una superficie interactiva y un conjunto de 
phicons que conforman la interfaz tangible. 
Además, una pantalla LCD permitirá 
visualizar el video tomado por las cámaras y 
otro tipo de información adicional.  
Sobre la superficie interactiva se proyectará 
un plano de la locación en alto contraste, 
indicando la posición de las cámaras 
disponibles en la zona. 
El plano estará dividido internamente en 
sectores, uno por cada sala existente. Además 
sobre el plano se visualizarán las alertas de 
distintos tipos de eventos, por ejemplo: un 
sensor que detecte movimiento en un área de 
acceso restringido. Para interactuar con la 
superficie tangible se utilizarán un conjunto 
de phicons, los cuales pueden clasificarse en 
dos grupos: 
• Phicons de cámara 
• Phicons de control de sector 
 
Los phicons de cámara se dividen en:  
• Phicon de cámara activa 
• Phicon de zoom 
• Phicon de ajuste de imagen (brillo, 
contraste, definición) 
• Phicon de visión nocturna 
 
Los phicons de cámara activa permiten 
seleccionar las cámaras que se visualizarán en 
la pantalla. Para ello, el usuario deberá apoyar 
el phicon sobre la superficie interactiva dentro 
del sector, en una zona cercana a la cámara a 
activar. Las cámaras que estén disponibles se 
identificarán visualmente sobre el plano con 
un pequeño triangulo. La dirección a la que 
apunta la cámara se indicará mediante la base 
del triángulo. Se podrá ajustar el ángulo de la 
cámara rotando el phicon de cámara 
correspondiente. Podrán visualizarse varias 
cámaras al mismo tiempo, utilizando un 
conjunto de phicons de cámara 
simultáneamente. En este caso, la pantalla se 
dividirá en tantas partes como cámaras haya 
para mostrar. Existe otro tipo de phicons que 
permiten ajustar el zoom de una determinada 
cámara. El usuario deberá posar el phicon 
sobre la superficie interactiva, cerca del 
phicon de cámara asociado. El sistema 
mostrará visualmente dicha asociación 
utilizando una línea punteada que une ambos 
phicons. Rotando el phicon de zoom hacia la 
derecha o izquierda se podrá aumentar o 
disminuir el zoom de la cámara asociada 
respectivamente. De manera similar, el 
usuario puede trabajar con los phicons de 
ajuste de imagen como el phicon de brillo, el 
de contraste, etc.  
Otro phicon que opera por proximidad a la 
cámara activa es el de visión nocturna, cuya 
funcionalidad es la de activar este modo de 
visión sobre la cámara activa más próxima. 
 
 
Fig. 1: Vista de la superficie interactiva 
 
Los phicons de control de sector permiten 
encender o apagar luces, ventilación, alarmas 
(de presencia, incendio, etc.). Todos estos 
funcionan como llave selectora. Es decir, 
apoyándolos una vez sobre la zona 
involucrada, se activa el control. Al apoyarlo 
                      323WICC 2010 - XII Workshop de Investigadores en Ciencias de la Computación
nuevamente se desactiva. El estado de los 
controles se visualizará sobre el plano. 
Dependiendo del tipo de control, si el mismo 
está asociado a un sistema que proporciona 
información de importancia para la tarea de 
vigilancia, la misma se mostrará en la 
pantalla. La ubicación de esta información 
estará enmarcada sobre la visualización del 
grupo de cámaras asociado a la locación del 
control. Por ejemplo, en un data center, donde 
se desea mantener la temperatura en los 22°C, 
podría haber un sistema de control de 
temperatura. Este sistema proporcionaría la 
temperatura actual y dispondría de una alarma 
que se dispararía en el caso de detectar una 
temperatura fuera del rango aceptable. En este 
caso, la temperatura se mostrará en la 
pantalla, sobre la visualización de las cámaras 
activas del datacenter. La notificación de 
alarma de advertencia se mostrará sobre el 
plano, iluminando de forma intermitente el 
datacenter. Para el caso de alarmas críticas, 
podría agregarse una notificación sonora.  
 
Módulos que componen el sistema. 
 
El sistema consta principalmente de cuatro 
módulos: 
 
• Módulo de superficie interactiva 
• Módulo de control 
• Módulo de pantalla 
• Módulo de comunicación 
 
El módulo de superficie interactiva es la 
unidad de interfaz tangible. Dentro del mismo 
se encuentra el software de seguimiento de 
objetos y los componentes de hardware que 
conforman la superficie interactiva. Sobre 
esta superficie se generarán acciones que 
serán interpretadas por el módulo y enviadas 
hacia otros módulos. Además se encarga de 
recibir el estado general de los sectores y 
mostrarlos sobre el plano. El módulo de 
control está asociado al manejo de cámaras 
de video y sensores y actuadores del 
ambiente. Los comandos, que son recibidos 
desde otros módulos, son procesados y 
ejecutados. Las señales de video provenientes 
de las cámaras activas son enviadas hacia 
otros módulos, al igual que la información 
asociada al estado de los sectores. El módulo 
de pantalla es el encargado de mostrar el 
video de las cámaras activas, recibiendo como 
entrada el estado general de los sectores y el 
video de las cámaras asociadas a dicho sector. 
El módulo de comunicación comunica los 
módulos entre sí, de manera de ordenar la 
comunicación entre los mismos. Además 
valida los datos que ingresan al módulo para 
la reducción de errores. 
 
4. ANALISIS DEL MODELO 
 
El sistema propuesto utiliza la metáfora 
global de una mesa, donde se pueden 
manipular objetos sobre ella, en este caso 
representando cámaras y controles de una 
sala. La idea de emplear una mesa no debería 
traer problemas de asimilación para la 
mayoría de los usuarios, ya que es un 
elemento de uso cotidiano. A diferencia de 
otras metáforas existentes, el mapeo de 
acciones es casi directo. Esto favorece al 
affordance, como en cualquier aplicación 
basada en este tipo de interfaces tangibles. 
Con respecto a las metáforas locales, se 
pueden observar tres tipos. La primera se 
aprecia sobre el phicon de cámara activa, que 
consiste en activar una visualización de 
cámara en pantalla, cuya imagen proviene de 
la cámara más cercana en el plano dentro de 
su sector. Similarmente, los demás phicons 
que modifican valores de las cámaras se 
relacionan por proximidad. La segunda se 
puede observar sobre los phicons de cámara y 
de control de imagen y zoom, que al girarlos 
modifican un valor, tal y como se haría al 
girar una perilla. Por último, los phicons de 
control de sector utilizan la metáfora de botón 
conmutador. Se activa apoyando el phicon en 
el sector y se desactiva de la misma manera.  
Los estilos de interacción utilizados son 
“manipulación directa” y “point and click”. 
Estos estilos se caracterizan por una sintaxis 
sencilla, que reduce la ocurrencia de errores y 
permite un aprendizaje ágil por parte del 
usuario. A modo de ejemplo se presentan 
algunas de las interacciones  soportadas en el 
modelo de interacción como activación de 
una cámara y ajuste del ángulo, ajuste de 
brillo, apagado de luces y cambio de cámara 
activa. 
 
                      324WICC 2010 - XII Workshop de Investigadores en Ciencias de la Computación
Activación de una cámara y ajuste del 
ángulo 
El usuario toma un phicon de cámara y lo 
apoya sobre la superficie interactiva, en el 
sector donde se encuentra la cámara a 
observar. Su activación se indicará sobre la 
superficie mediante una línea que une el 
phicon con la cámara. Al mismo tiempo se 
visualizará en la pantalla LCD las imágenes 
capturadas por la cámara. A continuación el 
usuario rota el phicon para ajustar el ángulo 
de la cámara. Dicho ajuste se puede visualizar 
instantáneamente sobre la mesa interactiva al 
verse el cambio de dirección del triangulo que 
representa la cámara. Al mismo tiempo se 
actualizará la vista sobre la pantalla LCD. 
 
Variación del brillo de una cámara 
El usuario toma un phicon de brillo y lo 
coloca próximo a la cámara a la cual desea 
realizar el ajuste. Se visualizará la asociación 
con la cámara mediante una línea de puntos y 
el valor de brillo actual alrededor del phicon. 
Para ajustar el brillo se rota el phicon 
mientras se observan los cambios sobre la 
indicación del valor y sobre la imagen final en 
la pantalla LCD. 
 
Apagado de luces de un conjunto de 
sectores 
El usuario toma un phicon de control de luz y 
lo posa sobre el sector donde quiere apagar la 
luz. Inmediatamente se podrá visualizar el 
cambio en la indicación de estado del sector. 
El mismo procedimiento se puede reproducir 
para apagar las luces de los sectores 
involucrados. 
 
Cambio de cámara activa en el mismo 
sector 
El usuario elige uno de los phicons de cámara 
actualmente activo. Luego lo desplaza hacia 
otra cámara disponible. Cuando la distancia 
entre el phicon y la cámara destino es menor 
que la distancia hacia la cámara activa, 
automáticamente se realizará el cambio de 
cámara. La nueva asociación se visualizará 
sobre la mesa y al mismo tiempo se verán las 
nuevas imágenes en la pantalla LCD. 
 
5. RESULTADOS OBTENIDOS / 
ESPERADOS 
 
En este trabajo, se ha presentado un modelo 
para un sistema de vigilancia que se basa en 
una interfaz tangible. Este tipo de interfaz nos 
permitió diseñar un conjunto de interacciones 
efectivas que resultan naturales para el 
usuario, logrando mejorar la usabilidad de los 
sistemas de vigilancia y monitoreo 
tradicionales. Se presentó brevemente el 
modelo explicando sus componentes 
principales y se describieron ciertas tareas 
típicas que un usuario podría realizar con el 
mismo. Los próximos pasos a dar son la 
concreción de un prototipo operativo, 
enfatizando los aspectos que hacen a la 
interacción con el usuario, por un lado, y la 
realización de test de usuarios tendientes a 
validar las interacciones propuestas por otro. 
En este último sentido ya se han realizado test 
preliminares sobre un prototipo de baja 
fidelidad que arrojaron resultados positivos lo 
que constituyó un incentivo para continuar 
con la propuesta.  
 
6.  FORMACION DE RECURSOS 
HUMANOS 
 
Este trabajo está encuadrado en un Proyecto 
de Investigación, que se está desarrollando en 
el VyGLab, y surge inicialmente como trabajo 
final de un curso de pregrado dictado por 
integrantes del grupo de trabajo. Dadas las 
características del mismo y los resultados 
preliminares obtenidos, se evaluó la 
posibilidad de profundizar en la investigación 
de los tópicos involucrados, constituyéndose 
en un proyecto de trabajo final de carrera. 
 
